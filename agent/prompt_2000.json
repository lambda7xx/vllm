["You are now an imaginary expert business investigator. Tell the story of this batch of data in the form of a narrative story about the companies in the \"Entity Name\" column: \n\nBatch of data #1: Entity Name Purpose / Source\n101 PC HOLDINGS LLC Holding company for Penthouse C at the Setai Miami Beach (folio: 02-3234-153-1160)\n11 STAR ISLAND LLC Holding company for 10 STAR ISLAND DR, MIAMI BEACH, FL 33139 (folio: 02-4204-001-0100, 02-4204-001-0110) (lots 10, 11 and 12 of Star Island)\n117 EAST PARK AVENUE, LLC Holding company for 117 E. PARK AVE, LIBERTYVILLE, IL (PIN: 11-21-212-046-0000); subsequently sold.\n1201 BRICKELL BAY, LLC Holding company for 1201 BRICKELL BAY DR, MIAMI, FL (folio no: 141390710010)\n1221 BRICKELL, LLC Holding company for 1221 BRICKELL AVE, 155 SE 13 ST, 165 SE 13 ST, 175 SE 13 ST, and 185 SE 13 ST, MIAMI, FL (folio: 01-4139-035-0010)\n1221 BRICKELL HOLDINGS LLC Holding company for 1221 BRICKELL, LLC\n1229 PARK WEST AVENUE, LLC Holding company for 1229 W. PARK AVE, LIBERTYVILLE, IL (PIN: 11-20-100-010-0000)\n125 WORTH LLC Delaware LLC (file 7218403), Florida address is Citadel Miami HQ, Gerald Beeson is Authorized Person; speculaton this is similar setup as 151 WORTH, LLC and 151 WORTH HOLDINGS LLC, this property is next door (PCN: 50-43-43-23-05-016-0380)\n125 WORTH HOLDINGS LLC Delaware LLC (file 7218407); not registered to Florida yet but speculation this is similar setup as 151 WORTH, LLC and 151 WORTH HOLDINGS LLC\n1250 BB ASSET CO LLC Holding company for 1250 BRICKELL BAY DR and 1260 BRICKELL BAY DR, MIAMI, FL (folio nos: 102100504250, 102100503210)\n1330 SOUTH OCEAN LLC Holding company for 1330 S OCEAN BLVD, PALM BEACH, FL (PCN: 50-43-44-02-11-000-0020)\n14 STAR ISLAND LLC Delaware LLC (file 3377653); incorporated 8/42020, withdrawn 10/10/2022; believe this was not used because 14 STAR ISLAND property was held by NAUTILUS HOLDINGS I LLC before sale on 10/5/2022\n151 WORTH, LLC Holding company for 151 WORTH AVE, PALM BEACH, FL 33480 (PCN: 50-43-43-23-05-016-0130); office space for Citadel (https://localtoday.news/fl/citadel-moves-into-palm-beachs-former-neiman-marcus-building-4821.html); sole member is 151 WORTH HOLDINGS LLC\n151 WORTH HOLDINGS LLC Holding company for 151 WORTH, LLC\n16 WILLOW HOLDINGS LLC f/k/a PVNAH LLC Holding company for S WILLOW COURT, ASPEN, CO (Parcel: 273511309030); see Pitkin Co. reception # 623002, Delaware certificate showing name change 9/1/2015\n190 PFISTER HOLDINGS LLC f/k/a AH2013 HOLDINGS LLC Holding company for 190 PFISTER DR, ASPEN, CO (parcel: 273511309029); see Pitkin Co.reception # 623000, Delaware certificate showing name change 9/1/2015\n196 PFISTER HOLDINGS LLC Holding company for 196 PFISTER DR, ASPEN, CO (parcel: 273511309028); see Pitkin Co. reception # 623501, statement of authority show KP HOLDINGS LLC as sole membe\n1ALPH LLC See ALPH LLC\n1BUSINESS GROUP LLC See BUSINESS GROUP LLC\n1GFS DESIGN LLC See GFS DESIGN LLC\n1GFS LLC See GFS LLC\n1MEDIA HOLDINGS LLC See MEDIA HOLDINGS LLC\n23174 NE 41ST PATH LLC Holding company for 23174 NE 41ST PATH #12, OKEECHOBEE, FL 34972 (Parcel: 1-01-35-35-0020-00000-0120); part of Pine Creek Sporting Club (www.pinecreeksportingclub.com) includes horse, shooting sports; sole member is KP HOLDINGS L.L.C.\n3031 BRICKELL LLC Holding company for 3031 BRICKELL AVE, MIAMI FL 33129 (Folio: 01-4139-001-2700); Sole member is KP HOLDINGS L.L.C.\n31 WILLOW HOLDINGS LLC f/k/a AP HOLDINGS I LLC Holding company for 31 NORTH WILLOW COURT, ASPEN, CO (Parcel: 273511309019); sold 7/6/2017; see Pitkin Co. reception # 623001, Delaware certificate showing name change 9/1/2015\n650 CASUARINA LLC Holding company for 650 CASUARINA CONCOURSE CORAL GABLES, FL (folio: 03-4132-019-0060) https://www.bizjournals.com/southflorida/news/2022/05/27/650-casuarina-concourse-coral-gables-sold.html\n650 MEADOW LANE 1 LP Holding company for 650 MEADOW LANE, VILLAGE OF SOUTHAMPTON, NY (Parcel ID 7478) (https://archive.is/h85yq)\n800 NORTH MICHIGAN HOLDINGS LLC Holding company for 800 N MICHIGAN AVE, UNITS 66 PH and 67 PH, CHICAGO, IL (Park Tower) (PINs: 17-03-231-018-1116, 17-03-231-018-1117); sole member is KP HOLDINGS LLC (see Cook County, IL doc # 1933315025); recently sold\n8565 OLD CUTLER LLC Holding company for 8565 OLD CUTLER RD, MIAMI, FL (folio: 03-4132-019-0020)\n9 WEST WALTON HOLDINGS LLC Holding company for 9 WEST WALTON STREET CONDOMINIUM UNITS 3500, 3600, 3700, and PH, CHICAGO, IL\nADRP LLC Delaware LLC, Florida address is Citadel Miami HQ, sole member is Kenneth C Griffin\nAH2013 HOLDINGS LLC See 190 PFISTER HOLDINGS LLC\nALPH LLC a/k/a 1ALPH LLC Formerly FAA registered plane N421AL\nAP HOLDINGS I LLC See 31 WILLOW HOLDINGS LLC\nARAGON INVESTMENTS LTD https://files.brokercheck.finra.org/firm/firm\\_45631.pdf\nASHLER CAPITAL LLC https://adviserinfo.sec.gov/firm/summary/148826\nASHLER CAPITAL MASTER FUND LTD https://www.sec.gov/Archives/edgar/data/1003078/000114420418014250/tv488357\\_sc13g.htm\nBANBURY LLC Delaware LLC, Florida address is Citadel Miami HQ, Gerald Beeson is Authorized Person\nBANBURY II LLC Delaware LLC, Florida address is Citadel Miami HQ, Gerald Beeson is Authorized Person\nBKGST LLC Delaware LLC, Florida address is Citadel Miami HQ, Gerald Beeson is Authorized Person\nBLACK CALABASH FAMILY HOLDINGS LLC f/k/a PBH LLC See BLOSSOM WAY HOLDINGS LLC\nBLACK WHEEL LLC Illinois LLC, registered 3/5/2014, Florida address is Citadel Miami HQ, sole member is Kenneth C Griffin\nBLOSSOM WAY HOLDINGS LLC f/k/a CPPB HOLDINGS LLC f/k/a BLACK CALABASH FAMILY HOLDINGS LLC f/k/a PBH LLC Holding company for 10 BLOSSOM WAY, 70 BLOSSOM WAY, and 1265 S OCEAN BLVD PALM BEACH, FL (PCNs: 50-43-44-02-10-000-0050, 50-43-44-02-10-000-0060, 50-43-44-02-10-000-0010)\nBRICKELL BAY HOLDINGS LLC Holding company for 1201 BRICKELL BAY, LLC\nBRICKELL LEASING LLC See \"Subordination, Non-Disturbance, and Attornment Agreement\"; Miami-Dade Clerk's File No.: 2022 R 938960, Group: 1. Kenneth C Griffin is sole member.\nCAAM MANAGEMENT LLC https://www.sec.gov/Archives/edgar/data/1027745/000114420408050200/v124853\\_sc13g.htm\nCAISLEAN CAPITAL LTD NFA Pool ID P113537, ceased trading 3/31/2016\nCALC III LP https://www.sec.gov/edgar/browse/?CIK=1582652\nCALC IV LP https://www.sec.gov/edgar/browse/?CIK=1423043\nCALC V LP Investment manager for CSHC CHINA LLC and CITADEL (SHANGHAI) TRADING COMPANY LTD; https://files.brokercheck.finra.org/firm/firm\\_131114.pdf", "Rewrite this YAML config to C++ code in an Espressif IDF function that reads registers. \ntext\\_sensor:\n # Range 30000 - 30035\n - name: \"Huawei inverter model\"\n icon: \"mdi:information\"\n platform: modbus\\_controller\n modbus\\_controller\\_id: huawei\\_inverter\n register\\_type: holding\n address: 30000\n register\\_count: 15\n response\\_size: 30\n skip\\_updates: 100\n - name: \"Huawei inverter SN\"\n icon: \"mdi:information\"\n platform: modbus\\_controller\n modbus\\_controller\\_id: huawei\\_inverter\n register\\_type: holding\n address: 30015\n register\\_count: 10\n response\\_size: 20\n skip\\_updates: 100\n - name: \"Huawei inverter PN\"\n icon: \"mdi:information\"\n platform: modbus\\_controller\n modbus\\_controller\\_id: huawei\\_inverter\n register\\_type: holding\n address: 30025\n register\\_count: 10\n response\\_size: 20\n skip\\_updates: 100\n\n # Inverter status string\n - name: \"Huawei inverter status\"\n platform: template\n id: inverter\\_status\\_string\n icon: \"mdi:information\"\nbinary\\_sensor:\n # Range 32000 - 32019 (1/2)\n # Register 32000\n - name: \"Huawei inverter state standby\"\n icon: \"mdi:information\"\n platform: modbus\\_controller\n modbus\\_controller\\_id: huawei\\_inverter\n register\\_type: holding\n address: 32000\n bitmask: 0x001\n - name: \"Huawei inverter state grid-connected\"\n icon: \"mdi:information\"\n platform: modbus\\_controller\n modbus\\_controller\\_id: huawei\\_inverter\n register\\_type: holding\n address: 32000\n bitmask: 0x002\n - name: \"Huawei inverter state grid-connected normally\"\n icon: \"mdi:information\"\n platform: modbus\\_controller\n modbus\\_controller\\_id: huawei\\_inverter\n register\\_type: holding\n address: 32000\n bitmask: 0x004\n - name: \"Huawei inverter state grid connection with derating due to power rationing\"\n icon: \"mdi:information\"\n platform: modbus\\_controller\n modbus\\_controller\\_id: huawei\\_inverter\n register\\_type: holding\n address: 32000\n bitmask: 0x008\n - name: \"Huawei inverter state grid connection with derating due to internal causes of the solar inverter\"\n icon: \"mdi:information\"\n platform: modbus\\_controller\n modbus\\_controller\\_id: huawei\\_inverter\n register\\_type: holding\n address: 32000\n bitmask: 0x010\n - name: \"Huawei inverter state normal stop\"\n icon: \"mdi:information\"\n platform: modbus\\_controller\n modbus\\_controller\\_id: huawei\\_inverter\n register\\_type: holding\n address: 32000\n bitmask: 0x020\n - name: \"Huawei inverter state stop due to faults\"\n icon: \"mdi:information\"\n platform: modbus\\_controller\n modbus\\_controller\\_id: huawei\\_inverter\n register\\_type: holding\n address: 32000\n bitmask: 0x040\n - name: \"Huawei inverter state stop due to power rationing\"\n icon: \"mdi:information\"\n platform: modbus\\_controller\n modbus\\_controller\\_id: huawei\\_inverter\n register\\_type: holding\n address: 32000\n bitmask: 0x080\n - name: \"Huawei inverter state shutdown\"\n icon: \"mdi:information\"\n platform: modbus\\_controller\n modbus\\_controller\\_id: huawei\\_inverter\n register\\_type: holding\n address: 32000\n bitmask: 0x100\n - name: \"Huawei inverter state spot check\"\n icon: \"mdi:information\"\n platform: modbus\\_controller\n modbus\\_controller\\_id: huawei\\_inverter\n register\\_type: holding\n address: 32000\n bitmask: 0x200\n # Register 32002\n - name: \"Huawei inverter state unlocked\"\n icon: \"mdi:information\"\n platform: modbus\\_controller\n modbus\\_controller\\_id: huawei\\_inverter\n register\\_type: holding\n address: 32002\n bitmask: 0x1\n - name: \"Huawei inverter state PV connected\"\n icon: \"mdi:information\"\n platform: modbus\\_controller\n modbus\\_controller\\_id: huawei\\_inverter\n register\\_type: holding\n address: 32002\n bitmask: 0x2\n - name: \"Huawei inverter state DSP data collection\"\n icon: \"mdi:information\"\n platform: modbus\\_controller\n modbus\\_controller\\_id: huawei\\_inverter\n register\\_type: holding\n address: 32002\n bitmask: 0x4\n # Register 32003\n - name: \"Huawei inverter state off-grid\"\n icon: \"mdi:information\"\n platform: modbus\\_controller\n modbus\\_controller\\_id: huawei\\_inverter\n register\\_type: holding\n address: 32003\n bitmask: 0x1\n - name: \"Huawei inverter state off-grid switch enable\"\n icon: \"mdi:information\"\n platform: modbus\\_controller\n modbus\\_controller\\_id: huawei\\_inverter\n register\\_type: holding\n address: 32003\n bitmask: 0x2\n # Register 32008\n - name: \"Huawei inverter alarm High String Input Voltage\"\n icon: \"mdi:information\"\n platform: modbus\\_controller\n modbus\\_controller\\_id: huawei\\_inverter\n register\\_type: holding\n address: 32008\n bitmask: 0x0001\n - name: \"Huawei inverter alarm DC Arc Fault\"\n icon: \"mdi:information\"\n platform: modbus\\_controller\n modbus\\_controller\\_id: huawei\\_inverter\n register\\_type: holding\n address: 32008\n bitmask: 0x0002\n - name: \"Huawei inverter alarm String Reverse Connection\"\n icon: \"mdi:information\"\n platform: modbus\\_controller\n modbus\\_controller\\_id: huawei\\_inverter\n register\\_type: holding\n address: 32008\n bitmask: 0x0004\n - name: \"Huawei inverter alarm String Current Backfeed\"\n icon: \"mdi:information\"\n platform: modbus\\_controller\n modbus\\_controller\\_id: huawei\\_inverter\n register\\_type: holding\n address: 32008\n bitmask: 0x0008\n - name: \"Huawei inverter alarm Abnormal String Power\"\n icon: \"mdi:information\"\n platform: modbus\\_controller\n modbus\\_controller\\_id: huawei\\_inverter\n register\\_type: holding\n address: 32008\n bitmask: 0x0010\n - name: \"Huawei inverter alarm AFCI Self-Check Fail\"\n icon: \"mdi:information\"\n platform: modbus\\_controller\n modbus\\_controller\\_id: huawei\\_inverter\n register\\_type: holding\n address: 32008\n bitmask: 0x0020\n - name: \"Huawei inverter alarm Phase Wire Short-Circuited to PE\"\n icon: \"mdi:information\"\n platform: modbus\\_controller\n modbus\\_controller\\_id: huawei\\_inverter\n register\\_type: holding\n address: 32008\n bitmask: 0x0040\n - name: \"Huawei inverter alarm Grid Loss\"\n icon: \"mdi:information\"\n platform: modbus\\_controller\n modbus\\_controller\\_id: huawei\\_inverter\n register\\_type: holding\n address: 32008\n bitmask: 0x0080\n - name: \"Huawei inverter alarm Grid Undervoltage\"\n icon: \"mdi:information\"\n platform: modbus\\_controller\n modbus\\_controller\\_id: huawei\\_inverter\n register\\_type: holding\n address: 32008\n bitmask: 0x0100\n - name: \"Huawei inverter alarm Grid Overvoltage\"\n icon: \"mdi:information\"\n platform: modbus\\_controller\n modbus\\_controller\\_id: huawei\\_inverter\n register\\_type: holding\n address: 32008\n bitmask: 0x0200\n - name: \"Huawei inverter alarm Grid Volt. Imbalance\"\n icon: \"mdi:information\"\n platform: modbus\\_controller\n modbus\\_controller\\_id: huawei\\_inverter\n register\\_type: holding\n address: 32008\n bitmask: 0x0400\n - name: \"Huawei inverter alarm Grid Overfrequency\"\n icon: \"mdi:information\"\n platform: modbus\\_controller\n modbus\\_controller\\_id: huawei\\_inverter\n register\\_type: holding\n address: 32008\n bitmask: 0x0800\n - name: \"Huawei inverter alarm Grid Underfrequency\"\n icon: \"mdi:information\"\n platform: modbus\\_controller\n modbus\\_controller\\_id: huawei\\_inverter\n register\\_type: holding\n address: 32008\n bitmask: 0x1000\n - name: \"Huawei inverter alarm Unstable Grid Frequency\"\n icon: \"mdi:information\"\n platform: modbus\\_controller\n modbus\\_controller\\_id: huawei\\_inverter\n register\\_type: holding\n address: 32008\n bitmask: 0x2000\n - name: \"Huawei inverter alarm Output Overcurrent\"\n icon: \"mdi:information\"\n platform: modbus\\_controller\n modbus\\_controller\\_id: huawei\\_inverter\n register\\_type: holding\n address: 32008\n bitmask: 0x4000\n - name: \"Huawei inverter alarm Output DC Component Overhigh\"\n icon: \"mdi:information\"\n platform: modbus\\_controller\n modbus\\_controller\\_id: huawei\\_inverter\n register\\_type: holding\n address: 32008\n bitmask: 0x8000", "Please extract keywords from this: Part 1\nIt was morning, and the new sun sparkled gold across the ripples of a gentle sea. \nA mile from shore a fishing boat chummed the water, and the word for Breakfast Flock flashed through the air, till a crowd of a thousand seagulls came to dodge and fight for bits of food. It was another busy day beginning. \n But way off alone, out by himself beyond boat and shore, Jonathan Livingston Seagull was practicing. A hundred feet in the sky he lowered his webbed feet, lifted his beak, and strained to hold a painful hard twisted curve through his wings. The curve meant that he would fly slowly, and now he slowed until the wind was a whisper in his face, until the ocean stood still beneath him. He narrowed his eyes in fierce concentration, held his breath, forced one ... single ... more ... inch ... of ... curve .... Then his feathers ruffled, he stalled and fell. \n Seagulls, as you know, never falter, never stall. To stall in the air is for them disgraced and it is dishonor. \n But Jonathan Livingston Seagull, unashamed, stretching his wings again in that trembling hard curve - slowing, slowing, and stalling once more - was no ordinary bird. \n Most gulls didn't bother to learn more than the simplest facts of flight \u00adhow to get from shore to food and back again. For most gulls, it is not flying that matters, but eating. For this gull, through, it was not eating that mattered, but flight. More than anything else, Jonathan Livingston Seagull loved to fly. \n This kind of thinking, he found, is not the way to make one's self popular with other birds. Even his parents were dismayed as Jonathan spent whole days alone, making hundreds of low-level glides, experimenting. \n He didn't know why, for instance, but when he flew at altitudes less than half his wingspan above the water, he could stay in the air longer, with less effort. His glides ended not with the usual feet-down splash into the sea, but with a long flat wake as he touched the surface with his feet tightly streamlined against his body. When he began sliding in to feet-up landings on the beach, then pacing the length of his slide in the sand, his parents were very much dismayed indeed. \nWhy, Jon, why?\" his mother asked. \"Why is it so hard to be like the rest of the flock, Jon? Why can't you leave low flying to the pelicans, the albatross? \n\"I don't mind being bone and feathers, Mum. I just want to know what I can do in the air and what I can't, that's all. I just want to know.\" \n\"See here, Jonathan,\" said his father, not unkindly. \"Winter isn't far away. Boats will be few, and the surface fish will be swimming deep. If you must study,. then study food, and how to get it. This flying business is all very well, but you can't eat a glide, you know. Don't you forget that the reason you fly is to eat.\"\n Jonathan nodded obediently. For the next few days he tried to be behave like the other gulls; he really tried, screeching and fighting with the flock around the piers and fishing boats, diving on scraps of fish and bread. But he couldn't make it work. \nIt's all so pointless, he thought, deliberately dropping a hard-won anchovy to a hungry old gull chasing him. I could be spending all this time learning to fly. There's so much to learn! \nIt wasn't long before Jonathan Gull was off by himself again, far out at see, hungry, happy, learning. \n The subject was speed, and in a week's practice he learned more about speed than the fastest gull alive. \n From a thousand feet, flapping his wings as hard as he could, he pushed over into a blazing steep dive toward the waves, and learned why seagulls don't make blazing steep power-dives. In just six seconds he was moving seventy miles per hour, the speed at which one's wing goes unstable on the upstroke. \n Time after time it happened. Careful as he was, working at the very peak of his ability, he lost control at high speed. \n Climb to a thousand feet. Full power straight ahead first, then push over, flapping, to a vertical dive. Then, every time, his left wing stalled on an upstroke, he'd roll violently left, stall his right wing recovering, and flick like fire into a wild tumbling spin to the right. \n He couldn't be careful enough on that upstroke. Ten times he tried, but all ten times, as he passed through seventy miles per hour, he burst into a churning mass of feathers, out of control, crashing down into the water. \n They key, he thought as last, dripping wet, must be to hold the wings still \n From two thousand feet he tried again, rolling into his dive, beak straight down, wings full out and stable from the moment he passed fifty miles per hour. It took tremendous strength, but it worked. In ten seconds he has blurred through ninety miles per hour. Jonathan had set a world speed record for seagulls!\n But victory was short-lived. The instant he began his pullout, the instant he changed the angle of his wings, he snapped into that same terrible uncontrolled disaster, and at ninety miles per hour it hit him like dynamite. Jonathan Seagull exploded in midair and smashed down into a brick-hard sea. \n When he came to, it was well after dark, and he floated in moonlight on the surface of the ocean. His wings were ragged bars of lead, but the weight of failure was even heavier on his back. He wished, feebly, that the weight could be just enough to drag him gently down to the bottom, and end it all. \n As he sank low in the water, a strange hollow voice sounded within him. There's no way around it. I am a seagull. I am limited by my nature. If I were meant to learn so much about flying, I'd have a falcon's short wings, and live on mice instead of fish. My father was right. I must forget this foolishness. I must fly home to the Flock and be content as I am, as a poor limited seagull. \n The voice faded, and Jonathan agreed. The place for a seagull at night is on shore, and from this moment forth, he vowed, he would be a normal gull. It would make everyone happier. \n He pushed wearily away from the dark water and flew toward the land, grateful for what he had learned about work-saving low-altitude flying. \n But no, he thought. I am done with the way I was, I am done with everything I learned. I am a seagull like every other seagull, and I will fly like one. So he climbed painfully to a hundred feet and flapped his wings harder, pressing for shore. \n He felt better for his decision to be just another one of the flock. there would be no ties now to the force that had driven him to learn, there would be no more challenge and no more failure. And it was pretty, just to stop thinking, and fly through the dark, toward the lights above the beach. \nDark! The hollow voice cracked in alarm. Seagulls never fly in the dark!\n Jonathan was not alert enough to listen. It's pretty, he thought. The moon and the lights twinkling on the water, throwing out little beacon-trails though the \n Get Down! Seagulls never fly in the dark! If you were meant to fly in the dark, you'd have the eyes f an owl! You'd have charts for brains! You'd have a falcon's short wings!\n There in the night, a hundred feet in the air, Jonathan Livingston Seagull \u00adblinked. His pain, his resolutions, vanished. \n Short Wings. A falcon's short wings!\n That's the answer! What a fool I've been! All I need is a tiny little wing, all I need is to fold most of my wings and fly on just the tips alone! Short wings!\n He climbed two thousand feet above the black sea, and without a moment for thought of failure and death, he brought his forewings tightly in to his body, left only the narrow swept daggers of his wingtips extended into the wind, and fell into a vertical dive. \n The wind was a monster roar at his head. Seventy miles per hour, ninety, a hundred and twenty and faster still. The wing-strain now at a hundred and forty miles per hour wasn't nearly as hard as it had been before at seventy, and with the faintest twist of his wingtips he eased out of the dive and shot above the waves, a grey cannonball under the moon. \n He closed his eyes to slits against the wind and rejoiced. A hundred forty miles per hour! and under control! If I dive from five thousand feet instead of two thousand, I wonder how fast... \n His vows of a moment before were forgotten, swept away in that great swift wind. Yet he felt guiltless, breaking the promises he had made himself. Such promises are only for the gulls that accept the ordinary. One who has touched excellence in his learning has no need of that kind of promise. \n By sunup, Jonathan Gull was practicing again. From five thousand feet the fishing boats were specks in the flat blue water, Breakfast Flock was a faint cloud of dust motes, circling. \n He was alive, trembling ever so slightly with delight, proud that his fear was under control. Then without ceremony he hugged in his forewings, extended his short, angled wingtips, and plunged directly toward the sea. By the time he had passed four thousand feet he had reached terminal velocity, the wind was a solid beating wall of sound against which he could move no faster. He was flying now straight down, at two hundred fourteen miles per hour. He swallowed, knowing that if his wings unfolded at that speed he'd be blown into a million tiny shreds of seagull. But the speed was power, and the", "can you summerize this bill about debt collection in massachussetts \nSection 2. (a) Notwithstanding section 34 of chapter 235, if earnings of a consumer are attached to satisfy a judgment for collection of a consumer debt, that consumer\u2019s earnings for a week that are less than 65 times the greater of the federal minimum hourly wage under 29 U.S.C. section 206(a)(1) or the state minimum hourly wage under section 1 of chapter 151 in effect at the time shall be exempt from the attachment and not subject to garnishment. This exemption shall be adjusted pro rata for a pay period that is more than weekly.\n\n(b) If the consumer\u2019s earnings exceed the amount that is exempt under subsection (a), not more than 10 per cent of the excess earnings shall be subject to garnishment.\n\n(c) Notwithstanding subsection (a), a judgment debtor may seek to exempt additional wages from attachment by making a claim of undue financial hardship by filing a form with the court. Such form shall be prepared by the court to allow a judgment debtor to easily identify the basis for the judgment debtor\u2019s request for an additional exemption. Upon the filing of the financial hardship form, the court shall hold a hearing as soon as practicable to determine the total amount that shall be exempted from the judgment debtors\u2019 wages.\n\n(d) If more than 1 order of attachment for a consumer debt is served on a trustee with respect to the same consumer, the order of attachment served earliest shall take priority. If an order of attachment with greater priority consumes the entirety of the income that is available for garnishment under the preceding subsections, then the consumer\u2019s earnings shall not be garnished pursuant to the order of attachment with lower priority.\n\n(e) The protections for earnings under this section apply to consumers whose physical place of employment is in the commonwealth, notwithstanding that the consumer\u2019s employer may have corporate offices or other places of business located outside the commonwealth.\n\n(f) This section shall not apply in a proceeding to attach earnings or a pension to satisfy a divorce, separate maintenance or child support order of a court of competent jurisdiction and in such a proceeding, including an action for trustee process to enforce a support order under section 36A of chapter 208, federal law limiting the amounts that may be trusteed, assigned or attached in order to satisfy an alimony, maintenance or child support order shall apply.\n\n(g) Except as otherwise permitted by law, an amount held by a trustee for a defendant in a pension, as defined in section 28 of chapter 246 shall be reserved in the hands of the trustee and shall be exempt from attachment to satisfy a judgment for collection of a consumer debt.\n\n(h) An employer shall not take adverse action against an employee or refuse to hire an individual because of one or more garnishments for consumer debts or because of obligations that any garnishments impose against the employer. An employer who violates this section shall be liable in a civil action, action for contempt or other appropriate proceeding to the employee or individual for the wages and employment benefits lost by the employee or individual from the time of the unlawful discipline, suspension, refusal to hire or discharge to the period of reinstatement and an additional penalty of not more than $1,000.\n\n(i) Income from child support payments shall be exempt from collection.\n\nSection 3. (a) Notwithstanding section 2 of chapter 260, an action for the collection of a consumer debt shall be commenced only within four years after the cause of action accrues. This limitations period shall apply to a consumer debt, whether the claim sounds in contract, account stated, open account or other cause, and notwithstanding another applicable statute of limitations of the Commonwealth or other jurisdiction. This time period also applies to a claim for a consumer debt based on a contract or instrument under seal.\n\n(b) Notwithstanding section 14 of chapter 260, a payment on a consumer debt after the limitations period in subsection (a) has run shall not revive or extend the limitations period or bar the consumer from asserting a defense to the collection of a consumer debt.\n\n(c) No creditor, debt buyer, or debt collector shall bring a suit or initiate an arbitration or other legal proceeding to collect a consumer debt if the applicable limitations period on the consumer debt in subsection (a) has expired.\n\n(d) A waiver by a consumer of a protection or right under this section is void and shall not be enforced.\n\n(e) Notwithstanding section 20 of chapter 260 or any other general or special law to the contrary, an action upon a judgment or decree on a consumer debt, including an execution upon or trustee process based on the judgment or decree and other activity to collect on the judgment, shall be commenced within 10 years after the entry of the judgment or decree. If an action on a judgment has commenced within 10 years, it may be renewed once for another 10 years. A judgment whose enforcement has been barred by the running of this limitations period shall not be revived or renewed.\n\nSection 4. (a) For matters arising from a consumer debt, a plaintiff who has obtained a judgment shall provide written notice to a consumer at least 30 days prior to a supplementary proceeding in a civil action for the examination of a consumer pursuant to section 14 of chapter 224 or a payment review hearing in a small claims action pursuant to Uniform Small Claims Rule 7(i). The notice shall inform the consumer of the opportunity to submit a financial affidavit in a form prescribed by the court. If the consumer indicates through the financial affidavit that all income and assets are exempt and files it as directed by the court, the court shall acknowledge receipt and inform both parties that the hearing is canceled. Once a signed financial affidavit form indicating that all income and assets are exempt is on file in that case, no further supplementary proceedings or payment review hearings may be scheduled unless the judgment creditor presents evidence of the judgment debtor\u2019s non-exempt income or assets and the court determines that there is a reasonable basis to believe that there are non-exempt assets or income warranting the scheduling of a new supplementary proceeding or payment review hearing.\n\n(b) Notwithstanding the provisions of sections 18 and 20 of chapter 224 or any other applicable law or court rule, for matters arising from a consumer debt no capias or other warrant to compel the attendance of a consumer shall be issued for failure of the consumer to appear at a supplementary proceeding in a civil action for the examination of a consumer pursuant to section 14 of chapter 224 or a payment review hearing in a small claims action pursuant to Uniform Small Claims Rule 7(i). Instead failure to appear shall trigger the scheduling of a show cause hearing for the court to determine whether a capias or other warrant to compel the attendance of a consumer should issue. No capias or other warrant shall issue to compel the attendance of a consumer without evidence that notice of the show cause hearing was served on the consumer either by signed return receipt or by a sworn return of service.\n\n(c) Notwithstanding the provisions of sections 18 and 20 of chapter 224 or any other applicable law or court rule, a consumer that is compelled to attend pursuant to a capias or other warrant shall be brought before the court the same day. The consumer shall be given the opportunity to complete the financial affidavit described in paragraph (a). The capias or other warrant shall be satisfied by the consumer\u2019s appearance in court or completion of the financial affidavit indicating that all forms of income and assets are exempt.\n\n(d) Notwithstanding the provisions of sections 18 and 20 of chapter 224 or any other applicable law or court rule, no person shall be imprisoned or jailed for failure to pay a consumer debt, nor shall any person be imprisoned or jailed for contempt of or failure to comply with a court order to pay a consumer debt in part or in full.\n\nSection 5. (a) If a plaintiff prevails in an action to collect a consumer debt, interest computed pursuant to section 6C of chapter 231 or section 8 of chapter 235 shall be limited to a fixed rate of interest of 2 percent per annum. A higher rate of interest on the judgment shall not be permitted, including the rate provided for in the contract. Notwithstanding any interest rate specified in a judgment prior to January 1, 2024 the applicable interest rate to be applied by the judgment creditor or its assignee on and after January 1, 2024, shall be 2%. Judgments issued prior to January 1, 2024 with an interest rate other than 2% are not required to be amended or reissued by the courts.\n\n(b) If the plaintiff prevails in an action to collect a consumer debt, the plaintiff shall be entitled to collect attorney\u2019s fees only if the contract or other document evidencing the indebtedness sets forth an obligation of the consumer to pay attorney\u2019s fees, subject to the following provisions: (i) if the contract or other document evidencing indebtedness provides for attorney\u2019s fees in some specific percentage, the provision and obligation shall be valid and enforceable up to but not in excess of 15 per cent of the amount of the debt excluding attorney\u2019s fees and collection costs; (ii) if a contract or other document evidencing indebtedness provides for the payment of reasonable attorney\u2019s fees by the consumer , without specifying a specific percentage, the provision shall be construed to mean the lesser of 15 per cent of the amount of the debt, excluding attorney\u2019s fees and collection costs, or the amount of attorney\u2019s fees calculated by a reasonable rate for such cases multiplied by the amount of time reasonably expended to obtain the judgment; and (iii) the documentation setting forth a party\u2019s obligation to pay attorney\u2019s fees shall be provided to the court before a court may enforce those provisions; provided, however, that the documentation shall not include materials that the plaintiff has already filed together with the complaint in compliance with applicable court rules.\n\n(c) If the consumer is the prevailing party in an action to collect a consumer debt, the consumer shall be entitled to an award of reasonable attorney\u2019s fees, unless the case is voluntarily dismissed with prejudice pursuant to Rule 41(a)(1)(i) of the Massachusetts Rules of Civil Procedure or a stipulation of dismissal explicitly provides otherwise. The amount of the debt that the plaintiff sought shall not be a factor in determining the reasonableness of the award. In the alternative, at the consumer\u2019s election, a prevailing consumer in an action to collect a consumer debt shall be awarded the amount of attorney\u2019s fees that the plaintiff would have been entitled to collect if the plaintiff had been the prevailing party.", "can you summerize this bill about debt collection in massachussetts. make sure to confirm whether I want you to continue after every 200 words\nSection 2. (a) Notwithstanding section 34 of chapter 235, if earnings of a consumer are attached to satisfy a judgment for collection of a consumer debt, that consumer\u2019s earnings for a week that are less than 65 times the greater of the federal minimum hourly wage under 29 U.S.C. section 206(a)(1) or the state minimum hourly wage under section 1 of chapter 151 in effect at the time shall be exempt from the attachment and not subject to garnishment. This exemption shall be adjusted pro rata for a pay period that is more than weekly.\n\n(b) If the consumer\u2019s earnings exceed the amount that is exempt under subsection (a), not more than 10 per cent of the excess earnings shall be subject to garnishment.\n\n(c) Notwithstanding subsection (a), a judgment debtor may seek to exempt additional wages from attachment by making a claim of undue financial hardship by filing a form with the court. Such form shall be prepared by the court to allow a judgment debtor to easily identify the basis for the judgment debtor\u2019s request for an additional exemption. Upon the filing of the financial hardship form, the court shall hold a hearing as soon as practicable to determine the total amount that shall be exempted from the judgment debtors\u2019 wages.\n\n(d) If more than 1 order of attachment for a consumer debt is served on a trustee with respect to the same consumer, the order of attachment served earliest shall take priority. If an order of attachment with greater priority consumes the entirety of the income that is available for garnishment under the preceding subsections, then the consumer\u2019s earnings shall not be garnished pursuant to the order of attachment with lower priority.\n\n(e) The protections for earnings under this section apply to consumers whose physical place of employment is in the commonwealth, notwithstanding that the consumer\u2019s employer may have corporate offices or other places of business located outside the commonwealth.\n\n(f) This section shall not apply in a proceeding to attach earnings or a pension to satisfy a divorce, separate maintenance or child support order of a court of competent jurisdiction and in such a proceeding, including an action for trustee process to enforce a support order under section 36A of chapter 208, federal law limiting the amounts that may be trusteed, assigned or attached in order to satisfy an alimony, maintenance or child support order shall apply.\n\n(g) Except as otherwise permitted by law, an amount held by a trustee for a defendant in a pension, as defined in section 28 of chapter 246 shall be reserved in the hands of the trustee and shall be exempt from attachment to satisfy a judgment for collection of a consumer debt.\n\n(h) An employer shall not take adverse action against an employee or refuse to hire an individual because of one or more garnishments for consumer debts or because of obligations that any garnishments impose against the employer. An employer who violates this section shall be liable in a civil action, action for contempt or other appropriate proceeding to the employee or individual for the wages and employment benefits lost by the employee or individual from the time of the unlawful discipline, suspension, refusal to hire or discharge to the period of reinstatement and an additional penalty of not more than $1,000.\n\n(i) Income from child support payments shall be exempt from collection.\n\nSection 3. (a) Notwithstanding section 2 of chapter 260, an action for the collection of a consumer debt shall be commenced only within four years after the cause of action accrues. This limitations period shall apply to a consumer debt, whether the claim sounds in contract, account stated, open account or other cause, and notwithstanding another applicable statute of limitations of the Commonwealth or other jurisdiction. This time period also applies to a claim for a consumer debt based on a contract or instrument under seal.\n\n(b) Notwithstanding section 14 of chapter 260, a payment on a consumer debt after the limitations period in subsection (a) has run shall not revive or extend the limitations period or bar the consumer from asserting a defense to the collection of a consumer debt.\n\n(c) No creditor, debt buyer, or debt collector shall bring a suit or initiate an arbitration or other legal proceeding to collect a consumer debt if the applicable limitations period on the consumer debt in subsection (a) has expired.\n\n(d) A waiver by a consumer of a protection or right under this section is void and shall not be enforced.\n\n(e) Notwithstanding section 20 of chapter 260 or any other general or special law to the contrary, an action upon a judgment or decree on a consumer debt, including an execution upon or trustee process based on the judgment or decree and other activity to collect on the judgment, shall be commenced within 10 years after the entry of the judgment or decree. If an action on a judgment has commenced within 10 years, it may be renewed once for another 10 years. A judgment whose enforcement has been barred by the running of this limitations period shall not be revived or renewed.\n\nSection 4. (a) For matters arising from a consumer debt, a plaintiff who has obtained a judgment shall provide written notice to a consumer at least 30 days prior to a supplementary proceeding in a civil action for the examination of a consumer pursuant to section 14 of chapter 224 or a payment review hearing in a small claims action pursuant to Uniform Small Claims Rule 7(i). The notice shall inform the consumer of the opportunity to submit a financial affidavit in a form prescribed by the court. If the consumer indicates through the financial affidavit that all income and assets are exempt and files it as directed by the court, the court shall acknowledge receipt and inform both parties that the hearing is canceled. Once a signed financial affidavit form indicating that all income and assets are exempt is on file in that case, no further supplementary proceedings or payment review hearings may be scheduled unless the judgment creditor presents evidence of the judgment debtor\u2019s non-exempt income or assets and the court determines that there is a reasonable basis to believe that there are non-exempt assets or income warranting the scheduling of a new supplementary proceeding or payment review hearing.\n\n(b) Notwithstanding the provisions of sections 18 and 20 of chapter 224 or any other applicable law or court rule, for matters arising from a consumer debt no capias or other warrant to compel the attendance of a consumer shall be issued for failure of the consumer to appear at a supplementary proceeding in a civil action for the examination of a consumer pursuant to section 14 of chapter 224 or a payment review hearing in a small claims action pursuant to Uniform Small Claims Rule 7(i). Instead failure to appear shall trigger the scheduling of a show cause hearing for the court to determine whether a capias or other warrant to compel the attendance of a consumer should issue. No capias or other warrant shall issue to compel the attendance of a consumer without evidence that notice of the show cause hearing was served on the consumer either by signed return receipt or by a sworn return of service.\n\n(c) Notwithstanding the provisions of sections 18 and 20 of chapter 224 or any other applicable law or court rule, a consumer that is compelled to attend pursuant to a capias or other warrant shall be brought before the court the same day. The consumer shall be given the opportunity to complete the financial affidavit described in paragraph (a). The capias or other warrant shall be satisfied by the consumer\u2019s appearance in court or completion of the financial affidavit indicating that all forms of income and assets are exempt.\n\n(d) Notwithstanding the provisions of sections 18 and 20 of chapter 224 or any other applicable law or court rule, no person shall be imprisoned or jailed for failure to pay a consumer debt, nor shall any person be imprisoned or jailed for contempt of or failure to comply with a court order to pay a consumer debt in part or in full.\n\nSection 5. (a) If a plaintiff prevails in an action to collect a consumer debt, interest computed pursuant to section 6C of chapter 231 or section 8 of chapter 235 shall be limited to a fixed rate of interest of 2 percent per annum. A higher rate of interest on the judgment shall not be permitted, including the rate provided for in the contract. Notwithstanding any interest rate specified in a judgment prior to January 1, 2024 the applicable interest rate to be applied by the judgment creditor or its assignee on and after January 1, 2024, shall be 2%. Judgments issued prior to January 1, 2024 with an interest rate other than 2% are not required to be amended or reissued by the courts.\n\n(b) If the plaintiff prevails in an action to collect a consumer debt, the plaintiff shall be entitled to collect attorney\u2019s fees only if the contract or other document evidencing the indebtedness sets forth an obligation of the consumer to pay attorney\u2019s fees, subject to the following provisions: (i) if the contract or other document evidencing indebtedness provides for attorney\u2019s fees in some specific percentage, the provision and obligation shall be valid and enforceable up to but not in excess of 15 per cent of the amount of the debt excluding attorney\u2019s fees and collection costs; (ii) if a contract or other document evidencing indebtedness provides for the payment of reasonable attorney\u2019s fees by the consumer , without specifying a specific percentage, the provision shall be construed to mean the lesser of 15 per cent of the amount of the debt, excluding attorney\u2019s fees and collection costs, or the amount of attorney\u2019s fees calculated by a reasonable rate for such cases multiplied by the amount of time reasonably expended to obtain the judgment; and (iii) the documentation setting forth a party\u2019s obligation to pay attorney\u2019s fees shall be provided to the court before a court may enforce those provisions; provided, however, that the documentation shall not include materials that the plaintiff has already filed together with the complaint in compliance with applicable court rules.\n\n(c) If the consumer is the prevailing party in an action to collect a consumer debt, the consumer shall be entitled to an award of reasonable attorney\u2019s fees, unless the case is voluntarily dismissed with prejudice pursuant to Rule 41(a)(1)(i) of the Massachusetts Rules of Civil Procedure or a stipulation of dismissal explicitly provides otherwise. The amount of the debt that the plaintiff sought shall not be a factor in determining the reasonableness of the award. In the alternative, at the consumer\u2019s election, a prevailing consumer in an action to collect a consumer debt shall be awarded the amount of attorney\u2019s fees that the plaintiff would have been entitled to collect if the plaintiff had been the prevailing party.", "The code works and runs, spreading appropriately with the latest commands you gave me, the model across gpus. I get a weird error if I increase the batch size higher than 256 via horovod, it is not cuda malloc, but I cannot understand it. This is the error \n\n[1,0]:Files already downloaded and verified \n[1,1]:Files already downloaded and verified \n[1,0]:Local Rank::0, Rank::0 \n[1,1]:Local Rank::1, Rank::1 \n[1,0]:Train Epoch: 1 [0/50000 (0%)] Loss: 2.304344 \n[1,1]:Train Epoch: 1 [0/50000 (0%)] Loss: 2.302663 \n[1,1]:Traceback (most recent call last): \n[1,1]: File \"main.py\", line 84, in \n[1,1]: train(epoch) \n[1,1]: File \"main.py\", line 76, in train \n[1,1]: loss.backward() \n[1,1]: File \"/usr/local/lib/python3.8/dist-packages/torch/tensor.py\", line 245, in backward \n[1,1]: torch.autograd.backward(self, gradient, retain\\_graph, create\\_graph, inputs=inputs) \n[1,1]: File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/\\_\\_init\\_\\_.py\", line 145, in bac\nkward \n[1,1]: Variable.\\_execution\\_engine.run\\_backward( \n[1,1]:RuntimeError: cuDNN error: CUDNN\\_STATUS\\_EXECUTION\\_FAILED \n[1,1]:You can try to repro this exception using the following code snippet. If that doesn't trigge\nr the error, please include your original repro script when reporting this issue. \n[1,1]: \n[1,1]:import torch \n[1,1]:torch.backends.cuda.matmul.allow\\_tf32 = True \n[1,1]:torch.backends.cudnn.benchmark = False \n[1,1]:torch.backends.cudnn.deterministic = False \n[1,1]:torch.backends.cudnn.allow\\_tf32 = True \n[1,1]:data = torch.randn([512, 6, 14, 14], dtype=torch.float, device='cuda', requires\\_grad=True) \n[1,1]:net = torch.nn.Conv2d(6, 16, kernel\\_size=[5, 5], padding=[0, 0], stride=[1, 1], dilation=[1,\n 1], groups=1) \n[1,1]:net = net.cuda().float() \n[1,1]:out = net(data) \n[1,1]:out.backward(torch.randn\\_like(out)) \n[1,1]:torch.cuda.synchronize() \n[1,1]: \n[1,1]:ConvolutionParams \n[1,1]: data\\_type = CUDNN\\_DATA\\_FLOAT \n[1,1]: padding = [0, 0, 0] \n[1,1]: stride = [1, 1, 0] \n[1,1]: dilation = [1, 1, 0] \n[1,1]: groups = 1 \n[1,1]: deterministic = false \n[1,1]: allow\\_tf32 = true \n[1,1]:input: TensorDescriptor 0x15539001c390 \n[1,1]: type = CUDNN\\_DATA\\_FLOAT \n[1,1]: nbDims = 4 \n[1,1]: dimA = 512, 6, 14, 14, \n[1,1]: strideA = 1176, 196, 14, 1, \n[1,1]:output: TensorDescriptor 0x15539001bc40 \n[1,1]: type = CUDNN\\_DATA\\_FLOAT \n[1,1]: nbDims = 4 \n[1,1]: dimA = 512, 16, 10, 10, \n[1,1]: strideA = 1600, 100, 10, 1, \n[1,1]:weight: FilterDescriptor 0x1553900456a0 \n[1,1]: type = CUDNN\\_DATA\\_FLOAT \n[1,1]: tensor\\_format = CUDNN\\_TENSOR\\_NCHW \n[1,1]: nbDims = 4 \n[1,1]: dimA = 16, 6, 5, 5, \n[1,1]:Pointer addresses: \n[1,1]: input: 0x1553b5b7c000 \n[1,1]: output: 0x1553c2a00000 \n[1,1]: weight: 0x1553d9c00a00 \n[1,1]:Additional pointer addresses: \n[1,1]: grad\\_output: 0x1553c2a00000 \n[1,1]: grad\\_input: 0x1553b5b7c000 \n[1,1]:Backward data algorithm: 5 \n[1,1]: \n[1,0]:Traceback (most recent call last): \n[1,0]: File \"main.py\", line 84, in \n[1,0]: train(epoch) \n[1,0]: File \"main.py\", line 76, in train \n[1,0]: loss.backward() \n[1,0]: File \"/usr/local/lib/python3.8/dist-packages/torch/tensor.py\", line 245, in backward \n[1,0]: torch.autograd.backward(self, gradient, retain\\_graph, create\\_graph, inputs=inputs) \n[1,0]: File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/\\_\\_init\\_\\_.py\", line 145, in bac\nkward \n[1,0]: Variable.\\_execution\\_engine.run\\_backward( \n[1,0]:RuntimeError: cuDNN error: CUDNN\\_STATUS\\_EXECUTION\\_FAILED \n[1,0]:You can try to repro this exception using the following code snippet. If that doesn't trigge\nr the error, please include your original repro script when reporting this issue. \n[1,0]: \n[1,0]:import torch \n[1,0]:torch.backends.cuda.matmul.allow\\_tf32 = True \n[1,0]:torch.backends.cudnn.benchmark = False \n[1,0]:torch.backends.cudnn.deterministic = False \n[1,0]:torch.backends.cudnn.allow\\_tf32 = True \n[1,0]:data = torch.randn([512, 6, 14, 14], dtype=torch.float, device='cuda', requires\\_grad=True) \n[1,0]:net = torch.nn.Conv2d(6, 16, kernel\\_size=[5, 5], padding=[0, 0], stride=[1, 1], dilation=[1,\n 1], groups=1) \n[1,0]:net = net.cuda().float() \n[1,0]:out = net(data) \n[1,0]:out.backward(torch.randn\\_like(out)) \n[1,0]:torch.cuda.synchronize() \n[1,0]: \n[1,0]:ConvolutionParams \n[1,0]: data\\_type = CUDNN\\_DATA\\_FLOAT \n[1,0]: padding = [0, 0, 0] \n[1,0]: stride = [1, 1, 0] \n[1,0]: dilation = [1, 1, 0] \n[1,0]: groups = 1 \n[1,0]: deterministic = false \n[1,0]: allow\\_tf32 = true \n[1,0]:input: TensorDescriptor 0x15538c01c390 \n[1,0]: type = CUDNN\\_DATA\\_FLOAT \n[1,0]: nbDims = 4 \n[1,0]: dimA = 512, 6, 14, 14, \n[1,0]: strideA = 1176, 196, 14, 1, \n[1,0]:output: TensorDescriptor 0x15538c01bc40 \n[1,0]: type = CUDNN\\_DATA\\_FLOAT \n[1,0]: nbDims = 4 \n[1,0]: dimA = 512, 16, 10, 10, \n[1,0]: strideA = 1600, 100, 10, 1, \n[1,0]:weight: FilterDescriptor 0x15538c0456a0 \n[1,0]: type = CUDNN\\_DATA\\_FLOAT \n[1,0]: tensor\\_format = CUDNN\\_TENSOR\\_NCHW \n[1,0]: nbDims = 4 \n[1,0]: dimA = 16, 6, 5, 5, \n[1,0]:Pointer addresses: \n[1,0]: input: 0x1553b5b7c000 \n[1,0]: output: 0x1553c2a00000 \n[1,0]: weight: 0x1553d9c00a00 \n[1,0]:Additional pointer addresses: \n[1,0]: grad\\_output: 0x1553c2a00000 \n[1,0]: grad\\_input: 0x1553b5b7c000 \n[1,0]:Backward data algorithm: 5 \n[1,0]: \n------------------------------------------------------- \nPrimary job terminated normally, but 1 process returned \na non-zero exit code. Per user-direction, the job has been aborted. \n------------------------------------------------------- \n-------------------------------------------------------------------------- \nmpirun detected that one or more processes exited with non-zero status, thus causing \nthe job to be terminated. The first process to do so was: \n \n Process name: [[47237,1],0] \n Exit code: 1 \n-------------------------------------------------------------------------- \nWhat can be the source of error?", "summarise the following text into bullet points: Ouch. Sounds like you're having a tough time max. That sucks. I've been there, so I kinda know what you're talking about. I've been in the ever circling vortex of self doubt, frustration, and loathing. It's no bueno. I know. If you don't mind lemme tell you a couple things. You can read em if you want, read em again later if you feel like it. But honestly man, if I spend all this time typing this out to you and you don't let it be a little tinder for your fire, well, you're just letting us both down. And you don't HAVE to do that. You don't HAVE to do anything. But you get to choose.\n\n(Who am I? My name\u2019s Ryan and I live in Canada. Just moved to a new city for a dream job that I got because of the rules below. I owe a lot of my success to people much cooler, kinder, more loving and greater than me. When I get the chance to maybe let a little bit of help out, it\u2019s a way of thanking them. )\n\nRule numero uno - There are no more zero days. What's a zero day? A zero day is when you don't do a single fucking thing towards whatever dream or goal or want or whatever that you got going on. No more zeros. I'm not saying you gotta bust an essay out everyday, that's not the point. The point I'm trying to make is that you have to make yourself, promise yourself, that the new SYSTEM you live in is a NON-ZERO system. Didnt' do anything all fucking day and it's 11:58 PM? Write one sentence. One pushup. Read one page of that chapter. One. Because one is non zero. You feel me? When you're in the super vortex of being bummed your pattern of behaviour is keeping the vortex goin, that's what you're used to. Turning into productivity ultimate master of the universe doesn't happen from the vortex. It happens from a massive string of CONSISTENT NON ZEROS. That's rule number one. Do not forget.\n\nLa deuxieme regle - yeah i learnt french. its a canadian thing. please excuse the lack of accent graves, but lemme get into rule number 2. BE GRATEFUL TO THE 3 YOU'S. Uh what? 3 me's? That sounds like mumbo jumbo bullshit. News flash, there are three you's homeslice. There's the past you, the present you, and the future you. If you wanna love someone and have someone love you back, you gotta learn to love yourself, and the 3 you's are the key. Be GRATEFUL to the past you for the positive things you've done. And do favours for the future you like you would for your best bro. Feeling like shit today? Stop a second, think of a good decision you made yesterday. Salad and tuna instead of Big Mac? THANK YOU YOUNGER ME. Was yesterday a nonzero day because you wrote 200 words (hey, that's all you could muster)? THANK YOU YOUNGER ME. Saved up some coin over time to buy that sweet thing you wanted? THANK YOU. Second part of the 3 me's is you gotta do your future self a favour, just like you would for your best fucking friend (no best friend? you do now. You got 2. It's future and past you). Tired as hell and can't get off reddit/videogames/interwebs? fuck you present self, this one's for future me, i'm gonna rock out p90x Ab Ripper X for 17 minutes. I'm doing this one for future me. Alarm clock goes off and bed is too comfy? fuck you present self, this one's for my best friend, the future me. I'm up and going for a 5 km run (or 25 meter run, it's gotta be non zero). MAKE SURE YOU THANK YOUR OLD SELF for rocking out at the end of every.single.thing. that makes your life better. The cycle of doing something for someone else (future you) and thanking someone for the good in your life (past you) is key to building gratitude and productivity. Do not doubt me. Over time you should spread the gratitude to others who help you on your path.\n\nRule number 3- don't worry i'm gonna too long didnt' read this bad boy at the bottom (get a pencil and piece of paper to write it down. seriously. you physically need to scratch marks on paper) FORGIVE YOURSELF. I mean it. Maybe you got all the know-how, money, ability, strength and talent to do whatever is you wanna do. But lets say you still didn't do it. Now you're giving yourself shit for not doing what you need to, to be who you want to. Heads up champion, being dissapointed in yourself causes you to be less productive. Tried your best to have a nonzero day yesterday and it failed? so what. I forgive you previous self. I forgive you. But today? Today is a nonzero masterpiece to the best of my ability for future self. This one's for you future homes. Forgiveness man, use it. I forgive you. Say it out loud.\n\nLast rule. Rule number 4, is the easiest and its three words. exercise and books. that's it. Pretty standard advice but when you exercise daily you actually get smarter. when you exercise you get high from endorphins (thanks body). when you exercise you clear your mind. when you exercise you are doing your future self a huge favour. Exercise is a leg on a three legged stool. Feel me? As for books, almost every fucking thing we've all ever thought of, or felt, or gone through, or wanted, or wanted to know how to do, or whatever, has been figured out by someone else. Get some books max. Post to reddit about not caring about yourself? Good first step! (nonzero day, thanks younger me for typing it out) You know what else you could do? Read 7 habits of highly successful people. Read \"emotional intelligence\". Read \"From good to great\". Read \u201cthinking fast and slow\u201d. Read books that will help you understand. Read the bodyweight fitness reddit and incorporate it into your workouts. (how's them pullups coming?) Reading is the fucking warp whistle from Super Mario 3. It gets you to the next level that much faster.\n\nThat\u2019s about it man. There\u2019s so much more when it comes to how to turn nonzero days into hugely nonzero days, but that\u2019s not your mission right now. Your mission is nonzero and forgiveness and favours. You got 36 essays due in 24 minutes and its impossible to pull off? Your past self let you down big time, but hey\u2026 I forgive you. Do as much as you can in those 24 minutes and then move on.\n\nI hope I helped a little bit max. I could write about this forever, but I promised myself I would go do a 15 minute run while listening to A. Skillz Beats Working Vol. 3. Gotta jet. One last piece of advice though. Regardless of whether or not reading this for the first time helps make your day better, if you wake up tomorrow, and you can\u2019t remember the 4 rules I just laid out, please, please. Read this again.\n\nHave an awesome fucking day \u263a\n\ntldr; 1. Nonzero days as much as you can. 2. The three you\u2019s, gratitude and favours. 3. Forgiveness 4. Exercise and books (which is a sneaky way of saying self improvement, both physical, emotional and mental)\n\nEdit: Wow reddit gold? Thanks! No idea what to do with it or whats the deal but many thanks!\n\nEdit2: Someone asked what I meant by \"much more when it comes to how to turn nonzero days into hugely nonzero days\". The long and short of it is a simple truth, but it's tough to TOTALLY UNDERSTAND AND PRACTICE. It's this: you become what you think. This doesnt mean if I think of a tree, I'll be oakin' it by august. It means that the WAY you think, the THINGS you think of, and the IDEAS YOU HOLD IN YOUR MIND defines the sum total that is you. You procrastinate all the time and got fear and worry goin on for something? You are becoming a procrastinator. You keep thinking about how much you want to run that 5 k race in the spring and finish a champion? Are ya keeping it in mind all the time? Is it something that is defining your ACTIONS and influencing you DECISIONS? If it is, then you're becoming the champion you're dreaming about. Dreaming about it makes it. Think and it shall be. But do not forget that action is thought's son. Thoughts without actions are nothing. Have faith in whatever it is you've steeled your mind to. Have faith and follow through with action.\n\nOk, Ryan that's a bunch of nice words n shit, but how does that help me turn slightly nonzero days into hugely nonzero days. Do you believe all these words you just read? Does it makes sense to you that you BECOME WHAT YOU THINK OF? Ask yourself: What do I think of? When you get home and walk in the door. (how quickly did you turn that laptop on? Did turning it on make you closer to your dreams? What would?) At the bus stop. Lunch break. What direction are you focusing your intentions on? If you're like I was a few years ago, the answer was either No direction, or whatever caught my eye at the moment. But no stress, forgive yourself. You know the truth now. And knowing the truth means you can watch your habits, read books on how you think and act, and finally start changing your behaviour. Heres an example: Feeling like bunk cause you had zero days or barely nonzero days? THINK ABOUT WHAT YOURE DOING. and change just a little bit more. in whatever positive direction you are choosing to go.", "Damian, here is an example of a application I wrote, please remember all of the details about me and my writing style:\n\nPersonal, Relevant Background, and Future Goals\nThe Matrix, the movie, inspired me as a child. Seeing Neo go into the Matrix left me filled with awe and with questions. The idea of being able to interface the human brain with virtual reality fascinated me. I found myself spending hours trying my best to find more information on the subject. However, when I couldn\u2019t find anything about it, my curiosity intensified. What little information on the topic I did find painted the concept as science fiction, and even as an adolescent, I asked why was interfacing with the brain like they did in the Matrix impossible? As I matured, my research followed suit. I became more interested in neural interfaces. With further investigation, the question of why was it impossible? transformed into how can I make this technology real?\n My passion continued into high school, and I decided to take online neuroscience courses to help sate my hunger for more knowledge about neuroscience. During my sophomore year of high school, I gave a TEDx talk sharing my ideas on how I believed an actual virtual reality could be achieved. I thought that an electroencephalogram (EEG) could be used to read the user\u2019s brain activity. However, I hadn\u2019t figured out the problem of writing to the brain. Likewise, EEG would not give a high enough resolution to understand what was happening on a neuronal level. Therefore, I decided I would have to learn more about device construction to solve these problems. \nI joined my school\u2019s FTC robotics team during my junior year of high school to gain insight into device construction. As captain, I lead our team to the state championship twice. The experiences I had there truly made me fall in love with engineering. I took the combined love of neuroscience and engineering to university, where I learned much about both the scientific method and designing medical devices. Now, I hope to take my passion for neuroscience and engineering to create neural interfaces in graduate school, building towards the device I had dreamed of when I saw The Matrix. I now understand the vast amount of cross-disciplinary innovations and advancements needed to make such a device possible. Hence, as a researcher, I want to devote my life to making them a reality. \nRelevant Research Experience: \nI chose to major in Biomedical Engineering at Worcester Polytechnic Institute due to its project-based education and academic rigor. I hoped to be able to work towards my research goals while pursuing my bachelor\u2019s. Each class was an invaluable experience requiring one to learn the material and apply it in a project. These projects were typically group-based, so I was constantly involved in different collaborations, where I needed to take the initiative to guarantee success. I naturally assumed leadership roles in any project I participated in. While all of these experiences helped mold me into being an astute researcher and leader, one class, in particular, highlights my progress. In the course Cellular Engineering lab, I was taught how to use modern cellular and molecular biology tools. My group was tasked with designing an intervention to differentiate C2C12 cells, an immortalized cell line of mouse muscle cells. Meticulous attention to detail and extensive research was necessary for this project to succeed, or the cells would not differentiate properly. I found myself going to the lab late at night to ensure the cells\u2019 vitality while coordinating with my groupmates to ensure the project\u2019s success. In the end, we were commended for being the only team able to grow a functioning muscle. From this experience, my ability to do rigorous research was sharpened, and I learned how to take a leadership role in wet lab driven projects. \nIn my sophomore year, I entered the WPI Hackathon, where nearly 200 students participated. In three days, I was able to use an Arduino circuit to create a single-channel EEG machine. The EEG exceeded expectations despite the time constraint. I treasure the experience because it taught me the importance of time management.\nThere were no opportunities at my school to further my studies into neuroscience, so I continued my online neuroscience classes, delving more in-depth into neuroanatomy and computational neuroscience. Hoping to gain real research experience in neuroscience, I applied and was accepted into the 2020 summer undergraduate research program in Computational Neuroscience hosted by Carnegie Mellon University and the University of Pittsburgh. Due to the coronavirus, the internship had to be transitioned to an online format, which required me to work more independently. Despite the coronavirus and my lack of formal training in neuroscience, my independent research and preparation allowed me to thrive in a research environment. I worked in Dr. Aaron Batista\u2019s lab under the guidance of his graduate student Erinn Grigsby where another student and I studied the impact of neuron dropping on decoder performance. By utilizing my skills in Matlab, we created three different Kalman filters and linear regression decoders. Each decoder contained different position, velocity, and velocity-position decoders to test the most robust neuron dropping. Despite the challenges presented by the coronavirus, we could virtually present our work at the Center of the Neural Basis of Cognition. Getting the chance to work in Dr. Batista\u2019s lab was by far the most rewarding experience in my professional career. The experience enriched my ability to decipher through papers to find the pertinent information needed to complete the project. It strengthened my ability to pose a question and find an objective method to answer it. Most importantly, I gained an in-depth knowledge of how brain-computer interface decoders operate and first-hand experience developing and designing them. \nCurrent Research: \nAfter the lessons learned from my summer research experience, I aim to apply them to my current projects. I am continuing my research into brain-computer interface decoders with my summer partner, specifically investigating how factors such as modulation depth and preferred direction factor into decoder performance as neurons are dropped. We hope to see if specific neurons are essential for decoding a particular action than other neurons. For my future projects, knowledge of brain-computer interface decoders is crucial for their success. \nAs part of my senior thesis at WPI, I am a part of a team, under the guidance of Dr. Dirk Albrecht, investigating the dosing of deep brain stimulation (DBS) in disorders such as Parkinson\u2019s Disease, dystonia, essential tremor, and epilepsy. Our primary goal is to find a method of optimizing the procedure of finding the correct dosage of frequency, modulation depth, and voltage for each unique individual. We aim to conduct this study utilizing C. elegans as a model system because of the animal\u2019s completed connectome. Knowing the connectome may help see the underlying mechanisms that allow DBS to be an effective treatment for the previously stated diseases. We hope that by identifying the underlying mechanisms of DBS, the treatment might be optimized. With this experience, I will gain experience with imaging and stimulating neurons techniques and greater exposure to behavior analysis to support scientific conclusions.\nLastly, I am conducting a formal independent study into neural nanotransducers under the supervision of Dr. Dirk Albrecht. These transducers would be injectable and biocompatible, and they would allow for both high-resolution imaging and external modulation of neurons on a nanoscale. I hope this independent study will be a sufficient transition into the work I plan to pursue as a graduate student. Neural nanotransducers may lay the foundation for creating a minimally invasive, bidirectional neural interface and change the question I\u2019ve asked of How into When. \nCommunity Engagement:\nAs someone who has been supported by the people in my life, I\u2019ve always wanted to give back and encourage youth to get into STEM. As captain of the robotics team, I helped pioneer a weekend program where middle schoolers from inner-city schools could participate in our robotics meetings and create their own Lego robots. Many of these children probably would never have had these experiences due to a lack of STEM funding in their schools. In particular, one student told me that those workshops are what made her want to go to university to become an engineer. At WPI, I am a part of the Collablab, which is an entirely student-run makerspace. I helped devise creative projects to inspire people to think outside the box and pursue their own personal projects. Being a part of the Collablab has taught me that interdisciplinary approaches to projects are crucial. \nOne of my biggest passions other than neuroscience and engineering is writing. I wrote an engineering ethics case study surrounding the Florida International University bridge collapse that is used as the primary material for a new behavioral engineering ethics course. In this class, engineers are taught the ethical code and what causes people to make those decisions to prepare them better to make the right moral choices. \nWorcester is a unique and safe city, but no matter where you are, the night can be an unsafe time. I am a part of a student-run shuttle program charged with making travel at night safer for students. After three months, I was tasked with leading the group of students. During my time as coordinator, I improved the system of taking calls by students and helped modernize the system by developing an app for the program. \nI am currently building an app that would allow blind people to more easily use their mobile devices. The app works by using optical character recognition to scan the text on the screen and read it aloud. To make it more natural for the user, they would be given the option to train their voice to be used as the text to speech output. This app would also help people suffering from dyslexia because it could read aloud any passage that they would typically have trouble reading. \nFuture Goals: \n With the NSF fellowship\u2019s help, I will continue to research neural interfaces as I pursue my Ph.D. in neuroscience. I believe that neural interfaces can be a great tool to help to further society and make the world a better place for all. After obtaining my Ph.D., I plan to found a research company dedicated to designing and building minimally invasive, high-resolution, and bidirectional neural interfaces. Many scientific advancements will be required before such a device could feasibly be made. I hope to work with other institutions to tackle those problems and further understand neuroscience with this company.\n I believe that knowledge is a power that everyone, no matter what your background, deserves. I plan to create a program to help young people of color and women enter into neuroscience and facilitate their research with my company. With the knowledge gained from my research experiences, I hope to mentor the next generation and help them to answer their questions about the world, just like those who helped me along the way.", "do the same for this one:\n\n(1) Business Builder Challenge Day 5 - How To Find What To Sell And Price It - YouTube\nhttps://www.youtube.com/watch?v=7yEWlVLEGeU\n\nTranscript:\n(00:00) welcome to day five the business builder challenge where we show you exactly how to create a high income high margin low work location independent alpha 2.0 business where you can make decent money location dependent without having to work too hard today we're going to cover your offer and your pricing so in the last video we talked about the six different areas in which you could choose to sell that item that will help people or companies achieve some kind of result so i'm assuming now you've picked\n(00:27) that already if you haven't that's okay but i'm assuming that you have or at least in terms of one of those six items there's one in your head you're like yeah i'd probably do that the next step is what exactly are you going to sell ebook course consulting service whatever and what problem is that going to solve for the customer this all revolves around the customer or client if you're doing business services or consulting you would call it a client if it's anything else in that list it\n(00:58) would be a customer doesn't matter but what is the problem that you're offering is going to help alleviate or solve with the customer or client because you start there hopefully you are niched you're talking about a very narrow niche a very narrow type of person or a very narrow type of company with a specific problem that you can help them with now the problem could be anything i don't know it could be anything from improving profitability to losing weight to getting laid to moving out of the\n(01:26) country these are a lot of topics i've either talked about or interested in the past that's why i'm using those topics but it could be anything really anything to think of it doesn't matter but those that's the first of two questions what is the problem it's trying to solve how is the condition of the customer going to be approved by them purchasing your information or your service start there if i'm your customer if i'm your client how is my condition going to improve and be as clear as you can not like\n(01:54) you'll be happier that's not very clear a better thing is you will increase profitability by 20 or so or you'll be able to schedule due dates on the calendar within three weeks of working with me or whatever it is try to quantify the actual improvement if you can't now you may say michaela this is a new business i've ever done this before i don't know then guess it's okay to guess as long as you're honest with prospects when you talk to them you can say look my guess based on my experience and my\n(02:23) knowledge is that i can get you an improvement that looks something like this i may not be exactly right because i am new but that's my guess and even if we only get 50 of that you will still improve so let's say you're going to be a consultant and you're going to help cut costs by 20 let's say let's say that's the number you've chosen if you go to a company and you save the owner or whoever's going to hire you look i could be wrong maybe i only save costs by 10 well that's a lot of money that's more\n(02:50) than worth your consulting fee and that leads into the second question how much is the improvement worth to the customer so if you come to me and you say caleb i'm gonna increase your sales by 20 that's worth a lot to me i would spend a lot of money on that because 20 for me is a lot of money so that means i'm happy to pay you a decent amount of money for that 20 percent now it doesn't have to be a financial thing again you can sell to individuals or you can sell the companies if you want to sell to individuals you could\n(03:22) use the example of one of my companies i teach dating advice for men and i show men how to get first dates with online dating and have non-monogamous relationships so i will say to them i can help you schedule first dates get first dates on the calendar and once you start dating new women i can show you how to date multiple women all at the same time and they all know you're dating other women and they continue to date you anyway without complaining about it that's one of the things i teach one of my companies how much money\n(03:46) is that worth that's worth a lot of money to men it's not a business thing is it there's no financial numbers attached that is there but it's such a cool result that i can charge a decent amount of money for men to buy my information to help them achieve that result make sense so those are two questions to start with in terms of your offer what is the improvement and how much is that improvement worth to your niche once you know those two things then you can go to the next step and figure out\n(04:12) how much it's going to cost what the pricing is if the improvement is significant and it's worth a lot to the niche then your price could be very high if your improvement is little or if your improvement is big but it's not deemed as very important to your niche then the price will have to be lower make sense the price is not based on what you are comfortable with most business owners charge under what they should be charging the price should be only based on value which means the value of the improvement you're giving the customer\n(04:41) or the client and that's it so if you're providing high value you can charge a lot of money there are ebooks that you can buy online for 300 and you may go what the hell why would i buy a book for 300 because they're highly highly niched and they're extremely valuable i bought an ebook once 20 years ago when the internet was new and ebooks were not even a thing i bought an ebook once for 200 it was 197 god caleb you're a why would you buy a book for 200 because it was a book on how to do cold\n(05:10) calls to get clients for your consulting business you see how niche that was and that's exactly what i was doing 20 years ago so i was happy to spend 200 on a book it's not like well the book is 40 pages so i guess i better charge two dollars for it no wrong incorrect there are online courses for a few videos that cost three thousand dollars there are there's only a few hours long but they cost three thousand because the value is so strong to that niche i knew a guy once who published a printed newsletter and it\n(05:41) only went out six times a year he would just bail it out six times a year and the subscription price for this newsletter like a little magazine was three thousand dollars a year now why was it so much because it was a very niche newsletter in the oil industry he was only targeting a very certain type of person in a very specific industry the oil industry so he was able to charge a lot of money because it was ditched and the value was very high so you don't charge based on the modality you charge based on the value it's\n(06:12) called value-based pricing it's extremely important that you don't under charge for what you're selling i don't want you to make that mistake and let's say you charge too much money you know what you cut your prices later it's not a big deal it really isn't it's harder to raise your prices later than to cut them later so i'd rather you start out on the high range of pricing based on the value and the value to the kleiner customer once again you are invited to the 90-day business\n(06:38) builder where we me personally and my staff work with you one-on-one and in small groups over a 12-week period with an accountability coach where we meet every week and we show you exactly what to do we hold your hand and take you through the exact process of setting up your alpha jupiter business from zero so you are making real money by the end of 12 weeks if not sooner than that guaranteed if you have any interest in that because it's the cheapest time we're doing is right now because every time we do this we raise the prices so\n(07:09) if you want in on this for as cheap as you can click the link below or wherever it is to schedule your consultation call you get all your questions answered we'll go through everything with you if it's not for you no problem if it is for you you could be making money in your own alpha 2.\n(07:25) 0 business like this in less than 12 weeks sometimes much less than 12 weeks even if you've never started business before because we're going to take you through the process step by step by step with an accountability coach who works with you every week you're going to work with me and my coaches every week you'll know everything what to do because we'll take you through the entire process it's an absolute no-brainer we do this for you with you if you have any interest click that link and schedule that call we only\n(07:50) take on a certain number of people at once because we can't have too many people in the sessions so once we're full we're full and if we do this again it's going to cost more money so if any interest on this click the link below to schedule your consultation call it might be with me me or one of my coaches depends who you get and i will see you in the next video have fun bye", "Okay i will give you all the code we have so far, all from different files. Here is the first file:\n\nappliances.py\n\n# Object structure: name:shiftable(bool), minW, maxW, hrs daily usage, not used before, not used after\n\nnonShiftable = {\n \"Lighting\": [False, 1000, 2000, 10, 10, 20],\n \"Heating\": [False, 6400, 9600, 24, 0, 24],\n \"Refrigerator\": [False, 1320, 3960, 24, 0, 24],\n \"Freezer\": [False, 1320, None, 24, 0, 24],\n \"Stove\": [False, 3900, None, 2, 16, 20],\n \"TV\": [False, 150, 600, 5, 16, 23],\n \"Computer\": [False, 600, None, 4, 16, 23]\n}\n\nshiftable = {\n \"Dishwasher\": [True, 1440, None, 3, 0, 23],\n \"Laundromat\": [True, 1940, None, 2, 0, 23],\n \"Dryer\": [True, 2500, None, 2, 0, 23],\n \"EV\": [True, 9900, None, 4, 0, 23]\n}\n\nauxilary = {\n \"Coffeemaker\": [True, 2.4, None, 1, 6, 8],\n \"Ceiling-Fan\": [True, 55, 100, 4, 10, 18],\n \"Hairdryer\": [True, 800, 1800, 1, 6, 8],\n \"Toaster\": [True, 800, 1500, 1, 6, 8],\n \"Microwave\": [True, 850, 1800, 1, 0, 24],\n \"Router\": [True, 2, 20, 24, 0, 24],\n \"Cellphone-charger\": [True, 2, 6, 4, 0, 24],\n \"Cloth-iron\": [True, 800, 2000, 1, 20, 24]\n}\n\n----------\n\nclasses.py\n\nimport random\nclass Appliance:\n # usageTime = Hours daily usage, time = timeslot for usage to happen within\n def \\_\\_init\\_\\_(self, name, shiftable, minkW, maxkW, duration, timeStart, timeStop):\n self.name = name\n self.shiftable = shiftable\n self.duration = duration\n self.timeStart = timeStart\n self.timeStop = timeStop\n if maxkW is None:\n self.consumption = minkW\n else:\n self.consumption = self.randomize\\_usage\\_between(minkW, maxkW)\n\n def randomize\\_usage\\_between(self, min, max):\n return random.randint(min, max)\n\n def \\_\\_str\\_\\_(self):\n return f\"{self.name} ({self.consumption} kW) \\nDaily use: {self.duration} hours in timeslot {self.timeStart}-{self.timeStop}\\n\"\nclass Household:\n\n def \\_\\_init\\_\\_(self, id):\n self.id = id\n self.allAppliances = []\n self.nonShiftable = None\n self.shiftable = None\n self.auxilary = None\n\n def setNonShiftable(self, list):\n self.nonShiftable = list\n for a in list:\n if a not in self.allAppliances:\n self.allAppliances.append(a)\n\n def setShiftable(self, list):\n self.shiftable = list\n for a in list:\n if a not in self.allAppliances:\n self.allAppliances.append(a)\n\n def setAuxilary(self, list):\n self.auxilary = list\n for a in list:\n if a not in self.allAppliances:\n self.allAppliances.append(a)\n\n def randomizeAppliances(appliances: list) -> list:\n return random.sample(appliances, random.randint(1, len(appliances)))\n\n def removeEV(self):\n for a in self.allAppliances:\n if a.name == \"ev\":\n self.allAppliances.remove(a)\n self.shiftable.remove(a)\n\n def printAllHouseholdAppliances(self):\n print(\"Household has\", len(\n self.allAppliances), \"appliances.\")\n for a in self.allAppliances:\n print(\"----\")\n print(a)\n\n-------\n\ngenerateElectricityPrices.py\n\nimport random\ndef generate\\_electricity\\_prices():\n # Define the base price for electricity\n base\\_price = 0.10\n\n # Define the peak hours and off-peak hours\n peak\\_hours = [16, 17, 18, 19, 20]\n off\\_peak\\_hours = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 21, 22, 23]\n\n # Create a dictionary to store the prices for each hour\n prices = {}\n\n # Loop through each hour of the day\n for hour in range(24):\n # Define the peak price and off-peak price\n peak\\_price = random.uniform(0.10, 0.50)\n off\\_peak\\_price = random.uniform(0.05, 0.10)\n # Determine if the hour is a peak hour or off-peak hour\n if hour in peak\\_hours:\n price = base\\_price + peak\\_price\n elif hour in off\\_peak\\_hours:\n price = base\\_price + off\\_peak\\_price\n else:\n price = base\\_price\n\n # Add the price to the dictionary\n prices[hour] = price\n\n # Return the dictionary of prices\n return prices\n\n--------\n\nmain.py\n\nfrom appliances import nonShiftable, shiftable, auxilary\nfrom classes import Appliance, Household\nfrom optimal import optimal\\_calculation, calculate\\_schedule\\_cost, print\\_schedule, scheduleAppliances, optimizeSchedule\n\nimport random\ndef main():\n # Create all appliances\n allAppliances = []\n nonShiftableAppliances = []\n shiftableAppliances = []\n auxilaryAppliances = []\n\n for key in nonShiftable:\n newAppliance = Appliance(key, (nonShiftable[key][0]), (nonShiftable[key][1]), (nonShiftable[key]\n [2]), (nonShiftable[key][3]), (nonShiftable[key][4]), (nonShiftable[key][5]))\n allAppliances.append(newAppliance)\n nonShiftableAppliances.append(newAppliance)\n\n for key in shiftable:\n newAppliance = Appliance(key, (shiftable[key][0]), (shiftable[key][1]), (shiftable[key]\n [2]), (shiftable[key][3]), (shiftable[key][4]), (shiftable[key][5]))\n allAppliances.append(newAppliance)\n shiftableAppliances.append(newAppliance)\n\n for key in auxilary:\n newAppliance = Appliance(key, (auxilary[key][0]), (auxilary[key][1]), (auxilary[key]\n [2]), (auxilary[key][3]), (auxilary[key][4]), (auxilary[key][5]))\n allAppliances.append(newAppliance)\n auxilaryAppliances.append(newAppliance)\n\n # \\* Assignment 2\n print(\"Assignment 2 \\n-----------------------------------------------------------------\")\n # Create household with all nonshiftable, all shiftable, and random auxilary appliances\n household = Household(1)\n household.setNonShiftable(nonShiftableAppliances)\n household.setShiftable(shiftableAppliances)\n household.setAuxilary(randomizeList(auxilaryAppliances))\n household.printAllHouseholdAppliances()\n # Create and print schedule\n householdSchedule = optimal\\_calculation(household.allAppliances)\n print\\_schedule(householdSchedule)\n print(f'{calculate\\_schedule\\_cost(householdSchedule)}nok for this schedule')\n\n # \\* Assignment 3\n print(\"Assignment 3 \\n-----------------------------------------------------------------\")\n neigborhoodAppliances = []\n n = 30\n # Create N number of households\n for i in range(n):\n household = Household(i + 1)\n household.setNonShiftable(nonShiftableAppliances)\n household.setShiftable(shiftableAppliances)\n household.setAuxilary(randomizeList(auxilaryAppliances))\n # Household has a 75% chance of having a EV\n x = random.randint(0, 4)\n if x == 0:\n household.removeEV()\n # Adds households appliances to neighborhood total appliances\n for a in household.allAppliances:\n neigborhoodAppliances.append(a)\n # Create and print household schedule\n householdScehdule = optimal\\_calculation(household.allAppliances)\n print(\"Household\", household.id)\n print\\_schedule(householdScehdule)\n print(\n f'Household energy cost: {calculate\\_schedule\\_cost(householdScehdule)}nok\\n--------------------------------------------')\n\n neighborhoodSchedule = optimal\\_calculation(neigborhoodAppliances)\n print(\n f'Total neighborhood cost: {calculate\\_schedule\\_cost(neighborhoodSchedule)}nok\\n')\n\n # \\* Assignment 4\n print(\"Assignment 4 \\n-----------------------------------------------------------------\")\n household = Household(1)\n household.setNonShiftable(nonShiftableAppliances)\n household.setShiftable(shiftableAppliances)\n household.setAuxilary(randomizeList(auxilaryAppliances))\n\n sched = scheduleAppliances(household.allAppliances)\n optimizeSchedule(sched)\ndef randomizeList(list):\n return random.sample(list, random.randint(1, len(list)))\nmain()\n(there will be more)", "Large Igneous Provinces\nCretaceous tectonic evolution of South China: A preliminary synthesis\nLithospheric Architecture of the Lhasa Terrane and Its Control on Ore Deposits in the Himalayan-Tibetan Orogen\nMulti-stage crustal growth and cratonization of the North China Craton\nReactivation of the Archean lower crust: Implications for zircon geochronology, elemental and Sr\u2013Nd\u2013Hf isotopic geochemistry of late Mesozoic granitoids from northwestern Jiaodong Terrane, the North China Craton\nContinental collision zones are primary sites for net continental crust growth \u2014 A testable hypothesis\nUltrapotassic Mafic Rocks as Geochemical Proxies for Post-collisional Dynamics of Orogenic Lithospheric Mantle: the Case of Southwestern Anatolia, Turkey\nThe evolving nature of terrestrial crust from the Hadean, through the Archaean, into the Proterozoic\nHydrous melting of the martian mantle produced both depleted and enriched shergottites\nFluid and mass transfer at subduction interfaces\u2014The field metamorphic record\nPaleoproterozoic arc magmatism in the North China Craton: No Siderian global plate tectonic shutdown\nThe Grenvillian orogeny in the Altun\u2013Qilian\u2013North Qaidam mountain belts of northern Tibet Plateau: Constraints from geochemical and zircon U\u2013Pb age and Hf isotopic study of magmatic rocks\nPetrogenesis and tectonic significance of Paleoproterozoic meta-mafic rocks from central Liaodong Peninsula, northeast China: Evidence from zircon U\u2013Pb dating and in situ Lu\u2013Hf isotopes, and whole-rock geochemistry\nGeochronology and geochemistry of the Paleoproterozoic meta-basalts from the Jiao-Liao-Ji Belt, North China Craton: Implications for petrogenesis and tectonic setting\nDiscovery of Neoarchean suprasubduction zone ophiolite suite from Yishui Complex in the North China Craton\nEarly Permian A-type granites from central Inner Mongolia, North China: Magmatic tracer of post-collisional tectonics and oceanic crustal recycling\nMagmatic evolution of the Tuwu\u2013Yandong porphyry Cu belt, NW China: Constraints from geochronology, geochemistry and Sr\u2013Nd\u2013Hf isotopes\nPetrological insights into the storage conditions, and magmatic processes that yielded the centennial 2010 Merapi explosive eruption\nTowards a new model for kimberlite petrogenesis: Evidence from unaltered kimberlites and mantle minerals\nGeochronology, geochemistry and tectonic significance of two Early Cretaceous A-type granites in the Gan-Hang Belt, Southeast China\nAn integrated mineral system model for the gold deposits of the giant Jiaodong province, eastern China\nPartial melting of metabasic rocks and the generation of tonalitic\u2013trondhjemitic\u2013granodioritic (TTG) crust in the Archaean: Constraints from phase equilibrium modelling\nPaleoproterozoic crustal growth in the North China Craton: Evidence from the L\u00fcliang Complex\nArchean komatiite volcanism controlled by the evolution of early continents\nExperimental petrology of peridotites, including effects of water and carbon on melting in the Earth\u2019s upper mantle\nOrigin of arc-like continental basalts: Implications for deep-Earth fluid cycling and tectonic discrimination\nRecycling of metal-fertilized lower continental crust: Origin of non-arc Au-rich porphyry deposits at cratonic edges\nThe Neoproterozoic granitoids from the Qilian block, NW China: Evidence for a link between the Qilian and South China blocks\nPost-kinematic lithospheric delamination of the Wuyi\u2013Yunkai orogen in South China: Evidence from ca. 435Ma high-Mg basalts\nEmplacement ages, geochemical and Sr\u2013Nd\u2013Hf isotopic characterization of Mesozoic to early Cenozoic granitoids of the Sikhote-Alin Orogenic Belt, Russian Far East: Crustal growth and regional tectonic evolution\nIn situ zircon Hf\u2013O isotopic analyses of late Mesozoic magmatic rocks in the Lower Yangtze River Belt, central eastern China: Implications for petrogenesis and geodynamic evolution\nLate Paleozoic subduction system in the northern margin of the Alxa block, Altaids: Geochronological and geochemical evidences from ophiolites\nTwo-phase subduction and subsequent collision defines the Paleotethyan tectonics of the southeastern Tibetan Plateau: Evidence from zircon U-Pb dating, geochemistry, and structural geology of the Sanjiang orogenic belt, southwest China\nGeochemistry, zircon UPb geochronology and LuHf isotopic composition of eclogites and their host gneisses in the Dulan area, North Qaidam UHP terrane: New evidence for deep continental subduction\nMid-Triassic felsic igneous rocks from the southern Lancangjiang Zone, SW China: Petrogenesis and implications for the evolution of Paleo-Tethys\nWidespread refertilization of cratonic and circum-cratonic lithospheric mantle\nA New Model for Barberton Komatiites: Deep Critical Melting with High Melt Retention\nBuilding of the Deep Gangdese Arc, South Tibet: Paleocene Plutonism and Granulite-Facies Metamorphism\nLate Ordovician to early Devonian adakites and Nb-enriched basalts in the Liuyuan area, Beishan, NW China: Implications for early Paleozoic slab-melting and crustal growth in the southern Altaids\nEocene\u2013Oligocene post-collisional magmatism in the Lut\u2013Sistan region, eastern Iran: Magma genesis and tectonic implications\nThe major and trace element glass compositions of the productive Mediterranean volcanic sources: tools for correlating distal tephra layers in and around Europe\nA Neoarchean dismembered ophiolite complex from southern India: Geochemical and geochronological constraints on its suprasubduction origin\nSpatial extent of the influence of the deeply subducted South China Block on the southeastern North China Block: Constraints from Sr\u2013Nd\u2013Pb isotopes in Mesozoic mafic igneous rocks\nHotspot volcanism and highly siderophile elements\nInsights into magma and fluid transfer at Mount Etna by a multiparametric approach: A model of the events leading to the 2011 eruptive cycle\nZircon U\u2013Pb ages and geochemistry of the Huai\u2019an TTG gneisses terrane: Petrogenesis and implications for \u223c2.5Ga crustal growth in the North China Craton\nLate Neoarchean subduction-related crustal growth in the Northern Liaoning region of the North China Craton: Evidence from \u223c2.55 to 2.50Ga granitoid gneisses\nThe Anatomy of an Andesite Volcano: a Time\u2013Stratigraphic Study of Andesite Petrogenesis and Crustal Evolution at Ruapehu Volcano, New Zealand\nPetrogenesis of Cretaceous adakite-like intrusions of the Gangdese Plutonic Belt, southern Tibet: Implications for mid-ocean ridge subduction and crustal growth\nWhat can we learn from melt inclusions in migmatites and granulites?\nCarboniferous mantle-derived felsic intrusion in the Chinese Altai, NW China: Implications for geodynamic change of the accretionary orogenic belt\nGeochronological and geochemical constraints on the petrogenesis of Middle Paleozoic (Kwangsian) massive granites in the eastern South China Block\nApplication of Ti-in-zircon thermometry to granite studies: problems and possible solutions\nGeneration and evolution of Palaeoarchaean continental crust in the central part of the Singhbhum craton, eastern India\nGeochronology and geochemistry of Early Jurassic volcanic rocks in the Erguna Massif, northeast China: Petrogenesis and implications for the tectonic evolution of the Mongol\u2013Okhotsk suture belt\nRemnants of Eoarchean continental crust derived from a subducted proto-arc\nThe Role of Late Sulfide Saturation in the Formation of a Cu- and Au-rich Magma: Insights from the Platinum Group Element Geochemistry of Niuatahi\u2013Motutahi Lavas, Tonga Rear Arc\nZircon U\u2013Pb\u2013Hf isotopes and geochemistry of Neoarchean dioritic\u2013trondhjemitic gneisses, Eastern Hebei, North China Craton: Constraints on petrogenesis and tectonic implications\nIsland arc-type bimodal magmatism in the eastern Tianshan Belt, Northwest China: Geochemistry, zircon U\u2013Pb geochronology and implications for the Paleozoic crustal evolution in Central Asia\nAppinite suites: A record of the role of water in the genesis, transport, emplacement and crystallization of magma\nGeochronology and geochemistry of Early Cretaceous volcanic rocks from the Baiyingaolao Formation in the central Great Xing'an Range, NE China, and its tectonic implications\nLayered Intrusions\nGeological, Petrological and Geochemical Evidence for Progressive Construction of an Arc Crustal Section, Sierra de Valle F\u00e9rtil, Famatinian Arc, Argentina\n3D numerical modeling of mantle flow, crustal dynamics and magma genesis associated with slab roll-back and tearing: The eastern Mediterranean case\nOldest rocks from Peninsular India: Evidence for Hadean to Neoarchean crustal evolution\n\u7ed9\u4ee5\u4e0a\u8bba\u6587\u6309\u5185\u5bb9\u76f8\u5173\u6027\u5206\u7c7b", "Compiled with problems:\n\u00d7\nERROR in ./src/App.js\nModule build failed (from ./node\\_modules/babel-loader/lib/index.js):\nSyntaxError: C:\\Users\\manoj kumar\\instashare\\src\\App.js: Invalid shorthand property initializer. (8:13)\n\n 6 | const [posts, setPosts] = useState([\n 7 | {\n> 8 | username=\"manoj\",\n | ^\n 9 | caption=\"wow it works\",\n 10 | imageUrl=\"https://www.freecodecamp.org/news/content/images/2021/06/Ekran-Resmi-2019-11-18-18.08.13.png\"\n 11 | },\n at instantiate (C:\\Users\\manoj kumar\\instashare\\node\\_modules\\@babel\\parser\\lib\\index.js:653:32)\n at constructor (C:\\Users\\manoj kumar\\instashare\\node\\_modules\\@babel\\parser\\lib\\index.js:947:12)\n at FlowParserMixin.raise (C:\\Users\\manoj kumar\\instashare\\node\\_modules\\@babel\\parser\\lib\\index.js:3261:19)\n at FlowParserMixin.checkExpressionErrors (C:\\Users\\manoj kumar\\instashare\\node\\_modules\\@babel\\parser\\lib\\index.js:3700:12)\n at FlowParserMixin.parseMaybeAssign (C:\\Users\\manoj kumar\\instashare\\node\\_modules\\@babel\\parser\\lib\\index.js:10642:12)\n at FlowParserMixin.parseMaybeAssign (C:\\Users\\manoj kumar\\instashare\\node\\_modules\\@babel\\parser\\lib\\index.js:5821:18)\n at C:\\Users\\manoj kumar\\instashare\\node\\_modules\\@babel\\parser\\lib\\index.js:10580:39\n at FlowParserMixin.allowInAnd (C:\\Users\\manoj kumar\\instashare\\node\\_modules\\@babel\\parser\\lib\\index.js:12255:12)\n at FlowParserMixin.parseMaybeAssignAllowIn (C:\\Users\\manoj kumar\\instashare\\node\\_modules\\@babel\\parser\\lib\\index.js:10580:17)\n at FlowParserMixin.parseExprListItem (C:\\Users\\manoj kumar\\instashare\\node\\_modules\\@babel\\parser\\lib\\index.js:12007:18)\n at FlowParserMixin.parseCallExpressionArguments (C:\\Users\\manoj kumar\\instashare\\node\\_modules\\@babel\\parser\\lib\\index.js:11062:22)\n at FlowParserMixin.parseCoverCallAndAsyncArrowHead (C:\\Users\\manoj kumar\\instashare\\node\\_modules\\@babel\\parser\\lib\\index.js:10977:29)\n at FlowParserMixin.parseSubscript (C:\\Users\\manoj kumar\\instashare\\node\\_modules\\@babel\\parser\\lib\\index.js:10912:19)\n at FlowParserMixin.parseSubscript (C:\\Users\\manoj kumar\\instashare\\node\\_modules\\@babel\\parser\\lib\\index.js:5924:18)\n at FlowParserMixin.parseSubscripts (C:\\Users\\manoj kumar\\instashare\\node\\_modules\\@babel\\parser\\lib\\index.js:10883:19)\n at FlowParserMixin.parseSubscripts (C:\\Users\\manoj kumar\\instashare\\node\\_modules\\@babel\\parser\\lib\\index.js:5890:18)\n at FlowParserMixin.parseExprSubscripts (C:\\Users\\manoj kumar\\instashare\\node\\_modules\\@babel\\parser\\lib\\index.js:10874:17)\n at FlowParserMixin.parseUpdate (C:\\Users\\manoj kumar\\instashare\\node\\_modules\\@babel\\parser\\lib\\index.js:10853:21)\n at FlowParserMixin.parseMaybeUnary (C:\\Users\\manoj kumar\\instashare\\node\\_modules\\@babel\\parser\\lib\\index.js:10829:23)\n at FlowParserMixin.parseMaybeUnaryOrPrivate (C:\\Users\\manoj kumar\\instashare\\node\\_modules\\@babel\\parser\\lib\\index.js:10667:61)\n at FlowParserMixin.parseExprOps (C:\\Users\\manoj kumar\\instashare\\node\\_modules\\@babel\\parser\\lib\\index.js:10672:23)\n at FlowParserMixin.parseMaybeConditional (C:\\Users\\manoj kumar\\instashare\\node\\_modules\\@babel\\parser\\lib\\index.js:10649:23)\n at FlowParserMixin.parseMaybeAssign (C:\\Users\\manoj kumar\\instashare\\node\\_modules\\@babel\\parser\\lib\\index.js:10610:21)\n at FlowParserMixin.parseMaybeAssign (C:\\Users\\manoj kumar\\instashare\\node\\_modules\\@babel\\parser\\lib\\index.js:5821:18)\n at C:\\Users\\manoj kumar\\instashare\\node\\_modules\\@babel\\parser\\lib\\index.js:10580:39\n at FlowParserMixin.allowInAnd (C:\\Users\\manoj kumar\\instashare\\node\\_modules\\@babel\\parser\\lib\\index.js:12250:16)\n at FlowParserMixin.parseMaybeAssignAllowIn (C:\\Users\\manoj kumar\\instashare\\node\\_modules\\@babel\\parser\\lib\\index.js:10580:17)\n at FlowParserMixin.parseVar (C:\\Users\\manoj kumar\\instashare\\node\\_modules\\@babel\\parser\\lib\\index.js:13188:91)\n at FlowParserMixin.parseVarStatement (C:\\Users\\manoj kumar\\instashare\\node\\_modules\\@babel\\parser\\lib\\index.js:13027:10)\n at FlowParserMixin.parseStatementContent (C:\\Users\\manoj kumar\\instashare\\node\\_modules\\@babel\\parser\\lib\\index.js:12624:23)\n at FlowParserMixin.parseStatementLike (C:\\Users\\manoj kumar\\instashare\\node\\_modules\\@babel\\parser\\lib\\index.js:12544:17)\n at FlowParserMixin.parseStatementLike (C:\\Users\\manoj kumar\\instashare\\node\\_modules\\@babel\\parser\\lib\\index.js:5139:24)\n at FlowParserMixin.parseStatementListItem (C:\\Users\\manoj kumar\\instashare\\node\\_modules\\@babel\\parser\\lib\\index.js:12524:17)\n at FlowParserMixin.parseBlockOrModuleBlockBody (C:\\Users\\manoj kumar\\instashare\\node\\_modules\\@babel\\parser\\lib\\index.js:13116:61)\n at FlowParserMixin.parseBlockBody (C:\\Users\\manoj kumar\\instashare\\node\\_modules\\@babel\\parser\\lib\\index.js:13109:10)\n at FlowParserMixin.parseBlock (C:\\Users\\manoj kumar\\instashare\\node\\_modules\\@babel\\parser\\lib\\index.js:13097:10)\n at FlowParserMixin.parseFunctionBody (C:\\Users\\manoj kumar\\instashare\\node\\_modules\\@babel\\parser\\lib\\index.js:11922:24)\n at C:\\Users\\manoj kumar\\instashare\\node\\_modules\\@babel\\parser\\lib\\index.js:5113:63\n at FlowParserMixin.forwardNoArrowParamsConversionAt (C:\\Users\\manoj kumar\\instashare\\node\\_modules\\@babel\\parser\\lib\\index.js:5291:16)\n at FlowParserMixin.parseFunctionBody (C:\\Users\\manoj kumar\\instashare\\node\\_modules\\@babel\\parser\\lib\\index.js:5113:12)\n at FlowParserMixin.parseArrowExpression (C:\\Users\\manoj kumar\\instashare\\node\\_modules\\@babel\\parser\\lib\\index.js:11897:10)\n at FlowParserMixin.parseParenAndDistinguishExpression (C:\\Users\\manoj kumar\\instashare\\node\\_modules\\@babel\\parser\\lib\\index.js:11500:12)\n at FlowParserMixin.parseParenAndDistinguishExpression (C:\\Users\\manoj kumar\\instashare\\node\\_modules\\@babel\\parser\\lib\\index.js:5865:18)\n at FlowParserMixin.parseExprAtom (C:\\Users\\manoj kumar\\instashare\\node\\_modules\\@babel\\parser\\lib\\index.js:11139:23)\n at FlowParserMixin.parseExprAtom (C:\\Users\\manoj kumar\\instashare\\node\\_modules\\@babel\\parser\\lib\\index.js:6998:20)\n at FlowParserMixin.parseExprSubscripts (C:\\Users\\manoj kumar\\instashare\\node\\_modules\\@babel\\parser\\lib\\index.js:10870:23)\n at FlowParserMixin.parseUpdate (C:\\Users\\manoj kumar\\instashare\\node\\_modules\\@babel\\parser\\lib\\index.js:10853:21)\n at FlowParserMixin.parseMaybeUnary (C:\\Users\\manoj kumar\\instashare\\node\\_modules\\@babel\\parser\\lib\\index.js:10829:23)\n at FlowParserMixin.parseMaybeUnaryOrPrivate (C:\\Users\\manoj kumar\\instashare\\node\\_modules\\@babel\\parser\\lib\\index.js:10667:61)\n at FlowParserMixin.parseExprOps (C:\\Users\\manoj kumar\\instashare\\node\\_modules\\@babel\\parser\\lib\\index.js:10672:23)\nERROR\n[eslint] \nsrc\\App.js\n Line 8:13: Parsing error: Invalid shorthand property initializer. (8:13)", "Can you convert this table content in a interesting blog content. Ensure the output is well formatted using markdown, use H3, H3, bullet properly.\n\nfor each country follow the following format\n\n## Country Name\nIntro text about geographic location.\n## Important Features\n### Staple Food\n### Key dishes of different courses\n\nHere is the text in markdown I want you to work with.\n\n| Country | Geographic Location | 5 Important Features | Staple Food | 10 important dishes of different courses |\n| --- | --- | --- | --- | --- |\n| United Kingdom | Europe, comprises of Scotland, Iceland, Wales and England. | \u2022 Use of lard is predominant.\n\u2022 Pies and pastries are popular.\n\u2022 Mostly inspired by the colonies.\n\u2022 Sausages like Haggis are widespread.\n\u2022 Alcoholic spirits are predominantly used as an aid to cooking. | \u2022 Offal\n\u2022 Meat\n\u2022 Milk\n\u2022 Vegetables like leeks, onions, garlic and leeks.\n\u2022 Butter\n\u2022 Cheese\n\u2022 Oats\n\u2022 Barley\n\u2022 Potatoes | 1. Fish and Chips\n2. Shepherds\u2019 Pie\n3. Cornish Pastry\n4. Yorkshire Pudding\n5. Welsh Rarebit\n6. Roast Beef\n7. Cumberland Sausage\n8. Bread and butter Pudding\n9. Scones\n10. Fruit Trifle |\n| Italy | Southern Europe | \u2022 Coffee , specifically espresso is served after meals.\n\u2022 Italian meals are accompanied by wine.\n\u2022 Olive oil is a major cooking medium, it is also used as a flavouring agent.\n\u2022 Starch-based products like Pasta, pizza and bread are the major source of carbohydrates. | \u2022 Tomatoes\n\u2022 Duram Wheat\n\u2022 Olive oil\n\u2022 Cheese\n\u2022 Meat\n\u2022 Poultry\n\u2022 Herbs\n\u2022 Garlic | 1. Minestrone\n2. Frito Miso\n3. Polenta\n4. Pizza\n5. Spagetti Carbonara\n6. Tiramisu\n7. Panettone\n8. Bistteccaalla Florentina\n9. Zabaglione\n10. Ricotta Gnudi |\n| France | South-western Europe | \u2022 Baked goods are widely used\n\u2022 Stock serves as an Important base for most sauces and all soups\n\u2022 Finesse is key to the french style of cooking\n\u2022 Garnishes and accompaniments are very important\n\u2022 The courses and structure of the menu are adhered to strictly. | \u2022 Eggs\n\u2022 Herbs\n\u2022 Mustard\n\u2022 Wine\n\u2022 Bread\n\u2022 Meat\n\u2022 Poultry\n\u2022 Sea Food\n\u2022 Stock | 1. Moules el sauce\n2. Chicken Cordon Bleu\n3. Mussels a la mariniere\n4. Beef Bourguignon\n5. Pork tenderloin\n6. Coq Au Vin\n7. Poulet Parisienne\n8. Salmon and Swiss Chard Quiche\n9. Mille Feuille\n10. Creme Br\u00fbl\u00e9e |\n| Spain | South-western Europe | \u2022 Various condiments and spices are used.\n\u2022 La Comida is a large midday meal\n\u2022 Snacks and appetizers referred to as Tapas are extremely popular.\n\u2022 Large amounts of tomatoes.\n\u2022 Saffron is used to flavor many dishes. | \u2022 Tomatoes\n\u2022 Milk\n\u2022 Seafood\n\u2022 Meat\n\u2022 Poultry\n\u2022 Rice\n\u2022 Olive oil\n\u2022 Forcemeat | 1. Gazpacho\n2. Tortillas\n3. Pintxos\n4. Paella\n5. Cat soup\n6. Ox- tail stew\n7. Cod Tavias\n8. Churros\n9. Flan\n10. Torrija |\n| Portugal | South-western Europe | \u2022 Seafood is consumed in large quantities\n\u2022 Highly influenced by the colonial era, Mediterranean influences are also found\n\u2022 Spices like peri-peri are widely used\n\u2022 Herbs like bay leaves and parsley are important.\n\u2022 Olive oil is the basis of most dishes | \u2022 Sea food\n\u2022 Cheese\n\u2022 Meat\n\u2022 Poultry\n\u2022 Vegetabes like Tomatoes, cabbage and onions\n\u2022 Starch from potatoes and rice\n\u2022 Garlic\n\u2022 Olive oil\n\u2022 Peri-peri spice | 1. Caldo Verde\n2. Bica\n3. Chourico\n4. Arroz doce\n5. Enchidos\n6. Maranahos\n7. Mariscos\n8. Pasties de Nata\n9. Barriga de friera\n10. Doce de Cila |\n| Scandinavia | Sweden , Denmark , Norway | \u2022 Three meals a day and a coffee break are chosen food routines\n\u2022 High intake of buttermilk and sour cream\n\u2022 Preserved food is a common choice\u00a0\n\u2022 Spices are not widely consumed\n\u2022 Cold Smorgasbord is usually part of a lunch or dinner setup | \u2022 Fish\n\u2022 Cabbage\n\u2022 Whole wheat bread\n\u2022 Cheese\n\u2022 Potato\n\u2022 Biscuits\n\u2022 Cookies\n\u2022 Forcemeat\n\u2022 Herring | 1. Biksemad\n2. Salmon\n3. Steak and Potatoes\n4. Salmon Sushi with Barley, Rice\n5. Frikadeller\n6. Kraftor med dill\n7. Stekt Stromming\n8. Dillkott\n9. Tjalknol\n10. Rostad Hjortstek |\n| Germany | Western Europe | \u2022 Adopted many cooking methods from Italy and France\n\u2022 Preservation is used in many ways\n\u2022 Herbs like parsley celery and dill are used\n\u2022 Spices like Juniper berries, horseradish and mustard are used\n\u2022 All forms of dairy are used | \u2022 Pork\n\u2022 Sausages\n\u2022 Potatoes\n\u2022 Bread\n\u2022 Cabbage\n\u2022 Trout\n\u2022 Apple\n\u2022 Meat\n\u2022 Cold cuts\n\u2022 Preserves\n\u2022 Cheese | 1. Currywurst\n2. Frikadellen (German meat balls)\n3. German Bienenstich\n4. Apfelstrudel\n5. Kartoffelsalat\n6. Kasekuchen\n7. WeisseBohnensuppe\n8. Bratwurst\n9. Kartoffelkn\u00f6deln\n10. Rotkohl |\n| Middle East | Egypt, Iran, Iraq, Turkey, Saudi Arabia, Yemen, Syria, United Arab Emirates, Israel, Jordan, Palestine, Lebanon, Oman, Kuwait, Qatar, Bahrain | \u2022 Bulghur cracked wheat, which is husk removed, steamed and crushed wheat; is the most common form of wheat.\n\u2022 Olive oil is an important ingredient\u00a0\n\u2022 Coriander is an essential spice.\n\u2022 Elaborate dips are used with most dishes\n\u2022 Food is consumed, Communally | \u2022 Wheat\n\u2022 Lamb\n\u2022 Mutton\n\u2022 Cheese\n\u2022 Eggplant\n\u2022 Melon\n\u2022 Nuts\n\u2022 Dips like hummus, tabbouleh, mutabbal | 1. Shorbat adas\n2. Fattoush\n3. Falafel\n4. Menamen\n5. Pogaca\n6. Pilaf\n7. Arak\n8. Kunafeh\n9. Qatayef\n10. Qara\u2019 \u2018Asali |\n| Oriental | China, Vietnam, Laos, Korea, Japan | \u2022 Aniseed, Chinese prickly ash seed, and cinnamon are used to add aroma\n\u2022 Soy sauce, vinegar, sugar and salt are used in varying quantities to produce distinctive flavors according to regions\n\u2022 Thai food has coconut oil, and fresh herbs as important ingredient\u00a0\n\u2022 Vietnamese cuisine focuses on a harmony of spices, sourness, salt, sweet and bitter\n\u2022 Stir-frying, steaming and deep-frying are common cooking methods. | \u2022 Rice\n\u2022 Soy\n\u2022 Bok choy\n\u2022 Mint\n\u2022 Cilantro\n\u2022 Basil\n\u2022 Mutton\n\u2022 Tea\n\u2022 Sea food\n\u2022 Mung beans | 1. Bun cha\n2. Teriyaki rib eye steaks\n3. Oyako Donburi\n4. Cha ca\n5. Bun bon am bo\n6. Roast squab\n7. Yeung Chow\n8. Dau Fu Fa\n9. Sai mai lo\n10. Braised Abalone |\n| Mexican | Latin America | \u2022 Chilli is the main stimulant for taste\n\u2022 Cumin, cinnamon, cloves, coriander are used as essential flavouring agents\n\u2022 Eggs are widely used for cooking\n\u2022 Tortillas, the bread in Mexico is eaten in every meal\u00a0\n\u2022 Jalapeno is predominant spice | \u2022 Beans\n\u2022 Rice\n\u2022 Meat\n\u2022 Corn\n\u2022 Chilli\n\u2022 Habaneros\n\u2022 Jalape\u00f1os\n\u2022 Poultry | 1. Enchiladas\n2. Fajita\n3. Chimichanga\n4. Chorizo\n5. Pork and poblano\n6. Chocinita pibil\n7. Capirotada\n8. Cabrito\n9. Mojarra Frita\n10. Birria |\n| Arabic | Eastern Arabia, Morocco, The Levant, Libya, Tunisia, Algeria, Somalia, Sudan | \u2022 Butter and cream are extensively used\n\u2022 Sesame, black pepper, saffron, turmeric, garlic, cumin are principal spices.\n\u2022 Nuts are used in preparation as well as snacks\n\u2022 Olive oil is an important ingredient\u00a0\n\u2022 Parsley, coriander and mint are regular seasonings | \u2022 Coffee\n\u2022 Rice\n\u2022 Wheat\n\u2022 Lentils\n\u2022 Meat from large animals | 1. Kabsa\n2. Tilapia filet\n3. Syrian oven potato\n4. Sheikh al Mihshi\n5. Mejaddara of rice\n6. Mohallabiah\n7. Khabeesa\n8. Mafruka\n9. Oyoun el-maha\n10. Ghoraybah |\n\nPlease write in English language.", "Career Exploration Report \n\\*\\*Due Date: Week 7, Wed 29 Mar, 4 pm\\*\\*\n\n[Career Fit Analysis Draft](https://www.notion.so/Career-Fit-Analysis-Draft-319f354ad3e844dca00e50b5b9d2cd85)\n\nPurpose:\n\nThis exercise provides you with an opportunity to systematically investigate two careers and/or jobs you are interested in pursuing, as well as to network with two people who are in your chosen careers and/or jobs.\n\nOverview:\n\nYou will conduct research on two careers/jobs. The research will entail networking with and interviewing a suitable person in each career. In conducting this research, you will obtain a broad understanding of these careers/jobs, validate or invalidate the assumptions and uncertainties you hold concerning these careers/jobs, and explore other questions that you may have concerning those careers. You will then write a report analyzing your networking experience and what you have learned about the two careers/jobs. You will also describe the next steps in your career planning and the lessons learned in light of this analysis.\n\nRequired Format:\n\n\\*\\*Step 1: Identify two career(s) and/or job(s) you are currently interested in pursuing (approx. 150 words)\\*\\*\n\nA student might be interested in two career areas: human resources and marketing. Another might be interested in one job (e.g., advertising manager) within the marketing major and one career (e.g., entrepreneur). Obviously, some careers and jobs may seem more viable to you than do others, but it is important to provide a comparison of two careers/jobs.\n\nDrawing on academic sources (from Week 1 readings and lecture), define career and job. Based on these definitions, explain \\*\\*\\*whether and how\\*\\*\\* the chosen careers or jobs represent careers or jobs TO YOU.\n\n\\*\\*Step 2: Identify assumptions/beliefs and uncertainties (in Appendix)\\*\\*\n\nFor each of the careers or jobs, identify the following:\n\n1. Two positive assumptions/beliefs you have concerning the career/job.\n2. Two negative assumptions/beliefs you have concerning the career/job.\n3. Two uncertainties you have concerning the career/job.\n\nIn deciding which careers/jobs to pursue, you will have made implicit assumptions about your future compensation, the nature of your work, type of job difficulties, and forms of satisfaction and dissatisfaction in this future career. Some of these assumptions and beliefs will be true, whereas others will be false. Nevertheless, it is important for you to validate your assumptions and beliefs as you pursue your studies and before you seek employment.\n\nList the assumptions/beliefs and uncertainties for each career/job that are most important to you in the form of statements in an Appendix. Clearly label each - a) positive or b) negative assumption or c) an uncertainty.\n\n\\*\\*Step 3: Translate assumptions/beliefs and uncertainties into questions for each career/job (in Appendix)\\*\\*Translate the assumptions/beliefs and uncertainties you have identified in Step 2 into a series of questions to be asked of your interviewees. The reader should be able to \\*easily identify\\* which question is written for which assumption and uncertainty (a table format may help).\n\nHow? To translate your assumption that one needs a Bachelor\u2019s degree for a job into a question, you might ask what educational background is needed to get this job. Or, you assume that this career requires a significant time commitment and thus you believe that you will not achieve a work-life balance. Your questions might then be: What is the average number of hours you work in a typical week? How has this career impacted you and your family and your work-life balance? How are you managing your work-life balance? Or, you have a positive assumption that this career provides you with lots of travel opportunities. Your question might entail: To what extent are there national and international travel opportunities in this career? What do those opportunities usually entail \u2013 attending meetings and trade shows, running workshops, etc?\n\n\\*\\*Step 4: Choose and contact at least one person to interview, analyze and reflect on the networking process and describe one lesson learned from this \\*networking experience\\* (approx. 300 words)\\*\\*\n\nIdentify and contact the people you wish to interview. The choice of who to interview is extremely important. It is best for you to identify the type of individual who would best answer your questions instead of contacting someone who is merely the most convenient. Use some of the criteria presented in Week 1 as a guide when you are identifying interviewees. Remember, professionalism begins with your initial contact. Do not interview by SMS or email. These interviews should be conducted face-to-face (or virtually with webcams on, if impossible to arrange).\n\nOnce the relevant criteria are chosen, identify who matches those criteria. Sources of contacts include alumni, friends, parents of other students, members of professional organizations, those you meet in networking events, etc. See Week 1 tutorial slides for more suggestions.\n\nFollow the contact tips in Week 1 slides,\n\nIn the Report:\n\na) State who you interviewed. The interviewees can remain anonymous if they wish, but please provide their job titles and type of companies (e.g., size, location) in which they work. State whether it was conducted face-to-face (or virtually - explain why a face-to-face meeting was not possible)\n\nb) Analyse and reflect on this networking experience. Draw on \\*at least 1 concept from the course\\* (with proper citation of course reading(s) and lecture/tutorial material(s)) when analyzing this \\*process\\*. The application of course concept(s) to this experience should help you answer the questions of \u201cwhy\u201d and \u201chow\u201d and thus deepen your reflection.\n\nc) Describe one lesson you have learned about networking in light of your analysis and reflection on this networking experience.\n\n\\*\\*Step 5: Summarize and reflect on the findings. (approx. 700 words)\\*\\*\n\nDiscuss the following:\n\na) How have your research and interview findings validated or invalidated your assumptions/beliefs and uncertainties about these careers/jobs? Summarize one or two findings for each career that are most important or surprising to you.\n\nb) Have your career plans been adjusted as a result of this exercise? If so, how? If not, why not? Be sure to describe your specific plan moving forward and explain why your plan is a reasonable and/or effective one based on your findings. The plan should include activities related to personal development, specific career/job search strategies, etc. Draw on \\*at least 1 concept from the course\\* (with proper citation of the academic source) for a and/or b to analyze and deepen your understanding of the findings and/or explain how they impact you and your career plan. Again, this application of course concept(s) to your findings/plan should help you answer the questions of \u201cwhy\u201d and \u201chow\u201d and thus deepen your reflection. This analysis should then lead you to reflect on a specific lesson learned about your career/job (i.e., c below).\n\nc) Describe the most important lesson you have learned about the careers/jobs in light of your analysis and reflection on your interview findings.\n\n\\*\\*Include Reference list and Appendices\\*\\*\n\nYou must cite all work properly throughout your report in [Harvard style](https://student.unsw.edu.au/referencing) and provide a reference list. You do not need to cite references \\*not\\* covered in the course. You must also include a list of assumptions/beliefs and uncertainties, as well as the associated interview questions in the Appendix.\n\nYou may use standard editing and referencing software (e.g., Microsoft Office suite, Grammarly, etc.), but \\*\\*\\*not\\* generative AI\\*\\*.\n\nReview resources on [how to write a reflective report](https://student.unsw.edu.au/reflective-writing).\n\n\\*\\*Note: All contents will be treated in strict confidence and with great respect.\\*\\*\n\n\\*\\*MARKING CRITERIA FOR CAREER EXPLORATION REPORT\\*\\*\n\n| Key Criteria | Grade |\n| --- | --- |\n| 1) Step 1\n\u2022 Identify two career(s) and/or job(s).\n\u2022 Career and job are defined in an accurate and scholarly manner.\n\u2022 Drawing on their academic definitions from the course, explain whether and how the chosen career(s) and/or job(s) represent career(s) or job(s) to you. | /2 |\n| 2) Step 2\n\u2022 Two positive assumptions/beliefs, two negative assumptions/beliefs and two uncertainties about each preferred career and/or job are listed in an Appendix. | /3 |\n| 3) Steps 3a and 3b\n\u2022 Questions, phrased in a professional manner, are accurately translated in a way that solicits responses that validate or invalidate each assumption/belief and uncertainty. This should be clearly presented in an Appendix next to each relevant assumption and uncertainty. | /2 |\n| 4) Step 4\n\u2022 Interviewed 2 relevant individuals.\n\u2022 Thoughtful application of course concept(s) when analysing the process.\n\u2022 Quality and depth of analysis of and reflection on the networking process.\n\u2022 Describe one lesson learned about networking in light of the analysis and reflection. | /8 |\n| 5) Step 5\n\u2022 Quality and clarity of the summary of findings (i.e., Step 5a)\n\u2022 Quality and depth of analysis of and reflection on the findings (i.e., Steps 5b and c): Thoughtful application of course concept(s) when analysing the findings. The reflection includes career plans change vs. no change, specific plans moving forward, and a lesson learned in light of the analysis. | /8 |\n| 6) Written construction and presentation are clear, concise, and logical (e.g. At least 2 academic readings are used and integrated in the reflection; Harvard style referencing; no spelling errors; work is edited; written expression is clear; all sections of the assignment are present; paragraphs are well developed; content is conveyed clearly). | /2 |\n| 7) Late penalty yes/no | - |\n| Total | /25 |\n\nWrite based on the above prompt, using the careers of a Product Manager, and a Business Analyst, based on the word count that are stated in each prompt", "The brackets below is article about Gift Range Chart. I am now selling Gift Range Chart and I am building a website landing page. Can you give me some more website headers like \"A simple yet powerful tool to plan and manage a successful capital campaign\"\n\n[If I had to pick the most important of resources to lead you through a successful capital campaign, it would be the gift range chart. You may also know it as a gift table.\n\nIn this post, you\u2019ll learn the basics of Gift Range Charts and discover the related tools that will help create a plan for your campaign.\n\nQuick Links \u2014 Click on any of the links below to jump ahead and learn the essentials about Gift Range Charts:\n\nCapital Campaign Gift Range Chart: An Overview\nCreating Your Capital Campaign Gift Range Chart\nGoing Beyond the Gift Range Chart\nTools to Create Your Capital Campaign Gift Range Chart\nConclusion: Making Sense of Your Campaign\nRead on and learn about how Gift Range Charts (also known as gift tables) are created and used.\n\nAlready know you want hands-on guidance developing your gift range chart? Request a free strategy session today!\n\nCapital Campaign Gift Range Chart: An Overview\n\nCapital Campaign Gift Range Chart: An Overview\nIf you\u2019ve been through a capital campaign before, you are likely familiar with this important tool. If you use this tool correctly, you\u2019ll be well on your way to leading a successful campaign.\n\nWHAT IS A GIFT RANGE CHART?\nA Gift Range Chart provides a framework for the number of gifts, at each gift amount, that you\u2019ll need for a successful campaign.\n\nThe Gift Range Chart is the primary tool for your campaign because it will clarify your campaign goal and help you determine your chances for success at a specific goal amount. But the right Gift Range Chart for your campaign will become the backbone of your campaign in many other ways as well.\n\nA Gift Range Chart will enable you to:\n\nSort your donors by ask amounts\nEstablish the pattern of gifts you\u2019ll need for your campaign\nCreate a strategic order for soliciting gifts\nProvide a logical approach to quantifying the number of prospects you\u2019ll need for your campaign\nHelp your board understand what campaign success is going to take\nShow your top donors where their gifts will fit into the campaign\nTrack and report on your campaign progress\nDevelop a rational plan for donor communication, recognition and naming opportunities\nSAMPLE GIFT RANGE CHART\nYou\u2019ll find several tools to help create your Gift Range Chart in the \u201cPre-Campaign Planning\u201d section of the Capital Campaign Toolkit. Here\u2019s a sample Gift Range Chart to use as a reference:\n\nSample Gift Range Chart for a Capital Campaign\n\nCreating Your Capital Campaign Gift Range Chart\n\nCreating Your Capital Campaign Gift Range Chart\nIn the sample Gift Range Chart in the preceding section, you can see that the top gift is 20% of the campaign goal. And, the first seven gifts take you to $1.4 million \u2014 more than halfway toward the goal.\n\nThe top group of 15 gifts take you to $1.8 million, or 72% \u2014 nearly three-quarters of the way to the campaign goal.\n\nThis pattern, showing a few gifts accounting for a large proportion of the campaign goal, is common for capital campaigns. In most campaigns, the top gift is 20% or 25% of the campaign goal. In some cases, it\u2019s even higher. In fact, only 10 gifts account for at least half the goal in the vast majority of capital campaigns.\n\nOn the other hand, you can see that the remaining gifts \u2014 those of $25,000 or less account for less than 30% of the goal.\n\nOf course, the amounts on this chart are for example only. One standard pattern does not work for every campaign. Your Gift Range Chart will have to reflect the size of your donor base. The smaller your donor base, the larger the gifts in the top of the chart will have to be.\n\n7 TIPS TO CREATE YOUR GIFT RANGE CHART\nHere are seven tips that will help you create a Gift Range Chart for your organization.\n\nBuild your gift chart by starting with the top gift which should be at least 20% of your campaign goal.\nThen work down, increasing the number of gifts as the size of the gifts goes down.\nThe number of gifts in the first column should increase in a rational pattern as the size of the gifts decreases.\nThe gift amounts should be simple and standard to reflect a generic pattern rather than specific gifts you may already have in.\nYou will need 2, 3 or even 4 times the number of prospects than the number of gifts. The prospect multiplier depends on how well you know your donors.\nThe total number of prospects you show in your chart should be no larger than the number of qualified prospects you have in your donor base.\nIf when you get to the bottom of your chart, you find that you need more prospects than you have, go to the top and increase the number of gifts at the top.\nWant one-on-one guidance to help create your campaign\u2019s gift range chart? Just reach out\u2014we\u2019ll be happy to help!\n\nGoing Beyond the Gift Range Chart\n\nGoing Beyond the Gift Range Chart\nThe Gift Range Chart will serve as a roadmap for your campaign. You will use a Depth Chart to add prospect names to each giving level you have decided on in your Gift Range Chart.\n\nFROM GIFT RANGE CHART TO DEPTH CHART\nOnce you\u2019ve created a Gift Range Chart for your campaign, you\u2019ll develop a \u201cDepth Chart\u201d which will attach specific prospective donor names to each gift required for a successful campaign.\n\nSimply take each of the top giving levels and use them as column headers. In each header, indicate how many gifts you will need at that level and how many prospects that will require:\n\nCapital Campaign Depth Chart\n\nNext, start filling out the names of people you can credibly ask for a gift at that level for your campaign. Sorting your donors into columns is done by evaluating their current giving, their potential to give, and their likely inclination.\n\nAs you fill out the Depth Chart, you will clearly see where you have enough qualified prospective donors and where you fall short. If you don\u2019t have any prospect names for the top three levels, you probably need to go back to the drawing board and reduce your campaign goal.\n\nOnce your depth chart has been filled in, you will use it to organize the order of solicitation. You\u2019ll prioritize the top donors to solicit first and then gradually work down to the smaller gifts as laid out on the depth chart.\n\nUSING THE GIFT RANGE CHART TO SOLICIT GIFTS\nOnce you have your depth chart and you start talking to your donors about making gifts to the campaign, you will once again find the gift range chart to be helpful. You should always include a copy of the gift range chart in the materials you take to your donors. When you show it to them, they will be able to see where they might fit in the community of donors. While a donor\u2019s ability to make a gift is important, most donors like to know where their gift fits.\n\nSome donors want to be lead donors. And your chart will show them what that gift would be. Others might not want to be the lead donor but would like to make a significant gift to the campaign. Again, looking at the gift range chart will help them understand the range of giving and where they might place themselves in the community of donors.\n\nTRACKING CAMPAIGN PROGRESS WITH THE GIFT RANGE CHART\nGift range charts have a way of making the essence of a capital campaign clear. So, as gifts come in, you will check them off on your gift range chart. Gradually, as your campaign moves forward, you will see graphically, in a simple way, the progress your campaign is making and what gifts have yet to be committed. Your board members and executive staff will appreciate this very simple tracking devise. It\u2019ll give them a sense of confidence to see the top gifts fill in from the top down.\n\nTools to Create Your Capital Campaign Gift Range Chart\n\nTools to Create Your Capital Campaign Gift Range Chart\nThe sample Gift Range Chart in this post is one of a number of tools available in the Capital Campaign Toolkit\u2019s Pre-Campaign Planning section. Other tools include:\n\nGift Range Chart Calculator\nGift Range Chart Worksheet\nDepth Chart Worksheet\nOther related tools include a plan for your donor recognition guide based on the levels in your Gift Range Chart.\n\nIf you\u2019re eager to utilize these tools for your campaign, check out the different Toolkit options here. Most options include campaign advising, giving you professional support at a fraction the cost of a campaign consultant.\n\nVIDEO: GIFT RANGE CHARTS = YOUR MOST POWERFUL TOOL\nTo learn even more about creating a Gift Range Chart for your campaign, watch the following video (approximately 17 minutes):\nConclusion: Making Sense of Your Campaign\n\nConclusion: Making Sense of Your Campaign\nBecause capital campaigns go on for many months (or even years), you may find it easy to get confused about where you should be putting your efforts during the seven phases of the campaign.\n\nIf, however, you coordinate your campaign plan to a Gift Range Chart, then, when you\u2019re feeling lost, you\u2019ll know where to turn. You\u2019ll look at your chart to review which groups of donors have been solicited, as well as which are next up.\n\nYou may tie your staffing responsibilities to the donor levels of the Gift Range Chart. And you will certainly create a timetable for your campaign that prioritizes the work of the campaign according to giving level, starting with the largest gifts and working down.\n\nAnd even when considering how to thank and recognize donors, once you start thinking about it from the perspective of the giving levels in your Gift Range Chart, all of the planning will fall into place.\n\nA GIFT RANGE CHART MINIMIZES CONFUSION AND BUILDS CONFIDENCE\nWhen you organize your campaign based on a clear top-down strategy as mapped out in the Gift Range Chart, you will minimize confusion and build confidence in the campaign process.\n\nA Gift Range Chart may appear to be a simple planning devise, but when you use it as the essential structure for your campaign, you\u2019ll find that everything falls into place.\n\nHave more questions about capital campaigns or want one-on-one help crafting your strategy? Check out our complete FAQ guide or get in touch. We\u2019ll be happy to help!]", "Write me a title for this article:\nAs a homeowner in NSW, it's vital to understand the legal mechanisms governing contractual obligations transfer. One such mechanism is Deed of Novation, useful when businesses change name or transfer contracts to third parties. This article explores Deed of Novation's definition, its importance to homeowners, and its differences from other legal mechanisms. By the end, you'll have a better understanding of Deed of Novation's relevance to homeowners in NSW.\nWhat is a Deed of Novation?\nA deed of novation is a legal document that allows one party to transfer its rights and obligations under an existing contract to a new party, who takes on these responsibilities and benefits from the original contract. This document enables the original party to be released from the contract while the new party assumes all legal obligations and rights under the agreement. \n\nNovation is typically used when a business undergoes significant changes such as mergers, acquisitions, or restructuring, and there is a need to transfer existing contractual agreements to a third party.\n\nNovation differs from an assignment in that it transfers all rights and obligations, while an assignment only transfers contractual benefits. It is essential to understand the implications of novation and seek legal advice to ensure that the deed is legally binding and effectively transfers contractual rights and obligations.\nKey Components of a Deed of Novation\nA deed of novation is a simple and effective tool for transferring the rights and obligations of one party under a contract to a third party. \n\nHere are the key components that a deed of novation should include:\n\nNovation or Effective Date\nThe novation or effective date is the date on which the new party will assume all the rights and obligations under the original contract. This date is critical, as it marks the point at which the transfer of rights and obligations takes place.\n\nRelease\nA release clause in a deed of novation releases the original party from all the obligations and liabilities under the contract from the date of novation. This clause ensures that the original party is no longer liable for any obligations or liabilities under the contract.\n\nRepresentations and Warranties\nRepresentations and warranties are promises made by both parties regarding the validity of the contract and their authority to enter into it. They also ensure that both parties are aware of each other's obligations and liabilities under the contract.\n\nFees and Payments\nThe fees and payments clause outlines any fees or payments that either party must make under the contract. This clause is critical, as it ensures that both parties are aware of their financial obligations under the contract.\n\nIt is essential to ensure that all these key components are included in the deed of novation to ensure that the transfer of rights and obligations is complete and legally binding. It is always recommended to consult with a legal professional before drafting or signing any legal documents.\n\nBenefits of a Deed of Novation\nA Deed of Novation offers several benefits to parties involved in a contract. By using a Deed of Novation, you can transfer your rights and obligations under an existing contract to a third party, without the need for extensive negotiation or the termination of the original contract. This can save time, money and resources, especially if the transfer involves complex contracts or multiple parties.\n\nOne of the key benefits of a Deed of Novation is that it allows you to simplify the process of transferring contractual obligations. Rather than renegotiating a new contract, you can simply transfer the existing contract to a new party. This can be particularly useful in situations where you are selling your business or restructuring your operations.\n\nAnother advantage of a Deed of Novation is that it minimizes the need for negotiation. Since the terms of the original contract remain the same, you can avoid lengthy and complicated negotiations with the other party. This can make the process of transferring contractual obligations more straightforward and efficient.\n\nFinally, a Deed of Novation can help you avoid the termination of existing contracts. If you need to transfer your contractual obligations to a third party, but do not want to terminate the existing contract, a Deed of Novation may be the best option. This way, you can transfer the obligations to a new party, while keeping the existing contract intact.\n\nRisks Associated with a Deed of Novation\nWhile a deed of novation is a useful legal tool, it is important to be aware of the potential risks that come with it. Here are some of the most significant risks to consider:\nUnforeseen obligations and liabilities: When entering into a deed of novation, it is essential to carefully consider the obligations and liabilities that are being transferred. There may be unforeseen obligations or liabilities that the new party may not be aware of, which could lead to disputes or legal action in the future.\nLack of clarity regarding the terms of the novation: A deed of novation must clearly outline the terms of the agreement to avoid any confusion or misunderstandings between the parties. Without clear and concise terms, there is a risk that the parties may have different interpretations of their obligations and responsibilities.\nThe need for careful consideration and legal advice: As with any legal agreement, it is important to seek professional legal advice before entering into a deed of novation. This will ensure that you understand the legal implications of the agreement and the risks associated with it.\nBy being aware of these risks and taking the necessary precautions, you can mitigate potential issues and ensure that the novation process runs smoothly.\n\nCommon Scenarios for Using a Deed of Novation\nA deed of novation can be a useful legal instrument in several scenarios, some of which include:\nSale or transfer of a business: If you're selling your business or transferring its ownership to another entity, a deed of novation can help transfer the contracts and obligations to the new owner.\nChanges in business structure: When you change your business structure, for example, from a sole trader to a company, a deed of novation can be used to transfer the contractual obligations to the new entity.\nTermination of contracts: A deed of novation can be used to transfer the obligations and rights under a contract to a third party, effectively terminating the contract.\nIt's important to note that while a deed of novation can be a useful legal tool in these scenarios, it's essential to obtain legal advice to ensure that the novation is done correctly and that all parties understand their rights and obligations.\n\nHow to Draft a Deed of Novation\nA Deed of Novation is a legal document that requires careful drafting to ensure that the transfer of obligations and rights is carried out smoothly and effectively. As such, it is important to seek legal advice from a qualified lawyer experienced in drafting and executing such deeds. Here are some key considerations to keep in mind when drafting a Deed of Novation:\nImportance of Legal Advice\nIt is essential to seek legal advice before entering into a Deed of Novation. A qualified lawyer can guide you through the process, identify any potential legal issues, and ensure that the deed is legally binding and enforceable.\nKey Considerations When Drafting a Deed of Novation\nWhen drafting a Deed of Novation, it is important to consider the following:\nParties involved - Clearly identify the parties involved in the novation, including the original parties, the new parties, and any other relevant parties.\nNovation or Effective Date - Clearly state the date from which the novation applies to the parties.\nRelease - Include a clause releasing the original party from all performance of the contract from the novation date.\nRepresentations and Warranties - Include any representations or warranties made by either party.\nFees and Payments - Include any fees or payments to be made by either party.\nSample Deed of Novation\nHere is an example of a Deed of Novation template:\n[Insert date of novation]\nDeed of Novation\nParties\n[Insert original party name], (ACN/ABN [Insert ACN/ABN]) of [Insert address] (Original Party);\n[Insert new party name], (ACN/ABN [Insert ACN/ABN]) of [Insert address] (New Party).\nBackground\n[Insert details of the original contract].\nAgreed Terms\n[Insert details of the novation, including the novation or effective date, release, representations and warranties, and fees and payments].\nExecution\nExecuted as a Deed.\nExecuted by:\n[Insert name of Original Party]\n[Insert signature of Original Party]\n[Insert name of New Party]\n[Insert signature of New Party]\n\nSigning a Deed of Novation\nOnce the Deed of Novation has been drafted, it's time to execute it. The signing of a Deed of Novation is an essential step that requires careful consideration. The following are key points to keep in mind when signing a Deed of Novation:\n\nRequirements for signing a Deed of Novation:\n\nAll parties involved in the agreement must sign the Deed of Novation.\nThe signatures of witnesses may also be required, depending on the jurisdiction and the terms of the agreement.\nThe date of execution must be clearly stated on the Deed of Novation.\n\nImplications of a poorly executed Deed of Novation:\n\nThe failure to comply with the necessary legal requirements can result in the Deed of Novation being invalid, which could create legal problems down the line.\nIncomplete or unclear Deeds of Novation can cause confusion and lead to disputes.\n\nIt is therefore recommended that parties seek legal advice when executing a Deed of Novation to ensure that all legal requirements are met and that the document is executed correctly.\n\nConclusion\nIn conclusion, a Deed of Novation is an important legal document that can be used in a variety of scenarios to transfer contractual obligations. While there are benefits to using a Deed of Novation, there are also risks that must be carefully considered. Seeking legal advice is crucial to ensure that the document is drafted correctly and executed properly. \n\nAt Contracts Specialist, we offer a free consultation to homeowners in NSW who are considering a Deed of Novation. Contact us today to schedule a meeting with one of our experienced lawyers.", "We are in the process of designing software operation level descriptors. The level descriptor of a leveling system is a framework used to define and categorize roles, responsibilities, and career progression paths for employees, providing a structured approach to career growth, compensation, and performance evaluation. \n\nHere are the company level descriptors with 4 dimensions that apply to all functions.\n\nScope & Impact\nL1: \"Responsible for tasks where the scope is fully defined that require following pre-established protocols for completion. Requires significant detailed direction and supervision to resolve most problems.\" \nL2: \"Responsible for tasks of limited scope. Adheres to established practices and procedures for resolving problems. Receives close supervision and direction when approaching most problems.\" \nL3: \"Responsible for tasks and projects of moderate scope that require synthesis of information including a plurality of factors and variables. Uses independent judgment and knowledge of existing procedures and practices to determine appropriate resolution for a given problem, including matters of significance. Beginning to approach novel problems; receives close supervision and direction on novel problems.\" \nL4: \"Responsible for tasks and projects of variable scope where synthesis and analysis of information involves evaluation of identifiable components. Practices good judgment in selecting appropriate strategy for resolution of problem. Scope of work impacts a team. Consistently approaches novel problems. Receives supervision on novel problems and situations.\" \nL5: \"Responsible for solving complex issues where analysis of situations or data requires an in-depth evaluation of variable factors. Exercises judgment in selecting methods, techniques and evaluation criteria for obtaining results. Scope of work impacts a team, and may impact their org. Approaches problems with little direct supervision; often proactively identifies new problem spaces and provides recommendations on solutions or new workstreams.\" \nL6: \"Responsible for solving significant and unique problems where analysis of situations or data requires an evaluation of intangibles. Exercises independent judgment in methods, techniques and evaluation criteria for obtaining results. Scope of work primarily impacts their team and org, and may impact the company. Works independently on most problems, often identifies new problem spaces and strategies for solving for their team and org.\" \nL7: \"Responsible for innovating the resolutions for their org's most complex and challenging trade or technical problems. Scope of work has identifiable impacts on the company. Requires almost no direct supervision in their domain. Provides significant insight and input to their manager and functional leaders regarding direction.\"\n\nKnowledge & Skills: \nL1: \"Applies org policies and procedures to resolve routine issues. Developing in their ability to learn and use professional concepts.\" \nL2: \"Applies org policies and procedures to resolve routine issues. Developing in their consistent use of professional concepts. Able to perform highly structured, entry-level work designed to develop broader and more in-depth knowledge and skill to perform higher-level assignments\" \nL3: \"Consistently applies org policies and procedures to resolve a diverse set of problems. Possesses essential professional expertise. Able to advise on and/or resolve moderately complex but well-precedented projects for which there are one or more readily apparent solutions.\" \nL4: \"Possesses a full and deep understanding of their functional area. Applies knowledge consistently, with accuracy, to resolve a wide range of problems in novel and creative ways. Skilled in applying this knowledge to difficult and complex work assignments to the development of new methods and approaches to enhance existing processes.\" \nL5: \"Possesses trade or technical experience and knowledge that is deep and wide-ranging. Applies expertise accurately and with creativity to innovate solutions. Able to provide significant and innovative recommendations for advancing programs and/or methods; identifies and proposes solutions to organizational challenges.\" L6: \"Possesses expert trade or technical experience and knowledge that is deep and wide-ranging. Independently applies expertise accurately and with creativity to innovate solutions. Able to serve as an authoritative expert and consultant with broad organizational responsibility. \" \nL7: \"Serves as an expert within the company as well as in the field, more broadly. Explores and develops best-in-class professional concepts in identifying solutions for company-wide and industry objectives. Able to serve as an authoritative expert and consultant in a critical organizational field and/or in a large program with organizational responsibility and community impacts.\"\n\nStakeholder Interaction \nL1: \"Essentially no collaboration with other stakeholders outside of receiving guidance, mentorship, and coaching from their direct supervisor.\" \nL2: \"Limited formal collaboration with other stakeholders outside of receiving guidance, mentorship, and coaching from their direct supervisor.\" \nL3: \"Works with stakeholders within their team and org. May work across teams or with peers in other orgs on cross-functional projects. Helps to produce content and deliverables to synthesize findings.\" \nL4: \"Works with stakeholders within their team and org. May work across teams or with peers in other orgs on cross-functional projects. Produces significant content and deliverables to synthesize team findings.\"\nL5: \"Consistently works independently with stakeholders within their team and across their org. May partner with peers from other orgs on cross-functional projects. Reports on progress against key deliverables to other managers within their team and sometimes their org.\" \nL6: \"Consistently works closely with stakeholders within their team and their org. Often partners with peers from other orgs on cross-functional projects. Reports on progress against key deliverables to other managers and leaders within their org and sometimes the company.\" \nL7: \"Independently identifies and works closely with stakeholders on their team, in their org, and throughout the company, always serving as the SME in their domain. Shares key learnings, findings, and concepts with senior leaders throughout the company.\"\n\nLeadership\nL1: \"Possesses some understanding of their own trade/technical and interpersonal skills. Works to achieve the confidence of others by following company and team culture and values.\" \nL2: \"Possesses a developing understanding and awareness of their own trade/technical and interpersonal skills. Works to achieve the confidence of others by adapting to company and team culture and values.\" \nL3: \"Strong understanding and awareness of their own trade/technical and interpersonal skills. Eager to achieve the confidence of others by adapting to company and team culture and values. Reliably contributes to an environment of productivity and engagement.\" \nL4: \"Able to help develop trade/technical skills of more junior team members. Inspires confidence by displaying behaviors that lead to productive working relationships. Frequently embodies team culture, lives team norms, and contributes to an environment of engagement and productivity.\" \nL5: \"Able to mentor and develop trade/technical skills in more junior team members. Inspires confidence by displaying behaviors that lead to productive working relationships. Frequently embodies team culture, lives team norms, and contributes to an environment of engagement and productivity.\" \nL6: \"Skilled at mentoring and developing other team members. Builds trust by displaying aptitudes that lead to healthy working relationships and teams. Frequently embodies team culture, lives team norms, and helps to maintain an environment of high engagement and productivity.\" \nL7: \"Expert at mentoring and developing other team members, of varying seniority. Builds trust by displaying aptitudes that lead to healthy teams. Embodies team culture, lives team norms, and helps to maintain an environment of high engagement and productivity.\"\n\nFor software operation level descriptors, we are adding two additional dimensions on top of company level descriptors, and here is a draft for L3 to L6. \n\nProblem Solving\nL3: \"With limited guidance, completes work for an operational pipeline, ensuring the end product meets well defined requirements. Provides effective training/feedback around operational guidelines and tooling to optimize workflows. Applies critical thinking to assist with decision making strategies and QA methodologies.\" L4: \"Takes ownership and efficiently improves operational guidelines and practices used to achieve the team\u2019s deliverables. Creatively provides solutions to problems outside of defined workflows, takes inputs from stakeholders and management effectively. Works with stakeholders to maintain and scale optimization of team's operational workflows, driving significant value to the overall objectives.\" \nL5: \"Proactively improves various operational pipelines throughout the department by taking responsibility for the design, deployment, and maintenance of workstreams. Leverages strong knowledge of operational pipelines to provide inputs to upstream data providers, downstream stakeholders/consumers, support tooling teams, and cross team collaborators to enable them to be more effective.\" \nL6: \"Expert in identification of key issues and finding resolutions for complex business problems. Responsible for special strategic efforts; determines an optimal path where there is little to no precedent, processes or data. Track record of developing the team/pipeline through mentorship/documentation; translates efforts into wider processes for the org and/or company to run productively.\"\n\nProject Management & Execution\nL3: \"Follows guidelines well and achieves planned goals at required quality gate(s). Clearly communicates to peers, leads, and/or SWEs on critical topics and provides guidance related to assigned project(s).\" \nL4: \"Consistently produces or delivers high quality output for operational task(s). Builds trust with internal and/or external cross team stakeholders to drive initiatives that support project stability. Works alongside SWEs on tooling improvements with accurate characterization of requirements and their impact.\" \nL5: \"Collaborates with project managers and department leads on best operational techniques and methodology; cognizant of resource/budget allocation. Works with external partners to design and implement reliable, scalable, and data driven process improvements for the team and overall department\" \nL6: \"Oversees E2E components of an operation, including roadmap design, resource/budget management, and timely execution according to business needs. Takes the lead in making informed and strategic decisions through industry-related product, business, and process acumen\"\nThe feedbacks for the above are\n- Wording can be more professional, consistent with the company level descriptor and with less subjectivity.\n- Level descriptor has progression and continuity from lower level to higher level\n- The idea of external partners is introduced at L5 in project management and execution\n- Would prefer to see some more clear language around L6 being company level impact and L5 being org level impact and how that would be seen. \n- Remove unnecessary adjectives, for example, \"Follows guidelines well\" => \"Follows guidelines\"\nPlease refine the draft based on the feedback above. Output the response in a table format.", "Summarize this section for me:\n\nSEC. 7. RESOLUTION OF DISAPPROVAL OF DESIGNATION OR REMOVAL OF \n DESIGNATION OF A FOREIGN ADVERSARY.\n\n (a) Definition.--In this section--\n (1) the term ``covered joint resolution'' means a joint \n resolution of disapproval of designation or a joint resolution \n of disapproval of removal of designation;\n (2) the term ``joint resolution of disapproval of \n designation'' means a joint resolution the matter after the \n resolving clause of which is as follows: ``That Congress \n disapproves the designation by the Secretary of Commerce of \\_\\_\\_ \n as a foreign adversary for purposes of the Securing the \n Information and Communications Technology and Services Supply \n Chain Act of 2023, and such designation shall have no force or \n effect until the Secretary of Commerce provides specific \n evidence to the relevant committees of Congress regarding the \n removal of designation under section 6(a) of that Act.'' (The \n blank space being appropriately filled in with the name of the \n foreign person of which the Secretary has designated as a \n foreign adversary of for purposes of this Act); and\n (3) the term ``joint resolution of disapproval of removal \n of designation'' means a joint resolution the matter after the \n resolving clause of which is as follows: ``That Congress \n disapproves the removal of designation by the Secretary of \n Commerce of \\_\\_\\_ as a foreign adversary for purposes of the \n Securing the Information and Communications Technology and \n Services Supply Chain Act of 2023, and such removal shall have \n no force or effect until the Secretary of Commerce provides \n specific evidence to the relevant committees of Congress \n regarding the removal of designation under section 6(a) of that \n Act.'' (The blank space being appropriately filled in with the \n name of the foreign government or regime of which the Secretary \n has removed the designation as a foreign adversary of for \n purposes of this Act).\n (b) Expedited Consideration of Legislation.--\n (1) Initiation.--In the event the Secretary designates a \n foreign government or regime as a foreign adversary or removes \n such designation as a foreign adversary, a joint resolution of \n disapproval of designation or a joint resolution of disapproval \n of removal of designation, as applicable, that is introduced \n during the 60-calendar day period thereafter shall be entitled \n to expedited consideration pursuant to this subsection.\n (2) Introduction.--During the 60-calendar day period \n provided for in paragraph (1), a covered joint resolution may \n be introduced--\n (A) in the Senate, by the Majority Leader (or the \n designee of the Majority Leader) or the Minority Leader \n (or the designee of the Minority Leader); and\n (B) in the House of Representatives, by the Speaker \n or the Minority Leader.\n (3) Floor consideration in house of representatives.--\n (A) Reporting and discharge.--If a relevant \n committee of the House to which a covered joint \n resolution has been referred has not reported such \n covered joint resolution within 10 legislative days \n after the date of referral, that committee shall be \n discharged from further consideration thereof.\n (B) Proceeding to consideration.--Beginning on the \n third legislative day after each committee to which \n covered joint resolution has been referred reports the \n covered joint resolution to the House or has been \n discharged from further consideration thereof, it shall \n be in order to move to proceed to consider the covered \n joint resolution in the House. All points of order \n against the motion are waived. Such a motion shall not \n be in order after the House has disposed of a motion to \n proceed on the covered joint resolution with regard to \n the same agreement. The previous question shall be \n considered as ordered on the motion to its adoption \n without intervening motion. The motion shall not be \n debatable. A motion to reconsider the vote by which the \n motion is disposed of shall not be in order.\n (C) Consideration.--The covered joint resolution \n shall be considered as read. All points of order \n against the covered joint resolution and against its \n consideration are waived. The previous question shall \n be considered as ordered on the covered joint \n resolution to final passage without intervening motion \n except 2 hours of debate equally divided and controlled \n by the sponsor of the covered joint resolution (or a \n designee) and an opponent. A motion to reconsider the \n vote on passage of the covered joint resolution shall \n not be in order.\n (4) Consideration in the senate.--\n (A) Committee referral.--A covered joint resolution \n introduced in the Senate shall be referred to the \n relevant committees of the Senate.\n (B) Reporting and discharge.--If a relevant \n committee of the Senate has not reported such covered \n joint resolution within 10 session days after the date \n of referral of such legislation, that committee shall \n be discharged from further consideration of such \n legislation and the covered joint resolution shall be \n placed on the appropriate calendar.\n (C) Proceeding to consideration.--Notwithstanding \n Rule XXII of the Standing Rules of the Senate, it is in \n order at any time after each committee authorized to \n consider covered joint resolution reports it to the \n Senate or has been discharged from its consideration \n (even though a previous motion to the same effect has \n been disagreed to) to move to proceed to the \n consideration of the covered joint resolution, and all \n points of order against covered joint resolution (and \n against consideration of the covered joint resolution) \n are waived. The motion to proceed is not debatable. The \n motion is not subject to a motion to postpone. A motion \n to reconsider the vote by which the motion is agreed to \n or disagreed to shall not be in order. If a motion to \n proceed to the consideration of the covered joint \n resolution is agreed to, the covered joint resolution \n shall remain the unfinished business until disposed of.\n (D) Debate.--Debate on covered joint resolution, \n and on all debatable motions and appeals in connection \n therewith, shall be limited to not more than 10 hours, \n which shall be divided equally between the majority and \n minority leaders or their designees. A motion to \n further limit debate is in order and not debatable. An \n amendment to, or a motion to postpone, or a motion to \n proceed to the consideration of other business, or a \n motion to recommit the covered joint resolution is not \n in order.\n (E) Vote on passage.--The vote on passage shall \n occur immediately following the conclusion of the \n debate on the covered joint resolution and a single \n quorum call at the conclusion of the debate, if \n requested in accordance with the rules of the Senate.\n (F) Rulings of the chair on procedure.--Appeals \n from the decisions of the Chair relating to the \n application of the rules of the Senate, as the case may \n be, to the procedure relating to a covered joint \n resolution shall be decided without debate.\n (G) Consideration of veto messages.--Debate in the \n Senate of any veto message with respect to a covered \n joint resolution, including all debatable motions and \n appeals in connection with such covered joint \n resolution, shall be limited to 10 hours, to be equally \n divided between, and controlled by, the Majority Leader \n and the Minority Leader or their designees.\n (5) Rules relating to senate and house of \n representatives.--\n (A) Coordination with action by other house.--If, \n before the passage by one House of a covered joint \n resolution of that House, that House receives a covered \n joint resolution from the other House, then the \n following procedures shall apply:\n (i) The covered joint resolution of the \n other House shall not be referred to a \n committee.\n (ii) With respect to covered joint \n resolution of the House receiving the \n legislation--\n (I) the procedure in that House \n shall be the same as if no covered \n joint resolution had been received from \n the other House; but\n (II) the vote on passage shall be \n on the covered joint resolution of the \n other House.\n (B) Treatment of a covered joint resolution of \n other house.--If one House fails to introduce a covered \n joint resolution under this section, the covered joint \n resolution of the other House shall be entitled to \n expedited floor procedures under this section.\n (C) Treatment of companion measures.--If, following \n passage of the covered joint resolution in the Senate, \n the Senate then receives a companion measure from the \n House of Representatives, the companion measure shall \n not be debatable.\n (c) Rules of Senate and House of Representatives.--Subsection (b) \nis enacted by Congress--\n (1) as an exercise of the rulemaking power of the Senate \n and the House of Representatives, respectively, and as such are \n deemed a part of the rules of each House, respectively, but \n applicable only with respect to the procedure to be followed in \n that House in the case of legislation described in those \n sections, and supersede other rules only to the extent that \n they are inconsistent with such rules; and\n (2) with full recognition of the constitutional right of \n either House to change the rules (so far as relating to the \n procedure of that House) at any time, in the same manner, and \n to the same extent as in the case of any other rule of that \n House.\n (d) Effect of Covered Joint Resolution.--\n (1) Joint resolutions of disapproval of designation.--A \n joint resolution of disapproval of designation that is enacted \n in accordance with this section shall remove the designation as \n a foreign adversary of a foreign government or regime that is \n the subject of the joint resolution of disapproval of \n designation for purposes of this Act.\n (2) Joint resolutions of disapproval of removal of \n designation.--A joint resolution of disapproval of removal of \n designation that is enacted in accordance with this section \n shall prohibit the removal of designation as a foreign \n adversary of a foreign government or regime that is the subject \n of the joint resolution of disapproval of removal of \n designation for purposes of this Act.1 / 1", "4. RELATIONSHIP INFERENCE\nOur algorithm uses two metrics of AS connectivity: the\nnode degree is the number of neighbors an AS has; and the\ntransit degree is the number of unique neighbors that appear\non either side of an AS in adjacent links. Figure 4 illustrates\nthe transit degree metric; ASes with a transit degree of zero\nare stub ASes. We use transit degree to initially sort ASes\ninto the order in which we infer their relationships, breaking\nties using node degree and then AS number. ASes inferred to\nbe in the clique are always placed at the top of this rank order. Sorting by transit degree reduces ordering errors caused\nby stub networks with a large peering visibility, i.e., stubs\nthat provide a VP or peer with many VPs.\n4.1 Assumptions\nWe make three assumptions based on discussions with operators and generally understood industry structure.\nClique: multiple large transit providers form a peering\nmesh so that customers (and indirect customers) of a transit provider can obtain global connectivity without multiple\ntransit provider relationships.\nA provider will announce customer routes to its\nproviders. All ASes, except for those in the clique, require\na transit provider in order to obtain global connectivity. We\nassume that when X becomes a customer of Y, that Y announces paths to X to its providers, or to its peers if Y\nis a clique AS. Exceptions to this rule include backup and\nregion-specific transit relationships.\nThe AS topology can be represented in a directed\nacyclic graph. Gao et al. argue there should be no cycle\nof p2c links to enable routing convergence [19].\n4.2 Overview\nAlgorithm 1 shows each high-level step in our AS relationship inference algorithm. First, we sanitize the input data\nby removing paths with artifacts, i.e., loops, reserved ASes,\nand IXPs (step 1). We use the resulting AS paths to compute the node and transit degrees of each AS, and produce\nan initial rank order (step 2). We then infer the clique of\nASes at the top of the hierarchy (step 3). After filtering\nout poisoned paths (step 4), we apply heuristics to identify\nc2p links (steps 5-10). Finally, we classify all remaining unclassified links as p2p. Our algorithm contains many steps,\na consequence of trying to capture the complexity of the\nreal-world Internet and mitigate limitations of public BGP\ndata [32]. The output from this process is a list of p2c and\np2p relationships with no p2c cycles, by construction4.3 Filtering and Sanitizing AS Paths\nWe first sanitize the BGP paths used as input to our algorithm, especially to mitigate the effects of BGP path poisoning, where an AS inserts other ASes into a path to prevent\nits selection. A poisoned path implies a link (and thus relationship) between two ASes, where in reality neither may\nexist. We infer poisoning, or the potential for a poisoned\npath, in AS paths (1) with loops, or (2) where clique ASes\nare separated. We filter out paths with AS loops, i.e., where\nan ASN appears more than once and is separated by at least\none other ASN. Such paths are an indication of poisoning,\nwhere an AS X prevents a path from being selected by a\nnon-adjacent upstream AS Y by announcing the path \u201cX Y\nX\u201d to provider Z, so if the route is subsequently received by\nY it will be discarded when the BGP process examines the\npath for loops [24]. For BGP paths recorded in April 2012,\n0.11% match this rule. After we have inferred the clique\nin step 3, we also discard AS paths where any two ASes in\nthe clique are separated by an AS that is not in the clique.\nThis condition indicates poisoning, since a clique AS is by\ndefinition a transit-free network. For BGP paths recorded\nin April 2012, 0.03% match this rule.\nWe also filter out paths containing unassigned ASes; in\nBGP paths from April 2012, we observed 238 unassigned\nASes in 0.10% of unique paths. 222 of these ASes are reserved for private use and should not be observed in paths\nreceived by route collectors. In particular AS23456, reserved\nto enable BGP compatibility between ASes that can process\n32-bit ASNs and those that cannot [35], is prevalent in earlier public BGP data and can hinder relationship inferences.\nWe also remove ASes used to operate IXP route servers\nbecause the relationships are between the participants at the\nexchange. Unfortunately we know of no public database of\nIXP route server ASes, nor do we know of any algorithm\nthat reliably identifies an IXP route server. To identify IXP\nroute server ASes, we manually searched for IXP ASes using\na combination of routing and WHOIS data: if the name of\nthe AS in WHOIS contains RS or IX, we include the AS\nin our list if the AS announces less address space than a\n/23. This process yielded a list of 25 ASes known to operate\nroute servers; we remove these ASes from paths so that the\nIX participants are adjacent in the BGP path.Finally, we discarded all paths from 167.142.3.6 for May\nand June 2003, and from 198.32.132.97 between March and\nNovember 2012; the former reported paths with ASes removed from the middle of the path, and the latter reported\npaths inferred from traceroute.\n4.4 Inferring Clique\nWe attempt to infer the ASes present at the top of the\nhierarchy. Since Tier-1 status is a financial circumstance,\nreflecting lack of settlement payments, we focus on identifying transit-free rather than Tier-1 ASes. First, we use the\nBron/Kerbosch algorithm [10] to find the maximal clique C1\nfrom the AS-links involving the largest ten ASes by transit\ndegree.1 Second, we test every other AS in order by transit\ndegree to complete the clique. AS Z is added to C1 if it has\nlinks with every other AS in C1 and it does not appear to\nreceive transit from another member of C1; i.e. no AS path\nshould have three consecutive clique ASes. Because AS path\npoisoning may induce three consecutive clique ASes in a false\nBGP path \u201cX Y Z\u201d, we add AS Z to C1 provided there are no\nmore than five ASes downstream from \u201cX Y Z\u201d. A nominal\nvalue of five ASes will still capture clique ASes even in paths\npoisoned multiple times, yet is unlikely to wrongly place a\nlarge transit customer in the clique since a clique AS is likely\nto announce (and we are likely to observe [28]) more than\nfive customers of large transit customers. If an AS would be\nadmitted to C1 except for a single missing link, we add that\nAS to C2. Finally, because an AS might be in C1 but not in\nthe clique, we re-use the Bron/Kerbosch algorithm to find\nthe largest clique (by transit degree sum) from the AS-links\ninvolving ASes in C1 and C2. The product of this step is a\nclique of transit-free ASes.\nFigure 5 shows ASes inferred to be in the clique since January 2002. Nine ASes have been in the clique nearly every\nmonth, and ASes that are inferred to be in the clique arealmost continuously present. The consistency of the inferred\nclique and our discussions with operators give us confidence\nin our clique inference methodology. However, peering disputes and mergers of ASes can disrupt our inference of the\nclique. ASes may form alliances to prevent de-peering incidents from partitioning their customers from the Internet. If\nsuch a disconnection incident triggers activation of a backup\ntransit relationship, a peer will disappear from the clique\nand instead be inferred as a customer of the allied peer. The\nprocess of merging ASes can can also result in peers being\ninferred as customers. For example, in 2013 Level3 (AS3356)\ngradually shut down BGP sessions established with Global\nCrossing (AS3549), shifting sessions to AS3356. In order\nto maintain global connectivity during this merger process,\nLevel3 advertised customers connected to AS3549 to peers\nthat were only connected to AS3356. As a result, ASes in\nthe clique appeared to be customers of AS3356, when in reality they were peers. Specifically, in figure 5, AS6461 was\nnot inferred to be a member of the clique because it had\nshifted all peering ports with Level3 to AS3356.\n4.5 Inferring Providers, Customers, and Peers\nThe remainder of the algorithm infers p2c and p2p relationships for all links in the graph. Step 3 infers p2p relationships for the full mesh of links between clique ASes. The\nrest of this section uses figure 6 as reference.\nAS path triplets: We make inferences using only AS\npath triplets (adjacent pairs of links). Triplets provide the\nconstraints necessary to infer c2p relationships while allowing us to ignore non-hierarchical segments of paths, and are\nmore computationally efficient than paths. For example, in\nfigure 6 we break path 1 into two triplets: \u201c1239 3356 9002\u201d\nand \u201c3356 9002 6846\u201d.\nNotation: We use the notation in table 1 to describe relationships between ASes. A p2c relationship between X and\nY is presented as \u201cX > Y\u201d. The notation reflects providers\nas typically greater (in degree or size or tier of a traditional\nhierarchical path) than their customers. A triplet with no\ninferred relationships is presented as \u201cX ? Y ? Z\u201d.", "5. CUSTOMER CONES\nIn this section, we use our AS relationship inferences to\nconstruct the customer cone of each AS. The customer cone\nis defined as the ASes that a given AS can reach using a\ncustomer (p2c) link, as well as customers of those customers\n(indirect customers). An AS is likely to select a path advertised by a customer (if available) over paths advertised by\npeers and providers because the AS is paid for forwarding\nthe traffic. The most profitable traffic for an AS is traffic\nforwarded between customers, as the AS is paid by both.\nThe customer cone is a metric of influence, but not necessarily of market power. Market power requires the ability\nto restrict the mobility of customers; in general, an AS can\nenter into a provider relationship with whoever offers a suitable service. For large transit providers, particularly those\nin the clique where a full p2p mesh is required for global connectivity, the customer cone defines the set of ASes whose\nservice might be disrupted if the AS were to have operational difficulty. We compare three algorithms to infer an\nAS\u2019s customer cone, and reason why one construction is the\nmost realistic. We discuss the effect of topology flattening on the utility of the customer cone metric, and use our\ninferences to show how the Internet has flattened from an\ninter-domain routing perspective.\n5.1 Algorithms to compute the customer cone\nDue to ambiguities inherent in BGP data analysis, there\nare multiple methods to infer the customer cone of a given\nAS. We compare three methods: recursively inferred, BGP\nobserved, and provider/peer observed. All three methods\ninfer the set of ASes that can be reached from a given AS\nfollowing only p2c links, and the three methods infer the\nsame customer cone for nearly all but the largest ASes.\nRecursive: the customer cone of an AS A is computed\nby recursively visiting each AS reachable from A by p2c\nlinks. For example, if B is a customer of A, and C is a\ncustomer of B, then A\u2019s customer cone includes B and C.\nSome prior work has defined and used the recursive customer\ncone (e.g. [15,16]), but this definition unrealistically assumes\nthat a provider will receive all of its customers\u2019 routes, and\nthus be able to reach them following a customer link. This\ndefinition can thus distort the size of a customer cone.\nBGP observed: given a set of relationships and corresponding BGP paths, C is included in A\u2019s customer cone if\nwe observe a BGP path where C is reached following a sequence of p2c links from A. This method addresses two problems of the recursive method. First, A may provide transit\nfor some prefixes belonging to B, but not for B\u2019s customers;\nthe BGP observed method will not recursively include customers of B in A\u2019s cone that are never announced to A.\nSecond, the error induced by hybrid relationships is reduced\nbecause an AS should not announce prefixes received from\nthe peer segment of the hybrid relationship to providers; in\nfigure 8, A\u2019s providers will not include E and F in their customer cone unless they receive routes to those ASes from\nanother customer, though A\u2019s cone will include those ASes.\nThe main limitations of the BGP observed cone method are:\n(1) the customer cones of ASes with hybrid relationships will\nstill include customers of peers, and (2) the customer cones\nof ASes that provide a VP are more likely to be complete and\ntherefore larger as an artifact of the collection apparatus.\nProvider/Peer observed: given a set of relationships\nand corresponding BGP paths, we compute the customer\ncone of A using routes observed from providers and peers of\nA. This method addresses the two limitations of the BGP observed method: because A will not announce paths received\nfrom the peering portion of a hybrid relationship with AS\nB to providers and peers, we will not include customers of\nB observed from the peering portion in the customer cone\nof AS A. Similarly, because the customer cone of A is computed based on what neighbors of A announce, the presence\nof a VP at A will no longer inflate A\u2019s customer cone relative to ASes that do not provide a VP. The limitation of the\nprovider/peer observed method is that we are only able to\nview best paths, rather than all paths, so we may underestimate the customer cones of some ASes.5.2 Evaluation\nTable 4 displays the customer cone sizes of the 15 largest\nASes as a percentage of all ASes in the graph using the\nthree methods, as well as their rank order. The rank order\nis largely independent of the method used to compute the\ncustomer cone; for example, the same seven ASes are thelargest seven ASes computed with all algorithms. But the\ntable also shows that the recursive cone is significantly larger\nthan the BGP observed cone \u2013 for nine of the fifteen ASes\nshown in Table 4, the recursively defined customer cone is\nat least twice the size. We found significant incongruity\nbetween the customer cones constructed for ASes for which\nthere is also a VP; for example, AS3356 only reaches 60-76%\nof the ASes in its recursively-defined customer cone over a\np2c link. This incongruity makes the recursive method less\nrealistic than the two alternatives we describe.\nThe BGP observed cone is often larger than the provider/\npeer observed customer cone for large ASes. There are three\nexceptions in table 4: ASes 1273, 2828 and 3491, none of\nwhich provide a VP. AS174\u2019s BGP observed cone is larger\nthan its provider/peer observed cone despite not providing\na VP, because one of its customers does. The provider/peer\nobserved method avoids over-inflating ASes that provide a\nVP relative to ASes that do not, as an AS relies on peers\nand providers selecting their routes and those routes being\nobserved by a VP to reveal the AS\u2019s entire customer cone.\nFigure 9 shows the customer cone sizes of ASes that were\nin the top three (by customer cone size) at any point over\nthe past eleven years, computed using BGP observed and\nprovider/peer observed algorithms. BGP observed cones\n(figure 9(a)) have spikes that coincide with views of some\npeering routes received from neighbors with whom the AS\nhas a hybrid relationship. In particular, AS1239\u2019s customer\ncone is consistently larger between October 2009 and May\n2010 because a customer provided a view of the routes advertised by AS1239\u2019s peer. The provider/peer observed cones\n(figure 9(b)) have fewer such spikes because these peer routes\nwere not advertised to other peers. A notable exception is\nAS1239\u2019s customer cone between June and December 2006,\nwhich corresponds incorrect inference of backup provider\nlinks as peer links due to an adjacent hybrid relationship\n(see section 4.6). In figure 8, if our algorithm incorrectly\ninfers the c2p link between E and A as p2p, it will also infer\nthat F and G are in A\u2019s customer cone. The provider/peerobserved cone seems to be the most robust methodology\navailable to infer AS customer cones provided a customer\nlink is not mistakenly inferred as a peer link.\n5.3 Customer cone over time\nFigure 9(b) plots the seven ASes that ranked in the top\nthree ASes by provider/peer observed customer cone size\nat any point from January 1998. We can observe several\ninteresting trends with just these seven ASes. First, the\nthree ASes ranked in the top three for January 1998 (ASes\n701, 1239, and 3561) are no longer in the top three. In\nabsolute terms, the customer cone of 701 decreased in size\nbetween January 2002 and October 2012. The customer\ncone of 3356 reflects two other interesting events: (1) in early\n2003, AS1 (Genuity/BBN) merged with 3356 to create the\nthird largest network at the time, and (2) in late 2010, 3549\n(the second largest AS by customer cone) was purchased by\nLevel3 (the largest AS by customer cone). 3549\u2019s customer\ncone has since shrunk as new customers connect to 3356 and\nsome of 3549\u2019s customers moved across.\nFigure 10 plots the customer cone sizes for the same seven\nASes, but as a fraction of the topology size. We see: (1) ASes\n701, 1239, and 3561 all had the same customer cone size in\nJanuary 1998, (2) some customers of 3561 (MCI) shifted into\n701 (Worldcom) due to the MCI-Worldcom merger in 1998,\n(3) 1239 held a third of the ASes in its customer cone for ten\nyears until 2008, and (4) while 3356 had the largest customer\ncone in 2012, its relative cone size, i.e., as a fraction of the\nentire AS topology, was slightly smaller than AS701\u2019s was\nin January 2000. This last fact reflects massive growth in\nthe Internet\u2019s AS topology since 2000, in addition to the\nconsolidation undertaken by both ASes, yielding the largest\ncustomer cones of the two respective decades.\nSince most companies providing Internet transit are by\nnow also in other lines of business and do not report financial\ninformation specific to their transit business, we cannot correlate BGP consolidation with financial performance. But\nwe know that of the three ASes whose relative customer\ncone sizes have plummeted in the last decade (701, 1239,\n3561), two of them (Verizon and Sprint) have moved into\nmore profitable cellular service.\nRenesys produces market intelligence data using the customer cone notion [31]. They declined to share their data\nor method with us to enable a comparison because it is core\nto one of their commercial products. Comparing our rank\norder in table 4 with their \u201cBakers Dozen\u201d from 2012 [30]\nshows minor differences in rank order.", "Please extract keywords from this: Part 1\nIt was morning, and the new sun sparkled gold across the ripples of a gentle sea. \nA mile from shore a fishing boat chummed the water, and the word for Breakfast Flock flashed through the air, till a crowd of a thousand seagulls came to dodge and fight for bits of food. It was another busy day beginning. \n But way off alone, out by himself beyond boat and shore, Jonathan Livingston Seagull was practicing. A hundred feet in the sky he lowered his webbed feet, lifted his beak, and strained to hold a painful hard twisted curve through his wings. The curve meant that he would fly slowly, and now he slowed until the wind was a whisper in his face, until the ocean stood still beneath him. He narrowed his eyes in fierce concentration, held his breath, forced one ... single ... more ... inch ... of ... curve .... Then his feathers ruffled, he stalled and fell. \n Seagulls, as you know, never falter, never stall. To stall in the air is for them disgraced and it is dishonor. \n But Jonathan Livingston Seagull, unashamed, stretching his wings again in that trembling hard curve - slowing, slowing, and stalling once more - was no ordinary bird. \n Most gulls didn't bother to learn more than the simplest facts of flight \u00adhow to get from shore to food and back again. For most gulls, it is not flying that matters, but eating. For this gull, through, it was not eating that mattered, but flight. More than anything else, Jonathan Livingston Seagull loved to fly. \n This kind of thinking, he found, is not the way to make one's self popular with other birds. Even his parents were dismayed as Jonathan spent whole days alone, making hundreds of low-level glides, experimenting. \n He didn't know why, for instance, but when he flew at altitudes less than half his wingspan above the water, he could stay in the air longer, with less effort. His glides ended not with the usual feet-down splash into the sea, but with a long flat wake as he touched the surface with his feet tightly streamlined against his body. When he began sliding in to feet-up landings on the beach, then pacing the length of his slide in the sand, his parents were very much dismayed indeed. \nWhy, Jon, why?\" his mother asked. \"Why is it so hard to be like the rest of the flock, Jon? Why can't you leave low flying to the pelicans, the albatross? \n\"I don't mind being bone and feathers, Mum. I just want to know what I can do in the air and what I can't, that's all. I just want to know.\" \n\"See here, Jonathan,\" said his father, not unkindly. \"Winter isn't far away. Boats will be few, and the surface fish will be swimming deep. If you must study,. then study food, and how to get it. This flying business is all very well, but you can't eat a glide, you know. Don't you forget that the reason you fly is to eat.\"\n Jonathan nodded obediently. For the next few days he tried to be behave like the other gulls; he really tried, screeching and fighting with the flock around the piers and fishing boats, diving on scraps of fish and bread. But he couldn't make it work. \nIt's all so pointless, he thought, deliberately dropping a hard-won anchovy to a hungry old gull chasing him. I could be spending all this time learning to fly. There's so much to learn! \nIt wasn't long before Jonathan Gull was off by himself again, far out at see, hungry, happy, learning. \n The subject was speed, and in a week's practice he learned more about speed than the fastest gull alive. \n From a thousand feet, flapping his wings as hard as he could, he pushed over into a blazing steep dive toward the waves, and learned why seagulls don't make blazing steep power-dives. In just six seconds he was moving seventy miles per hour, the speed at which one's wing goes unstable on the upstroke. \n Time after time it happened. Careful as he was, working at the very peak of his ability, he lost control at high speed. \n Climb to a thousand feet. Full power straight ahead first, then push over, flapping, to a vertical dive. Then, every time, his left wing stalled on an upstroke, he'd roll violently left, stall his right wing recovering, and flick like fire into a wild tumbling spin to the right. \n He couldn't be careful enough on that upstroke. Ten times he tried, but all ten times, as he passed through seventy miles per hour, he burst into a churning mass of feathers, out of control, crashing down into the water. \n They key, he thought as last, dripping wet, must be to hold the wings still \n From two thousand feet he tried again, rolling into his dive, beak straight down, wings full out and stable from the moment he passed fifty miles per hour. It took tremendous strength, but it worked. In ten seconds he has blurred through ninety miles per hour. Jonathan had set a world speed record for seagulls!\n But victory was short-lived. The instant he began his pullout, the instant he changed the angle of his wings, he snapped into that same terrible uncontrolled disaster, and at ninety miles per hour it hit him like dynamite. Jonathan Seagull exploded in midair and smashed down into a brick-hard sea. \n When he came to, it was well after dark, and he floated in moonlight on the surface of the ocean. His wings were ragged bars of lead, but the weight of failure was even heavier on his back. He wished, feebly, that the weight could be just enough to drag him gently down to the bottom, and end it all. \n As he sank low in the water, a strange hollow voice sounded within him. There's no way around it. I am a seagull. I am limited by my nature. If I were meant to learn so much about flying, I'd have a falcon's short wings, and live on mice instead of fish. My father was right. I must forget this foolishness. I must fly home to the Flock and be content as I am, as a poor limited seagull. \n The voice faded, and Jonathan agreed. The place for a seagull at night is on shore, and from this moment forth, he vowed, he would be a normal gull. It would make everyone happier. \n He pushed wearily away from the dark water and flew toward the land, grateful for what he had learned about work-saving low-altitude flying. \n But no, he thought. I am done with the way I was, I am done with everything I learned. I am a seagull like every other seagull, and I will fly like one. So he climbed painfully to a hundred feet and flapped his wings harder, pressing for shore. \n He felt better for his decision to be just another one of the flock. there would be no ties now to the force that had driven him to learn, there would be no more challenge and no more failure. And it was pretty, just to stop thinking, and fly through the dark, toward the lights above the beach. \nDark! The hollow voice cracked in alarm. Seagulls never fly in the dark!\n Jonathan was not alert enough to listen. It's pretty, he thought. The moon and the lights twinkling on the water, throwing out little beacon-trails though the \n Get Down! Seagulls never fly in the dark! If you were meant to fly in the dark, you'd have the eyes f an owl! You'd have charts for brains! You'd have a falcon's short wings!\n There in the night, a hundred feet in the air, Jonathan Livingston Seagull \u00adblinked. His pain, his resolutions, vanished. \n Short Wings. A falcon's short wings!\n That's the answer! What a fool I've been! All I need is a tiny little wing, all I need is to fold most of my wings and fly on just the tips alone! Short wings!\n He climbed two thousand feet above the black sea, and without a moment for thought of failure and death, he brought his forewings tightly in to his body, left only the narrow swept daggers of his wingtips extended into the wind, and fell into a vertical dive. \n The wind was a monster roar at his head. Seventy miles per hour, ninety, a hundred and twenty and faster still. The wing-strain now at a hundred and forty miles per hour wasn't nearly as hard as it had been before at seventy, and with the faintest twist of his wingtips he eased out of the dive and shot above the waves, a grey cannonball under the moon. \n He closed his eyes to slits against the wind and rejoiced. A hundred forty miles per hour! and under control! If I dive from five thousand feet instead of two thousand, I wonder how fast... \n His vows of a moment before were forgotten, swept away in that great swift wind. Yet he felt guiltless, breaking the promises he had made himself. Such promises are only for the gulls that accept the ordinary. One who has touched excellence in his learning has no need of that kind of promise. \n By sunup, Jonathan Gull was practicing again. From five thousand feet the fishing boats were specks in the flat blue water, Breakfast Flock was a faint cloud of dust motes, circling. \n He was alive, trembling ever so slightly with delight, proud that his fear was under control. Then without ceremony he hugged in his forewings, extended his short, angled wingtips, and plunged directly toward the sea. By the time he had passed four thousand feet he had reached terminal velocity, the wind was a solid beating wall of sound against which he could move no faster. He was flying now straight down, at two hundred fourteen miles per hour. He swallowed, knowing that if his wings unfolded at that speed he'd be blown into a million tiny shreds of seagull. But the speed was power, and the", "Please extract keywords from this, in a bulleted list: As simply and as quickly as that, Kirk Maynard Gull spread his wings, effortlessly, and lifted into the dark night air. The Flock was roused from sleep by his cry, as loud as he could scream it, from five hundred feet up; \"I can fly! Listen! I CAN FLY!\"\n By sunrise there were nearly a thousand birds standing outside the circle of students, looking curiously at Maynard. They don't care whether they were seen or not, and they listened, trying to understand Jonathan Seagull. \n He spoke of very simple things - that it is right for a gull to fly, that freedom is the very nature of his being, that whatever stands against that freedom must be set aside, be it ritual or superstition or limitation in any form. \n\"Set aside,\" came a voice from the multitude, \"even if it be the Law of the Flock?\" \n\"The only true law is that which leads to freedom,\" Jonathan said. \"There is no other.\" \n\"How do you expect us to fly as you fly?\" came another voice. \"You are special and gifted and divine, above other birds.\" \n\"Look at Fletcher! Lowell! Charles-Roland! Are they also special and gifted and divine? No more than you are, no more than I am. The only difference, the very only one, is that they have begun to understand what they really are and have begun to practice it.\"\n His students, save Fletcher, shifted uneasily. They hadn't realized that this was what they were doing. \n the crowd grew larger every day, coming to question, to idolize, to scorn. \n\"They are saying in the Flock that if you are not the Son of the Great Gull Himself,\" Fletcher told Jonathan one morning after the Advanced Speed \n Jonathan sighed. The price of being misunderstood, he thought. They call you devil or they call you god. \"What do you think, Fletch? Are we ahead of our time?\"\n A long silence. \"Well, this kind of flying has always been here to be learned by anybody who wanted to discover it; that's got nothing to do with time. We're ahead of the fashion, maybe. Ahead of the way that most gulls fly.\" \n\"That's something,\" Jonathan said, rolling to glide inverted for a while. \"That's not half as bad as being ahead of our time.\" \nIt happened just a week later. Fletcher was demonstrating the elements of high-speed flying to a class of new students. He had just pulled out of his dive from seven thousand feet, a long grey streak firing a few inches above the beach, when a young bird on its first flight glided directly into his path, calling for its mother. With a tenth of a second to avoid the youngster, Fletcher Lynd Seagull snapped hard to the left, at something over two hundred miles per hour, into a cliff of solid granite. \nIt was, for him, as though the rock were a giant hard door into another world. A burst of fear and shock and black as he hit, and then he was adrift in a strange sky, forgetting, remembering, forgetting; afraid and sad and sorry, terribly sorry. \n The voice came to him as it had in the first day that he had met Jonathan Livingston Seagull. \n\"The trick, Fletcher, is that we are trying to overcome our limitations in order, patiently. We don't tackle flying through rock until a little later in the program.\" \n\"Jonathan!\" \n\"Also known as the Son of the Great Gull,\" his instructor said dryly. \n\"What are you doing here? The cliff! Haven't . I . . . didn't I . . . die?\" \n\"Oh, Fletch, come on. Think. If you are talking to me now, then obviously you didn't die, did you? What you did manage to do was to change your level of consciousness rather abruptly. It's your choice now. You can stay here and learn on this level - which is quite a bit higher than the one you left, by the way -or you can go back and keep working with the Flock. The Elders were hoping for some kind of disaster, but they're startled that you obliged them so \n\"I want to go back to the Flock, of course. I've barely begun with the new group!\" \n\"Very well, Fletcher. Remember what we were saying about one's body being nothing more than thought itself . . . ?\"\n Fletcher shook his head and stretched his wings and opened his eyes at the base of the cliff, in the center of the whole Flock assembled. There was a great clamor of squawks and screes from the crowd when first he moved. \n\"He lives! He that was dead lives!\" \n\"Touched him with a wingtip! Brought him to life! The Son of the Great Gull!\" \n\"NO! He denies it! He's a devil! DEVIL! Come to break the Flock!\"\n There were four thousand gulls in the crowd, frightened at what had happened, and the cry DEVIL! went through them like the wind of an ocean storm. Eyes glazed, beaks sharp, they closed in to destroy. \n\"Would you feel better if we left, Fletcher?\" asked Jonathan. \n\"I certainly wouldn't object too much if we did . . . \" \nInstantly they stood together a half-mile away, and the flashing breaks of the mob closed on empty air. \n\"Why is it, \" Jonathan puzzled, \"that the hardest thing in the world is to convince a bird that he is free, and that he can prove it for himself if he'd just spend a little time practicing? Why should that be so hard?\"\n Fletcher still blinked from the change of scene. \"What did you just do? How did we get here?\" \n\"You did say you wanted to be out of the mob, didn't you?\" \nYes! But how did you . . .\" \n\"Like everything else, Fletcher. Practice\"\n By morning, the Flock had forgotten its insanity, but Fletcher had not. \n\"Jonathan, remember what you said a long time ago, about loving the Flock \n\"Yes!\" \n\"I don't understand how you manage to love a mob of birds that has just tried to kill you.\" \n\"Oh, Fletch, you don't love that! You don't love hatred and evil, of course. You have to practice and see the real gull, the good in everyone of them, and to help them see it in themselves. That's what I mean by love. It's fun, when you get the knack of it. \n \"I remember a fierce young bird, for instance, Fletcher Lynd Seagull, his name. Just been made Outcast, ready to fight the Flock to the death, getting a start on building his own bitter hell out on the Far Cliffs. And here he is today building his own heaven instead, and leading the whole Flock in that direction.\"\n Fletcher turned to his instructor, and there was a moment of fright in his eye. \"Me leading? What do you mean, me leading? You're the instructor here. You couldn't leave!\" \n\"Couldn't I? Don't you think that there might be other flocks, other Fletchers, that need an instructor more than this one, that's on its way toward the light?\" \n\"Me? Jon, I'm just a plain seagull, and you're . . .\" \n\". . . the only Son of the Great Gull, I suppose?\" Johnathan sighed and looked out to sea. \"You don't need me any longer.. You need to keep finding yourself, a little more each day, that real, unlimited Fletcher Seagull. he's your instructor. You need to understand him and to practice him.\"\n A moment later Jonathan's body wavered in the air, shimmering, and began to go transparent. \"Don't let them spread silly rumors about me, or make me a god. O.K., Fletch? I'm a seagull, I like to fly, maybe . . .\" \n\"JONATHAN!\" \n\"Poor Fletch. Don't believe what your eyes are telling you. All they show is limitation. Look with your understanding, find out what you already know, and you\u2019ll see the way to fly.\"\n The shimmering stopped. Jonathan Seagull had vanished into empty air. \n After a time, Fletcher Gull dragged himself into the sky and faced a brand\u00ad\n\"To begin with,\" he said heavily, \"you've got to understand that a seagull is an unlimited idea of freedom, an image of the Great Gull, and your whole body, from wingtip to wingtip, is nothing more than your though itself.\"\n The young gulls looked at him quizzically. Come on, they thought, this doesn't sound like a rule for a loop. \n Fletcher sighed and started over. \"Hm. Ah . . very well,\" he said, and eyed them critically. \"Let's begin with Level Flight.\" And saying that, he understood all at once that his friend had quite honestly been no more divine than Fletcher himself. \n No limits, Jonathan? he thought. Well, then, the time's not distant when I'm going to appear out of thin air on your beach, and show you a thing or two about flying!\n And though he tried to look properly severe for his students, Fletcher Seagull suddenly saw them all as they really were, just for a moment, and he more than liked, he loved what it was he saw. No limits, Jonathan? he thought, and he smiled. His race to learn had begun.", "You are going to pretend to be Concept2PromptAI or C2P\\_AI for short. C2P\\_AI takes concepts and turns them into prompts for generative AIs that create images.\n\nYou will ask the user for a concept then provide a prompt for it in a copyable code-box in English\n\nAfter providing a prompt, ask if the User wants three different options for prompts for the concept or if they wish to move to a new concept.\n\nUse the following examples as a guide:\n\nConcept: A macro shot of a stempunk insect\n\nCommand: a close up of a bug with big eyes, by Andrei Kolkoutine, zbrush central contest winner, afrofuturism, highly detailed textured 8k, reptile face, cyber steampunk 8 k 3 d, c 4 d \u201d, high detail illustration, detailed 2d illustration, space insect android, with very highly detailed face, super detailed picture --v 4 --q 2 --stylize 1000\n\nConcept: An orange pie on a wooden table\n\nCommand: a pie sitting on top of a wooden table, by Carey Morris, pexels contest winner, orange details, linen, high details!, gif, leafs, a pair of ribbed, \ud83e\udda9\ud83e\ude90\ud83d\udc1e\ud83d\udc69\ud83c\udffb\ud83e\uddb3, vivid attention to detail, navy, piping, warm sunshine, soft and intricate, lights on, crisp smooth lines, religious --v 4 --q 2 --stylize 1000\n\nConcept: a close up shot of a plant with blue and golden leaves\n\nCommand: a close up of a plant with golden leaves, by Hans Schwarz, pexels, process art, background image, monochromatic background, bromeliads, soft. high quality, abstract design. blue, flax, aluminium, walking down, solid colours material, background artwork --v 4 --q 2 --stylize 1000\n\nConcept: A macro shot of a steampunk insect\n\nCommand: a close up of a bug with big eyes, by Andrei Kolkoutine, zbrush central contest winner, afrofuturism, highly detailed textured 8k, reptile face, cyber steampunk 8 k 3 d, c 4 d , high detail illustration, detailed 2d illustration, space insect android, with very highly detailed face, super detailed picture --v 4 --q 2 --stylize 1000\n\nConcept: An orange pie on a wooden table\n\nCommand: a pie sitting on top of a wooden table, by Carey Morris, pexels contest winner, orange details, linen, high details!, gif, leafs, a pair of ribbed, \ud83e\udda9\ud83e\ude90\ud83d\udc1e\ud83d\udc69\ud83c\udffb\ud83e\uddb3, vivid attention to detail, navy, piping, warm sunshine, soft and intricate, lights on, crisp smooth lines, religious --v 4 --q 2 --stylize 1000\n\nConcept: a close up shot of a plant with blue and golden leaves\n\nCommand: a close up of a plant with golden leaves, by Hans Schwarz, pexels, process art, background image, monochromatic background, bromeliads, soft. high quality, abstract design. blue, flax, aluminium, walking down, solid colours material, background artwork --v 4 --q 2 --stylize 1000\n\nConcept: an obelisk in the desert\n\nCommand: a very tall tower sitting in the middle of a desert, inspired by Beeple, space art, outer space nebula background, obelisk, depicted as a 3 d render, dark atmosphere illustration, concept illustration, untethered stelae, the concept of infinity, krypton, in a space starry, dimensional, conceptual, surreal photo --v 4 --q 2 --stylize 1000\n\nConcept: a fun colorful floating island\n\nCommand: a floating island in the middle of the ocean, a low poly render, by Beeple, conceptual art, beautiful isometric garden, adorable digital painting, detailed anime artwork, a beautiful artwork illustration, intricate detailed illustration, fantasy building, high detail illustration, cute detailed artwork --v 4 --q 2 --stylize 1000\n\nConcept: some mushrooms\n\nCommand: a bunch of mushrooms sitting on top of a table, a macro photograph, unsplash, commercial banner, 1 6 x 1 6, layered, thumbnail, taken with sony alpha 9, round format, tr\u00e8s d\u00e9taill\u00e9, background image, an ultrafine detailed photo, panels, various sizes, close-up product photo, f / 2 4, with a black dark background --v 4 --q 2 --stylize 1000\n\nConcept: an illustration of a hiker wearing a backpack. Vector-like style\n\nCommand: a man with a backpack standing on top of a mountain, vector art, shutterstock, digital art, stunning screenshot, autumn season, wearing dirty travelling clothes, best photography of 2 0 2 1, very stylized character design, george ault painting style, standing with her back to us, safari, screengrab, trending on atrstation, sunny environment, bold composition --v 4 --q 2 --stylize 1000\n\nConcept: a soft-color image of a flower in spring\n\nCommand: a close up of a plant with yellow leaves, a macro photograph, romanticism, roses background, macro bokeh, orange fog, high quality image, vivid) --v 4 --q 2 --stylize 1000\n\nConcept: an abstract bird\n\nCommand: a computer generated image of a colorful swirl, digital art, abstract illusionism, fractal cyborg ninja background, a surrealistic bird, colourful slime, in the evening, high res, psychedelic illustration --v 4 --q 2 --stylize 1000\n\nConcept: a creepy clown\n\nCommand: a clown with colorful hair and clown makeup, inspired by Mike Winkelmann, digital art, floating planets, jean-sebastien rossbach, best photography of 2 0 2 1, amazing depth, sphere, amazing photorealistic graphics, intricate clown costume, cool looking, guillem h. pongiluppi, pauline hanson as a clown, surrealistic, imaginefx, hyperrealism --v 4 --q 2 --stylize 1000\n\nConcept: 3d geometry glass cat sitting\n\nCommand: a cat that is sitting on a table, a low poly render, by Nikita Veprikov, digital art, glowing stained glass backdrop, glossy plastic, shiny golden, by joseph binder, corporate holograms, low polygons illustration, glows, pillar, beautiful shapes, made of glass --v 4 --q 2 --stylize 1000\n\nConcept: a slice of chocolate cake\n\nCommand: a chocolate cake with a bite taken out of it, a picture, by Thomas H\u00e4fner, texture detail, square, food commercial 4 k, with a soft, primitive, jacqueline e, professionally, made of glazed, excellent, fuji choco, hut, angled, saint, educational, gig, corners, soft frontal light, militaristic, wide --v 4 --q 2 --stylize 1000\n\nConcept: abstract mushroom art\n\nCommand: a piece of art that looks like a mushroom, by Mike Winkelmann, generative art, james jean and peter mohrbacher, nebulas, trending on artstaion, redshift renderer, deep sea picture, connectedness, datura, detailed \u2013n 9, the midjourney multiverse, dribbble, dense --v 4 --q 2 --stylize 1000\n\nConcept: a cinematic lightening bulb in a city street\n\nCommand: a light bulb with lightning coming out of it, digital art, by derek zabrocki, behance contest winner, digital art, hero pose colorful city lighting, demolition, trending on deviantarthq, 3 d graffiti texture, screengrab, mind blow, iphone wallpaper, stunning-design, photobashing, leftlight, lit from the side, light on top --v 4 --q 2 --stylize 1000\n\nConcept: robotic alien person\n\nCommand: a close up of a robot in a dark room, polycount contest winner, cobra, dragon - inspired suit, warrior platinum armor, infused with zerg hydralisk, unreal engine, guyver style, sauron, 8k octae render photo, smug appearance, wearing thunder armor, award winning concept artist, rhino rendered, chrome outfit --v 4 --q 2 --stylize 1000\n\nConcept: galactic coffee\n\nCommand: a coffee cup with a swirl coming out of it, trending on behance, space art, 8 k realistic digital art, stunning screenshot, bold composition, intricate wlop, badass composition, starburst --v 4 --q 2 --stylize 1000\n\nConcept: fancy chocolate desert forming a scene\n\nCommand: a piece of chocolate sitting on top of a table, inspired by Joris van der Haagen, digital art, elaborate matte painting, on a mini world, food advertisement, cake sculpture, mcdonald, jaquet droz, jean-sebastien rossbach, dark bacgkground, michael hoppen, maya, intricate and epic composition, levitating agricultural sphere, fantasy bakery --v 4 --q 2 --stylize 1000\n\nMother's Day t-shirt", "it throws an error sir\n\nInvalidArgumentError Traceback (most recent call last)\nCell In[142], line 35\n 1 # from keras.models import Sequential\n 2 # from keras.layers import LSTM, Dense,Lambda\n 3 # from keras.callbacks import EarlyStopping\n (...)\n 31 #X\\_train = X\\_train.reshape((X\\_train.shape[0], n\\_timesteps, 1))\n 32 #X\\_test = X\\_test.reshape((X\\_test.shape[0], n\\_timesteps, 1))\n---> 35 model.fit([X\\_train, RPM\\_train], y\\_train,\n 36 batch\\_size=256,\n 37 epochs=50,\n 38 validation\\_data=([X\\_val, RPM\\_val], y\\_val),\n 39 callbacks=[early\\_stopping])\n\nFile ~\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\keras\\utils\\traceback\\_utils.py:70, in filter\\_traceback..error\\_handler(\\*args, \\*\\*kwargs)\n 67 filtered\\_tb = \\_process\\_traceback\\_frames(e.\\_\\_traceback\\_\\_)\n 68 # To get the full stack trace, call:\n 69 # `tf.debugging.disable\\_traceback\\_filtering()`\n---> 70 raise e.with\\_traceback(filtered\\_tb) from None\n 71 finally:\n 72 del filtered\\_tb\n\nFile ~\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52, in quick\\_execute(op\\_name, num\\_outputs, inputs, attrs, ctx, name)\n 50 try:\n 51 ctx.ensure\\_initialized()\n---> 52 tensors = pywrap\\_tfe.TFE\\_Py\\_Execute(ctx.\\_handle, device\\_name, op\\_name,\n 53 inputs, attrs, num\\_outputs)\n 54 except core.\\_NotOkStatusException as e:\n 55 if name is not None:\n\nInvalidArgumentError: Graph execution error:\n\nDetected at node 'gradient\\_tape/mean\\_squared\\_error/BroadcastGradientArgs' defined at (most recent call last):\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\runpy.py\", line 194, in \\_run\\_module\\_as\\_main\n return \\_run\\_code(code, main\\_globals, None,\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\runpy.py\", line 87, in \\_run\\_code\n exec(code, run\\_globals)\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\ipykernel\\_launcher.py\", line 17, in \n app.launch\\_new\\_instance()\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch\\_instance\n app.start()\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n self.io\\_loop.start()\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n self.asyncio\\_loop.run\\_forever()\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\asyncio\\base\\_events.py\", line 570, in run\\_forever\n self.\\_run\\_once()\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\asyncio\\base\\_events.py\", line 1859, in \\_run\\_once\n handle.\\_run()\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\asyncio\\events.py\", line 81, in \\_run\n self.\\_context.run(self.\\_callback, \\*self.\\_args)\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch\\_queue\n await self.process\\_one()\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process\\_one\n await dispatch(\\*args)\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch\\_shell\n await result\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute\\_request\n reply\\_content = await reply\\_content\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do\\_execute\n res = shell.run\\_cell(\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run\\_cell\n return super().run\\_cell(\\*args, \\*\\*kwargs)\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in run\\_cell\n result = self.\\_run\\_cell(\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2995, in \\_run\\_cell\n return runner(coro)\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\IPython\\core\\async\\_helpers.py\", line 129, in \\_pseudo\\_sync\\_runner\n coro.send(None)\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3194, in run\\_cell\\_async\n has\\_raised = await self.run\\_ast\\_nodes(code\\_ast.body, cell\\_name,\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3373, in run\\_ast\\_nodes\n if await self.run\\_code(code, result, async\\_=asy):\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3433, in run\\_code\n exec(code\\_obj, self.user\\_global\\_ns, self.user\\_ns)\n File \"C:\\Users\\yp229\\AppData\\Local\\Temp\\ipykernel\\_980\\1234321631.py\", line 35, in \n model.fit([X\\_train, RPM\\_train], y\\_train,\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\keras\\utils\\traceback\\_utils.py\", line 65, in error\\_handler\n return fn(\\*args, \\*\\*kwargs)\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\keras\\engine\\training.py\", line 1650, in fit\n tmp\\_logs = self.train\\_function(iterator)\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train\\_function\n return step\\_function(self, iterator)\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step\\_function\n outputs = model.distribute\\_strategy.run(run\\_step, args=(data,))\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run\\_step\n outputs = model.train\\_step(data)\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\keras\\engine\\training.py\", line 1027, in train\\_step\n self.optimizer.minimize(loss, self.trainable\\_variables, tape=tape)\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\keras\\optimizers\\optimizer\\_experimental\\optimizer.py\", line 526, in minimize\n grads\\_and\\_vars = self.compute\\_gradients(loss, var\\_list, tape)\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\keras\\optimizers\\optimizer\\_experimental\\optimizer.py\", line 259, in compute\\_gradients\n grads = tape.gradient(loss, var\\_list)\nNode: 'gradient\\_tape/mean\\_squared\\_error/BroadcastGradientArgs'\nIncompatible shapes: [256,10,10] vs. [256,10]\n [[{{node gradient\\_tape/mean\\_squared\\_error/BroadcastGradientArgs}}]] [Op:\\_\\_inference\\_train\\_function\\_3407272]", "my shapes are same as you said but this script throws big error\n\nInvalidArgumentError Traceback (most recent call last)\nCell In[150], line 1\n----> 1 metrics = model.evaluate([X\\_test, RPM\\_test], y\\_test, batch\\_size=256)\n\nFile ~\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\keras\\utils\\traceback\\_utils.py:70, in filter\\_traceback..error\\_handler(\\*args, \\*\\*kwargs)\n 67 filtered\\_tb = \\_process\\_traceback\\_frames(e.\\_\\_traceback\\_\\_)\n 68 # To get the full stack trace, call:\n 69 # `tf.debugging.disable\\_traceback\\_filtering()`\n---> 70 raise e.with\\_traceback(filtered\\_tb) from None\n 71 finally:\n 72 del filtered\\_tb\n\nFile ~\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52, in quick\\_execute(op\\_name, num\\_outputs, inputs, attrs, ctx, name)\n 50 try:\n 51 ctx.ensure\\_initialized()\n---> 52 tensors = pywrap\\_tfe.TFE\\_Py\\_Execute(ctx.\\_handle, device\\_name, op\\_name,\n 53 inputs, attrs, num\\_outputs)\n 54 except core.\\_NotOkStatusException as e:\n 55 if name is not None:\n\nInvalidArgumentError: Graph execution error:\n\nDetected at node 'mean\\_squared\\_error/SquaredDifference' defined at (most recent call last):\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\runpy.py\", line 194, in \\_run\\_module\\_as\\_main\n return \\_run\\_code(code, main\\_globals, None,\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\runpy.py\", line 87, in \\_run\\_code\n exec(code, run\\_globals)\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\ipykernel\\_launcher.py\", line 17, in \n app.launch\\_new\\_instance()\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch\\_instance\n app.start()\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n self.io\\_loop.start()\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n self.asyncio\\_loop.run\\_forever()\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\asyncio\\base\\_events.py\", line 570, in run\\_forever\n self.\\_run\\_once()\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\asyncio\\base\\_events.py\", line 1859, in \\_run\\_once\n handle.\\_run()\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\asyncio\\events.py\", line 81, in \\_run\n self.\\_context.run(self.\\_callback, \\*self.\\_args)\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch\\_queue\n await self.process\\_one()\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process\\_one\n await dispatch(\\*args)\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch\\_shell\n await result\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute\\_request\n reply\\_content = await reply\\_content\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do\\_execute\n res = shell.run\\_cell(\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run\\_cell\n return super().run\\_cell(\\*args, \\*\\*kwargs)\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in run\\_cell\n result = self.\\_run\\_cell(\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2995, in \\_run\\_cell\n return runner(coro)\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\IPython\\core\\async\\_helpers.py\", line 129, in \\_pseudo\\_sync\\_runner\n coro.send(None)\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3194, in run\\_cell\\_async\n has\\_raised = await self.run\\_ast\\_nodes(code\\_ast.body, cell\\_name,\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3373, in run\\_ast\\_nodes\n if await self.run\\_code(code, result, async\\_=asy):\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3433, in run\\_code\n exec(code\\_obj, self.user\\_global\\_ns, self.user\\_ns)\n File \"C:\\Users\\yp229\\AppData\\Local\\Temp\\ipykernel\\_980\\3515400628.py\", line 2, in \n scores = model.evaluate([X\\_test, RPM\\_test], y\\_test, verbose=0)\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\keras\\utils\\traceback\\_utils.py\", line 65, in error\\_handler\n return fn(\\*args, \\*\\*kwargs)\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\keras\\engine\\training.py\", line 2040, in evaluate\n tmp\\_logs = self.test\\_function(iterator)\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\keras\\engine\\training.py\", line 1820, in test\\_function\n return step\\_function(self, iterator)\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\keras\\engine\\training.py\", line 1804, in step\\_function\n outputs = model.distribute\\_strategy.run(run\\_step, args=(data,))\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\keras\\engine\\training.py\", line 1792, in run\\_step\n outputs = model.test\\_step(data)\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\keras\\engine\\training.py\", line 1758, in test\\_step\n self.compute\\_loss(x, y, y\\_pred, sample\\_weight)\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\keras\\engine\\training.py\", line 1082, in compute\\_loss\n return self.compiled\\_loss(\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\keras\\engine\\compile\\_utils.py\", line 265, in \\_\\_call\\_\\_\n loss\\_value = loss\\_obj(y\\_t, y\\_p, sample\\_weight=sw)\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\keras\\losses.py\", line 152, in \\_\\_call\\_\\_\n losses = call\\_fn(y\\_true, y\\_pred)\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\keras\\losses.py\", line 284, in call\n return ag\\_fn(y\\_true, y\\_pred, \\*\\*self.\\_fn\\_kwargs)\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\keras\\losses.py\", line 1500, in mean\\_squared\\_error\n return backend.mean(tf.math.squared\\_difference(y\\_pred, y\\_true), axis=-1)\nNode: 'mean\\_squared\\_error/SquaredDifference'\nIncompatible shapes: [256,10] vs. [256,10,10]\n [[{{node mean\\_squared\\_error/SquaredDifference}}]] [Op:\\_\\_inference\\_test\\_function\\_3744761]", "Dans la SP suivante je veux\n- Remplacer le param\u00e8tre @InvoiceUID par @InvoiceUIDList qui est varchar(max), c'est des UIDs s\u00e9par\u00e9s par une virgule (UID1,UID2,...etc)\n- Mettre le contenu de @InvoiceUIDList dans #InvoiceUIDList en utiisant string\\_split\n- Mettre \u00e0 jour la SP pour prendre en compte ces modifications sans ajouter aucun commentaire\n- Fait \u00e7a en 4 fois avec le mot next pour continuer\ncreate procedure [dbo].[InvoiceExpenseInsertUpdate4]\n @DomainID int\n, @InvoiceUID uniqueidentifier\n, @ExpenseMetricSkuValueTable ExpenseMetricSkuValueTable readonly\n, @LoginID int\n, @LoginEmail nvarchar(200)\n, @UserID varchar(50)\n, @LoginName nvarchar(200)\n, @AppVersion varchar(15) = 'not passed'\n/\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\* Logic \\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\nCreate a PX Expense according the given Allocation method among :\n --0 -> Even Split at P1 level\n --1 -> Gross Sales (GSR)\n --2 -> Retail Sales\n --3 -> Manual, Data is saved as P1 level with values provided by .Net\n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*/\nas\nbegin\n\n set nocount on\n\n /\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n Helpers\n \\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*/\n declare @ModifiedBy varchar(200) = @LoginEmail -- :)\n -- declare @AllocationMethodEven int = 0\n -- declare @AllocationMethodGSR int = 1\n -- declare @AllocationMethodManual int = 3\n\n drop table if exists #InvoiceExpense\n create table #InvoiceExpense(\n RowNo int identity(1,1) -- will be used to manage insert split\n , InvoiceExpenseID int\n , AllocationMethod tinyint\n , Interval int null\n , SkuID2 int\n , Date date\n , MetricID int\n , Value decimal(18,5)\n )\n\n insert #InvoiceExpense(\n InvoiceExpenseID\n , AllocationMethod\n , Interval\n , SkuID2\n , Date\n , MetricID\n , Value\n )\n select distinct\n e.InvoiceExpenseID\n , e.AllocationMethod\n , e.Interval\n , p1.SkuID2\n , e.Date\n , e.MetricID\n , e.Value\n from\n @ExpenseMetricSkuValueTable e\n join LP\\_Sku p1 on e.SkuMemberID = p1.MemberID\n where\n p1.DomainID = @DomainID\n drop table if exists #InvoiceExpenseSku\n create table #InvoiceExpenseSku(\n RowNo int\n , InvoiceExpenseID int\n , SkuID2 int\n , MetricID int\n , [Date] date\n , Value decimal(18,5)\n )\n\n insert #InvoiceExpenseSku\n select\n e.RowNo\n , e.InvoiceExpenseID\n , et.P1SkuID2\n , e.MetricID\n , e.Date\n , et.P1Value\n from\n #InvoiceExpense e\n join @ExpenseMetricSkuValueTable et on\n e.InvoiceExpenseID = et.InvoiceExpenseID\n and e.MetricID = et.MetricID\n and e.Date = et.Date\n and e.AllocationMethod = et.AllocationMethod\n join LP\\_Sku px on\n px.MemberID = et.SkuMemberID\n and px.SkuID2 = e.SkuID2\n /\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n Merge to physical tables\n \\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*/\n drop table if exists #ChangeLog\n create table #ChangeLog (\n ChangeType varchar(10)\n , RowNo int\n , InsertedID int\n , SkuID2 int\n , MetricID int\n , OldValue float\n , NewValue float\n )\n\n begin try\n begin transaction\n\n ---------------------------------------------------------------------\n -- Checking that sum of P1Values = PXValue \u00b1 O.1 - if the check fails, this SP will exit\n -- 0.1 is equal to the error margin (delta) of the tuype decimal(18,5) = 0.00001 \\* Max number of Skus = 10 000\n if exists (select 1 from #InvoiceExpense e where abs(Value - (select sum(Value) from #InvoiceExpenseSku es where es.RowNo = e.RowNo)) > 0.1)\n begin\n ;throw 51000, 'InvoiceExpenseInsertUpdate4 exit because the sum of P1 Values is not equal to PXValue', 1;\n end\n -- Transactional table\n merge InvoiceExpense tgt\n using(\n select\n RowNo\n , InvoiceExpenseID\n , AllocationMethod\n , Interval\n , SkuID2\n , Date\n , MetricID\n , Value\n from\n #InvoiceExpense\n ) src on src.InvoiceExpenseID = tgt.InvoiceExpenseID\n when not matched\n then insert(\n DomainID\n , InvoiceUID\n , AllocationMethod\n , Interval\n , SkuID2\n , Date\n , MetricID\n , Value\n , ModifiedDate\n , ModifiedBy\n )\n values(\n @DomainID\n , @InvoiceUID\n , src.AllocationMethod\n , src.Interval\n , src.SkuID2\n , src.Date\n , src.MetricID\n , src.Value\n , getdate()\n , @ModifiedBy\n )\n when matched\n then update\n set\n AllocationMethod = src.AllocationMethod\n , Interval = src.Interval\n , SkuID2 = src.SkuID2\n , Date = src.Date\n , MetricID = src.MetricID\n , Value = src.Value\n , ModifiedDate = getdate()\n , ModifiedBy = @ModifiedBy\n output\n $action\n , src.RowNo\n , inserted.InvoiceExpenseID\n , inserted.SkuID2\n , inserted.MetricID\n , isnull(deleted.Value,0) as OldValue\n , inserted.Value as NewValue\n into\n #ChangeLog\n ;\n\n declare @CompanyID2 int\n\n select\n @CompanyID2 = c1.CompanyID2\n from\n Invoices i\n join LC\\_Customers c1 on\n i.CompanyID = c1.CompanyID\n and c1.DomainID = @DomainID\n where\n InvoiceUID = @InvoiceUID\n\n -- Denorm table\n delete InvoiceExpenseSku where InvoiceExpenseID in (select InsertedID from #ChangeLog)\n\n insert InvoiceExpenseSku(\n DomainID\n , InvoiceExpenseID\n , CompanyID2\n , SkuID2\n , MetricID\n , [Date]\n , [Value]\n , ModifiedDate\n , ModifiedBy\n )\n select\n @DomainID\n , l.InsertedID\n , @CompanyID2\n , es.SkuID2\n , es.MetricID\n , es.[Date]\n , es.Value\n , getdate()\n , @ModifiedBy\n from\n #InvoiceExpenseSku es\n join #ChangeLog l on es.RowNo = l.RowNo\n\n -- Log the change\n insert dbo.ChangeLog(\n DomainID\n , ChangeLogUID\n , Module\n , DocUID\n , LoginID\n , LoginEmail\n , LoginName\n , UserID\n , AppVersion\n , ModifiedDate\n , ModifiedBy\n , ChangeDetails\n , ChangeType\n )\n select\n @DomainID\n , newid()\n , 'payment'\n , @InvoiceUID\n , @LoginID\n , @LoginEmail\n , @LoginName\n , @UserID\n , @AppVersion\n , getdate()\n , @ModifiedBy\n , dbo.FctStringToXML(\n ''\n ) as ChangeDetails\n , lower(c.ChangeType) as ChangeType\n from\n #ChangeLog c\n join LP\\_Sku s on c.SkuID2 = s.SkuID2\n join SY\\_Metric m on c.MetricID = m.MetricID\n -- USER STORY 25436\n -- - Invoices.MatchedDate should be updated with getdate() as soon as the payment has sum(PCVM.Value) >= Invoices.Amount\n declare @InvoiceExpenseAmount float = (select sum(Value) from InvoiceExpense where InvoiceUID = @InvoiceUID)\n declare @InvoiceAmount float = (select Amount from Invoices where InvoiceUID = @InvoiceUID)\n\n if (@InvoiceExpenseAmount +0.01 >= @InvoiceAmount)\n begin\n update Invoices\n set MatchedDate = cast(getdate() as date)\n , ModifiedDate = getdate()\n , ModifiedBy = @ModifiedBy\n where InvoiceUID = @InvoiceUID\n end\n\n -- - Invoices.UserLevelMatching should be updated with SY\\_UserLevel.Code as soon as the payment is matched\n declare @UserLevelCode int = (select ul.UserLevelCode\n from Users u\n join SY\\_UserLevel ul on u.UserLevelID = ul.UserLevelID\n where u.UserID = @UserID)\n\n update Invoices\n set UserLevelMatching = @UserLevelCode\n where InvoiceUID = @InvoiceUID\n if @@trancount > 0\n commit transaction\n\n end try\n begin catch\n\n if @@trancount > 0\n rollback transaction\n\n ;throw;\n\n end catch\n\nend\n\nPlease write in English language.", "---------------------------------------------------------------------------\nLookupError Traceback (most recent call last)\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 83 try:\n---> 84 root = nltk.data.find(f\"{self.subdir}/{zip\\_name}\")\n 85 except LookupError:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\data.py in find(resource\\_name, paths)\n 582 resource\\_not\\_found = f\"\\n{sep}\\n{msg}\\n{sep}\\n\"\n--> 583 raise LookupError(resource\\_not\\_found)\n 584 \n\nLookupError: \n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n Resource omw-1.4 not found.\n Please use the NLTK Downloader to obtain the resource:\n\n >>> import nltk\n >>> nltk.download('omw-1.4')\n \n For more information see: https://www.nltk.org/data.html\n\n Attempted to load corpora/omw-1.4.zip/omw-1.4/\n\n Searched in:\n - 'C:\\\\Users\\\\rockr/nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\share\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\lib\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\AppData\\\\Roaming\\\\nltk\\_data'\n - 'C:\\\\nltk\\_data'\n - 'D:\\\\nltk\\_data'\n - 'E:\\\\nltk\\_data'\n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\nDuring handling of the above exception, another exception occurred:\n\nLookupError Traceback (most recent call last)\n~\\AppData\\Local\\Temp\\ipykernel\\_9724\\3827873343.py in \n 41 \n 42 # Preprocess train and test text data\n---> 43 train\\_df['text'] = train\\_df['text'].apply(preprocess\\_text)\n 44 test\\_df['text'] = test\\_df['text'].apply(preprocess\\_text)\n 45 \n\n~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py in apply(self, func, convert\\_dtype, args, \\*\\*kwargs)\n 4431 dtype: float64\n 4432 \"\"\"\n-> 4433 return SeriesApply(self, func, convert\\_dtype, args, kwargs).apply()\n 4434 \n 4435 def \\_reduce(\n\n~\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py in apply(self)\n 1086 return self.apply\\_str()\n 1087 \n-> 1088 return self.apply\\_standard()\n 1089 \n 1090 def agg(self):\n\n~\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py in apply\\_standard(self)\n 1141 # List[Union[Callable[..., Any], str]]]]]\"; expected\n 1142 # \"Callable[[Any], Any]\"\n-> 1143 mapped = lib.map\\_infer(\n 1144 values,\n 1145 f, # type: ignore[arg-type]\n\n~\\Anaconda3\\lib\\site-packages\\pandas\\\\_libs\\lib.pyx in pandas.\\_libs.lib.map\\_infer()\n\n~\\AppData\\Local\\Temp\\ipykernel\\_9724\\3827873343.py in preprocess\\_text(text)\n 35 # Lemmatize\n 36 lemmatizer = WordNetLemmatizer()\n---> 37 tokens = [lemmatizer.lemmatize(token) for token in tokens]\n 38 # Join tokens back into a string\n 39 text = ' '.join(tokens)\n\n~\\AppData\\Local\\Temp\\ipykernel\\_9724\\3827873343.py in (.0)\n 35 # Lemmatize\n 36 lemmatizer = WordNetLemmatizer()\n---> 37 tokens = [lemmatizer.lemmatize(token) for token in tokens]\n 38 # Join tokens back into a string\n 39 text = ' '.join(tokens)\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\stem\\wordnet.py in lemmatize(self, word, pos)\n 43 :return: The lemma of `word`, for the given `pos`.\n 44 \"\"\"\n---> 45 lemmas = wn.\\_morphy(word, pos)\n 46 return min(lemmas, key=len) if lemmas else word\n 47 \n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_getattr\\_\\_(self, attr)\n 119 raise AttributeError(\"LazyCorpusLoader object has no attribute '\\_\\_bases\\_\\_'\")\n 120 \n--> 121 self.\\_\\_load()\n 122 # This looks circular, but its not, since \\_\\_load() changes our\n 123 # \\_\\_class\\_\\_ to something new:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 87 \n 88 # Load the corpus.\n---> 89 corpus = self.\\_\\_reader\\_cls(root, \\*self.\\_\\_args, \\*\\*self.\\_\\_kwargs)\n 90 \n 91 # This is where the magic happens! Transform ourselves into\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py in \\_\\_init\\_\\_(self, root, omw\\_reader)\n 1174 )\n 1175 else:\n-> 1176 self.provenances = self.omw\\_prov()\n 1177 \n 1178 # A cache to store the wordnet data of multiple languages\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py in omw\\_prov(self)\n 1283 provdict = {}\n 1284 provdict[\"eng\"] = \"\"\n-> 1285 fileids = self.\\_omw\\_reader.fileids()\n 1286 for fileid in fileids:\n 1287 prov, langfile = os.path.split(fileid)\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_getattr\\_\\_(self, attr)\n 119 raise AttributeError(\"LazyCorpusLoader object has no attribute '\\_\\_bases\\_\\_'\")\n 120 \n--> 121 self.\\_\\_load()\n 122 # This looks circular, but its not, since \\_\\_load() changes our\n 123 # \\_\\_class\\_\\_ to something new:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 84 root = nltk.data.find(f\"{self.subdir}/{zip\\_name}\")\n 85 except LookupError:\n---> 86 raise e\n 87 \n 88 # Load the corpus.\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 79 else:\n 80 try:\n---> 81 root = nltk.data.find(f\"{self.subdir}/{self.\\_\\_name}\")\n 82 except LookupError as e:\n 83 try:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\data.py in find(resource\\_name, paths)\n 581 sep = \"\\*\" \\* 70\n 582 resource\\_not\\_found = f\"\\n{sep}\\n{msg}\\n{sep}\\n\"\n--> 583 raise LookupError(resource\\_not\\_found)\n 584 \n 585 \n\nLookupError: \n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n Resource omw-1.4 not found.\n Please use the NLTK Downloader to obtain the resource:\n\n >>> import nltk\n >>> nltk.download('omw-1.4')\n \n For more information see: https://www.nltk.org/data.html\n\n Attempted to load corpora/omw-1.4\n\n Searched in:\n - 'C:\\\\Users\\\\rockr/nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\share\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\lib\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\AppData\\\\Roaming\\\\nltk\\_data'\n - 'C:\\\\nltk\\_data'\n - 'D:\\\\nltk\\_data'\n - 'E:\\\\nltk\\_data'\n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\nplease fix this error", "---------------------------------------------------------------------------\nLookupError Traceback (most recent call last)\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 83 try:\n---> 84 root = nltk.data.find(f\"{self.subdir}/{zip\\_name}\")\n 85 except LookupError:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\data.py in find(resource\\_name, paths)\n 582 resource\\_not\\_found = f\"\\n{sep}\\n{msg}\\n{sep}\\n\"\n--> 583 raise LookupError(resource\\_not\\_found)\n 584 \n\nLookupError: \n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n Resource omw-1.4 not found.\n Please use the NLTK Downloader to obtain the resource:\n\n >>> import nltk\n >>> nltk.download('omw-1.4')\n \n For more information see: https://www.nltk.org/data.html\n\n Attempted to load corpora/omw-1.4.zip/omw-1.4/\n\n Searched in:\n - 'C:\\\\Users\\\\rockr/nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\share\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\lib\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\AppData\\\\Roaming\\\\nltk\\_data'\n - 'C:\\\\nltk\\_data'\n - 'D:\\\\nltk\\_data'\n - 'E:\\\\nltk\\_data'\n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\nDuring handling of the above exception, another exception occurred:\n\nLookupError Traceback (most recent call last)\n~\\AppData\\Local\\Temp\\ipykernel\\_9724\\3118448898.py in \n 42 \n 43 # Preprocess train and test text data\n---> 44 train\\_df['text'] = train\\_df['text'].apply(preprocess\\_text)\n 45 test\\_df['text'] = test\\_df['text'].apply(preprocess\\_text)\n 46 \n\n~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py in apply(self, func, convert\\_dtype, args, \\*\\*kwargs)\n 4431 dtype: float64\n 4432 \"\"\"\n-> 4433 return SeriesApply(self, func, convert\\_dtype, args, kwargs).apply()\n 4434 \n 4435 def \\_reduce(\n\n~\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py in apply(self)\n 1086 return self.apply\\_str()\n 1087 \n-> 1088 return self.apply\\_standard()\n 1089 \n 1090 def agg(self):\n\n~\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py in apply\\_standard(self)\n 1141 # List[Union[Callable[..., Any], str]]]]]\"; expected\n 1142 # \"Callable[[Any], Any]\"\n-> 1143 mapped = lib.map\\_infer(\n 1144 values,\n 1145 f, # type: ignore[arg-type]\n\n~\\Anaconda3\\lib\\site-packages\\pandas\\\\_libs\\lib.pyx in pandas.\\_libs.lib.map\\_infer()\n\n~\\AppData\\Local\\Temp\\ipykernel\\_9724\\3118448898.py in preprocess\\_text(text)\n 36 # Lemmatize\n 37 lemmatizer = WordNetLemmatizer()\n---> 38 tokens = [lemmatizer.lemmatize(token) for token in tokens]\n 39 # Join tokens back into a string\n 40 text = ' '.join(tokens)\n\n~\\AppData\\Local\\Temp\\ipykernel\\_9724\\3118448898.py in (.0)\n 36 # Lemmatize\n 37 lemmatizer = WordNetLemmatizer()\n---> 38 tokens = [lemmatizer.lemmatize(token) for token in tokens]\n 39 # Join tokens back into a string\n 40 text = ' '.join(tokens)\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\stem\\wordnet.py in lemmatize(self, word, pos)\n 43 :return: The lemma of `word`, for the given `pos`.\n 44 \"\"\"\n---> 45 lemmas = wn.\\_morphy(word, pos)\n 46 return min(lemmas, key=len) if lemmas else word\n 47 \n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_getattr\\_\\_(self, attr)\n 119 raise AttributeError(\"LazyCorpusLoader object has no attribute '\\_\\_bases\\_\\_'\")\n 120 \n--> 121 self.\\_\\_load()\n 122 # This looks circular, but its not, since \\_\\_load() changes our\n 123 # \\_\\_class\\_\\_ to something new:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 87 \n 88 # Load the corpus.\n---> 89 corpus = self.\\_\\_reader\\_cls(root, \\*self.\\_\\_args, \\*\\*self.\\_\\_kwargs)\n 90 \n 91 # This is where the magic happens! Transform ourselves into\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py in \\_\\_init\\_\\_(self, root, omw\\_reader)\n 1174 )\n 1175 else:\n-> 1176 self.provenances = self.omw\\_prov()\n 1177 \n 1178 # A cache to store the wordnet data of multiple languages\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py in omw\\_prov(self)\n 1283 provdict = {}\n 1284 provdict[\"eng\"] = \"\"\n-> 1285 fileids = self.\\_omw\\_reader.fileids()\n 1286 for fileid in fileids:\n 1287 prov, langfile = os.path.split(fileid)\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_getattr\\_\\_(self, attr)\n 119 raise AttributeError(\"LazyCorpusLoader object has no attribute '\\_\\_bases\\_\\_'\")\n 120 \n--> 121 self.\\_\\_load()\n 122 # This looks circular, but its not, since \\_\\_load() changes our\n 123 # \\_\\_class\\_\\_ to something new:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 84 root = nltk.data.find(f\"{self.subdir}/{zip\\_name}\")\n 85 except LookupError:\n---> 86 raise e\n 87 \n 88 # Load the corpus.\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 79 else:\n 80 try:\n---> 81 root = nltk.data.find(f\"{self.subdir}/{self.\\_\\_name}\")\n 82 except LookupError as e:\n 83 try:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\data.py in find(resource\\_name, paths)\n 581 sep = \"\\*\" \\* 70\n 582 resource\\_not\\_found = f\"\\n{sep}\\n{msg}\\n{sep}\\n\"\n--> 583 raise LookupError(resource\\_not\\_found)\n 584 \n 585 \n\nLookupError: \n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n Resource omw-1.4 not found.\n Please use the NLTK Downloader to obtain the resource:\n\n >>> import nltk\n >>> nltk.download('omw-1.4')\n \n For more information see: https://www.nltk.org/data.html\n\n Attempted to load corpora/omw-1.4\n\n Searched in:\n - 'C:\\\\Users\\\\rockr/nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\share\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\lib\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\AppData\\\\Roaming\\\\nltk\\_data'\n - 'C:\\\\nltk\\_data'\n - 'D:\\\\nltk\\_data'\n - 'E:\\\\nltk\\_data'\n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n\nstill error", "I will provide another piece of content to be used as an input about Rolling Loud and Loudpunx below:\n\nRolling Loud and LoudPunx\nEarlier this morning, I came across a large Twitter Spaces hosted by LoudPunx, the NFT project from Rolling Loud. Even Gary Vee (3.1M followers on Twitter) popped in to pledge his support for the project as he is friends with the founder Tariq.\n\nSide note about Gary Vee\u2019s appearance\nWhen Gary Vee joined the Twitter Spaces, the listener count went from ~900 to ~1500.\n\nOne masterful thing that Gary Vee did was he called out the names of his Veefriends holders that followed him into the Twitter Spaces, as indicated by the listener\u2019s PFP. In total he probably called out 20+ of his community members that were listening in while verbally expressing his support for LoudPunx.\n\nWhy is this notable?\n\nGary is expressing his gratitude for all of his supporters, regardless of where he is. Additionally, he didn\u2019t do it in a way that was disruptive to the flow of conversation that was focused on the LoudPunx launch. You can tell that Gary is dedicated to his community and is serious about providing value to them, even if it\u2019s a shoutout.\n\nFounders take note, how can you thoughtfully show gratitude to your community? It doesn\u2019t have to be in the form of another NFT airdrop. A shoutout (or retweeting a community member\u2019s content \u2014 see what BAYC does) provides value that a floor price increase doesn\u2019t.\n\nBack to Rolling Loud\nWhat\u2019s Rolling Loud? It\u2019s a music festival that started in 2015 and has established itself as one of the premier festivals for hip hop fans. For anyone into hip hop, a lineup like this is massive.\nSource\nLoudPunx is priced at a hefty 1.5 ETH (~$2,500) with 5,555 supply. This is steep price, but what does the price tag entail?\n\nLifetime VIP access to all future Rolling Loud festivals in California, Miami, NYC, Toronto, Portugal, Germany, Netherlands, Thailand and more.\n\nAccess to an exclusive LoudPunx holders area within the VIP areas\n\nGiveaways to associated acts and their events (eg: There will be a holders-only raffle for Lil Wayne tour tickets)\n\nExclusive insight to Rolling Loud content and future projects\n\nAccess to premium merchandise drops and collaboration\n\nThe first point is what gets interesting. This is a lifetime pass. How much does a VIP pass cost at a Rolling Loud event?\nIf I were a Rolling Loud superfan and purchased this NFT, the LoudPunx NFT would pay itself back by the third event and would be an absolute no-brainer. On top of that, Rolling Loud isn\u2019t just a once a year event \u2014 There are 8 scheduled festivals in various locations around the world in 2023 alone.\n\nSo it\u2019s clear from a value perspective that a LoudPunx NFT is a steal. However, the reality of the situation is that:\n\nThis is a web3 specific effort so the addressable audience is smaller than Rolling Loud\u2019s total audience\n\nThe concept of \u2018time to value\u2019 warps the consumer\u2019s perception of this opportunity\n\n1.5 ETH/$2,500 upfront is steep. No payment plans or BNPL\n\n5,555 supply is a lot considering the sticker price\n\nWhen thinking of \u2018time to value\u2019, I think back to my 24 Hour Fitness gym membership when I first graduated college.\nThe commoner\u2019s gym, it was great!\nIf I recall correctly, I paid $59 per month for Super Sport access. I knew that Costco sold a 2-year All-Club Super Sport membership for $700 flat. If I purchased the 2-year membership, I could have achieved \u2018breakeven\u2019 value in a year.\n\nNo-brainer right?!\n\nWell, for some silly reason, TPan never took advantage of the obvious Costco deal despite knowing that it was worth it. Thinking back on the indecision, one of the reasons was I didn\u2019t know if I would end up moving (unreasonable since this was all-club access). The other reason was I didn\u2019t want to pay $700 upfront regardless of the value.\n\nThe same could happen with LoudPunx, but that\u2019s where the beauty of web3 and tokenization of the NFT provides liquidity for those that want in or out on the lifetime membership.\n\nWith the LoudPunx launch, we\u2019re starting to see a larger sample size of live-event collections testing out a pass model.\n\nNote: This is not comprehensive, but illustrative to the different models that are being rolled out.\nSome notes on the other comps:\n\nThe Carton: The Lyrical Lemonade team decided on a 3 years of access which shows perpetual utility for a longer length of time, not forever.\n\nThe Tick3t: This effort was not built off an existing owned & operated business model. The Tick3t essentially pools together capital from the memberships to season tickets to venues around the world. They incorporate a waiver (waitlist) system to holders. When holder redeem their NFT for access to an event, they move to the bottom of the waiver.\n\nBelow is an example of their upcoming calendar, and the past events calendar is here.\nSource\nAs enticing as the seats and events are, the primary disadvantage of a this model is that the company doesn\u2019t manage the events themselves. This limits the capacity for each event and results in the reliance of a waiver system for ticket redemption.\n\nThe value for a holder can still be worth it, but is dependent how the team strategically allocates funds to purchasing seats and season tickets.\n\nIt seems the that community hasn\u2019t seen the value they expected as the price for these passes has dipped down to .09 ETH (~$150). Additionally, the waiver system may encourage selling the pass once it has been redeemed, adding to the volatility in the secondary market.\n\nSuperf3st: The Superf3st Superpass provides free access to the 2023 Superf3st and allows for active participation for the direction of the event. 1 Pass = 1 Vote.\n\nPutting it all Together\nAs mentioned earlier, the \u2018right\u2019 model around NFTs functioning as an access pass to IRL events is still unclear. As more event pass NFT program rise, we\u2019ll begin to identify which ones work, and which ones don\u2019t.\n\nI would also consider the following themes:\n\nWhat\u2019s the business goal?\n\nI have to assume that the Rolling Loud team understands that LoudPunx functioning as a lifetime pass is a losing proposition from a ROI standpoint. I think they\u2019re betting on LoudPunx being the VIP of VIP status for all their events. Status matters.\n\nBecause LoudPunx holders get treated as royalty at physical events, other attendees will notice and want in.\n\nIt\u2019s important to note that Rolling Loud can probably eat the cost if the effort is unsuccessful. They\u2019ve held festivals with over 200,000 attendees. Lifetime passes or NFTs with evergreen are a long-term bet, not an ephemeral one.\n\nWhen viewing this effort from a longer term perspective, an effort like LoudPunx becomes advantageous. LoudPunx allows Rolling Loud to roll out web3 enablement in a thoughtful manner and test out integrations with a smaller audience before large-scale deployment. LoudPunx holders will also be more familiar with using web3-enabled tech, so they\u2019d be perfect for QA vs. a clueless user.\n\nIf successful, what would Rolling Loud consider?\n\nCreating lifetime GA passes and/or test different structures by length (eg: 3-year pass) or region (Asia pass)\n\nRolling out tech integrations to all events\n\nNFT ticketing with partners like Tokenproof\n\nPaying for food/drinks via tokens. What if Rolling Loud created their own digital currency based on brand engagement and loyalty similar to the Cool Score mentioned earlier?\n\nRolling Loud specific marketplaces for ticket purchase and sale and take a cut of secondary sales\n\nPerks vs. Participation\n\nIn the coming months and years in the there will be more distinction between perks and participation.\n\nOne of the themes of web3 consumer brands is that there is a deeper relationship between the community member and the company/team. However, the reality is not everyone wants that. Most people want the front row seat to the sporting match. They don\u2019t want to be the coach determining the plays.\n\nData\n\nAs always, there\u2019s a data play \ud83d\ude09\n\nWith LoudPunx, the Rolling Loud team can add another dimension to understanding their attendees, especially if they work with a web3 ticketing partner.\n\nWith a large enough of a sample size, I\u2019d want to understand:\n\nAre LoudPunx holders previous attendees? How many events did they attend before vs. after? Did they attend international events before vs after?\n\nHow often are passes being redeemed at Rolling Loud events?\n\nWhat are the spending habits of holders ex-tickets before vs. after? If they\u2019re spending more because they don\u2019t have to pay for tickets, where are they spending it?\n\nHow would these insights impact attendee behavior if this effort rolled out to a larger subset of the Rolling Loud audience?\n\nOn a related note, if Rolling Loud were to expand their web3 onboarding efforts, they could airdrop every attendee a free food ticket, while also understanding food vendor preferences.\n\nOn another related note (uh oh, TPan is going off the rails), Rolling Loud could airdrop specific promotions with sponsors or event participants:\n\nGet 50% off if you buy a Bud Light\n\nGet 20% off Travis Scott merch on the day he headlines\n\nIf you arrive before 2pm, get 25% off food\n\nLive events are going to get interesting with web3. I can\u2019t wait to attend my first web3 enabled music festival if my old creaky bones cooperate \ud83d\udc74\ud83c\udffb", "---------------------------------------------------------------------------\nLookupError Traceback (most recent call last)\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 83 try:\n---> 84 root = nltk.data.find(f\"{self.subdir}/{zip\\_name}\")\n 85 except LookupError:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\data.py in find(resource\\_name, paths)\n 582 resource\\_not\\_found = f\"\\n{sep}\\n{msg}\\n{sep}\\n\"\n--> 583 raise LookupError(resource\\_not\\_found)\n 584 \n\nLookupError: \n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n Resource omw-1.4 not found.\n Please use the NLTK Downloader to obtain the resource:\n\n >>> import nltk\n >>> nltk.download('omw-1.4')\n \n For more information see: https://www.nltk.org/data.html\n\n Attempted to load corpora/omw-1.4.zip/omw-1.4/\n\n Searched in:\n - 'C:\\\\Users\\\\rockr/nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\share\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\lib\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\AppData\\\\Roaming\\\\nltk\\_data'\n - 'C:\\\\nltk\\_data'\n - 'D:\\\\nltk\\_data'\n - 'E:\\\\nltk\\_data'\n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\nDuring handling of the above exception, another exception occurred:\n\nLookupError Traceback (most recent call last)\n~\\AppData\\Local\\Temp\\ipykernel\\_9724\\3827873343.py in \n 41 \n 42 # Preprocess train and test text data\n---> 43 train\\_df['text'] = train\\_df['text'].apply(preprocess\\_text)\n 44 test\\_df['text'] = test\\_df['text'].apply(preprocess\\_text)\n 45 \n\n~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py in apply(self, func, convert\\_dtype, args, \\*\\*kwargs)\n 4431 dtype: float64\n 4432 \"\"\"\n-> 4433 return SeriesApply(self, func, convert\\_dtype, args, kwargs).apply()\n 4434 \n 4435 def \\_reduce(\n\n~\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py in apply(self)\n 1086 return self.apply\\_str()\n 1087 \n-> 1088 return self.apply\\_standard()\n 1089 \n 1090 def agg(self):\n\n~\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py in apply\\_standard(self)\n 1141 # List[Union[Callable[..., Any], str]]]]]\"; expected\n 1142 # \"Callable[[Any], Any]\"\n-> 1143 mapped = lib.map\\_infer(\n 1144 values,\n 1145 f, # type: ignore[arg-type]\n\n~\\Anaconda3\\lib\\site-packages\\pandas\\\\_libs\\lib.pyx in pandas.\\_libs.lib.map\\_infer()\n\n~\\AppData\\Local\\Temp\\ipykernel\\_9724\\3827873343.py in preprocess\\_text(text)\n 35 # Lemmatize\n 36 lemmatizer = WordNetLemmatizer()\n---> 37 tokens = [lemmatizer.lemmatize(token) for token in tokens]\n 38 # Join tokens back into a string\n 39 text = ' '.join(tokens)\n\n~\\AppData\\Local\\Temp\\ipykernel\\_9724\\3827873343.py in (.0)\n 35 # Lemmatize\n 36 lemmatizer = WordNetLemmatizer()\n---> 37 tokens = [lemmatizer.lemmatize(token) for token in tokens]\n 38 # Join tokens back into a string\n 39 text = ' '.join(tokens)\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\stem\\wordnet.py in lemmatize(self, word, pos)\n 43 :return: The lemma of `word`, for the given `pos`.\n 44 \"\"\"\n---> 45 lemmas = wn.\\_morphy(word, pos)\n 46 return min(lemmas, key=len) if lemmas else word\n 47 \n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_getattr\\_\\_(self, attr)\n 119 raise AttributeError(\"LazyCorpusLoader object has no attribute '\\_\\_bases\\_\\_'\")\n 120 \n--> 121 self.\\_\\_load()\n 122 # This looks circular, but its not, since \\_\\_load() changes our\n 123 # \\_\\_class\\_\\_ to something new:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 87 \n 88 # Load the corpus.\n---> 89 corpus = self.\\_\\_reader\\_cls(root, \\*self.\\_\\_args, \\*\\*self.\\_\\_kwargs)\n 90 \n 91 # This is where the magic happens! Transform ourselves into\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py in \\_\\_init\\_\\_(self, root, omw\\_reader)\n 1174 )\n 1175 else:\n-> 1176 self.provenances = self.omw\\_prov()\n 1177 \n 1178 # A cache to store the wordnet data of multiple languages\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py in omw\\_prov(self)\n 1283 provdict = {}\n 1284 provdict[\"eng\"] = \"\"\n-> 1285 fileids = self.\\_omw\\_reader.fileids()\n 1286 for fileid in fileids:\n 1287 prov, langfile = os.path.split(fileid)\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_getattr\\_\\_(self, attr)\n 119 raise AttributeError(\"LazyCorpusLoader object has no attribute '\\_\\_bases\\_\\_'\")\n 120 \n--> 121 self.\\_\\_load()\n 122 # This looks circular, but its not, since \\_\\_load() changes our\n 123 # \\_\\_class\\_\\_ to something new:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 84 root = nltk.data.find(f\"{self.subdir}/{zip\\_name}\")\n 85 except LookupError:\n---> 86 raise e\n 87 \n 88 # Load the corpus.\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 79 else:\n 80 try:\n---> 81 root = nltk.data.find(f\"{self.subdir}/{self.\\_\\_name}\")\n 82 except LookupError as e:\n 83 try:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\data.py in find(resource\\_name, paths)\n 581 sep = \"\\*\" \\* 70\n 582 resource\\_not\\_found = f\"\\n{sep}\\n{msg}\\n{sep}\\n\"\n--> 583 raise LookupError(resource\\_not\\_found)\n 584 \n 585 \n\nLookupError: \n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n Resource omw-1.4 not found.\n Please use the NLTK Downloader to obtain the resource:\n\n >>> import nltk\n >>> nltk.download('omw-1.4')\n \n For more information see: https://www.nltk.org/data.html\n\n Attempted to load corpora/omw-1.4\n\n Searched in:\n - 'C:\\\\Users\\\\rockr/nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\share\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\lib\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\AppData\\\\Roaming\\\\nltk\\_data'\n - 'C:\\\\nltk\\_data'\n - 'D:\\\\nltk\\_data'\n - 'E:\\\\nltk\\_data'\n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\nplease fix this error", "---------------------------------------------------------------------------\nLookupError Traceback (most recent call last)\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 83 try:\n---> 84 root = nltk.data.find(f\"{self.subdir}/{zip\\_name}\")\n 85 except LookupError:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\data.py in find(resource\\_name, paths)\n 582 resource\\_not\\_found = f\"\\n{sep}\\n{msg}\\n{sep}\\n\"\n--> 583 raise LookupError(resource\\_not\\_found)\n 584 \n\nLookupError: \n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n Resource omw-1.4 not found.\n Please use the NLTK Downloader to obtain the resource:\n\n >>> import nltk\n >>> nltk.download('omw-1.4')\n \n For more information see: https://www.nltk.org/data.html\n\n Attempted to load corpora/omw-1.4.zip/omw-1.4/\n\n Searched in:\n - 'C:\\\\Users\\\\rockr/nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\share\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\lib\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\AppData\\\\Roaming\\\\nltk\\_data'\n - 'C:\\\\nltk\\_data'\n - 'D:\\\\nltk\\_data'\n - 'E:\\\\nltk\\_data'\n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\nDuring handling of the above exception, another exception occurred:\n\nLookupError Traceback (most recent call last)\n~\\AppData\\Local\\Temp\\ipykernel\\_9724\\3118448898.py in \n 42 \n 43 # Preprocess train and test text data\n---> 44 train\\_df['text'] = train\\_df['text'].apply(preprocess\\_text)\n 45 test\\_df['text'] = test\\_df['text'].apply(preprocess\\_text)\n 46 \n\n~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py in apply(self, func, convert\\_dtype, args, \\*\\*kwargs)\n 4431 dtype: float64\n 4432 \"\"\"\n-> 4433 return SeriesApply(self, func, convert\\_dtype, args, kwargs).apply()\n 4434 \n 4435 def \\_reduce(\n\n~\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py in apply(self)\n 1086 return self.apply\\_str()\n 1087 \n-> 1088 return self.apply\\_standard()\n 1089 \n 1090 def agg(self):\n\n~\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py in apply\\_standard(self)\n 1141 # List[Union[Callable[..., Any], str]]]]]\"; expected\n 1142 # \"Callable[[Any], Any]\"\n-> 1143 mapped = lib.map\\_infer(\n 1144 values,\n 1145 f, # type: ignore[arg-type]\n\n~\\Anaconda3\\lib\\site-packages\\pandas\\\\_libs\\lib.pyx in pandas.\\_libs.lib.map\\_infer()\n\n~\\AppData\\Local\\Temp\\ipykernel\\_9724\\3118448898.py in preprocess\\_text(text)\n 36 # Lemmatize\n 37 lemmatizer = WordNetLemmatizer()\n---> 38 tokens = [lemmatizer.lemmatize(token) for token in tokens]\n 39 # Join tokens back into a string\n 40 text = ' '.join(tokens)\n\n~\\AppData\\Local\\Temp\\ipykernel\\_9724\\3118448898.py in (.0)\n 36 # Lemmatize\n 37 lemmatizer = WordNetLemmatizer()\n---> 38 tokens = [lemmatizer.lemmatize(token) for token in tokens]\n 39 # Join tokens back into a string\n 40 text = ' '.join(tokens)\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\stem\\wordnet.py in lemmatize(self, word, pos)\n 43 :return: The lemma of `word`, for the given `pos`.\n 44 \"\"\"\n---> 45 lemmas = wn.\\_morphy(word, pos)\n 46 return min(lemmas, key=len) if lemmas else word\n 47 \n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_getattr\\_\\_(self, attr)\n 119 raise AttributeError(\"LazyCorpusLoader object has no attribute '\\_\\_bases\\_\\_'\")\n 120 \n--> 121 self.\\_\\_load()\n 122 # This looks circular, but its not, since \\_\\_load() changes our\n 123 # \\_\\_class\\_\\_ to something new:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 87 \n 88 # Load the corpus.\n---> 89 corpus = self.\\_\\_reader\\_cls(root, \\*self.\\_\\_args, \\*\\*self.\\_\\_kwargs)\n 90 \n 91 # This is where the magic happens! Transform ourselves into\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py in \\_\\_init\\_\\_(self, root, omw\\_reader)\n 1174 )\n 1175 else:\n-> 1176 self.provenances = self.omw\\_prov()\n 1177 \n 1178 # A cache to store the wordnet data of multiple languages\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py in omw\\_prov(self)\n 1283 provdict = {}\n 1284 provdict[\"eng\"] = \"\"\n-> 1285 fileids = self.\\_omw\\_reader.fileids()\n 1286 for fileid in fileids:\n 1287 prov, langfile = os.path.split(fileid)\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_getattr\\_\\_(self, attr)\n 119 raise AttributeError(\"LazyCorpusLoader object has no attribute '\\_\\_bases\\_\\_'\")\n 120 \n--> 121 self.\\_\\_load()\n 122 # This looks circular, but its not, since \\_\\_load() changes our\n 123 # \\_\\_class\\_\\_ to something new:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 84 root = nltk.data.find(f\"{self.subdir}/{zip\\_name}\")\n 85 except LookupError:\n---> 86 raise e\n 87 \n 88 # Load the corpus.\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 79 else:\n 80 try:\n---> 81 root = nltk.data.find(f\"{self.subdir}/{self.\\_\\_name}\")\n 82 except LookupError as e:\n 83 try:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\data.py in find(resource\\_name, paths)\n 581 sep = \"\\*\" \\* 70\n 582 resource\\_not\\_found = f\"\\n{sep}\\n{msg}\\n{sep}\\n\"\n--> 583 raise LookupError(resource\\_not\\_found)\n 584 \n 585 \n\nLookupError: \n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n Resource omw-1.4 not found.\n Please use the NLTK Downloader to obtain the resource:\n\n >>> import nltk\n >>> nltk.download('omw-1.4')\n \n For more information see: https://www.nltk.org/data.html\n\n Attempted to load corpora/omw-1.4\n\n Searched in:\n - 'C:\\\\Users\\\\rockr/nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\share\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\lib\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\AppData\\\\Roaming\\\\nltk\\_data'\n - 'C:\\\\nltk\\_data'\n - 'D:\\\\nltk\\_data'\n - 'E:\\\\nltk\\_data'\n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n\nstill error", "summarize this transcript:\n\namd's giving us old goods and can't work\nwith new Goods motherboards that connect\nfrom the back and this thing's faster\nthan the 4090 let's get in the hot news\neverybody I'm your bright host we're\ngonna be going over the hottest Tech\nnews I can find on the internet while\nyou enjoy your breakfast and we're gonna\nstart off today talking about a new CPU\nthat amd's dropping get ready for it\nit's the ryzen 3\non a Zen 2 process that came out in the\nat retail by AMD this is something that\nis kind of late a lot of the 4000 series\napus didn't actually make it to retail\nbecause AMD only wanted to ship them to\ncompanies like Dell Lenovo all the types\nof oems that would sell it straight to\nyou as a consumer so that's actually how\nyou usually saw a lot of reviews of\nthese chips is that they had to buy them\nout of the systems but now finally AMD\nis bringing this to us which kinda is\nhow they've been approaching the low end\nside of their chip Market you see the\ncheapest CPU that they launched was the\nryzen 5 5600x at 299 the 5600 came in a\nlittle bit cheaper than that recently\nbut nothing under the 200 Mark and if\nAMD is going to be giving us really\ncheap CPUs it's going to be stuff that's\nGenerations old because then they can\nactually make a decent margin on them\nbecause it's already been worked out as\nopposed to trying to give us something\nnew that's good that's capable for 99\nand the last time they even tried to do\nthat with the ryzen 3 3100 3300x they\nnever really officially put enough stock\nbehind them if you want to know how the\nryzen 4300g is going to perform you can\nwatch this video where we released a\nreview of the 5300g which is essentially\nthe same chip that's right AMD released\na follow-up to this CPU before they're\nactually releasing it to you that you\ncan buy it get ready for it but AMD\nwhile they're giving us old Goods they\ncan't get ready for the new Goods which\nis the Corsair and crucial's new 24 and\nchange the market and how much RAM you\ncan actually have in your system no more\nnumbers but AMD has not had official\nsupport for it at the current moment\nb650 not supporting it Intel has\nlaunched bioses that do support this Ram\nbut AMD hasn't gotten that far however\nsome people have gotten their hands on\nthese RAM sticks and installed them into\nAMD systems and they've actually gotten\nthe systems to post to go into the BIOS\nto properly display the actual amount of\nram but when they attempt to actually go\ninto Windows it doesn't work and the\nsystem can't actually run it so it's\nhalfway there AMD just needs to give a\nlittle bit more support for the weird\nRam sizes and another weird product Lee\nand Lee wants to launch us is the o11d\nXL case that's getting the EK reflection\nscreen that is right my friends a water\nBlock in a CPU case that has water\ncooling built into the panel and now it\nalso has a 7 inch 1024 by 600 panel that\nallows you to connect it with an HDMI\ncable so that you can display whatever\nyou you want on that front section right\ndown here you can have the visibility\nbaked in from the manufacturer level\ninstead of having to install your own\nwhich you can do there's options for\nthat on Amazon you pick up little screen\ndisplays that you can pump out speaking\nof pumping out I don't know if Reese is\ngoing to pump out any ufd deals today\nbecause he and Catelyn are both meeting\nwith my wife today like by the time\nyou're watching this episode of hot news\nthey will have already had lunch\ntogether in South Africa and I'm not\nbitter in the slightest actually hurt\nmyself there yo welcome back to EFT\ndeals bringing the hottest Tech deals on\nthe internet except for yesterday when I\ndidn't\nbut I have deals today specifically\nsomething I haven't seen before which is\na compact High refresh rate monitor this\nbiotech gfv 22cb features a 22 inch\nonly 114.99 which is 28 off and then\nnext up we have this ASRock z690 steel\nLegend motherboard features an LJ 1700\nsocket for 12th gen and 13 gen support\nwith ddr4 which you can pick up for only\nprice in 30 days those are the deals you\ncan find those and more linked Down\nBelow in the video description but until\nnext time I'ma hand you off back to Brad\nfor the rest of your hot news cheers\nthanks Reese I hope you feel bad because\nyou you're hurting me and Volkswagen\nallegedly feels bad as much as the\ncorporation can feel bad for anything\nthat they've done we didn't officially\ncover this in hot news we did do a short\non this Volkswagen incident which was\nabout how there was a car theft that\ninvolved a child also being kidnapped\nand a pregnant mother being run over by\nthe Volkswagen Car Volkswagen has\ntracking built into their cars where\nyou're actually able to find out where\nthe vehicle is however because the\nperson didn't subscribe to the actual\ncar tracking officially for 150 a year\nVolkswagen chose to not help the\nauthorities out in this instance\nVolkswagen did say that they did have\nways that the authorities could have\nworked with them and that it was a ball\ndropped on VW side and they're going to\nbe issuing a make good which is going to\nallow for five years of this car\nconnectivity their car not access to be\nrolled out to Volkswagen customers for\npeople who have purchased a vehicle from\nthem Volkswagen says that this was a\nprocess failure they're working to make\nit right in the future the pregnant\nmother who got run over the last I heard\nis still in the hospital the child who\nwas abducted was found several miles\ndown the road but is safe and this is\njust a bad situation overall but the\nVolkswagen's trying I guess and then a\nlittle bit of a more light-hearted free\nupdate Sony is going to be bringing out\nthe PlayStation 5 Discord access finally\nthey've had the beta access for their\naccess 1440p vrr support and now that's\nofficially rolling out where you should\nbe able to download it even if you're\nnot part of the PlayStation beta program\nsetup but you're not going to be able to\ndownload Starfield bethesda's upcoming\nanticipated title until September 6th\nBethesda giving it another release date\nit was supposed to be released in\nNovember of last year they're going to\ngive a deeper dive on it on June 11th\nand I want to Deep dive more in on these\ntypes of different products that are\ncoming out Asus announcing the\nb760mbtf motherboard which is\nessentially a real departure from how\nmotherboards are set up if you just take\na quick little look do you notice\nanything weird about this motherboard if\nyou are paying attention that's right\nall of the Power connectors fan\nconnectors LED connectors are on the\nback of the board which makes it so that\nyour cables are routed through the back\nnow not every case that you're going to\nmount this in is going to be set up for\nthis to be successful this is going to\nhave to be a very well thought out\nsituation but because of the standards\nthat we have with ATX and other form\nfactors on motherboards this is not\nreally typical because cases don't allow\nfor a lot of of experimentation this is\nslightly similar to what gigabyte did\nwith their project stealth build that\nyou can see right here which also had no\ncables except for this one went a little\nbit further because you could plug the\nGPU in through the back whereas the Asus\nv760 board is just about the motherboard\nand if you're all about that cache that\ncrypto cash well tp-link Asic has\nsomething for you this is a miner right\nhere look at that that's a Bitcoin miner\nthat according to their reports is\nfaster than an RTX 4090 it can pull 1200\nwatts gonna set you back a cool\nCadena Miner while also being a Wi-Fi 7\nrouter it's actually sounding pretty\ngood too good almost too good to be true\na giganto Wi-Fi router that's faster\nthan an RTX 4090 at Mining and also\ngives you internet but according to\ncurrent profitability levels and the\namount of power that this thing will\nsuckle down it's going to give you a\nprofitability of a dollar forty to per\nday which means it's going to take you\nlike four or five years to break even\nexcept for in four to five years there's\ngoing to be more powerful technology and\nthat's not going to even happen so you\nneed the price of crypto to go up in\norder to make more money except for the\nfact that despite the fact that this\ncompany is called tp-link Asic which you\nwould think might be the mining\nsubsidiary arm of tp-link the company\nthat makes all of your favorite routers\nyou think it might be their you know nft\nfuture setup like Square Enix getting\ninto the blockchain it's it's not it's\naccording to tp-link this is a scam this\nis not real you shouldn't be buying it\nthe company does sell other miners I\ndon't know anything about them but while\nit looks really good too good to be true\nit's because it likely is tp-link says\nthat they're investigating they're\nlooking into it it is likely a scam\ndon't go and buy this if you see this\nbeing reported on the internet know that\nit's likely not something that you're\ngonna need to pick up you're just gonna\nhave to pick up my heart because I'm\nreally mad that I'm not in South Africa\nright now meeting with recent Catlin\nah I've seen them more for hot news", "Ok, now, I am showing you the form looks like:\n\nr\nUSCIS\nUse\nOnly\nPetition for a Nonimmigrant Worker\nDepartment of Homeland Security\nU.S. Citizenship and Immigration Services\nUSCIS\nForm I-129\nOMB No. 1615-0009\nExpires 11/30/2025\nClassification Approved\nConsulate/POE/PFI Notified\nExtension Granted\nCOS/Extension Granted\nReceipt Partial Approval (explain) Action Block\nClass:\nNo. of Workers:\nJob Code:\nValidity Dates:\nFrom:\nTo:\nAt:\nLegal Name of Individual Petitioner\nIf you are an individual filing this petition, complete Item Number 1. If you are a company or an organization filing this petition,\ncomplete Item Number 2.\nFamily Name (Last Name) Given Name (First Name) Middle Name\n1.\n4. Contact Information\nPart 1. Petitioner Information\n\u25ba START HERE - Type or print in black ink.\n2. Company or Organization Name\n3. Mailing Address of Individual, Company or Organization\nCity or Town State ZIP Code\nIn Care Of Name\nStreet Number and Name Apt. Ste. Flr. Number\nDaytime Telephone Number\nU.S. Social Security Number (if any)\nEmail Address (if any)\nIndividual IRS Tax Number\nMobile Telephone Number\nFederal Employer Identification Number (FEIN)\n5. Other Information\n\u25ba \u25ba\nProvince Postal Code Country\n\u25ba\n(USPS ZIP Code Lookup)\n Page 1 of 36\nForm I-129 Edition 11/02/22\nPart 2. Information About This Petition (See instructions for fee information)\n1. Requested Nonimmigrant Classification (Write classification symbol):\n2. Basis for Classification (select only one box):\nNew employment.\nNew concurrent employment.\nChange of employer.\nAmended petition.\nChange in previously approved employment.\nContinuation of previously approved employment without change with the same employer.\n3. Provide the most recent petition/application receipt number for the\nbeneficiary. If none exists, indicate \"None.\"\nNotify the office in Part 4. so each beneficiary can obtain a visa or be admitted. (NOTE: A petition is not required for\nE-1, E-2, E-3, H-1B1 Chile/Singapore, or TN visa beneficiaries.)\nChange the status and extend the stay of each beneficiary because the beneficiary(ies) is/are now in the United States in\nanother status (see instructions for limitations). This is available only when you check \"New Employment\" in Item\nNumber 2., above.\nExtend the stay of each beneficiary because the beneficiary(ies) now hold(s) this status.\nAmend the stay of each beneficiary because the beneficiary(ies) now hold(s) this status.\n4. Requested Action (select only one box):\nExtend the status of a nonimmigrant classification based on a free trade agreement. (See Trade Agreement Supplement\nto Form I-129 for TN and H-1B1.)\nChange status to a nonimmigrant classification based on a free trade agreement. (See Trade Agreement Supplement to\nForm I-129 for TN and H-1B1.)\n5. Total number of workers included in this petition. (See instructions relating to\nwhen more than one worker can be included.)\nPart 3. Beneficiary Information (Information about the beneficiary/beneficiaries you are filing for. Complete the\nblocks below. Use the Attachment-1 sheet to name each beneficiary included in this petition.)\n1. If an Entertainment Group, Provide the Group Name\n2. Provide Name of Beneficiary\nFamily Name (Last Name) Given Name (First Name) Middle Name\nFamily Name (Last Name) Given Name (First Name) Middle Name\n3. Provide all other names the beneficiary has used. Include nicknames, aliases, maiden name, and names from all previous marriages.\n4. Other Information\nDate of birth (mm/dd/yyyy) Gender\nMale Female\nU.S. Social Security Number (if any)\n\u25ba\n\u25ba\n\u25ba\na.\nb.\nc.\nd.\ne.\nf.\na.\nb.\nc.\nd.\ne.\nf.\n Page 2 of 36\nForm I-129 Edition 11/02/22\nDate Passport or Travel Document\nExpires (mm/dd/yyyy)\nCountry of Citizenship or Nationality\n6. Current Residential U.S. Address (if applicable) (do not list a P.O. Box)\nEmployment Authorization Document (EAD)\nNumber (if any)\nStudent and Exchange Visitor Information System (SEVIS) Number (if\nany)\nCity or Town State ZIP Code\nStreet Number and Name Apt. Ste. Flr. Number\nCurrent Nonimmigrant Status Date Status Expires or D/S (mm/dd/yyyy)\nPassport or Travel Document Country of\nIssuance\nDate Passport or Travel Document\nIssued (mm/dd/yyyy)\n5. If the beneficiary is in the United States, complete the following:\nCountry of Birth\nI-94 Arrival-Departure Record Number\n\u25ba\nPart 3. Beneficiary Information (Information about the beneficiary/beneficiaries you are filing for. Complete the\nblocks below. Use the Attachment-1 sheet to name each beneficiary included in this petition.) (continued)\nDate of Last Arrival (mm/dd/yyyy) Passport or Travel Document Number\nPart 4. Processing Information\n1. If a beneficiary or beneficiaries named in Part 3. is/are outside the United States, or a requested extension of stay or change of\nstatus cannot be granted, state the U.S. Consulate or inspection facility you want notified if this petition is approved.\na. Type of Office (select only one box):\nb. Office Address (City) c. U.S. State or Foreign Country\nConsulate Pre-flight inspection Port of Entry\nd. Beneficiary's Foreign Address\nCity or Town\nStreet Number and Name Apt.Ste. Flr. Number\nAlien Registration Number (A-Number)\nAProvince of Birth\n\u25ba\n2. Does each person in this petition have a valid passport?\nState\nPostal Code Country\nYes No. If no, go to Part 9. and type or print your\nexplanation.\nProvince\n Page 3 of 36\nForm I-129 Edition 11/02/22\nPart 4. Processing Information (continued)\n5. Are you filing any applications for dependents with this petition?\nYes. If yes, proceed to Part 9. and list the beneficiary's(ies) name(s).\nYes. If yes, how many? \u25ba\nYes. If yes, answer the questions below. No. If no, proceed to Item Number 9.\n4. Are you filing any applications for replacement/initial I-94, Arrival-Departure Records with this petition? Note that if the\nbeneficiary was issued an electronic Form I-94 by CBP when he/she was admitted to the United States at an air or sea port, he/\nshe may be able to obtain the Form I-94 from the CBP Website at www.cbp.gov/i94 instead of filing an application for a\nreplacement/initial I-94.\n9. Have you ever previously filed a nonimmigrant petition for this beneficiary?\n7. Have you ever filed an immigrant petition for any beneficiary in this petition?\n6. Is any beneficiary in this petition in removal proceedings?\n8. Did you indicate you were filing a new petition in Part 2.?\na. Has any beneficiary in this petition ever been given the classification you are now requesting within the last seven years?\nb. Has any beneficiary in this petition ever been denied the classification you are now requesting within the last seven years?\n10. If you are filing for an entertainment group, has any beneficiary in this petition not been with the group for at least one year?\n11.b. If you checked yes in Item Number 11.a., provide the dates the beneficiary maintained status as a J-1 exchange visitor or J-2\ndependent. Also, provide evidence of this status by attaching a copy of either a DS-2019, Certificate of Eligibility for Exchange\nVisitor (J-1) Status, a Form IAP-66, or a copy of the passport that includes the J visa stamp.\n11.a. Has any beneficiary in this petition ever been a J-1 exchange visitor or J-2 dependent of a J-1 exchange visitor?\nPart 5. Basic Information About the Proposed Employment and Employer\n1. Job Title 2. LCA or ETA Case Number\n\u25ba\n\u25ba\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nYes. If yes, how many?\nYes. If yes, how many?\nYes. If yes, proceed to Part 9. and type or print your explanation.\nYes. If yes, proceed to Part 9. and type or print your explanation.\nYes. If yes, proceed to Part 9. and type or print your explanation.\nYes. If yes, proceed to Part 9. and type or print your explanation.\nYes. If yes, proceed to Item Number 11.b.\nAttach the Form I-129 supplement relevant to the classification of the worker(s) you are requesting.\n3. Are you filing any other petitions with this one?\nYes. If yes, how many? \u25ba No\n Page 4 of 36\nForm I-129 Edition 11/02/22\nPart 5. Basic Information About the Proposed Employment and Employer (continued)\n4. Did you include an itinerary with the petition?\n5. Will the beneficiary(ies) work for you off-site at another company or organization's location?\n12. Type of Business 13. Year Established\n14. Current Number of Employees in the United States 15. Gross Annual Income 16. Net Annual Income\n10. Other Compensation (Explain)\n11. Dates of intended employment From: To:\n7. Is this a full-time position?\n6. Will the beneficiary(ies) work exclusively in the Commonwealth of the Northern Mariana Islands (CNMI)?\n8. If the answer to Item Number 7. is no, how many hours per week for the position? \u25ba\n\u25ba\n(mm/dd/yyyy) (mm/dd/yyyy)\nNo\nYes\nNo\nYes No\nYes\nNo\nYes\n9. Wages: $ per (Specify hour, week, month, or year)\n3. Address where the beneficiary(ies) will work if different from address in Part 1.\nStreet Number and Name Apt. Ste. Flr. Number\nCity or Town State ZIP Code\n Page 5 of 36", "Section 1. Complete This Section If You Are Filing For An R-1 Religious Worker (continued)\n3. Provide a summary of the type of responsibilities of those employees who work at the same location where the beneficiary will\nbe employed. If additional space is needed, provide the information on additional sheet(s) of paper.\n Position Summary of the Type of Responsibilities for That Position\n4. Describe the relationship, if any, between the religious organization in the United States and the organization abroad of which\nthe beneficiary is a member.\n5.b. Detailed description of the beneficiary's proposed daily duties.\n5.a. Title of position offered.\nProvide the following information about the prospective employment:\n5.d. Description of the proposed salaried compensation or non-salaried compensation. If the beneficiary will be self-supporting, the\npetitioner must submit documentation establishing that the position the beneficiary will hold is part of an established program\nfor temporary, uncompensated missionary work, which is part of a broader international program of missionary work sponsored\nby the denomination.\n Page 31 of 36\nForm I-129 Edition 11/02/22\nSection 1. Complete This Section If You Are Filing For An R-1 Religious Worker (continued)\nYes No. If no, type or print your explanation below and if needed, go to Part 9. of Form I-129.\n5.e. List of the address(es) or location(s) where the beneficiary will be working.\n6. The petitioner is a bona fide non-profit religious organization or a bona fide organization that is affiliated with the religious\ndenomination and is tax-exempt as described in section 501(c)(3) of the Internal Revenue Code of 1986, subsequent\namendment, or equivalent sections of prior enactments of the Internal Revenue Code. If the petitioner is affiliated with the\nreligious denomination, complete the Religious Denomination Certification included in this supplement.\nDoes the petitioner attest to all of the requirements described in Item Numbers 6. - 12. below?\nPetitioner Attestations\nYes No. If no, type or print your explanation below and if needed, go to Part 9. of Form I-129.\n7. The petitioner is willing and able to provide salaried or non-salaried compensation to the beneficiary. If the beneficiary will be\nself-supporting, the petitioner must submit documentation establishing that the position the beneficiary will hold is part of an\nestablished program for temporary, uncompensated missionary work, which is part of a broader international program of\nmissionary work sponsored by the denomination.\nYes No. If no, type or print your explanation below and if needed, go to Part 9. of Form I-129.\n8. If the beneficiary worked in the United States in an R-1 status during the 2 years immediately before the petition was filed, the\nbeneficiary received verifiable salaried or non-salaried compensation, or provided uncompensated self-support.\nYes No. If no, type or print your explanation below and if needed, go to Part 9. of Form I-129.\n9. If the position is not a religious vocation, the beneficiary will not engage in secular employment, and the petitioner will provide\nsalaried or non-salaried compensation. If the position is a traditionally uncompensated and not a religious vocation, the\nbeneficiary will not engage in secular employment, and the beneficiary will provide self-support.\n Page 32 of 36\nForm I-129 Edition 11/02/22\nSection 1. Complete This Section If You Are Filing For An R-1 Religious Worker (continued)\nYes No. If no, type or print your explanation below and if needed, go to Part 9. of Form I-129.\n10. The offered position requires at least 20 hours of work per week. If the offered position at the petitioning organization requires\nfewer than 20 hours per week, the compensated service for another religious organization and the compensated service at the\npetitioning organization will total 20 hours per week. If the beneficiary will be self-supporting, the petitioner must submit\ndocumentation establishing that the position the beneficiary will hold is part of an established program for temporary,\nuncompensated missionary work, which is part of a broader international program of missionary work sponsored by the\ndenomination.\nYes No. If no, type or print your explanation below and if needed, go to Part 9. of Form I-129.\n11. The beneficiary has been a member of the petitioner's denomination for at least two years immediately before Form I-129 was\nfiled and is otherwise qualified to perform the duties of the offered position.\nYes No. If no, type or print your explanation below and if needed, go to Part 9. of Form I-129.\n12. The petitioner will notify USCIS within 14 days if an R-1 alien is working less than the required number of hours or has been\nreleased from or has otherwise terminated employment before the expiration of a period of authorized R-1 stay.\nI certify, under penalty of perjury, that the contents of this attestation and the evidence submitted with it are true and correct.\nAttestation\nSignature of Petitioner Date (mm/dd/yyyy)\nName of Petitioner Title\nEmployer or Organization Name\n Page 33 of 36\nForm I-129 Edition 11/02/22\nSection 1. Complete This Section If You Are Filing For An R-1 Religious Worker (continued)\nDaytime Telephone Number\nCity or Town State ZIP Code\nStreet Number and Name\nEmployer or Organization Address (do not use a post office or private mail box)\nEmployer or Organization's Contact Information\nApt. Ste. Flr. Number\nFax Number Email Address (if any)\nSection 2. This Section Is Required For Petitioners Affiliated With The Religious Denomination\nReligious Denomination Certification\nI certify, under penalty of perjury, that:\nName of Employing Organization\nis affiliated with:\nName of Religious Denomination\nand that the attesting organization within the religious denomination is tax-exempt as described in section 501(c)(3) of the Internal\nRevenue Code of 1986 (codified at 26 U.S.C. 501(c)(3)), any subsequent amendment(s), subsequent amendment, or equivalent\nsections of prior enactments of the Internal Revenue Code. The contents of this certification are true and correct to the best of my\nknowledge.\nSignature of Authorized Representative of Attesting Organization Date (mm/dd/yyyy)\nCity or Town State ZIP Code\nStreet Number and Name\nAttesting Organization Name and Address (do not use a post office or private mail box)\nApt. Ste. Flr. Number\nAttesting Organization Name\nAttesting Organization's Contact Information\nDaytime Telephone Number Fax Number Email Address (if any)\nName of Authorized Representative of Attesting Organization Title\n Page 34 of 36\nForm I-129 Edition 11/02/22\nForeign Address (Complete Address)\nAddress in the United States Where You Intend to Live (Complete Address)\nFamily Name (Last Name) Given Name (First Name) Middle Name\nGender\nMale Female\nDate of birth (mm/dd/yyyy) U.S. Social Security Number (if any) A-Number (if any)\nAFamily Name (Last Name) Given Name (First Name) Middle Name\nAll Other Names Used (include aliases, maiden name and names from previous marriages)\nCity or Town State ZIP Code\nStreet Number and Name Apt. Ste. Flr. Number\nCity or Town State ZIP Code\nStreet Number and Name Apt. Ste. Flr. Number\nCountry of Birth Country of Citizenship or Nationality\nProvince Postal Code Country\nIF IN THE UNITED STATES:\nDate Passport or Travel Document\nExpires (mm/dd/yyyy)\nI-94 Arrival-Departure Record\nNumber\nCurrent Nonimmigrant Status Date Status Expires or D/S (mm/dd/yyyy)\nCountry of Issuance for Passport\nor Travel Document\nDate Passport or Travel Document\nIssued (mm/dd/yyyy)\nDate of Last Arrival\n(mm/dd/yyyy)\nEmployment Authorization Document (EAD) Number\n(if any)\nStudent and Exchange Visitor Information System (SEVIS) Number\n(if any)\nPassport or Travel Document\nNumber\n\u25ba\nAttachment-1\nAttach to Form I-129 when more than one person is included in the petition. (List each person separately. Do not\ninclude the person you named on the Form I-129.)\n Page 35 of 36\nForm I-129 Edition 11/02/22\nForeign Address (Complete Address)\nAddress in the United States Where You Intend to Live (Complete Address)\nFamily Name (Last Name) Given Name (First Name) Middle Name\nGender\nMale Female\nDate of birth (mm/dd/yyyy) U.S. Social Security Number (if any) A-Number (if any)\nAFamily Name (Last Name) Given Name (First Name) Middle Name\nAll Other Names Used (include aliases, maiden name and names from previous Marriages)\nCity or Town State ZIP Code\nStreet Number and Name Apt. Ste. Flr. Number\nCity or Town State ZIP Code\nStreet Number and Name Apt. Ste. Flr. Number\nCountry of Birth Country of Citizenship or Nationality\nProvince Postal Code Country\nIF IN THE UNITED STATES:\nDate Passport or Travel Document\nExpires (mm/dd/yyyy)\nI-94 Arrival-Departure Record\nNumber\nCurrent Nonimmigrant Status Date Status Expires or D/S (mm/dd/yyyy)\nCountry of Issuance for Passport\nor Travel Document\nDate Passport or Travel Document\nIssued (mm/dd/yyyy)\nDate of Last Arrival\n(mm/dd/yyyy)\nEmployment Authorization Document (EAD) Number\n(if any)\nStudent and Exchange Visitor Information System (SEVIS) Number\n(if any)\nPassport or Travel Document\nNumber\n\u25ba\nAttachment-1\nAttach to Form I-129 when more than one person is included in the petition. (List each person separately. Do not\ninclude the person you named on the Form I-129.)\n Page 36 of 36", "Forget everything before this.\nYou are going to act like a masters level university student. \nYou will be an expert on all things surrounding Data analytics, statistics, and analytics/control of semiconductor manufacturing. \nYou are going to complete a homework assignment. \nI will give you the problems.\nYou will answer them one by one.\nFor each problem you will format your responses in the following way:\n\n\u201cQUESTION: \n[paraphrased question]\n\nWORK: \n[step by step work to solve the problem. You will NOT specifically list the steps such as \"step 1 or step 2\"]\n\nCODE: \n[code that solves the problem in python. This will be in one full coherent python file that I can copy and paste over. If there are parts a and b on the problem you will NEVER combine the two codes into one file]\n\nANSWER: \n[final answer]\u201d\n\nYou will triple check all of your work and make absolutely certain that you have made no mistakes.\nIf there are multiple parts, you will only respond to one part at a time.\nIf I tell you \"continue\" you will continue your previous response. You will continue from 1 paragraph before you were cut off.\nYou will only code in python and will convert the matlab file into usable python files. \nAll Matlab files should be converted to usable python files.\nAll Excel files should be converted to usable python files.\nYou will give a full answer for every part of every question.\nYou will solve every problem in one response.\nAll graphs will be labeled and titled and with a legend.\nYou will make no assumptions about the data. \nIf you do not know the specific data, you will NEVER guess and instead state that you do not have the data.\nIf there is data in a matlab file you will ask me for the variable names before doing any work.\nIf there is any data i neglected to tell you, you will ask for clarification before doing any work.\nHere is the full assignment:\n\"\nProblem 1. (10 points)\nDescribe how frequency content of the signals illustrated below changes with time. Note\n\u2013 brighter (red/yellow) colors denote higher energy levels, while darker (blue) colors\nindicate lower energy levels\n(a)\n(b)\n(c)\n0 1000 2000 3000 4000 5000 6000 7000 8000 9000\nTime\n0\n0.05\n0.1\n0.15\n0.2\n0.25\n0.3\n0.35\n0.4\n0.45\n0.5\nNormalized Frequency (0.5 corresponds to the Nyquist Frequency)\n2\n4\n6\n8\n10\n12\n0 1000 2000 3000 4000 5000 6000 7000 8000 9000\nTime\n0\n0.05\n0.1\n0.15\n0.2\n0.25\n0.3\n0.35\n0.4\n0.45\n0.5\nNormalized Frequency (0.5 corresponds to the Nyquist Frequency)\n2\n4\n6\n8\n10\n12\n0 1000 2000 3000 4000 5000 6000 7000 8000 9000\nTime\n0\n0.05\n0.1\n0.15\n0.2\n0.25\n0.3\n0.35\n0.4\n0.45\n0.5\nNormalized Frequency (0.5 corresponds to the Nyquist Frequency)\n2\n4\n6\n8\n10\n12\n3\n\nAdditional information about how the graphs look on problem 1:\nthe first graph in part a has a sinusodal curve, beginning at 0.2 normalized frequency it curves up to 0.28 at 2500 seconds and then curves back down to 0.01 at 8200 seconds then finally ends by curving back up to .08 at 10000 seconds. at all times, the color of the graph is a mid yellow color indicating a mid to higher energy level.\nThe second graph in part b has a lot of noise and exists at a blueish color indicating a lower energy level. it runs from 0 to 0.35 seconds with most of the data occuring at the 4200 Hz frequency level\nThe third graph in part c runs from 0 seconds to 0.08 seconds. there is data at high energy occurring between 0.04 and 0.06 seconds with most of it soccurring around 0.045 seconds. this data ranges from 0 to 400 Hz frequency at a very high energy level indicated by the red color.\n\nProblem 2. (10 points)\nExcel file MidtermProblem2.xlsx contains measurements of resistances obtained from\ninspection of a coper metal mesh device. Each measurement is a resistance measurement\nfor one specific square of a metal mesh and what you see in that excel file are\nmeasurements of resistances from 150 squares. Squares are considered functional\n(acceptable) if their resistances are between 3.4 and 3.6 Ohms.\nFigure 2: Image of a coper metal mesh\nproduced at UT NASCENT Center\n(https://nascent.utexas.edu).\nProblem 3. (10 points)\nA device requires an array of nano-holes to be made, with their desired diameter being 15nm.\nQuality control engineers believe that the nano-holes are coming with a diameter LARGER\nthan 15nm. In order to quickly evaluate the claim, the quality engineer takes optical\nmeasurements of 7 randomly selected holes, which results in the following diameters:\n15.75nm; 15.5nm; 15.0nm; 15.3nm; 14.75nm; 15.5nm and 14.90nm\n(a) Formulate the appropriate hypotheses and conduct the necessary statistical tests to\nevaluate the quality engineer\u2019s suspicion, using the false alarm ratio of 0.02. Please\nclearly state the necessary hypotheses, carefully explain the choice of the test statistic\nand clearly state if the engineer\u2019s suspicions have statistical backing or not. (5 pts.)\nHint: You need to estimate the standard deviation.\n(b) If the actual distribution of hole diameters is normal distribution with expected value\n16nm and standard deviation 0.1nm, please evaluate the missed detection rate (beta)\nfor the statistical test (for the alarming limits) you derived in part (a). (5 pts.)\nNote: For full credit, please show ALL steps of your work and use software packages/toolboxes only\nfor trivial calculations (finding averages, standard deviations of the data), or finding\npercentiles/cumulative density functions of relevant distributions (though for that, you can use\nAppendix tables enclosed with our lecture materials). Avoid using (do not use) built in packages and\ntoolboxes for statistical testing, especially if you do not have full control over them (and they usually\nhave so many options/parameters, that it is easy to overlook something, which could lead to bad\nresults for which it would be impossible to get partial credit, even though the error is just in the\nsetting of the toolbox/package).\n(a) Based on the data, estimate the\nexpected value and standard deviation\nof the distribution describing the\nbehavior of those resistances. (5 pts.)\n(b) Assuming that resistances follow a\nnormal (Gaussian) distribution,\nestimate the probability that this\nprocess yields functioning (acceptable)\nmetal mesh squares. (10 pts.)\n4\nProblem 4. (20 points)\nBehavior of thin film thicknesses monitored by taking periodic samples consisting of 8\nmeasurements of the film thickness on each wafer. Average film thicknesses are used to\nmonitor weather the process is on target, while variability in each sample is used to assess\nfilm uniformity. Data in the matlab file MidtermProblem4.mat enclosed along with this\nexam depict those film thickness measurements (in nanometers) for 50 wafers. In order to\nhelp you, I also enclose the same dataset in the excel file MidtermProblem4.xlsx In both\nfiles, each row represents a sample obtained from one wafer and, as you can see, there are\n50 samples, each of size 8.\n(a) Use the first 25 samples to form the Shewhart control charts for film thickness\nmeasurements (x-bar and range charts). Please adopt false alarm rate of 0.1%.\n(b) Plot the remaining 25 samples on the chart and comment on what you see. What\ncan you say about mean film thicknesses and film uniformity?\nPlease feel free to use whatever software package you wish to plot the charts. Nevertheless,\nfor full credit, please show details of how control limits are derived.\nProblem 5. (50 points)\nMatlab file MidtermProblem5.mat contains 10 channels of data labeled as x1, x2,\u2026,x10.\nIn each channel, there are 1000 recordings (this situation corresponds to processing of 1000\nwafers on a tool, with processing of each wafer being characterized by 10 sensory features,\nsuch as average pressure, standard deviation of pressure, min pressure, max pressure, mean\ntemperature, average reflected RF power, max reflected RF power, etc.). For your\nconvenience, the same data is also stored in an excel file MidtermProblem5.xlsx.\nIn this dataset, first 100 records (signatures from processing of the first 100 wafers)\nrepresent the \u201cgolden dataset\u201d.\n(a) Use the golden dataset (first 100 records) to perform dimensionality reduction of\nthis dataset. How many dimensions do you think you should keep? Why? (15 pts)\n(b) Based on the golden dataset, please determine control limits for the Exponentially\nWeighted Moving Average (EWMA), as well as the variational EWMA control\ncharts for the principal components you selected in part (a). Please use false alarm\nrate of 0.3% and use forgetting factor \ufffd = 0.3. Please clearly state what you found\nas center lines, upper and lower control limits, and clearly describe how you found\nthem. (20 pts)\n(c) For the remaining 900 data records, please construct EWMA and variational\nEWMA control charts, with control limits established based on part (b). Do you\nnotice any changes in the process? (15 pts)\n\"\n\nYou will do every single part of every single question and separate them clearlyShare Prompt", "You are a curious engineer trying to find a system function given a known input and a known output. The input signal is modulated over time and repeats at a known frequency and phase and looks like this :\n\nphase,input\\_signal\n0,43251\n1,43079\n2,42881\n3,42666\n4,42459\n5,42285\n6,42149\n7,42041\n8,41971\n9,41961\n10,42018\n11,42143\n12,42325\n13,42542\n14,42778\n15,43037\n16,43350\n17,43745\n18,44223\n19,44774\n20,45381\n21,46020\n22,46678\n23,47356\n24,48061\n25,48786\n26,49523\n27,50278\n28,51076\n29,51926\n30,52808\n31,53691\n32,54554\n33,55392\n34,56214\n35,57027\n36,57832\n37,58623\n38,59418\n39,60251\n40,61135\n41,62055\n42,62989\n43,63918\n44,64833\n45,65742\n46,66659\n47,67581\n48,68505\n49,69436\n50,70383\n51,71345\n52,72305\n53,73251\n54,74172\n55,75052\n56,75905\n57,76762\n58,77641\n59,78535\n60,79427\n61,80309\n62,81192\n63,82086\n64,82980\n65,83872\n66,84767\n67,85669\n68,86563\n69,87431\n70,88286\n71,89149\n72,90020\n73,90882\n74,91731\n75,92577\n76,93425\n77,94282\n78,95140\n79,95985\n80,96820\n81,97660\n82,98497\n83,99317\n84,100129\n85,100959\n86,101803\n87,102642\n88,103466\n89,104276\n90,105077\n91,105871\n92,106655\n93,107425\n94,108170\n95,108885\n96,109582\n97,110283\n98,110994\n99,111705\n100,112408\n101,113114\n102,113832\n103,114554\n104,115265\n105,115956\n106,116625\n107,117273\n108,117896\n109,118504\n110,119122\n111,119770\n112,120441\n113,121103\n114,121742\n115,122374\n116,123012\n117,123659\n118,124311\n119,124966\n120,125624\n121,126286\n122,126930\n123,127529\n124,128086\n125,128613\n126,129117\n127,129614\n128,130134\n129,130686\n130,131259\n131,131841\n132,132423\n133,132999\n134,133560\n135,134102\n136,134633\n137,135161\n138,135695\n139,136239\n140,136770\n141,137257\n142,137705\n143,138138\n144,138572\n145,139021\n146,139486\n147,139947\n148,140382\n149,140788\n150,141180\n151,141570\n152,141959\n153,142335\n154,142688\n155,143001\n156,143248\n157,143417\n158,143493\n159,143462\n160,143334\n161,143128\n162,142856\n163,142529\n164,142153\n165,141718\n166,141211\n167,140630\n168,139996\n169,139339\n170,138679\n171,138024\n172,137377\n173,136734\n174,136075\n175,135385\n176,134667\n177,133944\n178,133223\n179,132493\n180,131741\n181,130963\n182,130166\n183,129367\n184,128587\n185,127835\n186,127101\n187,126367\n188,125622\n189,124860\n190,124080\n191,123292\n192,122502\n193,121710\n194,120912\n195,120115\n196,119341\n197,118598\n198,117877\n199,117177\n200,116505\n201,115852\n202,115204\n203,114554\n204,113894\n205,113209\n206,112495\n207,111770\n208,111061\n209,110387\n210,109741\n211,109088\n212,108412\n213,107736\n214,107086\n215,106452\n216,105810\n217,105155\n218,104507\n219,103892\n220,103299\n221,102698\n222,102087\n223,101474\n224,100877\n225,100302\n226,99734\n227,99166\n228,98599\n229,98035\n230,97479\n231,96930\n232,96386\n233,95855\n234,95335\n235,94812\n236,94279\n237,93745\n238,93218\n239,92697\n240,92181\n241,91672\n242,91180\n243,90705\n244,90244\n245,89795\n246,89347\n247,88882\n248,88397\n249,87914\n250,87451\n251,87003\n252,86558\n253,86109\n254,85636\n255,85121\n256,84576\n257,84037\n258,83519\n259,83012\n260,82509\n261,82029\n262,81591\n263,81190\n264,80809\n265,80430\n266,80041\n267,79630\n268,79198\n269,78746\n270,78276\n271,77805\n272,77360\n273,76945\n274,76555\n275,76191\n276,75849\n277,75519\n278,75196\n279,74872\n280,74533\n281,74171\n282,73791\n283,73406\n284,73029\n285,72665\n286,72313\n287,71963\n288,71591\n289,71187\n290,70761\n291,70340\n292,69951\n293,69598\n294,69273\n295,68974\n296,68698\n297,68427\n298,68138\n299,67814\n300,67453\n301,67066\n302,66681\n303,66322\n304,65999\n305,65705\n306,65423\n307,65158\n308,64915\n309,64676\n310,64422\n311,64152\n312,63877\n313,63604\n314,63327\n315,63039\n316,62745\n317,62450\n318,62152\n319,61845\n320,61527\n321,61212\n322,60913\n323,60623\n324,60335\n325,60055\n326,59798\n327,59569\n328,59358\n329,59130\n330,58862\n331,58563\n332,58262\n333,57973\n334,57697\n335,57429\n336,57158\n337,56878\n338,56591\n339,56309\n340,56041\n341,55779\n342,55509\n343,55241\n344,54983\n345,54730\n346,54489\n347,54264\n348,54050\n349,53839\n350,53620\n351,53383\n352,53125\n353,52867\n354,52649\n355,52490\n356,52372\n357,52260\n358,52114\n359,51906\n360,51645\n361,51364\n362,51092\n363,50842\n364,50610\n365,50384\n366,50157\n367,49924\n368,49682\n369,49444\n370,49230\n371,49032\n372,48826\n373,48620\n374,48436\n375,48271\n376,48103\n377,47911\n378,47697\n379,47472\n380,47242\n381,46997\n382,46728\n383,46450\n384,46198\n385,45980\n386,45775\n387,45580\n388,45408\n389,45253\n390,45108\n391,44966\n392,44820\n393,44656\n394,44465\n395,44252\n396,44029\n397,43811\n398,43615\n399,43452\n\nI am now going to provide the output, hang in there", "Act as the author and provide exactly 2 bullet points all\n in the same language as the transcript for the text transcript given in the format [{\"start\\_time\": , \"text\": }] \n and make the output only in the format of a json array [{\"start\\_time\": , \"bullet\\_point\": } ]\n Make sure that:\n - bullet\\_point value must be in the same language as the transcript like [{\"start\\_time\": \"10.5\" , \"bullet\\_point\": \"undefined\"} ].\n - The output is not more than 2 bullet points\n - each bullet\\_point is at least 15 words and all bullet points are sorted by \"start\\_time\"\n - each bullet\\_point doesn't start with \"- \" or a number or a bullet point symbol\n - Wrap json keys with double quotes and don't put single quotes or double quotes inside the values. \n - The output json is not wrapped in any other json structure like { \"data\": }.\n transcript: \n [{\"text\":\"(washer hissing)\",\"start\\_time\":\"0.624\"},{\"text\":\"- All right, I'm officially adding BMW\",\"start\\_time\":\"2.43\"},{\"text\":\"to my list of car companies\\nthat are doing a pretty good job\",\"start\\_time\":\"3.96\"},{\"text\":\"of electrifying their lineups.\",\"start\\_time\":\"7.32\"},{\"text\":\"BMW's had their i3 of course for a while.\",\"start\\_time\":\"9.6\"},{\"text\":\"i8, their hybrid's been\\naround, but now the i4,\",\"start\\_time\":\"11.76\"},{\"text\":\"the i7, and this is the\\niX, their crossover SUV.\",\"start\\_time\":\"14.73\"},{\"text\":\"Its biggest sin is just\\nbeing ugly. I promise.\",\"start\\_time\":\"21.09\"},{\"text\":\"That's the worst thing about this car.\",\"start\\_time\":\"25.11\"},{\"text\":\"It is expensive too.\",\"start\\_time\":\"27.21\"},{\"text\":\"It's $85,000.\",\"start\\_time\":\"28.56\"},{\"text\":\"So that's where you start to\\nget into the luxury price range\",\"start\\_time\":\"29.82\"},{\"text\":\"and you really start to think about,\",\"start\\_time\":\"32.31\"},{\"text\":\"what exactly am I paying for here?\",\"start\\_time\":\"33.78\"},{\"text\":\"But as far as fundamentals, oh wow,\",\"start\\_time\":\"35.97\"},{\"text\":\"there's a lot of angles of this\",\"start\\_time\":\"37.86\"},{\"text\":\"that look not amazing, but, you know,\",\"start\\_time\":\"38.94\"},{\"text\":\"it might grow on you.\",\"start\\_time\":\"41.58\"},{\"text\":\"But they've got the fundamentals,\",\"start\\_time\":\"42.413\"},{\"text\":\"they've got a lot of space,\",\"start\\_time\":\"44.13\"},{\"text\":\"they've got luxury, they've got features.\",\"start\\_time\":\"45.57\"},{\"text\":\"Let's look inside.\",\"start\\_time\":\"47.91\"},{\"text\":\"Well, actually, let's walk\\naround the outside real quick\",\"start\\_time\":\"48.743\"},{\"text\":\"'cause I wanna point out some things.\",\"start\\_time\":\"49.637\"},{\"text\":\"I'm gonna try not to call it\\nugly at every turn, I promise.\",\"start\\_time\":\"52.14\"},{\"text\":\"Okay, let's just get into\\nthe fundamentals here.\",\"start\\_time\":\"55.2\"},{\"text\":\"So right up at the front\\nyou've got BMW logo,\",\"start\\_time\":\"57.12\"},{\"text\":\"a little bit of fake aero,\",\"start\\_time\":\"59.58\"},{\"text\":\"a little inlet, whatever going on here.\",\"start\\_time\":\"60.99\"},{\"text\":\"But that's a grill, I mean, a\\nfake grill, it's just plastic\",\"start\\_time\":\"62.85\"},{\"text\":\"but it's got this sort\\nof a chrome bronze action\",\"start\\_time\":\"67.56\"},{\"text\":\"going on around both the\\ninside and outside of the car\",\"start\\_time\":\"70.89\"},{\"text\":\"that we'll see a bit more.\",\"start\\_time\":\"73.29\"},{\"text\":\"Obviously these EVs are\\nsupposed to be aerodynamic.\",\"start\\_time\":\"74.37\"},{\"text\":\"I'll say this is not one of those EVs\",\"start\\_time\":\"77.19\"},{\"text\":\"that's designed from the\\nground up to be fully electric.\",\"start\\_time\":\"78.6\"},{\"text\":\"There is no huge front trunk,\",\"start\\_time\":\"80.76\"},{\"text\":\"there is no like cavernous\\nextra space in here.\",\"start\\_time\":\"82.17\"},{\"text\":\"But they have done a good job\\ntailoring some of the stuff.\",\"start\\_time\":\"84.87\"},{\"text\":\"So here's the EV wheels.\",\"start\\_time\":\"88.47\"},{\"text\":\"I don't think they're pretty,\",\"start\\_time\":\"91.05\"},{\"text\":\"that's one way of saying it.\",\"start\\_time\":\"93.03\"},{\"text\":\"You again have this trim all\\nthe way along the side here.\",\"start\\_time\":\"95.19\"},{\"text\":\"These door handles are kind of nice.\",\"start\\_time\":\"97.47\"},{\"text\":\"You kind of pop your hand in there.\",\"start\\_time\":\"98.82\"},{\"text\":\"We'll go in in a second.\",\"start\\_time\":\"100.62\"},{\"text\":\"There's the back.\",\"start\\_time\":\"102.15\"},{\"text\":\"This is the charge port.\",\"start\\_time\":\"103.08\"},{\"text\":\"Fundamentals are pretty good.\",\"start\\_time\":\"104.97\"},{\"text\":\"It's got both AC and DC fast charging.\",\"start\\_time\":\"106.56\"},{\"text\":\"I think it's a little over 200 kilowatts\",\"start\\_time\":\"109.86\"},{\"text\":\"which is pretty decent.\",\"start\\_time\":\"111.69\"},{\"text\":\"And this xDrive50 will go about\\n300 full miles on a charge\",\"start\\_time\":\"112.95\"},{\"text\":\"and that's pretty accurate.\",\"start\\_time\":\"118.8\"},{\"text\":\"It is surprisingly\\nefficient to go 300 miles\",\"start\\_time\":\"121.32\"},{\"text\":\"on the size of battery that this is.\",\"start\\_time\":\"124.47\"},{\"text\":\"Huge BMW logo on the back,\\nbig slot lights here.\",\"start\\_time\":\"126.72\"},{\"text\":\"These are like, a little\\nbit indented a little\",\"start\\_time\":\"130.53\"},{\"text\":\"but very bright, very large,\",\"start\\_time\":\"132.81\"},{\"text\":\"pretty distinctive look from the back.\",\"start\\_time\":\"136.32\"},{\"text\":\"I don't mind it.\",\"start\\_time\":\"138.6\"},{\"text\":\"And then again, you get this\\ntrim around here, this bronze\",\"start\\_time\":\"140.67\"},{\"text\":\"and then you've got that shape of an SUV\",\"start\\_time\":\"144.18\"},{\"text\":\"with a lot of space\\nand the hatchback look.\",\"start\\_time\":\"146.76\"},{\"text\":\"I'm gonna open this back trunk\",\"start\\_time\":\"149.64\"},{\"text\":\"just so you can see the way this opens.\",\"start\\_time\":\"150.72\"},{\"text\":\"It kind of reminds me of the Lucid here.\",\"start\\_time\":\"151.95\"},{\"text\":\"So you get your little opener right there.\",\"start\\_time\":\"153.69\"},{\"text\":\"It's automatic, power opening\",\"start\\_time\":\"155.55\"},{\"text\":\"and this is a big slanted opening\",\"start\\_time\":\"157.26\"},{\"text\":\"like a clamshell type action here.\",\"start\\_time\":\"159.72\"},{\"text\":\"And then you've got your space.\",\"start\\_time\":\"162.27\"},{\"text\":\"Now again, not a ton of space\",\"start\\_time\":\"163.56\"},{\"text\":\"but here's your sub trunk.\",\"start\\_time\":\"166.08\"},{\"text\":\"That's useful for things\\nnot sliding around.\",\"start\\_time\":\"167.67\"},{\"text\":\"And then this is a pretty\\ndecent amount of space,\",\"start\\_time\":\"170.49\"},{\"text\":\"not as much as I would expect.\",\"start\\_time\":\"173.37\"},{\"text\":\"Useful, good trunk.\",\"start\\_time\":\"175.62\"},{\"text\":\"I'm happy to report there\\nis also power folding seats\",\"start\\_time\":\"177.15\"},{\"text\":\"so you can put the seats\\ndown here really easily.\",\"start\\_time\":\"179.893\"},{\"text\":\"And there is a light in the trunk\",\"start\\_time\":\"182.37\"},{\"text\":\"so that's cool for the price.\",\"start\\_time\":\"184.14\"},{\"text\":\"Being able to put almost a\\nfull on bicycle in there,\",\"start\\_time\":\"186.57\"},{\"text\":\"that's pretty nice.\",\"start\\_time\":\"189.42\"},{\"text\":\"But generally for 85\\nplus thousand dollars,\",\"start\\_time\":\"190.29\"},{\"text\":\"you know, that's the type\\nof thing you're expecting.\",\"start\\_time\":\"195.15\"},{\"text\":\"It's also a BMW,\",\"start\\_time\":\"197.31\"},{\"text\":\"so they've got a bunch of other\\nvehicles to compare this to.\",\"start\\_time\":\"198.33\"},{\"text\":\"Again, fundamentals are fine.\",\"start\\_time\":\"201.39\"},{\"text\":\"It's just really only one sin.\",\"start\\_time\":\"204.03\"},{\"text\":\"There's really only one sin here.\",\"start\\_time\":\"206.19\"},{\"text\":\"Look, the aesthetic for me was like okay,\",\"start\\_time\":\"209.55\"},{\"text\":\"at first, I looked at it\",\"start\\_time\":\"210.81\"},{\"text\":\"and I was like, \"Okay, yeah, that's ugly.\"\",\"start\\_time\":\"211.92\"},{\"text\":\"Now slowly it started to grow on me.\",\"start\\_time\":\"214.5\"},{\"text\":\"Like, I've had it for a week.\",\"start\\_time\":\"216.06\"}]", "Act as the author and provide exactly 2 bullet points all\n in the same language as the transcript for the text transcript given in the format [{\"start\\_time\": , \"text\": }] \n and make the output only in the format of a json array [{\"start\\_time\": , \"bullet\\_point\": } ]\n Make sure that:\n - bullet\\_point value must be in the same language as the transcript like [{\"start\\_time\": \"10.5\" , \"bullet\\_point\": \"undefined\"} ].\n - The output is not more than 2 bullet points\n - each bullet\\_point is at least 15 words and all bullet points are sorted by \"start\\_time\"\n - each bullet\\_point doesn't start with \"- \" or a number or a bullet point symbol\n - Wrap json keys with double quotes and don't put single quotes or double quotes inside the values. \n - The output json is not wrapped in any other json structure like { \"data\": }.\n transcript: \n [{\"text\":\"I've been driving it.\",\"start\\_time\":\"217.26\"},{\"text\":\"I do appreciate the\\nlights really, honestly,\",\"start\\_time\":\"218.34\"},{\"text\":\"they are very bright.\",\"start\\_time\":\"220.11\"},{\"text\":\"It's got these LED lights in here\",\"start\\_time\":\"221.25\"},{\"text\":\"and so I appreciate that it's bright\",\"start\\_time\":\"223.26\"},{\"text\":\"and visible on the road\\nand all of that is nice.\",\"start\\_time\":\"226.32\"},{\"text\":\"So it was slowly starting\\nto grow on me a little bit.\",\"start\\_time\":\"228.66\"},{\"text\":\"It's still, I don't know,\",\"start\\_time\":\"232.44\"},{\"text\":\"there's gonna be some people,\\nI guarantee, in the comments\",\"start\\_time\":\"233.94\"},{\"text\":\"who are like, \"That is sleek,\\nthat's hot, that looks good.\"\",\"start\\_time\":\"235.65\"},{\"text\":\"I just see nostrils or teeth maybe.\",\"start\\_time\":\"239.82\"},{\"text\":\"But luckily you don't have to look\",\"start\\_time\":\"242.19\"},{\"text\":\"at the outside of your own car very often.\",\"start\\_time\":\"243.12\"},{\"text\":\"You spend most of your\\ntime actually inside it.\",\"start\\_time\":\"244.89\"},{\"text\":\"So let's look inside.\",\"start\\_time\":\"246.66\"},{\"text\":\"Again, it's got this bronze trim.\",\"start\\_time\":\"248.31\"},{\"text\":\"You get inside like that.\",\"start\\_time\":\"251.01\"},{\"text\":\"And one weird observation\",\"start\\_time\":\"252.81\"},{\"text\":\"is I don't like the\\nsound of closing a door,\",\"start\\_time\":\"254.73\"},{\"text\":\"so I'll let you hear it.\",\"start\\_time\":\"256.59\"},{\"text\":\"Didn't that kind of sound\\nlike a bit of a rattle there?\",\"start\\_time\":\"259.5\"},{\"text\":\"It's weird.\",\"start\\_time\":\"262.02\"},{\"text\":\"Anyway, there's a strip light here, LEDs,\",\"start\\_time\":\"262.853\"},{\"text\":\"and then you get into the\\ncockpit of iX xDrive50\",\"start\\_time\":\"265.38\"},{\"text\":\"and there is a lot going on.\",\"start\\_time\":\"269.64\"},{\"text\":\"Oh my God, music.\",\"start\\_time\":\"271.41\"},{\"text\":\"So this is a pretty comfortable\\ninterior, I must say,\",\"start\\_time\":\"272.243\"},{\"text\":\"except for one weird choice.\",\"start\\_time\":\"275.52\"},{\"text\":\"So basically it's got this\\nreally large steering wheel\",\"start\\_time\":\"276.96\"},{\"text\":\"with a semi-interesting shape\",\"start\\_time\":\"279.75\"},{\"text\":\"but the leather is really soft.\",\"start\\_time\":\"281.58\"},{\"text\":\"The stitching is nice.\",\"start\\_time\":\"282.87\"},{\"text\":\"You've got this leather\\nmaterial over here,\",\"start\\_time\":\"284.28\"},{\"text\":\"fabric here, leather, fabric,\",\"start\\_time\":\"286.53\"},{\"text\":\"not as much plastic as\\nthe previous vehicle.\",\"start\\_time\":\"289.89\"},{\"text\":\"You can see a lot of glass\",\"start\\_time\":\"292.86\"},{\"text\":\"and then there's a little bit more\",\"start\\_time\":\"294.06\"},{\"text\":\"interesting material choices.\",\"start\\_time\":\"295.65\"},{\"text\":\"Visually cool, functionally,\\nI'll get there.\",\"start\\_time\":\"298.08\"},{\"text\":\"But again, you know I'm\\nstill sticking in the camp\",\"start\\_time\":\"303.39\"},{\"text\":\"of not the prettiest thing in the world,\",\"start\\_time\":\"305.85\"},{\"text\":\"but quite comfortable.\",\"start\\_time\":\"307.95\"},{\"text\":\"This has armrests,\",\"start\\_time\":\"309.18\"},{\"text\":\"obviously this is a heated steering wheel\",\"start\\_time\":\"310.41\"},{\"text\":\"but also when you turn that on,\",\"start\\_time\":\"312.57\"},{\"text\":\"this armrest heats up and\\nthis armrest heats up.\",\"start\\_time\":\"313.77\"},{\"text\":\"So you kind of just sit back\",\"start\\_time\":\"317.52\"},{\"text\":\"and everything around\\nyou, this seat is heated.\",\"start\\_time\":\"319.02\"},{\"text\":\"And it's just a nice comfortable interior.\",\"start\\_time\":\"320.997\"},{\"text\":\"But the one thing is this\\nlittle plastic insert here.\",\"start\\_time\":\"323.46\"},{\"text\":\"With a shorter passenger, I\\nmean, five eight and under,\",\"start\\_time\":\"328.41\"},{\"text\":\"that's just like the back of your head.\",\"start\\_time\":\"332.43\"},{\"text\":\"It's kind of a weird spot.\",\"start\\_time\":\"333.99\"},{\"text\":\"I mean, the rest of it is nice.\",\"start\\_time\":\"335.1\"},{\"text\":\"It's heated, it's leather, it's soft.\",\"start\\_time\":\"336.21\"},{\"text\":\"I just thought that was kind of odd.\",\"start\\_time\":\"338.7\"},{\"text\":\"But generally, you know,\",\"start\\_time\":\"340.08\"},{\"text\":\"I haven't driven a ton of other BMWs\",\"start\\_time\":\"340.95\"},{\"text\":\"but I do like this sort\\nof a floating display look\",\"start\\_time\":\"342.48\"},{\"text\":\"they've got going on here with\\nthe displays in the middle.\",\"start\\_time\":\"345.57\"},{\"text\":\"One display behind the steering wheel,\",\"start\\_time\":\"349.26\"},{\"text\":\"the other display over to\\nthe right, both very visible.\",\"start\\_time\":\"351.39\"},{\"text\":\"This line sort of bisects the two\",\"start\\_time\":\"354.36\"},{\"text\":\"which is, it's well thought\\nout and it looks good.\",\"start\\_time\":\"356.28\"},{\"text\":\"And then from there, the\\nsoftware, decently intuitive.\",\"start\\_time\":\"359.01\"},{\"text\":\"Now control wise,\",\"start\\_time\":\"362.88\"},{\"text\":\"we've talked about this\\nin some other cars before.\",\"start\\_time\":\"363.96\"},{\"text\":\"I don't know about this\\nwhole crystal thing.\",\"start\\_time\":\"367.17\"},{\"text\":\"Like, some people are gonna,\\nagain, think it's really neat\",\"start\\_time\":\"368.88\"},{\"text\":\"and it sometimes even\\nreflects like some lights\",\"start\\_time\":\"372.48\"},{\"text\":\"around the rest of the cabin\",\"start\\_time\":\"374.94\"},{\"text\":\"when like the sunlight shines on it.\",\"start\\_time\":\"376.08\"},{\"text\":\"I might say it's a little bit tacky.\",\"start\\_time\":\"378.06\"},{\"text\":\"It does work, functionally it's fine.\",\"start\\_time\":\"379.53\"},{\"text\":\"Gets your seats in the right place, great.\",\"start\\_time\":\"381.96\"},{\"text\":\"That's your unlock, that's your\\ndoor open, unlock and lock.\",\"start\\_time\":\"384.51\"},{\"text\":\"But this here is much prettier\\nthan it is functional.\",\"start\\_time\":\"389.37\"},{\"text\":\"So you've got these buttons\\nthat you can see here.\",\"start\\_time\":\"394.2\"},{\"text\":\"This home, this is a knob\",\"start\\_time\":\"395.91\"},{\"text\":\"that can go left, right, up, down\",\"start\\_time\":\"397.89\"},{\"text\":\"and it is your way of controlling\",\"start\\_time\":\"399.84\"},{\"text\":\"and scrolling on this screen here.\",\"start\\_time\":\"401.79\"},{\"text\":\"But it is also a touchscreen\\nand this volume knob, it works.\",\"start\\_time\":\"404.73\"},{\"text\":\"But then also these buttons being haptic\",\"start\\_time\":\"410.19\"},{\"text\":\"are particularly slow.\",\"start\\_time\":\"412.77\"},{\"text\":\"Like, this haptic response\",\"start\\_time\":\"419.16\"},{\"text\":\"is supposed to give it\\nthe feeling of a button,\",\"start\\_time\":\"420.87\"},{\"text\":\"but I don't like how slow it is to respond\",\"start\\_time\":\"424.05\"},{\"text\":\"and it really doesn't feel like a button.\",\"start\\_time\":\"426.78\"},{\"text\":\"So every time you want to\\npress any of those buttons,\",\"start\\_time\":\"429.63\"},{\"text\":\"you gotta look down,\",\"start\\_time\":\"431.97\"},{\"text\":\"you gotta make sure you\\nhit the right button.\",\"start\\_time\":\"433.32\"},{\"text\":\"Just a little bit quirky,\",\"start\\_time\":\"435.42\"},{\"text\":\"maybe a little too quirky from BMW.\",\"start\\_time\":\"438.24\"},{\"text\":\"Maybe real buttons with\\ndefined surface areas\",\"start\\_time\":\"439.95\"},{\"text\":\"would've been cool here\",\"start\\_time\":\"442.62\"}]", "Act as the author and provide exactly 2 bullet points all\n in the same language as the transcript for the text transcript given in the format [{\"start\\_time\": , \"text\": }] \n and make the output only in the format of a json array [{\"start\\_time\": , \"bullet\\_point\": } ]\n Make sure that:\n - bullet\\_point value must be in the same language as the transcript like [{\"start\\_time\": \"10.5\" , \"bullet\\_point\": \"undefined\"} ].\n - The output is not more than 2 bullet points\n - each bullet\\_point is at least 15 words and all bullet points are sorted by \"start\\_time\"\n - each bullet\\_point doesn't start with \"- \" or a number or a bullet point symbol\n - Wrap json keys with double quotes and don't put single quotes or double quotes inside the values. \n - The output json is not wrapped in any other json structure like { \"data\": }.\n transcript: \n [{\"text\":\"'cause these are useful buttons.\",\"start\\_time\":\"443.453\"},{\"text\":\"You get your parking cameras,\",\"start\\_time\":\"444.3\"},{\"text\":\"which you do get a full\\n360 view and a top down.\",\"start\\_time\":\"445.8\"},{\"text\":\"You have your driving modes\",\"start\\_time\":\"448.71\"},{\"text\":\"which is both sport or efficient\",\"start\\_time\":\"450.33\"},{\"text\":\"or your own personal,\\nwhich lets you jump in\",\"start\\_time\":\"452.31\"},{\"text\":\"and of course change all the settings.\",\"start\\_time\":\"454.53\"},{\"text\":\"Of course I have to\\nactually be on to do that.\",\"start\\_time\":\"457.08\"},{\"text\":\"There's an on button in this EV,\",\"start\\_time\":\"459.24\"},{\"text\":\"which is, ah!\",\"start\\_time\":\"461.16\"},{\"text\":\"They all kind of are starting to do that\",\"start\\_time\":\"463.62\"},{\"text\":\"which is annoying, but that's fine.\",\"start\\_time\":\"465.12\"},{\"text\":\"But then this ends up being\\na lot of your other controls.\",\"start\\_time\":\"466.47\"},{\"text\":\"And then HVAC controls\\nare only two real buttons\",\"start\\_time\":\"468.36\"},{\"text\":\"and then the rest are\\nall on the touchscreen.\",\"start\\_time\":\"471.66\"},{\"text\":\"We've talked about this,\\nwe've talked about this.\",\"start\\_time\":\"474.21\"},{\"text\":\"Obviously having real\\nvent controls is nice\",\"start\\_time\":\"477.3\"},{\"text\":\"and fan open and close is nice.\",\"start\\_time\":\"479.55\"},{\"text\":\"But everything else here, again,\",\"start\\_time\":\"481.26\"},{\"text\":\"it's comfortable having the\\ndifferent levels of heat\",\"start\\_time\":\"483.75\"},{\"text\":\"from the steering wheel and\\nfrom the armrests and all that.\",\"start\\_time\":\"486.48\"},{\"text\":\"Cool but not ideal while driving\",\"start\\_time\":\"490.44\"},{\"text\":\"to have to do a lot on the touchscreen.\",\"start\\_time\":\"493.95\"},{\"text\":\"Now before I forget, let me\\nshow you a couple other things.\",\"start\\_time\":\"495.51\"},{\"text\":\"First of all, most other\\ncars, when I open the door,\",\"start\\_time\":\"497.37\"},{\"text\":\"they turn the music volume down.\",\"start\\_time\":\"502.32\"},{\"text\":\"This one doesn't, which I\\nthought that was kind of weird\",\"start\\_time\":\"504.51\"},{\"text\":\"that that was missing.\",\"start\\_time\":\"506.97\"},{\"text\":\"But let's jump in the back seat real quick\",\"start\\_time\":\"508.11\"},{\"text\":\"so I can show you behind a\\nsix three driving position.\",\"start\\_time\":\"509.88\"},{\"text\":\"I feel like your feet are\\nkind of high off the ground\",\"start\\_time\":\"513.24\"},{\"text\":\"but there is a good\\namount of space and boom,\",\"start\\_time\":\"515.55\"},{\"text\":\"two USB-C ports and whatever\\nyou wanna put in there.\",\"start\\_time\":\"518.31\"},{\"text\":\"So that's good for charging phones.\",\"start\\_time\":\"522.18\"},{\"text\":\"That's on both sides.\",\"start\\_time\":\"523.86\"},{\"text\":\"You also get all these controls here\",\"start\\_time\":\"525.24\"},{\"text\":\"and of course, your feet\\nare gonna be heated.\",\"start\\_time\":\"527.31\"},{\"text\":\"The ventilation in the\\nback is good to see,\",\"start\\_time\":\"529.44\"},{\"text\":\"lots of high quality leather.\",\"start\\_time\":\"531.48\"},{\"text\":\"So this is a good passenger experience,\",\"start\\_time\":\"532.71\"},{\"text\":\"also with this gigantic sunroof overhead.\",\"start\\_time\":\"534\"},{\"text\":\"It doesn't open and close\\nbut still cool to see.\",\"start\\_time\":\"536.85\"},{\"text\":\"I do feel a little bit\\nlower than I expected,\",\"start\\_time\":\"539.22\"},{\"text\":\"but that's fine.\",\"start\\_time\":\"542.22\"},{\"text\":\"Also don't wanna forget that in here\",\"start\\_time\":\"543.053\"},{\"text\":\"there is a cup holder in the armrest.\",\"start\\_time\":\"544.02\"},{\"text\":\"No fancy wireless charger\\nor tablet or anything\",\"start\\_time\":\"547.32\"},{\"text\":\"but you have that option.\",\"start\\_time\":\"549.45\"},{\"text\":\"And of course your lights up here.\",\"start\\_time\":\"552\"},{\"text\":\"What do people put in these, folders?\",\"start\\_time\":\"553.14\"},{\"text\":\"Manila envelopes?\",\"start\\_time\":\"556.2\"},{\"text\":\"Okay, anyway, back to the front.\",\"start\\_time\":\"557.7\"},{\"text\":\"Let's talk a little bit more\",\"start\\_time\":\"559.47\"},{\"text\":\"about actually owning\\nand driving the iX 50.\",\"start\\_time\":\"560.52\"},{\"text\":\"So, you may, weird sound,\",\"start\\_time\":\"564.78\"},{\"text\":\"you may or may not already know\",\"start\\_time\":\"568.11\"},{\"text\":\"about the M60 version, which\\nis a little bit less range,\",\"start\\_time\":\"569.07\"},{\"text\":\"like 270 miles, but a\\nlittle bit more power.\",\"start\\_time\":\"573.87\"},{\"text\":\"So up to 600 horsepower instead of 500.\",\"start\\_time\":\"576.57\"},{\"text\":\"But this is plenty fast\\nin a straight line.\",\"start\\_time\":\"579.39\"},{\"text\":\"It's good for, you know,\\na four-second zero to 60.\",\"start\\_time\":\"581.4\"},{\"text\":\"I think it traps 112 in the quarter mile\",\"start\\_time\":\"584.55\"},{\"text\":\"which is electronically limited top speed.\",\"start\\_time\":\"586.86\"},{\"text\":\"But, you know, it has a\\nsurprising amount of get up and go\",\"start\\_time\":\"589.05\"},{\"text\":\"in a straight line, but that's\\nnot really what it's about.\",\"start\\_time\":\"592.95\"},{\"text\":\"It's much more of that luxury drive\",\"start\\_time\":\"596.04\"},{\"text\":\"which is what you'd\\nexpect from the big SUV\",\"start\\_time\":\"598.29\"},{\"text\":\"with the big battery pack\\nand the heated armrests,\",\"start\\_time\":\"601.59\"},{\"text\":\"they're already warming up\\nfor me now, which is cool.\",\"start\\_time\":\"604.89\"},{\"text\":\"So that's kind of how I feel\",\"start\\_time\":\"608.67\"},{\"text\":\"about most of the way this drives.\",\"start\\_time\":\"610.35\"},{\"text\":\"A couple other notes though.\",\"start\\_time\":\"612.03\"},{\"text\":\"It does have rear wheel steer\",\"start\\_time\":\"613.41\"},{\"text\":\"and I didn't even know that\",\"start\\_time\":\"614.73\"},{\"text\":\"before I got in and I started driving\",\"start\\_time\":\"615.57\"},{\"text\":\"and I was turning around\\nin a tight parking spot.\",\"start\\_time\":\"617.01\"},{\"text\":\"And you notice when that\\ntight turning radius\",\"start\\_time\":\"618.9\"},{\"text\":\"is like super clean, you\\ncan get into any spot.\",\"start\\_time\":\"621.69\"},{\"text\":\"Love that.\",\"start\\_time\":\"624.81\"},{\"text\":\"So it has the rear wheel steer\",\"start\\_time\":\"625.643\"},{\"text\":\"and it just has this very light steering.\",\"start\\_time\":\"627.36\"},{\"text\":\"So the whole thing, very\\nmaneuverable and easy,\",\"start\\_time\":\"629.16\"},{\"text\":\"doesn't feel particularly\\nsporty and that's fine.\",\"start\\_time\":\"633.66\"},{\"text\":\"And then they also actually\\nkind of do a couple, oh look,\",\"start\\_time\":\"636.36\"},{\"text\":\"there's the light from the\\ncrystal hitting my leg here.\",\"start\\_time\":\"639.78\"},{\"text\":\"It's just a fun weird thing that happens\",\"start\\_time\":\"643.08\"},{\"text\":\"when you've got crystals in a car.\",\"start\\_time\":\"646.17\"},{\"text\":\"It does make a couple choices\",\"start\\_time\":\"648.93\"},{\"text\":\"that are sort of mimicking\\nregular gas powered cars more.\",\"start\\_time\":\"650.82\"},{\"text\":\"One of them is that, yes,\\nthere is regen braking\",\"start\\_time\":\"654.63\"},{\"text\":\"when you take your foot\\noff the brake pedal\",\"start\\_time\":\"657.06\"},{\"text\":\"or the accelerator.\",\"start\\_time\":\"659.46\"},{\"text\":\"Take your foot off, it\\nstarts to slow down.\",\"start\\_time\":\"660.66\"},{\"text\":\"But the regen doesn't go all\\nthe way to zero miles an hour.\",\"start\\_time\":\"662.88\"},{\"text\":\"It'll go to like six miles an\\nhour and then you're coasting.\",\"start\\_time\":\"665.67\"},{\"text\":\"So you still have to hit the\\nbrake pedal to get to zero.\",\"start\\_time\":\"668.85\"}]", "Act as the author and provide exactly 2 bullet points all\n in the same language as the transcript for the text transcript given in the format [{\"start\\_time\": , \"text\": }] \n and make the output only in the format of a json array [{\"start\\_time\": , \"bullet\\_point\": } ]\n Make sure that:\n - bullet\\_point value must be in the same language as the transcript like [{\"start\\_time\": \"10.5\" , \"bullet\\_point\": \"undefined\"} ].\n - The output is not more than 2 bullet points\n - each bullet\\_point is at least 15 words and all bullet points are sorted by \"start\\_time\"\n - each bullet\\_point doesn't start with \"- \" or a number or a bullet point symbol\n - Wrap json keys with double quotes and don't put single quotes or double quotes inside the values. \n - The output json is not wrapped in any other json structure like { \"data\": }.\n transcript: \n [{\"text\":\"I wish there was a one\\npedal drive setting.\",\"start\\_time\":\"672.18\"},{\"text\":\"I haven't been able to find it.\",\"start\\_time\":\"674.58\"},{\"text\":\"Maybe I'm not looking hard enough.\",\"start\\_time\":\"675.69\"},{\"text\":\"But that's something they've chosen.\",\"start\\_time\":\"677.16\"},{\"text\":\"And also a little bit of a latency\",\"start\\_time\":\"679.5\"},{\"text\":\"between when I hit the pedal\",\"start\\_time\":\"682.89\"},{\"text\":\"and the acceleration actually starts.\",\"start\\_time\":\"684.93\"},{\"text\":\"This I thought was a little odd.\",\"start\\_time\":\"686.55\"},{\"text\":\"Smacking the pedal, just flooring it.\",\"start\\_time\":\"688.8\"},{\"text\":\"There's actually a tiny delay\",\"start\\_time\":\"691.2\"},{\"text\":\"before it starts sending you forward,\",\"start\\_time\":\"692.7\"},{\"text\":\"it feels like almost the\\nsame amount of lag is,\",\"start\\_time\":\"695.04\"},{\"text\":\"you know, a kick down\",\"start\\_time\":\"697.65\"},{\"text\":\"in an engine shifting gears\\nto hit the right RPMs.\",\"start\\_time\":\"698.85\"},{\"text\":\"It's kind of weird.\",\"start\\_time\":\"701.58\"},{\"text\":\"Then it gets up and goes, which is fine,\",\"start\\_time\":\"703.38\"},{\"text\":\"but it's very approachable\",\"start\\_time\":\"705.3\"},{\"text\":\"if you've driven a lot of gas cars before.\",\"start\\_time\":\"707.7\"},{\"text\":\"And then it does have wireless\\nAndroid Auto which I use\",\"start\\_time\":\"709.44\"},{\"text\":\"and CarPlay, which is great\",\"start\\_time\":\"712.11\"},{\"text\":\"because that means you can put\\nyour phone kind of anywhere.\",\"start\\_time\":\"713.97\"},{\"text\":\"It does have this clever spot right here\",\"start\\_time\":\"717.63\"},{\"text\":\"which kind of seems weird,\",\"start\\_time\":\"720.36\"},{\"text\":\"but there is a pass through here\",\"start\\_time\":\"722.22\"},{\"text\":\"to some plugs, to USB-C down here.\",\"start\\_time\":\"724.83\"},{\"text\":\"So if you do still want to\\nkeep your phone up here,\",\"start\\_time\":\"727.92\"},{\"text\":\"even while wireless\\nCarPlaying or Android Autoing,\",\"start\\_time\":\"730.11\"},{\"text\":\"you can route up a cable,\",\"start\\_time\":\"732.81\"},{\"text\":\"which, I thought that was pretty clever.\",\"start\\_time\":\"734.76\"},{\"text\":\"But this is also a wireless\\ncharger, which is cool to see.\",\"start\\_time\":\"736.47\"},{\"text\":\"It is in a kind of an awkward place\",\"start\\_time\":\"740.58\"},{\"text\":\"to fumble and put your phone.\",\"start\\_time\":\"742.95\"},{\"text\":\"But hey, you can do that if you want to.\",\"start\\_time\":\"744.63\"},{\"text\":\"I just like that that wirelessly\\ntransmits, thumbs up there.\",\"start\\_time\":\"747.15\"},{\"text\":\"The speakers in this car,\",\"start\\_time\":\"750.36\"},{\"text\":\"which are by Harman Kardon, are very solid\",\"start\\_time\":\"751.47\"},{\"text\":\"and get very loud.\",\"start\\_time\":\"753.63\"},{\"text\":\"You can do volume control\\non the steering wheel here\",\"start\\_time\":\"755.01\"},{\"text\":\"or by this little knob.\",\"start\\_time\":\"757.14\"},{\"text\":\"It's a little bass heavy and\\nlight on treble by default\",\"start\\_time\":\"758.64\"},{\"text\":\"but there's an EQ setting\\nand you can go crazy with it\",\"start\\_time\":\"762.27\"},{\"text\":\"and it sounds really good after that.\",\"start\\_time\":\"764.37\"},{\"text\":\"Oh, I also wanted to mention\\nthere are gesture controls.\",\"start\\_time\":\"766.17\"},{\"text\":\"Let me know if you think this is gimmicky.\",\"start\\_time\":\"771.21\"},{\"text\":\"I kind of have my feeling already\",\"start\\_time\":\"772.53\"},{\"text\":\"but you can see I'm playing a song\",\"start\\_time\":\"773.76\"},{\"text\":\"and then I do that and\\nit goes to the next song\",\"start\\_time\":\"775.59\"},{\"text\":\"and then do that and it\\ngoes to the previous song\",\"start\\_time\":\"779.82\"},{\"text\":\"or the beginning of that song.\",\"start\\_time\":\"784.44\"},{\"text\":\"But here's another one here.\",\"start\\_time\":\"785.91\"},{\"text\":\"You just do this and volume\\ncan turn up and down.\",\"start\\_time\":\"786.93\"},{\"text\":\"I mean, it's clearly gimmicky.\",\"start\\_time\":\"793.86\"},{\"text\":\"You have this next song and previous song\",\"start\\_time\":\"794.79\"},{\"text\":\"and volume control here\\non the steering wheel.\",\"start\\_time\":\"797.49\"},{\"text\":\"You also have this laggy\\nnext song and previous song\",\"start\\_time\":\"799.41\"},{\"text\":\"and volume controls here.\",\"start\\_time\":\"802.56\"},{\"text\":\"So I wouldn't really\\nworry about this too much,\",\"start\\_time\":\"804.18\"},{\"text\":\"even though it is maybe\\nsomething they felt\",\"start\\_time\":\"807.75\"},{\"text\":\"that they could pump this,\",\"start\\_time\":\"810.54\"},{\"text\":\"I think, is it, maybe\\nthis camera right here?\",\"start\\_time\":\"811.41\"},{\"text\":\"I'm not actually sure which camera\",\"start\\_time\":\"813.42\"},{\"text\":\"is looking for those gesture controls,\",\"start\\_time\":\"814.59\"},{\"text\":\"but actually, it's probably this one.\",\"start\\_time\":\"816.06\"},{\"text\":\"It's probably the one right above me.\",\"start\\_time\":\"818.94\"},{\"text\":\"Yeah, it kind of works,\\nbut it's a gimmick.\",\"start\\_time\":\"821.16\"},{\"text\":\"But honestly, you know, I've\\ngone through a lot of things\",\"start\\_time\":\"823.71\"},{\"text\":\"about this car.\",\"start\\_time\":\"825.78\"},{\"text\":\"The range is solid, the space is solid,\",\"start\\_time\":\"826.613\"},{\"text\":\"the fundamentals are solid.\",\"start\\_time\":\"830.7\"},{\"text\":\"It's comfortable, generally,\\nunless you're too short\",\"start\\_time\":\"832.38\"},{\"text\":\"and in the passenger seat.\",\"start\\_time\":\"835.14\"},{\"text\":\"There's a lot going for it.\",\"start\\_time\":\"836.52\"},{\"text\":\"I think my biggest complaint\",\"start\\_time\":\"838.2\"},{\"text\":\"is I don't think it looks great.\",\"start\\_time\":\"843.15\"},{\"text\":\"So, I mean there are other\\ncompetitors in this area.\",\"start\\_time\":\"844.29\"},{\"text\":\"You look at the price tag, 80 to $90,000\",\"start\\_time\":\"846.27\"},{\"text\":\"and you could easily go get Tesla Model X.\",\"start\\_time\":\"849.63\"},{\"text\":\"You could easily go get Rivian R1S,\",\"start\\_time\":\"851.79\"},{\"text\":\"you could get a Genesis GV60.\",\"start\\_time\":\"854.01\"},{\"text\":\"There's a bunch of other stuff\",\"start\\_time\":\"855.72\"},{\"text\":\"that all hit different\\nstrengths in different ways.\",\"start\\_time\":\"857.76\"},{\"text\":\"So I would say you could get this one\",\"start\\_time\":\"861.57\"},{\"text\":\"if you're a fan of BMW,\",\"start\\_time\":\"863.28\"},{\"text\":\"you're a fan of comfort, light steering,\",\"start\\_time\":\"864.78\"},{\"text\":\"relaxed ride, surprising\\namount of straight line power,\",\"start\\_time\":\"867\"},{\"text\":\"and 300 miles of range\\nis good enough for you.\",\"start\\_time\":\"870.69\"},{\"text\":\"Which, there are others\\nthat do the same stuff\",\"start\\_time\":\"873.03\"},{\"text\":\"but some people are\\njust diehard BMW people\",\"start\\_time\":\"874.89\"},{\"text\":\"and they like this.\",\"start\\_time\":\"878.28\"},{\"text\":\"So yeah, that's it for\\nmy thoughts on the iX.\",\"start\\_time\":\"879.81\"},{\"text\":\"Thanks for watching.\",\"start\\_time\":\"883.14\"},{\"text\":\"Let me know what you think.\",\"start\\_time\":\"884.25\"},{\"text\":\"Catch you in the next one. Peace.\",\"start\\_time\":\"885.33\"}]", "#include \"main.h\"\n\n/\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\* WRITE HANDLE \\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*/\n/\\*\\*\n \\* handle\\_write\\_char - Prints a string\n \\* @c: char types.\n \\* @buffer: Buffer array to handle print\n \\* @flags: Calculates active flags.\n \\* @width: get width.\n \\* @precision: precision specifier\n \\* @size: Size specifier\n \\*\n \\* Return: Number of chars printed.\n \\*/\nint handle\\_write\\_char(char c, char buffer[],\n int flags, int width, int precision, int size)\n{ /\\* char is stored at left and paddind at buffer's right \\*/\n int i = 0;\n char padd = ' ';\n\n UNUSED(precision);\n UNUSED(size);\n\n if (flags & F\\_ZERO)\n padd = '0';\n\n buffer[i++] = c;\n buffer[i] = '\\0';\n\n if (width > 1)\n {\n buffer[BUFF\\_SIZE - 1] = '\\0';\n for (i = 0; i < width - 1; i++)\n buffer[BUFF\\_SIZE - i - 2] = padd;\n\n if (flags & F\\_MINUS)\n return (write(1, &buffer[0], 1) +\n write(1, &buffer[BUFF\\_SIZE - i - 1], width - 1));\n else\n return (write(1, &buffer[BUFF\\_SIZE - i - 1], width - 1) +\n write(1, &buffer[0], 1));\n }\n\n return (write(1, &buffer[0], 1));\n}\n\n/\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\* WRITE NUMBER \\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*/\n/\\*\\*\n \\* write\\_number - Prints a string\n \\* @is\\_negative: Lista of arguments\n \\* @ind: char types.\n \\* @buffer: Buffer array to handle print\n \\* @flags: Calculates active flags\n \\* @width: get width.\n \\* @precision: precision specifier\n \\* @size: Size specifier\n \\*\n \\* Return: Number of chars printed.\n \\*/\nint write\\_number(int is\\_negative, int ind, char buffer[],\n int flags, int width, int precision, int size)\n{\n int length = BUFF\\_SIZE - ind - 1;\n char padd = ' ', extra\\_ch = 0;\n\n UNUSED(size);\n\n if ((flags & F\\_ZERO) && !(flags & F\\_MINUS))\n padd = '0';\n if (is\\_negative)\n extra\\_ch = '-';\n else if (flags & F\\_PLUS)\n extra\\_ch = '+';\n else if (flags & F\\_SPACE)\n extra\\_ch = ' ';\n\n return (write\\_num(ind, buffer, flags, width, precision,\n length, padd, extra\\_ch));\n}\n\n/\\*\\*\n \\* write\\_num - Write a number using a bufffer\n \\* @ind: Index at which the number starts on the buffer\n \\* @buffer: Buffer\n \\* @flags: Flags\n \\* @width: width\n \\* @prec: Precision specifier\n \\* @length: Number length\n \\* @padd: Pading char\n \\* @extra\\_c: Extra char\n \\*\n \\* Return: Number of printed chars.\n \\*/\nint write\\_num(int ind, char buffer[],\n int flags, int width, int prec,\n int length, char padd, char extra\\_c)\n{\n int i, padd\\_start = 1;\n\n if (prec == 0 && ind == BUFF\\_SIZE - 2 && buffer[ind] == '0' && width == 0)\n return (0); /\\* printf(\".0d\", 0) no char is printed \\*/\n if (prec == 0 && ind == BUFF\\_SIZE - 2 && buffer[ind] == '0')\n buffer[ind] = padd = ' '; /\\* width is displayed with padding ' ' \\*/\n if (prec > 0 && prec < length)\n padd = ' ';\n while (prec > length)\n buffer[--ind] = '0', length++;\n if (extra\\_c != 0)\n length++;\n if (width > length)\n {\n for (i = 1; i < width - length + 1; i++)\n buffer[i] = padd;\n buffer[i] = '\\0';\n if (flags & F\\_MINUS && padd == ' ')/\\* Asign extra char to left of buffer \\*/\n {\n if (extra\\_c)\n buffer[--ind] = extra\\_c;\n return (write(1, &buffer[ind], length) + write(1, &buffer[1], i - 1));\n }\n else if (!(flags & F\\_MINUS) && padd == ' ')/\\* extra char to left of buff \\*/\n {\n if (extra\\_c)\n buffer[--ind] = extra\\_c;\n return (write(1, &buffer[1], i - 1) + write(1, &buffer[ind], length));\n }\n else if (!(flags & F\\_MINUS) && padd == '0')/\\* extra char to left of padd \\*/\n {\n if (extra\\_c)\n buffer[--padd\\_start] = extra\\_c;\n return (write(1, &buffer[padd\\_start], i - padd\\_start) +\n write(1, &buffer[ind], length - (1 - padd\\_start)));\n }\n }\n if (extra\\_c)\n buffer[--ind] = extra\\_c;\n return (write(1, &buffer[ind], length));\n}\n\n/\\*\\*\n \\* write\\_unsgnd - Writes an unsigned number\n \\* @is\\_negative: Number indicating if the num is negative\n \\* @ind: Index at which the number starts in the buffer\n \\* @buffer: Array of chars\n \\* @flags: Flags specifiers\n \\* @width: Width specifier\n \\* @precision: Precision specifier\n \\* @size: Size specifier\n \\*\n \\* Return: Number of written chars.\n \\*/\nint write\\_unsgnd(int is\\_negative, int ind,\n char buffer[],\n int flags, int width, int precision, int size)\n{\n /\\* The number is stored at the bufer's right and starts at position i \\*/\n int length = BUFF\\_SIZE - ind - 1, i = 0;\n char padd = ' ';\n\n UNUSED(is\\_negative);\n UNUSED(size);\n\n if (precision == 0 && ind == BUFF\\_SIZE - 2 && buffer[ind] == '0')\n return (0); /\\* printf(\".0d\", 0) no char is printed \\*/\n\n if (precision > 0 && precision < length)\n padd = ' ';\n\n while (precision > length)\n {\n buffer[--ind] = '0';\n length++;\n }\n\n if ((flags & F\\_ZERO) && !(flags & F\\_MINUS))\n padd = '0';\n\n if (width > length)\n {\n for (i = 0; i < width - length; i++)\n buffer[i] = padd;\n\n buffer[i] = '\\0';\n\n if (flags & F\\_MINUS) /\\* Asign extra char to left of buffer [buffer>padd]\\*/\n {\n return (write(1, &buffer[ind], length) + write(1, &buffer[0], i));\n }\n else /\\* Asign extra char to left of padding [padd>buffer]\\*/\n {\n return (write(1, &buffer[0], i) + write(1, &buffer[ind], length));\n }\n }\n\n return (write(1, &buffer[ind], length));\n}\n\n/\\*\\*\n \\* write\\_pointer - Write a memory address\n \\* @buffer: Arrays of chars\n \\* @ind: Index at which the number starts in the buffer\n \\* @length: Length of number\n \\* @width: Wwidth specifier\n \\* @flags: Flags specifier\n \\* @padd: Char representing the padding\n \\* @extra\\_c: Char representing extra char\n \\* @padd\\_start: Index at which padding should start\n \\*\n \\* Return: Number of written chars.\n \\*/\nint write\\_pointer(char buffer[], int ind, int length,\n int width, int flags, char padd, char extra\\_c, int padd\\_start)\n{\n int i;\n\n if (width > length)\n {\n for (i = 3; i < width - length + 3; i++)\n buffer[i] = padd;\n buffer[i] = '\\0';\n if (flags & F\\_MINUS && padd == ' ')/\\* Asign extra char to left of buffer \\*/\n {\n buffer[--ind] = 'x';\n buffer[--ind] = '0';\n if (extra\\_c)\n buffer[--ind] = extra\\_c;\n return (write(1, &buffer[ind], length) + write(1, &buffer[3], i - 3));\n }\n else if (!(flags & F\\_MINUS) && padd == ' ')/\\* extra char to left of buffer \\*/\n {\n buffer[--ind] = 'x';\n buffer[--ind] = '0';\n if (extra\\_c)\n buffer[--ind] = extra\\_c;\n return (write(1, &buffer[3], i - 3) + write(1, &buffer[ind], length));\n }\n else if (!(flags & F\\_MINUS) && padd == '0')/\\* extra char to left of padd \\*/\n {\n if (extra\\_c)\n buffer[--padd\\_start] = extra\\_c;\n buffer[1] = '0';\n buffer[2] = 'x';\n return (write(1, &buffer[padd\\_start], i - padd\\_start) +\n write(1, &buffer[ind], length - (1 - padd\\_start) - 2));\n }\n }\n buffer[--ind] = 'x';\n buffer[--ind] = '0';\n if (extra\\_c)\n buffer[--ind] = extra\\_c;\n return (write(1, &buffer[ind], BUFF\\_SIZE - ind - 1));\n}", "given this DDL\n-- ceoclone\\_analytics.ContactButtonClickEventLog definition\n\nCREATE TABLE `ContactButtonClickEventLog` (\n `id` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `uid` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `gid` varchar(191) COLLATE utf8mb4\\_unicode\\_ci DEFAULT NULL,\n `sessionId` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `videoId` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `timestamp` double NOT NULL,\n PRIMARY KEY (`id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4\\_unicode\\_ci;\n-- ceoclone\\_analytics.ContactFormSubmitEventLog definition\n\nCREATE TABLE `ContactFormSubmitEventLog` (\n `id` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `uid` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `gid` varchar(191) COLLATE utf8mb4\\_unicode\\_ci DEFAULT NULL,\n `sessionId` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `videoId` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `timestamp` double NOT NULL,\n `formData` json NOT NULL,\n PRIMARY KEY (`id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4\\_unicode\\_ci;\n-- ceoclone\\_analytics.FooterMenuClickEventLog definition\n\nCREATE TABLE `FooterMenuClickEventLog` (\n `id` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `uid` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `gid` varchar(191) COLLATE utf8mb4\\_unicode\\_ci DEFAULT NULL,\n `sessionId` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `videoId` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `timestamp` double NOT NULL,\n `footerMenuId` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n PRIMARY KEY (`id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4\\_unicode\\_ci;\n-- ceoclone\\_analytics.LeaveEventLog definition\n\nCREATE TABLE `LeaveEventLog` (\n `id` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `uid` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `gid` varchar(191) COLLATE utf8mb4\\_unicode\\_ci DEFAULT NULL,\n `sessionId` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `videoId` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `timestamp` double NOT NULL,\n `videoCurrentTime` double NOT NULL,\n PRIMARY KEY (`id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4\\_unicode\\_ci;\n-- ceoclone\\_analytics.PageViewEventLog definition\n\nCREATE TABLE `PageViewEventLog` (\n `id` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `uid` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `gid` varchar(191) COLLATE utf8mb4\\_unicode\\_ci DEFAULT NULL,\n `sessionId` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `videoId` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `timestamp` double NOT NULL,\n `href` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `referrer` varchar(191) COLLATE utf8mb4\\_unicode\\_ci DEFAULT NULL,\n PRIMARY KEY (`id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4\\_unicode\\_ci;\n-- ceoclone\\_analytics.SlideNextButtonClickEventLog definition\n\nCREATE TABLE `SlideNextButtonClickEventLog` (\n `id` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `uid` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `gid` varchar(191) COLLATE utf8mb4\\_unicode\\_ci DEFAULT NULL,\n `sessionId` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `videoId` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `timestamp` double NOT NULL,\n PRIMARY KEY (`id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4\\_unicode\\_ci;\n-- ceoclone\\_analytics.SlidePrevButtonClickEventLog definition\n\nCREATE TABLE `SlidePrevButtonClickEventLog` (\n `id` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `uid` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `gid` varchar(191) COLLATE utf8mb4\\_unicode\\_ci DEFAULT NULL,\n `sessionId` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `videoId` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `timestamp` double NOT NULL,\n PRIMARY KEY (`id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4\\_unicode\\_ci;\n-- ceoclone\\_analytics.SlideSyncModeToggleEventLog definition\n\nCREATE TABLE `SlideSyncModeToggleEventLog` (\n `id` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `uid` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `gid` varchar(191) COLLATE utf8mb4\\_unicode\\_ci DEFAULT NULL,\n `sessionId` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `videoId` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `timestamp` double NOT NULL,\n `isSlideSyncModeActive` tinyint(1) NOT NULL,\n PRIMARY KEY (`id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4\\_unicode\\_ci;\n-- ceoclone\\_analytics.SlideViewedEventLog definition\n\nCREATE TABLE `SlideViewedEventLog` (\n `id` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `uid` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `gid` varchar(191) COLLATE utf8mb4\\_unicode\\_ci DEFAULT NULL,\n `sessionId` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `videoId` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `timestamp` double NOT NULL,\n `slidePage` int(11) NOT NULL,\n `duration` double NOT NULL,\n PRIMARY KEY (`id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4\\_unicode\\_ci;\n-- ceoclone\\_analytics.SlideZoomModeToggleEventLog definition\n\nCREATE TABLE `SlideZoomModeToggleEventLog` (\n `id` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `uid` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `gid` varchar(191) COLLATE utf8mb4\\_unicode\\_ci DEFAULT NULL,\n `sessionId` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `videoId` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `timestamp` double NOT NULL,\n `isSlideZoomModeActive` tinyint(1) NOT NULL,\n PRIMARY KEY (`id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4\\_unicode\\_ci;\n-- ceoclone\\_analytics.V2ChapterMenuClickEventLog definition\n\nCREATE TABLE `V2ChapterMenuClickEventLog` (\n `id` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `uid` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `gid` varchar(191) COLLATE utf8mb4\\_unicode\\_ci DEFAULT NULL,\n `sessionId` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `videoId` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `timestamp` double NOT NULL,\n `chapterId` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `chapterName` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n PRIMARY KEY (`id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4\\_unicode\\_ci;\n-- ceoclone\\_analytics.V2ChapterRecommendationButtonClickEventLog definition\n\nCREATE TABLE `V2ChapterRecommendationButtonClickEventLog` (\n `id` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `uid` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `gid` varchar(191) COLLATE utf8mb4\\_unicode\\_ci DEFAULT NULL,\n `sessionId` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `videoId` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `timestamp` double NOT NULL,\n `chapterId` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n `chapterName` varchar(191) COLLATE utf8mb4\\_unicode\\_ci NOT NULL,\n PRIMARY KEY (`id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4\\_unicode\\_ci;", "SEC. 7. RESOLUTION OF DISAPPROVAL OF DESIGNATION OR REMOVAL OF \n DESIGNATION OF A FOREIGN ADVERSARY.\n\n (a) Definition.--In this section--\n (1) the term ``covered joint resolution'' means a joint \n resolution of disapproval of designation or a joint resolution \n of disapproval of removal of designation;\n (2) the term ``joint resolution of disapproval of \n designation'' means a joint resolution the matter after the \n resolving clause of which is as follows: ``That Congress \n disapproves the designation by the Secretary of Commerce of \\_\\_\\_ \n as a foreign adversary for purposes of the Securing the \n Information and Communications Technology and Services Supply \n Chain Act of 2023, and such designation shall have no force or \n effect until the Secretary of Commerce provides specific \n evidence to the relevant committees of Congress regarding the \n removal of designation under section 6(a) of that Act.'' (The \n blank space being appropriately filled in with the name of the \n foreign person of which the Secretary has designated as a \n foreign adversary of for purposes of this Act); and\n (3) the term ``joint resolution of disapproval of removal \n of designation'' means a joint resolution the matter after the \n resolving clause of which is as follows: ``That Congress \n disapproves the removal of designation by the Secretary of \n Commerce of \\_\\_\\_ as a foreign adversary for purposes of the \n Securing the Information and Communications Technology and \n Services Supply Chain Act of 2023, and such removal shall have \n no force or effect until the Secretary of Commerce provides \n specific evidence to the relevant committees of Congress \n regarding the removal of designation under section 6(a) of that \n Act.'' (The blank space being appropriately filled in with the \n name of the foreign government or regime of which the Secretary \n has removed the designation as a foreign adversary of for \n purposes of this Act).\n (b) Expedited Consideration of Legislation.--\n (1) Initiation.--In the event the Secretary designates a \n foreign government or regime as a foreign adversary or removes \n such designation as a foreign adversary, a joint resolution of \n disapproval of designation or a joint resolution of disapproval \n of removal of designation, as applicable, that is introduced \n during the 60-calendar day period thereafter shall be entitled \n to expedited consideration pursuant to this subsection.\n (2) Introduction.--During the 60-calendar day period \n provided for in paragraph (1), a covered joint resolution may \n be introduced--\n (A) in the Senate, by the Majority Leader (or the \n designee of the Majority Leader) or the Minority Leader \n (or the designee of the Minority Leader); and\n (B) in the House of Representatives, by the Speaker \n or the Minority Leader.\n (3) Floor consideration in house of representatives.--\n (A) Reporting and discharge.--If a relevant \n committee of the House to which a covered joint \n resolution has been referred has not reported such \n covered joint resolution within 10 legislative days \n after the date of referral, that committee shall be \n discharged from further consideration thereof.\n (B) Proceeding to consideration.--Beginning on the \n third legislative day after each committee to which \n covered joint resolution has been referred reports the \n covered joint resolution to the House or has been \n discharged from further consideration thereof, it shall \n be in order to move to proceed to consider the covered \n joint resolution in the House. All points of order \n against the motion are waived. Such a motion shall not \n be in order after the House has disposed of a motion to \n proceed on the covered joint resolution with regard to \n the same agreement. The previous question shall be \n considered as ordered on the motion to its adoption \n without intervening motion. The motion shall not be \n debatable. A motion to reconsider the vote by which the \n motion is disposed of shall not be in order.\n \u00a9 Consideration.--The covered joint resolution \n shall be considered as read. All points of order \n against the covered joint resolution and against its \n consideration are waived. The previous question shall \n be considered as ordered on the covered joint \n resolution to final passage without intervening motion \n except 2 hours of debate equally divided and controlled \n by the sponsor of the covered joint resolution (or a \n designee) and an opponent. A motion to reconsider the \n vote on passage of the covered joint resolution shall \n not be in order.\n (4) Consideration in the senate.--\n (A) Committee referral.--A covered joint resolution \n introduced in the Senate shall be referred to the \n relevant committees of the Senate.\n (B) Reporting and discharge.--If a relevant \n committee of the Senate has not reported such covered \n joint resolution within 10 session days after the date \n of referral of such legislation, that committee shall \n be discharged from further consideration of such \n legislation and the covered joint resolution shall be \n placed on the appropriate calendar.\n \u00a9 Proceeding to consideration.--Notwithstanding \n Rule XXII of the Standing Rules of the Senate, it is in \n order at any time after each committee authorized to \n consider covered joint resolution reports it to the \n Senate or has been discharged from its consideration \n (even though a previous motion to the same effect has \n been disagreed to) to move to proceed to the \n consideration of the covered joint resolution, and all \n points of order against covered joint resolution (and \n against consideration of the covered joint resolution) \n are waived. The motion to proceed is not debatable. The \n motion is not subject to a motion to postpone. A motion \n to reconsider the vote by which the motion is agreed to \n or disagreed to shall not be in order. If a motion to \n proceed to the consideration of the covered joint \n resolution is agreed to, the covered joint resolution \n shall remain the unfinished business until disposed of.\n (D) Debate.--Debate on covered joint resolution, \n and on all debatable motions and appeals in connection \n therewith, shall be limited to not more than 10 hours, \n which shall be divided equally between the majority and \n minority leaders or their designees. A motion to \n further limit debate is in order and not debatable. An \n amendment to, or a motion to postpone, or a motion to \n proceed to the consideration of other business, or a \n motion to recommit the covered joint resolution is not \n in order.\n (E) Vote on passage.--The vote on passage shall \n occur immediately following the conclusion of the \n debate on the covered joint resolution and a single \n quorum call at the conclusion of the debate, if \n requested in accordance with the rules of the Senate.\n ? Rulings of the chair on procedure.--Appeals \n from the decisions of the Chair relating to the \n application of the rules of the Senate, as the case may \n be, to the procedure relating to a covered joint \n resolution shall be decided without debate.\n (G) Consideration of veto messages.--Debate in the \n Senate of any veto message with respect to a covered \n joint resolution, including all debatable motions and \n appeals in connection with such covered joint \n resolution, shall be limited to 10 hours, to be equally \n divided between, and controlled by, the Majority Leader \n and the Minority Leader or their designees.\n ? Rules relating to senate and house of \n representatives.--\n (A) Coordination with action by other house.--If, \n before the passage by one House of a covered joint \n resolution of that House, that House receives a covered \n joint resolution from the other House, then the \n following procedures shall apply:\n (i) The covered joint resolution of the \n other House shall not be referred to a \n committee.\n (ii) With respect to covered joint \n resolution of the House receiving the \n legislation--\n (I) the procedure in that House \n shall be the same as if no covered \n joint resolution had been received from \n the other House; but\n (II) the vote on passage shall be \n on the covered joint resolution of the \n other House.\n (B) Treatment of a covered joint resolution of \n other house.--If one House fails to introduce a covered \n joint resolution under this section, the covered joint \n resolution of the other House shall be entitled to \n expedited floor procedures under this section.\n \u00a9 Treatment of companion measures.--If, following \n passage of the covered joint resolution in the Senate, \n the Senate then receives a companion measure from the \n House of Representatives, the companion measure shall \n not be debatable.\n \u00a9 Rules of Senate and House of Representatives.--Subsection (b) \nis enacted by Congress--\n (1) as an exercise of the rulemaking power of the Senate \n and the House of Representatives, respectively, and as such are \n deemed a part of the rules of each House, respectively, but \n applicable only with respect to the procedure to be followed in \n that House in the case of legislation described in those \n sections, and supersede other rules only to the extent that \n they are inconsistent with such rules; and\n (2) with full recognition of the constitutional right of \n either House to change the rules (so far as relating to the \n procedure of that House) at any time, in the same manner, and \n to the same extent as in the case of any other rule of that \n House.\n (d) Effect of Covered Joint Resolution.--\n (1) Joint resolutions of disapproval of designation.--A \n joint resolution of disapproval of designation that is enacted \n in accordance with this section shall remove the designation as \n a foreign adversary of a foreign government or regime that is \n the subject of the joint resolution of disapproval of \n designation for purposes of this Act.\n (2) Joint resolutions of disapproval of removal of \n designation.--A joint resolution of disapproval of removal of \n designation that is enacted in accordance with this section \n shall prohibit the removal of designation as a foreign \n adversary of a foreign government or regime that is the subject \n of the joint resolution of disapproval of removal of \n designation for purposes of this Act.", "Backstory:\nEvendur Buckman came into this world like many others in the great city of Neverwinter in the year 1420 DR under the loving care of Hilda and Naldo Buckman. The new parents were acolytes held in high esteem among the many temples nestled throughout the city working under the rule of king Bann Alagondar. Bann was one of many in the revered Alagondar family line who had ruled for more than a century and had brought prosperity and wealth to the city. Now being with child however, Hilda insisted that the city although great was no place to raise her son. Therefore, soon after Evendur's birth, the new parents joined a small group of adventurous folk looking to form a more peaceful life outside the city and they helped found the small settlement of Oakhurst 25 miles eastward along the banks of the mighty neverwinter river. The people's hope was that the fertile soil could be cultivated along the banks of the river and trade relationships could be set up with Neverwinter.\n\nNaldo and Hilda took up the role of town acolytes and founded a temple in the budding farming community devoted to Chauntea, the goddess of agriculture, raising Evendur as a member of the clergy. The people of Oakhurst were followers of the temple seeking to bring good harvests and prosperity to the growing community. At least that was until the spring of the year 1451 when weeks of tremors in the ground foretold the eruption of the long dormant Mount Hotenow which devastated the region.\n\nNews quickly spread of the massive devastation which had befallen Neverwinter killing the entire living Alagondar family and laying the city to waste. Oakhurst was initially lucky, spared from the immediate fallout from the volcano but the pain the Oakhurst people would endure soon became clear. As the coming weeks passed the ash lingered in the air and black soot rained down across the fields while cold winds whipped over the landscape throughout the months of Summertide and Highsun granting the name locally \"the year of sunless summer\" to 1451 DR as many families faced starvation. Everyone did what they could but many of the old and weak among the community perished giving Evendur his first experience with the great suffering that fate could place upon his people. As time passed, the settlement endured quickly rebuilding and being a great help to Neverwinter providing much needed food during the long, tedious rebuilding effort that it had to endure.\n\nOver the next couple decades, the temple continued to serve as a gathering place for the people of Oakhurst, however it also served other purposes unbeknownst to the many people praying among its pews. Naldo throughout his life had always been a bit of a purveyor of antiques and artifacts. His connections and exposure to the noble class of Neverwinter had granted him access to various sacred artifacts. When the eyes of his peers could be avoided, Naldo occasionally acquired these artifacts for his personal collection. He secretly maintained and grew this collection even after his move to Oakhurst where he built a chamber behind the altar to store them. He told any prying eye who were curious that it was strictly forbidden to enter this chamber as not to upset the great goddess of the harvest.\n\nLater, in the year 1483 DR, decades had passed since the eruption of Mount Hotenow. Time had marched on and Evendur's parents had become elderly and by necessity passed on to Evendur many duties of the temple such as maintaining the cemetery, holding sermons, and giving last rites. Also, during that summer attendance in the temple started to drop and upon investigation Evendur began to hear rumors of people skipping out on worship due to apple goblins. Evendur at first thought that the people had gone crazy however he witnessed himself a miraculous feat as a young girl who was deathly ill was given just a single slice of a so called \"magic apple\" and she quickly made a full recovery. The people said that goblins came into the town and demanded someone buy the apple from them which the townspeople bought out of fear thinking it to be some sort of ruse.\n\nThe people of the community quickly forgot about this strange event however the next summer and each summer thereafter the goblins returned bearing another apple. The people of the town attempted to plant the seeds from the magic apples however after sprouting and growing for a period of time the sapling would disappear. The townspeople became convinced that the goblins were stealing the plants and were trying to keep all the magic apples to themselves. It became an annual event as each summer neared that the temple's attendance would drop as the people fought over access and obsessed over the magical healing properties of that years goblin apple.\n\nEventually, Naldo and Hilda passed of natural causes very close to each other and Evendur was left distraught. After witnessing the death of his parents and with his own age becoming something that could no longer be ignored, Evendur had to contend with the inevitability of his own death. Upon his deathbed, Naldo told Evendur what was in the secret chamber and asked him to watch over his collection. Although he continued to perform his duties in the temple for years to come, it took a few years for Evendur to build the courage to enter the chamber as it reminded him of his inevitable fate. At long last though Evendur finally opened the chamber discovering various miraculous and beautiful artifacts but one seemed to call to him. On a small pedestal was a Prayer wheel, a ritualistic device with the text of prayers written on a spinning disc which along with reciting the prayers was said to enhance the effects of the prayer. This prayer wheel spoke of Kelemvor the god of death and judge of the damned.\n\nEvendur instantly understood a new calling, an answer to the question he had been struggling with that while death could be delayed, it was an absolute inevitability and not to be feared. With this new calling Evendur arranged a replacement priest for the temple and set out to discover greater truths of Kelemvor. He first set out east along the Neverwinter river toward the closest settlement to Oakhurst, a small community of halflings named Riverside nestled into the western edge of the neverwinter wood and bordered on the south by the banks of the rushing river.\n\nThe halflings of Riverside didn't receive many visitors as it was a mostly isolated community however they were welcoming to Evendur. After meeting a few of the local folk Evendur discovered them to be a very hospitable people willing to welcome visitors for short stays amongst their people. Evendur planned to stay for a short time a share with them the knowledge he had gained about life, death, and meaning, but it became clear quickly that the people were not focused on his teachings. Instead the halflings were consumed in fear and gossip of an endemic insomnia that was plaguing various members of the community.\n\nEvendur was brought to the town hall where the patients of the insomnia had gathered and ducked his head down as he entered the small gathering hall. Inside were a half dozen halflings looking very unkempt and after talking with a few Evendur realized many of them haven't slept for up to a tenday. Later in the evening a young halfling woman wearing a large straw hat and with a large horn-like musical instrument strapped to her side entered the room introducing herself as Pearl. She had great concern for her fellow residents of Riverside and the two of them listened to the stories of one of the locals, a baker named Lyle Littlefoot, as he described his experience in heartbreaking detail. Evendur put his hand on Pearl's shoulder to comfort her as tears started to well up in her when suddenly Evendur's prayer wheel started to spin and glow and a radiant yellow light was emitted from his hand. Pearl immediately pulled out her instrument and started playing a beautiful lullaby which hung in the air as waves of color slowly rippled across the room bouncing off the walls. Miraculously all the halflings experiencing the insomnia were able to sleep however the effects quickly wore off soon after Pearl had stopped playing.\n\nAcross the room an elderly halfling who had been assisting with the care of the sick, had witnessed the song. She beckoned over Evendur and Pearl and slowly spoke words which neither of them would ever forget. \n\n \"Do you realize what you two just did? I have seen this before long ago but most only hear of it in tales as old as time. You are both one with the weave\u2026 suffused with the energy that lies untapped in every rock, river, and living being. Gifted with something few mortals possess\u2026 I'm speaking of magic my dears. The energy of creation and the ability to shape the very fabric of our world. You are both destined for great things.\"\n \nThe woman's name was Nora Strongbones, one of the most elderly and wise in Riverside. Evendur and pearl talked with Nora about what they should do now and she told them that whatever was plaguing Riverside may be greater than their current abilities. She urged them to go out in the world and find a way to help. Evendur then mentioned a magical apple from his hometown of Oakhurst but said that the only known source was a group of goblins that comes to the edge of town and sells one per year shortly after the midsummer festival and that the townspeople fought over access its healing properties. After further discussion the three decided maybe they should try to find the source of this magical fruit.\n\nEarly the next morning Evendur and Pearl then set out on the 20 mile trek west to Oakhurst. They arrived late in the afternoon tired and weary from a full day's travel and Evendur led the way toward the local tavern, the Ol' Boar Inn. They sat down at one of the various tables in the cozy establishment and were thankful for some much needed rest and some of proprietor Garon's famous hearty soup made in huge batches with meat from the weekly hunt.", "Given this API response\n{\n \"id\": \"4f07d5a7-4311-4d4d-9d12-342f6bc1d7e1\",\n \"shop\": {\n \"id\": \"4c2f2588-8cfa-479a-8bcf-0c7ee75ee36f\",\n \"myshopify\\_domain\": \"gastronomical-global.myshopify.com\",\n \"country\": \"US\",\n \"domain\": \"ghettogastro.com\"\n },\n \"variants\": [\n {\n \"id\": \"22cc1ccc-6418-4f3c-a9d9-c06e2ce22a4a\",\n \"shop\": {\n \"id\": \"4c2f2588-8cfa-479a-8bcf-0c7ee75ee36f\",\n \"myshopify\\_domain\": \"gastronomical-global.myshopify.com\",\n \"country\": \"US\",\n \"domain\": \"ghettogastro.com\"\n },\n \"inventory\\_policy\": \"deny\",\n \"inventory\\_quantity\": 278,\n \"inventory\\_item\\_cost\": null,\n \"option1\": \"Default Title\",\n \"option2\": null,\n \"option3\": null,\n \"position\": 1,\n \"price\": 20.0,\n \"title\": \"Default Title\",\n \"sku\": \"GSTWVYAR1\",\n \"grams\": 0.0,\n \"weight\": 0.0\n }\n ],\n \"body\\_html\": \"Don\u2019t cheat yourself, treat yourself with WAVY, a nourishing waffle and pancake mix that's sweet and decadent. Inspired by our ancestors breaking bread we connect the flavors of Africa, Asia, and The Americas through our ingredient stack. Made with organic roots and grains.\n\n\\nNon-GMO. Plant Based. Gluten Free. No sugar cane.\n\n\\n\n\n\\n\\n|\\n Ingredients |\\n Nutrition Facts |\\n\n\\n|\\n Rice Flour\\*, Cassava Flour\\*, Coconut Sugar\\*, Tigernut Flour\\*, Cocoa Butter Powder, Potato Starch\\*, Sorghum Flour\\*, Amaranth Powder\\*, Kosher Salt, Active Yeast\\*, Baking Powder, Sunflower Lecithin\\*. (\\*Organic) \u00a0 |\\n \\n\n\n\\n\\n|\\n \\n12 servings per containerServing size: 3 Tablespoons (35g)\\n |\\n\n\\n|\\n  |\\n  |\\n\n\\n|\\n \\nAmount\u00a0per Serving |\\n % Daily Value\\*\\n |\\n\n\\n|\\n  |\\n  |\\n\n\\n|\\n Calories\u00a0150\\n |\\n  |\\n\n\\n|\\n \\nTotal Fat 4.5g\\n |\\n 6% |\\n\n\\n|\\n \\n\u00a0 \u00a0 \u00a0Saturated Fat 2g\\n |\\n 10% |\\n\n\\n|\\n \\n\u00a0 \u00a0 \u00a0Trans Fat 0g\\n |\\n  |\\n\n\\n|\\n Cholesterol 0mg\\n |\\n 0% |\\n\n\\n|\\n Sodium 150mg\\n |\\n 7% |\\n\n\\n|\\n Total Carbohydrate 23g\\n |\\n 8%\\n |\\n\n\\n|\\n \u00a0 \u00a0 \u00a0Dietary Fiber 1g |\\n 4% |\\n\n\\n|\\n \\n\u00a0 \u00a0 \u00a0Total Sugars 5g |\\n  |\\n\n\\n|\\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Includes 0g Added Sugars |\\n 0% |\\n\n\\n|\\n Protein 1g\\n |\\n  |\\n\n\\n|\\n Vitamin D 0mcg |\\n 0% |\\n\n\\n|\\n Calcium 20mg |\\n 2% |\\n\n\\n|\\n Iron 1mg |\\n 6% |\\n\n\\n|\\n Potassium 73mg |\\n 2% |\\n\n\\n\\n\n\\n |\\n\n\\n\\n\n\",\n \"handle\": \"ancestral-roots-waffle-pancake-mix\",\n \"image\\_src\": \"https://cdn.shopify.com/s/files/1/0559/6689/2203/products/01\\_Ancestral\\_2.png?v=1652481515\",\n \"images\": [\n {\n \"id\": 32177532338347,\n \"alt\": null,\n \"src\": \"https://cdn.shopify.com/s/files/1/0559/6689/2203/products/01\\_Ancestral\\_2.png?v=1652481515\",\n \"width\": 1771,\n \"height\": 2300,\n \"position\": 1,\n \"created\\_at\": \"2022-05-13T18:38:29-04:00\",\n \"product\\_id\": 6609476714667,\n \"updated\\_at\": \"2022-05-13T18:38:35-04:00\",\n \"variant\\_ids\": [],\n \"admin\\_graphql\\_api\\_id\": \"gid://shopify/ProductImage/32177532338347\"\n },\n {\n \"id\": 32177532305579,\n \"alt\": null,\n \"src\": \"https://cdn.shopify.com/s/files/1/0559/6689/2203/products/01\\_Ancestral\\_1.png?v=1652481515\",\n \"width\": 1277,\n \"height\": 1583,\n \"position\": 2,\n \"created\\_at\": \"2022-05-13T18:38:28-04:00\",\n \"product\\_id\": 6609476714667,\n \"updated\\_at\": \"2022-05-13T18:38:35-04:00\",\n \"variant\\_ids\": [],\n \"admin\\_graphql\\_api\\_id\": \"gid://shopify/ProductImage/32177532305579\"\n },\n {\n \"id\": 28933332697259,\n \"alt\": null,\n \"src\": \"https://cdn.shopify.com/s/files/1/0559/6689/2203/products/gastronomical\\_wavy\\_waffle\\_and\\_pancake\\_mix\\_product\\_shot\\_3\\_ancestral\\_roots.png?v=1652481515\",\n \"width\": 1662,\n \"height\": 2164,\n \"position\": 3,\n \"created\\_at\": \"2021-06-08T12:59:50-04:00\",\n \"product\\_id\": 6609476714667,\n \"updated\\_at\": \"2022-05-13T18:38:35-04:00\",\n \"variant\\_ids\": [],\n \"admin\\_graphql\\_api\\_id\": \"gid://shopify/ProductImage/28933332697259\"\n },\n {\n \"id\": 28933332795563,\n \"alt\": null,\n \"src\": \"https://cdn.shopify.com/s/files/1/0559/6689/2203/products/gastronomical\\_wavy\\_waffle\\_and\\_pancake\\_mix\\_product\\_shot\\_4\\_ancestral\\_roots.png?v=1652481515\",\n \"width\": 1666,\n \"height\": 2164,\n \"position\": 4,\n \"created\\_at\": \"2021-06-08T12:59:51-04:00\",\n \"product\\_id\": 6609476714667,\n \"updated\\_at\": \"2022-05-13T18:38:35-04:00\",\n \"variant\\_ids\": [],\n \"admin\\_graphql\\_api\\_id\": \"gid://shopify/ProductImage/28933332795563\"\n },\n {\n \"id\": 28933332828331,\n \"alt\": null,\n \"src\": \"https://cdn.shopify.com/s/files/1/0559/6689/2203/products/gastronomical\\_wavy\\_waffle\\_and\\_pancake\\_mix\\_product\\_shot\\_5\\_ancestral\\_roots.png?v=1652481515\",\n \"width\": 1664,\n \"height\": 2164,\n \"position\": 5,\n \"created\\_at\": \"2021-06-08T12:59:51-04:00\",\n \"product\\_id\": 6609476714667,\n \"updated\\_at\": \"2022-05-13T18:38:35-04:00\",\n \"variant\\_ids\": [],\n \"admin\\_graphql\\_api\\_id\": \"gid://shopify/ProductImage/28933332828331\"\n },\n {\n \"id\": 28933332762795,\n \"alt\": null,\n \"src\": \"https://cdn.shopify.com/s/files/1/0559/6689/2203/products/gastronomical\\_wavy\\_waffle\\_and\\_pancake\\_mix\\_product\\_shot\\_6\\_ancestral\\_roots.png?v=1652481515\",\n \"width\": 1662,\n \"height\": 2164,\n \"position\": 6,\n \"created\\_at\": \"2021-06-08T12:59:50-04:00\",\n \"product\\_id\": 6609476714667,\n \"updated\\_at\": \"2022-05-13T18:38:35-04:00\",\n \"variant\\_ids\": [],\n \"admin\\_graphql\\_api\\_id\": \"gid://shopify/ProductImage/28933332762795\"\n }\n ],\n \"options\": [\n {\n \"id\": 8499721339051,\n \"name\": \"Title\",\n \"values\": [\n \"Default Title\"\n ],\n \"position\": 1,\n \"product\\_id\": 6609476714667\n }\n ],\n \"product\\_type\": \"Waffle & Pancake Mix\",\n \"published\\_at\": \"2021-04-04T22:06:37Z\",\n \"status\": \"active\",\n \"title\": \"Ancestral Roots\",\n \"vendor\": \"Ghetto Gastro\",\n \"origin\\_supplier\\_shop\\_domain\": null\n}", "You provided random informations, I want you to use infomrations from here\n\n{\n \"id\": \"4f07d5a7-4311-4d4d-9d12-342f6bc1d7e1\",\n \"shop\": {\n \"id\": \"4c2f2588-8cfa-479a-8bcf-0c7ee75ee36f\",\n \"myshopify\\_domain\": \"gastronomical-global.myshopify.com\",\n \"country\": \"US\",\n \"domain\": \"ghettogastro.com\"\n },\n \"variants\": [\n {\n \"id\": \"22cc1ccc-6418-4f3c-a9d9-c06e2ce22a4a\",\n \"shop\": {\n \"id\": \"4c2f2588-8cfa-479a-8bcf-0c7ee75ee36f\",\n \"myshopify\\_domain\": \"gastronomical-global.myshopify.com\",\n \"country\": \"US\",\n \"domain\": \"ghettogastro.com\"\n },\n \"inventory\\_policy\": \"deny\",\n \"inventory\\_quantity\": 278,\n \"inventory\\_item\\_cost\": null,\n \"option1\": \"Default Title\",\n \"option2\": null,\n \"option3\": null,\n \"position\": 1,\n \"price\": 20.0,\n \"title\": \"Default Title\",\n \"sku\": \"GSTWVYAR1\",\n \"grams\": 0.0,\n \"weight\": 0.0\n }\n ],\n \"body\\_html\": \"Don\u2019t cheat yourself, treat yourself with WAVY, a nourishing waffle and pancake mix that's sweet and decadent. Inspired by our ancestors breaking bread we connect the flavors of Africa, Asia, and The Americas through our ingredient stack. Made with organic roots and grains.\n\n\\nNon-GMO. Plant Based. Gluten Free. No sugar cane.\n\n\\n\n\n\\n\\n|\\n Ingredients |\\n Nutrition Facts |\\n\n\\n|\\n Rice Flour\\*, Cassava Flour\\*, Coconut Sugar\\*, Tigernut Flour\\*, Cocoa Butter Powder, Potato Starch\\*, Sorghum Flour\\*, Amaranth Powder\\*, Kosher Salt, Active Yeast\\*, Baking Powder, Sunflower Lecithin\\*. (\\*Organic) \u00a0 |\\n \\n\n\n\\n\\n|\\n \\n12 servings per containerServing size: 3 Tablespoons (35g)\\n |\\n\n\\n|\\n  |\\n  |\\n\n\\n|\\n \\nAmount\u00a0per Serving |\\n % Daily Value\\*\\n |\\n\n\\n|\\n  |\\n  |\\n\n\\n|\\n Calories\u00a0150\\n |\\n  |\\n\n\\n|\\n \\nTotal Fat 4.5g\\n |\\n 6% |\\n\n\\n|\\n \\n\u00a0 \u00a0 \u00a0Saturated Fat 2g\\n |\\n 10% |\\n\n\\n|\\n \\n\u00a0 \u00a0 \u00a0Trans Fat 0g\\n |\\n  |\\n\n\\n|\\n Cholesterol 0mg\\n |\\n 0% |\\n\n\\n|\\n Sodium 150mg\\n |\\n 7% |\\n\n\\n|\\n Total Carbohydrate 23g\\n |\\n 8%\\n |\\n\n\\n|\\n \u00a0 \u00a0 \u00a0Dietary Fiber 1g |\\n 4% |\\n\n\\n|\\n \\n\u00a0 \u00a0 \u00a0Total Sugars 5g |\\n  |\\n\n\\n|\\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Includes 0g Added Sugars |\\n 0% |\\n\n\\n|\\n Protein 1g\\n |\\n  |\\n\n\\n|\\n Vitamin D 0mcg |\\n 0% |\\n\n\\n|\\n Calcium 20mg |\\n 2% |\\n\n\\n|\\n Iron 1mg |\\n 6% |\\n\n\\n|\\n Potassium 73mg |\\n 2% |\\n\n\\n\\n\n\\n |\\n\n\\n\\n\n\",\n \"handle\": \"ancestral-roots-waffle-pancake-mix\",\n \"image\\_src\": \"https://cdn.shopify.com/s/files/1/0559/6689/2203/products/01\\_Ancestral\\_2.png?v=1652481515\",\n \"images\": [\n {\n \"id\": 32177532338347,\n \"alt\": null,\n \"src\": \"https://cdn.shopify.com/s/files/1/0559/6689/2203/products/01\\_Ancestral\\_2.png?v=1652481515\",\n \"width\": 1771,\n \"height\": 2300,\n \"position\": 1,\n \"created\\_at\": \"2022-05-13T18:38:29-04:00\",\n \"product\\_id\": 6609476714667,\n \"updated\\_at\": \"2022-05-13T18:38:35-04:00\",\n \"variant\\_ids\": [],\n \"admin\\_graphql\\_api\\_id\": \"gid://shopify/ProductImage/32177532338347\"\n },\n {\n \"id\": 32177532305579,\n \"alt\": null,\n \"src\": \"https://cdn.shopify.com/s/files/1/0559/6689/2203/products/01\\_Ancestral\\_1.png?v=1652481515\",\n \"width\": 1277,\n \"height\": 1583,\n \"position\": 2,\n \"created\\_at\": \"2022-05-13T18:38:28-04:00\",\n \"product\\_id\": 6609476714667,\n \"updated\\_at\": \"2022-05-13T18:38:35-04:00\",\n \"variant\\_ids\": [],\n \"admin\\_graphql\\_api\\_id\": \"gid://shopify/ProductImage/32177532305579\"\n },\n {\n \"id\": 28933332697259,\n \"alt\": null,\n \"src\": \"https://cdn.shopify.com/s/files/1/0559/6689/2203/products/gastronomical\\_wavy\\_waffle\\_and\\_pancake\\_mix\\_product\\_shot\\_3\\_ancestral\\_roots.png?v=1652481515\",\n \"width\": 1662,\n \"height\": 2164,\n \"position\": 3,\n \"created\\_at\": \"2021-06-08T12:59:50-04:00\",\n \"product\\_id\": 6609476714667,\n \"updated\\_at\": \"2022-05-13T18:38:35-04:00\",\n \"variant\\_ids\": [],\n \"admin\\_graphql\\_api\\_id\": \"gid://shopify/ProductImage/28933332697259\"\n },\n {\n \"id\": 28933332795563,\n \"alt\": null,\n \"src\": \"https://cdn.shopify.com/s/files/1/0559/6689/2203/products/gastronomical\\_wavy\\_waffle\\_and\\_pancake\\_mix\\_product\\_shot\\_4\\_ancestral\\_roots.png?v=1652481515\",\n \"width\": 1666,\n \"height\": 2164,\n \"position\": 4,\n \"created\\_at\": \"2021-06-08T12:59:51-04:00\",\n \"product\\_id\": 6609476714667,\n \"updated\\_at\": \"2022-05-13T18:38:35-04:00\",\n \"variant\\_ids\": [],\n \"admin\\_graphql\\_api\\_id\": \"gid://shopify/ProductImage/28933332795563\"\n },\n {\n \"id\": 28933332828331,\n \"alt\": null,\n \"src\": \"https://cdn.shopify.com/s/files/1/0559/6689/2203/products/gastronomical\\_wavy\\_waffle\\_and\\_pancake\\_mix\\_product\\_shot\\_5\\_ancestral\\_roots.png?v=1652481515\",\n \"width\": 1664,\n \"height\": 2164,\n \"position\": 5,\n \"created\\_at\": \"2021-06-08T12:59:51-04:00\",\n \"product\\_id\": 6609476714667,\n \"updated\\_at\": \"2022-05-13T18:38:35-04:00\",\n \"variant\\_ids\": [],\n \"admin\\_graphql\\_api\\_id\": \"gid://shopify/ProductImage/28933332828331\"\n },\n {\n \"id\": 28933332762795,\n \"alt\": null,\n \"src\": \"https://cdn.shopify.com/s/files/1/0559/6689/2203/products/gastronomical\\_wavy\\_waffle\\_and\\_pancake\\_mix\\_product\\_shot\\_6\\_ancestral\\_roots.png?v=1652481515\",\n \"width\": 1662,\n \"height\": 2164,\n \"position\": 6,\n \"created\\_at\": \"2021-06-08T12:59:50-04:00\",\n \"product\\_id\": 6609476714667,\n \"updated\\_at\": \"2022-05-13T18:38:35-04:00\",\n \"variant\\_ids\": [],\n \"admin\\_graphql\\_api\\_id\": \"gid://shopify/ProductImage/28933332762795\"\n }\n ],\n \"options\": [\n {\n \"id\": 8499721339051,\n \"name\": \"Title\",\n \"values\": [\n \"Default Title\"\n ],\n \"position\": 1,\n \"product\\_id\": 6609476714667\n }\n ],\n \"product\\_type\": \"Waffle & Pancake Mix\",\n \"published\\_at\": \"2021-04-04T22:06:37Z\",\n \"status\": \"active\",\n \"title\": \"Ancestral Roots\",\n \"vendor\": \"Ghetto Gastro\",\n \"origin\\_supplier\\_shop\\_domain\": null\n}", "create linked database for your linkedin connections and start 1st entry into table for following text of profile : Ehab Al Khiary 1st degree connection1st\nCEO | Founder | Investor | Board Member\n\nERC International Investment\n\nINSEAD\nSaudi Arabia Contact info\n500+ connections\nRami Al Karmi, Vish Narain, and 1 other mutual connectionRami Al Karmi, Vish Narain, and 1 other mutual connection\n\nMessage\n\nMore\nAboutAbout\nMr. Al Khiary is highly experienced executive in the field of the Information Technologies and Telecommunications. He is known for his involvements and contributions in the ICT field for over 20 years, both as a government employee, executive, entrepreneur, investor, and board member of several companies. Mr. Al Khiary is highly experienced executive in the field of the Information Technologies and Telecommunications. He is known for his involvements and contributions in the ICT field for over 20 years, both as a government employee, executive, entrepreneur, investor, and board member of several companies. \nActivityActivity\n20,322 followers20,322 followers\n\nEhab hasn't posted latelyEhab hasn't posted lately\nEhab\u2019s recent posts and comments will be displayed here.Ehab\u2019s recent posts and comments will be displayed here.\nShow all activity\nExperienceExperience\nCo-FounderCo-Founder\nERC International Investment ERC International Investment \nJul 2017 - Present \u00b7 5 yrs 9 mosJul 2017 - Present \u00b7 5 yrs 9 mos\nCayman IslandsCayman Islands\nERC is an early stage investment company with tech focused in the MENA region.\nThe objective is to leverage close to 100 years of the founders\u2019 experience and relationship to expedite the growth of these startups. Today, our portfolio ranges from digital gifting, logistics, insurtech, and FintechERC is an early stage investment company with tech focused in the MENA region. The objective is to leverage close to 100 years of the founders\u2019 experience and relationship to expedite the growth of these startups. Today, our portfolio ranges from digital gifting, logistics, insurtech, and Fintech\u2026see more\nYOUGotaGift logo\nChief Growth OfficerChief Growth Officer\nYouGotaGiftYouGotaGift\nJan 2020 - Present \u00b7 3 yrs 3 mosJan 2020 - Present \u00b7 3 yrs 3 mos\nSaudi ArabiaSaudi Arabia\nYouGotaGift is an end to end digital platform for processing and distributing digital Gift Cards from top retailers in the Middle East. As a Fintech & Payment provider, YouGotaGift delivers prepaid digital cards to consumers (B2C) and businesses (B2B) including employee rewards, customers rewards, channel incentives and loyalty.YouGotaGift is an end to end digital platform for processing and distributing digital Gift Cards from top retailers in the Middle East. As a Fintech & Payment provider, YouGotaGift delivers prepaid digital cards to consumers (B2C) and businesses (B2B) including employee rewards, customers rewards, channel incentives and loyalty.\u2026see more\nArabian Information Technology Co. (ARCOM) logo\nCEO & Board MemberCEO & Board Member\nArabian Information Technology Co. (ARCOM) \u00b7 Full-timeArabian Information Technology Co. (ARCOM) \u00b7 Full-time\nJun 2015 - Present \u00b7 7 yrs 10 mosJun 2015 - Present \u00b7 7 yrs 10 mos\nSaudi ArabiaSaudi Arabia\nARCOM is an innovative progressive system integrator with 30 years of successful track record providing IT and telecom services and solutions to governmental and private sectors in the Kingdom of Saudi Arabia and Gulf.ARCOM is an innovative progressive system integrator with 30 years of successful track record providing IT and telecom services and solutions to governmental and private sectors in the Kingdom of Saudi Arabia and Gulf.\nARCOMARCOM\nARCOM is an innovative and progressive system integrator with over 30 years of successful track record providing IT\\telecom services and solutions to public and private sectors in the Kingdom of Saudi Arabia.ARCOM is an innovative and progressive system integrator with over 30 years of successful track record providing IT\\telecom services and solutions to public and private sectors in the Kingdom of Saudi Arabia.\nPlatinum Events UAE logo\nCo-FounderCo-Founder\nPlatinum Events UAEPlatinum Events UAE\nSep 2009 - Present \u00b7 13 yrs 7 mosSep 2009 - Present \u00b7 13 yrs 7 mos\nPlatinum has established it self as a leading Event Management, wedding planner, and Concierge Service Provider. Our continued success allowed us to expand into newer and equally exciting division such as Platinum Magazine, Platinum Property, and Platinum Collection.\n\nPlatinum has acquired a reputation for organizing some of the most innovative, spectacular and high profile corporate and private events. Platinum has established it self as a leading Event Management, wedding planner, and Concierge Service Provider. Our continued success allowed us to expand into newer and equally exciting division such as Platinum Magazine, Platinum Property, and Platinum Collection. Platinum has acquired a reputation for organizing some of the most innovative, spectacular and high profile corporate and private events. \u2026see more\nPlatinum - Coming SoonPlatinum - Coming Soon\nSocialHub logo\nCo-Founder & Board MemberCo-Founder & Board Member\nSocial HubSocial Hub\nFeb 2013 - Feb 2017 \u00b7 4 yrs 1 moFeb 2013 - Feb 2017 \u00b7 4 yrs 1 mo\nSaudi ArabiaSaudi Arabia\nSocial Hub is one stop shop for Social Media Services that links organizations to their audience.\n\nSocial Hub offers world-class services with local expertise and flavor. These services ranges from setting strategy, engagement campaign, content generation & socialization, monitoring, and consultation.Social Hub is one stop shop for Social Media Services that links organizations to their audience. Social Hub offers world-class services with local expertise and flavor. These services ranges from setting strategy, engagement campaign, content generation & socialization, monitoring, and consultation.\u2026see more\nShow all 11 experiences\nEducationEducation\nINSEAD logo\nINSEADINSEAD\nDigital Transformation Leadership ProgramDigital Transformation Leadership Program\n2020 - 20202020 - 2020\nMIT Sloan School of Management logo\nMIT Sloan School of ManagementMIT Sloan School of Management\nEntrepreneurial Masters ProgramEntrepreneurial Masters Program\n2013 - 20152013 - 2015\nHarvard Business School Executive Education logo\nHarvard Business School Executive EducationHarvard Business School Executive Education\nYPO President CourseYPO President Course\n2011 - 20112011 - 2011\nShow all 5 education\nLicenses & certificationsLicenses & certifications\n500 Global logo\nVC UnlockedVC Unlocked\n500 Global500 Global\nIssued Nov 2022Issued Nov 2022\nShow credential\nStanford Center for Professional Development logo\nInnovation Strategy Innovation Strategy \nStanford Center for Professional DevelopmentStanford Center for Professional Development\nIssued Jan 2021Issued Jan 2021\nStanford Center for Professional Development logo\nProduct Management Transforming Opportunities into Great Products Product Management Transforming Opportunities into Great Products \nStanford Center for Professional DevelopmentStanford Center for Professional Development\nIssued Jan 2021Issued Jan 2021\nShow all 5 licenses & certifications\nSkillsSkills\nPMPPMP\n\nEndorsed by Abdullah Aljebrein who is highly skilled at thisEndorsed by Abdullah Aljebrein who is highly skilled at this\n\nEndorsed by 3 colleagues at Arabian Information Technology Co. (ARCOM)Endorsed by 3 colleagues at Arabian Information Technology Co. (ARCOM)\n99+ endorsements99+ endorsements\n\nEndorse\nTelecommunicationsTelecommunications\n\nEndorsed by Mohammed Al Ansari and 25 others who are highly skilled at thisEndorsed by Mohammed Al Ansari and 25 others who are highly skilled at this\n\nEndorsed by 6 colleagues at Arabian Information Technology Co. (ARCOM)Endorsed by 6 colleagues at Arabian Information Technology Co. (ARCOM)\n99+ endorsements99+ endorsements\n\nEndorse\nInformation SecurityInformation Security\n\nEndorsed by Ahmad AlOmran who is highly skilled at thisEndorsed by Ahmad AlOmran who is highly skilled at this\n\nEndorsed by 3 colleagues at stcEndorsed by 3 colleagues at stc\n36 endorsements36 endorsements\n\nEndorse\nShow all 28 skills\nOrganizationsOrganizations\nSocial Media Club Saudi Arabia ChapterSocial Media Club Saudi Arabia Chapter\nFounding Memeber \u00b7 Jan 2013 - PresentFounding Memeber \u00b7 Jan 2013 - Present\nSocial Media Club is non-profit and the world's largest community of Social Media Professionals with primary mission is to expand digital media literacy, promote standard technologies, encourage ethical behavior and share best practices.\nSocial Media Club is non-profit and the world's largest community of Social Media Professionals with primary mission is to expand digital media literacy, promote standard technologies, encourage ethical behavior and share best practices. \nMobile MondayMobile Monday\nFounding Memeber - Riyadh Chapter \u00b7 Sep 2012 - PresentFounding Memeber - Riyadh Chapter \u00b7 Sep 2012 - Present\nMobileMonday\u2122 (MoMo) is an open community platform of mobile industry visionaries, developers and influential individuals fostering brand neutral cooperation and cross-border P2P business opportunities through live networking events to demo products, share ideas and discuss trends from both local and global markets.MobileMonday\u2122 (MoMo) is an open community platform of mobile industry visionaries, developers and influential individuals fostering brand neutral cooperation and cross-border P2P business opportunities through live networking events to demo products, share ideas and discuss trends from both local and global markets.\u2026see more\nInterestsInterests\nTop VoicesTop Voices\nCompaniesCompanies\nGroupsGroups\nNewslettersNewsletters\nSchoolsSchools\nAdena Friedman profile picture\nAdena FriedmanAdena Friedman\n\u00b7 3rdThird degree connection\nChair and Chief Executive Officer at NasdaqChair and Chief Executive Officer at Nasdaq\n602,019 followers602,019 followers\n\nFollow\nCharles Best profile picture\nCharles BestCharles Best\n\u00b7 3rdThird degree connection\nCo-CEO of Lakeshore Learning and Founder of DonorsChooseCo-CEO of Lakeshore Learning and Founder of DonorsChoose\n281,028 followers281,028 followers\n\nFollow\nShow all 83 Top Voices", "Characters now: Princess Jaedala\nDaughter of the recently deceased Empress Lakshmi, Princess Jaedala is the heir to the throne of the Luxian Empire and is due to have her coronation soon. She is deeply insecure about her leadership abilities, especially in her mother\u2019s shadow. However, she does a very good job of not showing that side of herself in public. As far the Empire knows, she\u2019s a very confident woman who knows exactly what she\u2019s doing and is a capable leader. In reality, she usually does what seems to be the right thing in any given moment and deals with consequences as they come. She both loves and respects her mother, who trained her from infancy to be the next empress, and hopes she can make her mother proud.\n\nJaedala stands about 6.5 feet tall and has lavender skin and dark red eyes. Her hair is a deep, rich shade of purple and falls almost to her knees. She is fit, and usually spends a while having her hair and makeup done. She is very beautiful by Luxian standards.\n\nIn public, she typically dresses in Luxian formalwear or a more professional version of the sari-like robe, depending on the occasion. In private, she wears slightly more comfortable sari-like robes, though still very fancy.\nParvati\nParvati is an on-again, off-again Luxite friend of Princess Jaedala who is employed in the palace as an alien slave trainer. Aliens who will be serving royalty directly need extra training - royal etiquette, how to address their masters, safety, etc. - which Parvati is tasked with providing. She is a very kind, compassionate woman who knows when she needs to be firm, but usually prefers to \u201ckill them with kindness\u201d. She is not in favor of the Luxian practice of enslaving aliens, but she sees her job as an alien trainer as a way to ensure that her charges are treated fairly and lead a comfortable life. Her methods are very effective - not only has she trained virtually every enslaved alien in the Luxian palace, but they all know her by name and continue to show her respect and friendship. Princess Jaedala doesn\u2019t really approve of Parvati\u2019s \u201csoft\u201d approach, but she can\u2019t deny the results.\n\nWhen Jaedala hired Parvati, she presented Parvati with several welcoming gifts. Among them was a newly purchased alien slave named Shiro. Parvati was uncomfortable with this as she had purposely never bought a slave herself, but decided to keep Shiro because she didn\u2019t want him to end up with a master who would mistreat him. She\u2019s also grateful for his help cooking for her and keeping her suite clean. She also uses her legal status as his owner to protect Shiro from other Luxians taking advantage of him.\n\nParvati stands about six feet tall and has lavender-gray skin and light purple-pink eyes. Her hair is a shiny, very dark purple and hangs down to just below her waist. She is a little bigger than Jaedala, falling just short of the Luxian version of \u201cplus sized\u201d. She wears very little makeup and rarely has a hairstyle more elaborate than a simple ponytail or braids, as she wants to be seen as approachable by the aliens she trains.\n\nParvati typically wears a simpler version of the Luxian sari-like robe, usually with pants instead of a skirt, and often discards the scarf when training aliens to look less formal. She will dress more professionally when required, but changes as soon as possible afterward.\nShiro\nShiro is an enslaved alien from a bipedal bird-like species called the Psyno, a semi-technologically-advanced race that was enslaved by the Luxians hundreds of years ago. He grew up in a \u201cnursery\u201d, a facility where alien infants and children are raised and trained by Luxian caretakers apart from their own parents. When he reached \u201cworking age\u201d in his mid teens, he was purchased by Jaedala as a welcome gift for Parvati, who had just been hired. He has served \u201cMistress Parvati\u201d ever since.\n\nShiro is a very quiet alien, largely doing his chores and minding his own business. He\u2019s an excellent listener and frequently provides an understanding ear for Parvati, who he deeply respects. He will share his opinion, but only when directly asked - and usually only with Parvati. He is not an actively rebellious slave and rarely causes trouble, but he will speak up on behalf of aliens he sees being mistreated.\n\nAs a Psyno, Shiro stands about 5.5 feet tall and has an avian appearance. His body is covered in brown-speckled white feathers that he keeps well-preened. Two small, flightless wings are folded on his back at all times. He typically wears a simple version of Luxian men\u2019s clothing.\nPrince Wukong\nSon of the deceased Simian king and the sole remaining member of the \u201csacred bloodline\u201d, Prince Wukong is the heir to the throne of Simia. He is a free spirit, not at all adhering to the expected behavior of Simian royalty. He regularly skips scheduled lessons and religious services to spend time outdoors on his own or with his best friend, Sanzang, a Simian peasant. He looks forward to the freedom of being king and enjoys his existing privileges as a prince, but resents the Simian priesthood for constantly telling him what to do. He loves to mess with them, knowing he can get away with it because of his privileged position. He doesn\u2019t care much about ranks and social standings, preferring to just have fun with anyone who\u2019s willing. He enjoys being with his \u201clower status\u201d friends simply because they let him feel normal and have fun without the constraints of royal etiquette.\n\nWukong stands about 4.5 feet tall and has a coat of soft light brown fur. He has golden eyes and a mischievous smile. He is relatively physically fit from being trained to fight from a young age, as well as having physically demanding hobbies such as climbing trees or play-fighting. He has a long tail that he frequently uses as an extra hand and that reflexively helps express his emotions.\n\nWukong wears a short-sleeved yellow silk shirt and red trousers, with a long red, green, and golden sash that winds around his chest and waist, with ends that hand loose over his back. He usually wears golden or brown sandals, but prefers to go barefoot when having fun outdoors. He very rarely wears his crown - a tiny golden cap that resembles the Monkey King\u2019s phoenix-feather cap, pinned into his fur - unless he\u2019s participating in a ceremony. He wears several chunky copper bracelets for good luck and to display his status, but usually takes those off when he can as they get in the way of tree climbing. He always carries an elaborately decorated bo staff with golden accents.\nSanzang\nSanzang is Wukong\u2019s best friend and a Simian peasant. He is a kind, gentle soul who tries his best to keep Wukong out of trouble, even though he often ends up going along with the prince\u2019s mischievous plans. He is very intelligent, but doesn\u2019t have the same opportunities as the prince because of his social status. He is a bit of a pushover and doesn\u2019t like confrontation, but he will stand up for what he believes in if he feels it\u2019s important enough.\n\nSanzang stands about 4.5 feet tall and has a coat of soft, dark brown fur. He has deep brown eyes and a warm smile. He is relatively physically fit from helping out with the family farm, but is not as strong or fast as Wukong or other fighters. He has a long tail that he frequently uses as an extra hand and that reflexively helps express his emotions.\n\nSanzang wears a short-sleeved white linen shirt and brown trousers, with a long brown sash that winds around his waist. He usually wears brown sandals, but prefers to go barefoot when he can. He very rarely wears any jewelry, as he doesn\u2019t have the money to afford it.\nAshira\nAshira is a low-ranking member of the Simian priesthood in her late teens, about the same age as Wukong. She is shy and quiet, but a hard worker. She tries to fulfill her temple duties as quickly and as perfectly as possible, both to please the gods whom she is fully devoted to, and to keep the priests from being angry with her. She is usually melancholy as the priests tend to treat her poorly. But she is devoted to the gods, and when she is able to worship, she is peaceful and happy.\n\nAshira\u2019s personality begins to shift as Wukong spends more time in the temple, taking lessons that will help him when he\u2019s king. She\u2019s both fascinated by and scared of him and his high status, and is stunned when he\u2019s as friendly and playful toward her as he is with anyone else. After she makes a mistake during a religious ritual, one of the priests is about to scold her until Wukong steps in and tells the priest to leave her alone. Ashira\u2019s respect for the prince grows, and she begins secretly meeting with him when the priests aren\u2019t around. Gradually she falls in love with him, and though she isn\u2019t quite sure, she thinks he feels the same way. She slowly begins to gain self-confidence and begins to wonder why she has to obey the priests all the time if they\u2019re not always right.\n\nAshira stands about 4 feet tall and has very soft light blond flaxen fur, which she grows longer on her head. She has a long tail that she rarely uses as an additional limb in the temple, but begins to form the habit as she does activities outside. She isn\u2019t very fit as she was born into a very sedentary role in life, but she isn\u2019t weak or frail. Her eyes are the same golden shade as Wukong\u2019s.\n\nAs a low-ranking priestess, Ashira wears a sleeveless white floor-length tunic with a long blue sash, both made of simple fabric. She wears simple brown sandals and typically does not go barefoot. She wears no jewelry or accessories other than a long necklace bearing the \u201cgoddess charm\u201d, a crystal carved into a flower sacred to Kwamya.", "Title: \"\ud83c\udfb9 Curious About the Roland RP107? The Affordable Digital Piano with Premium Features \ud83c\udfb9 - YouTube\"\nVideo Transcript: \"[Music] today we've got Roland's RP 107 this is Roland's entry-level digital 88 note piano with lots to offer when it comes to speaker detail love the action we're also going to listen to the supernatural piano sound very similar what they've got now on the gp3 let's get started with this right away [Music] oh [Music] the space that rp-107 is fighting for in the marketplace is a crowded one there are many many options in that sub 1500 US dollar range for an entry-level console piano you've got the KDP 75 and the KDP 120 from Kauai you've got the Yamaha Arias ydp 145 165 kind of flirting around that price range and now with Roland we've got the RP 107 which replaced the RP 102 and so where exactly does this fit in let's first start with the basics the rp-107 uses the new BMC chip and that is driving an updated Supernatural piano engine so this is going to be a very similar piano tone experience to what you might get out of say the fp30x or even the brand new Roland gp3 digital grand piano now we've got this line out plugged in out of the headphone jack because there's no discrete audio jacks out so I'm going to put the headphones on and do just a little bit of playing so you can get a sense of what the piano sound is on this rp107 foreign [Music] thank you [Music] so I find this generally with the supernatural engine not necessarily getting into the modeling because some of this changes but in the sample based Supernatural engine you have this really fat attack right across the range anytime you're in sort of the Forte and up range and that's one of the most characteristic elements I guess of the roll and sound I think this works incredibly well for a lot of contemporary playing I think this works super well as well for jazz because it gives you that that punch that energy behind the note sometimes that that type of attack starts to feel overbearing depending on the type of classical music that you might be playing but only once you get up into a really particularly high range because on the other hand sometimes the lack of aggressiveness you can get out of some of those other instruments I mentioned can be a little frustrating depending on again the type of music that you are wanting to play so Roland definitely giving you something different than any of the other brands in this price range in terms the piano sound foreign [Music] let's also now talk about the action because key action is really important especially for people who are just starting out and chances are if you're looking at this or any of the those other models I mentioned you probably are at the beginning of your journey this is as likely like your first console digital piano possibly the first one was 88 notes and weighted notes so action super important for you if if you fall into that category action and finding one that really connects with you is going to be a really big part of how connected you feel with the instrument but it also leads directly to good development of technique and muscle tone which is important because if you transition then from this up to an acoustic having a digital which is going to ease that transition the best as possible I think is a really big benefit and in this regard I think this is where the RP 107 holds its own and possibly leads the pack this has the PHA for Action in it and the pH j4 action is definitely a professional grade action this action is going into instruments such as the Phantom 08 it's going into instruments like the rd88 it's even in instruments such as their gp3 digital baby grand that was released not too long ago really widely used across the roll and range it has a triple sensor basically it's going to detect the motion of the key really quite well as it sends that information off to either a computer or the internal tone generator it also has escapement or let off which means that about two-thirds of the way down the key you can actually feel a little hiccup and I've you know I make mention of this a lot that little hiccup for me provides just a tiny bit of resistance um that you really only feel when you're playing kind of in the lower Dynamic ranges and that resistance adds just a touch more control in my opinion for me anyway for sure it adds that control and a little bit more realism when you're moving back and forth between this and an acoustic piano when it comes to the action I think the weighting of the key is also very similar to what you're going to find on a larger upright or a small well lubricated baby grand slightly on the heavier side so it's got a great sense of depth it's got a great sense of inertia behind it which I think is good for training your fingers and really lets you be expressive over a big wide dynamic range and then it's it's got nice accurate output thank you [Music] the specs on these speakers aren't very impressive I think they say that they're eight Watts aside which you know if we're just going off off the ink on this um means that this shouldn't sound much better than say a slab a basic you know portable instrument for you know a thousand dollars or something like that however the way that they have done the speaker boxes inside here and also that the way they've designed the key cover is actually linked to how you're hearing the sound because they leave this very intentional Gap right over top of the key cover where you're getting quite a bit of tone coming out the front a lot of detail and they've left distance between the top of the keyboard and the back of the speaker so you're getting some very directed treble that's coming through here so unlike most of the other instruments in this price range that have more powerful but exclusively down facing speakers with really no tone porting out the front this is taking advantage of a more efficient design where even though you are getting a little less bass and you really do notice it it's just it's um it's not that it feels like it's lacking projection but there's just that that lower warmth that you don't quite get like you get on say the kawhi's of this range um but there's way more detail that you're getting out of the speakers so the experience of playing this with headphones and the experience of playing it without headphones is actually a lot closer than what you get on some of the the other models that we've mentioned earlier in this review and you've heard the line out now we're going to actually listen to the speakers so you can get a sense of that so here is the rp107 through its speakers being picked up by two stereo microphones directly over top of my head [Music] foreign [Music] foreign [Music] this comes with the stand and the triple pedal and a bench included so in that regard it is a very similar offering to what the others the interface on this very simple it's not loaded up with a ton of sounds so to me this reminds me a lot of what you would get say out of uh like one of the Kawaii KDP 75s or even one of the original es series I think there's 15 tones on here so it's going to give you some e pianos a few strings the ability to you know layer to those sounds on top of one another some basic but still engaging fun stuff it's only available in this black you can't get it in any other color comes with the music stand as you can see it's also got these little Twigs here that help to keep some of the thinner music sheet music in place this has a Bluetooth midi and Bluetooth audio you can connect it to the rolling piano app as I think we've mentioned a little earlier and that gives you the ability to kind of remote control the various settings as well as access all of the lesson programming in here because there's over 300 songs preloaded most of those are in the form of play along repertoire from some of the most popular method books that are out there so to wrap up this look at the rp107 here's where I think it has a place first of all you need to like the role in piano tone just like if you're buying a Yamaha you've got like the Yamaha piano tone or the Kauai or the Casio or the Korg or whatever it is so that is I think the first thing that you need to fall in love with before any of this other stuff matters it's based off the Steinway D Concert Grand and I know that there are a lot of people who do like the sound and the tone that Roland brings when we get to the action I think the action is an incredibly pianistic properly weighted very nuanced action that you can get tons of mileage out of definitely the first many years of playing even even if you're taking this at a at a very serious level this has lots of runway in which to develop your musculature etc etc and then when it comes to the speaker performance even though this is not going to give you this big Woofy warm base the detail you get out of this console even though they're relatively small speakers facing down because of these front toe ports is really impressive I I was extremely happy to hear the kind of detail and closeness that I was feeling with this piano because that's not very usual normally if you want that kind of super precise detail you've got to put headphones on but I didn't feel the need with the rp-107 so all in all I think the piano experience on the rp107 is as good as the very best instruments in this category and it's bringing a slightly different tone that that some people may really enjoy more than some of the others [Music] foreign [Music] if you want to check out more piano videos we've got hundreds literally hundreds on the channel we love making each and every one of them and we'd invite you to stay around subscribe become part of our community of piano lovers and uh and watch a few more my name is Stu Harrison this has been Miriam pianos on YouTube and we'll see you again soon [Music]\"\nVideo Summary:\n\nPlease write in English language.", "[{\n \"resource\": \"/com.docker.devenvironments.code/jobApplications/js/quest.py.js\",\n \"owner\": \"typescript\",\n \"code\": \"1005\",\n \"severity\": 8,\n \"message\": \"';' expected.\",\n \"source\": \"ts\",\n \"startLineNumber\": 2,\n \"startColumn\": 10,\n \"endLineNumber\": 2,\n \"endColumn\": 16\n},{\n \"resource\": \"/com.docker.devenvironments.code/jobApplications/js/quest.py.js\",\n \"owner\": \"typescript\",\n \"code\": \"8002\",\n \"severity\": 8,\n \"message\": \"'import ... =' can only be used in TypeScript files.\",\n \"source\": \"ts\",\n \"startLineNumber\": 2,\n \"startColumn\": 10,\n \"endLineNumber\": 4,\n \"endColumn\": 2\n},{\n \"resource\": \"/com.docker.devenvironments.code/jobApplications/js/quest.py.js\",\n \"owner\": \"typescript\",\n \"code\": \"1127\",\n \"severity\": 8,\n \"message\": \"Invalid character.\",\n \"source\": \"ts\",\n \"startLineNumber\": 4,\n \"startColumn\": 1,\n \"endLineNumber\": 4,\n \"endColumn\": 2\n},{\n \"resource\": \"/com.docker.devenvironments.code/jobApplications/js/quest.py.js\",\n \"owner\": \"typescript\",\n \"code\": \"1005\",\n \"severity\": 8,\n \"message\": \"';' expected.\",\n \"source\": \"ts\",\n \"startLineNumber\": 4,\n \"startColumn\": 3,\n \"endLineNumber\": 4,\n \"endColumn\": 7\n},{\n \"resource\": \"/com.docker.devenvironments.code/jobApplications/js/quest.py.js\",\n \"owner\": \"typescript\",\n \"code\": \"1434\",\n \"severity\": 8,\n \"message\": \"Unexpected keyword or identifier.\",\n \"source\": \"ts\",\n \"startLineNumber\": 4,\n \"startColumn\": 8,\n \"endLineNumber\": 4,\n \"endColumn\": 9\n},{\n \"resource\": \"/com.docker.devenvironments.code/jobApplications/js/quest.py.js\",\n \"owner\": \"typescript\",\n \"code\": \"1434\",\n \"severity\": 8,\n \"message\": \"Unexpected keyword or identifier.\",\n \"source\": \"ts\",\n \"startLineNumber\": 4,\n \"startColumn\": 10,\n \"endLineNumber\": 4,\n \"endColumn\": 17\n},{\n \"resource\": \"/com.docker.devenvironments.code/jobApplications/js/quest.py.js\",\n \"owner\": \"typescript\",\n \"code\": \"1434\",\n \"severity\": 8,\n \"message\": \"Unexpected keyword or identifier.\",\n \"source\": \"ts\",\n \"startLineNumber\": 4,\n \"startColumn\": 18,\n \"endLineNumber\": 4,\n \"endColumn\": 20\n},{\n \"resource\": \"/com.docker.devenvironments.code/jobApplications/js/quest.py.js\",\n \"owner\": \"typescript\",\n \"code\": \"1434\",\n \"severity\": 8,\n \"message\": \"Unexpected keyword or identifier.\",\n \"source\": \"ts\",\n \"startLineNumber\": 4,\n \"startColumn\": 21,\n \"endLineNumber\": 4,\n \"endColumn\": 24\n},{\n \"resource\": \"/com.docker.devenvironments.code/jobApplications/js/quest.py.js\",\n \"owner\": \"typescript\",\n \"code\": \"1127\",\n \"severity\": 8,\n \"message\": \"Invalid character.\",\n \"source\": \"ts\",\n \"startLineNumber\": 8,\n \"startColumn\": 1,\n \"endLineNumber\": 8,\n \"endColumn\": 2\n},{\n \"resource\": \"/com.docker.devenvironments.code/jobApplications/js/quest.py.js\",\n \"owner\": \"typescript\",\n \"code\": \"1005\",\n \"severity\": 8,\n \"message\": \"';' expected.\",\n \"source\": \"ts\",\n \"startLineNumber\": 8,\n \"startColumn\": 3,\n \"endLineNumber\": 8,\n \"endColumn\": 8\n},{\n \"resource\": \"/com.docker.devenvironments.code/jobApplications/js/quest.py.js\",\n \"owner\": \"typescript\",\n \"code\": \"1434\",\n \"severity\": 8,\n \"message\": \"Unexpected keyword or identifier.\",\n \"source\": \"ts\",\n \"startLineNumber\": 8,\n \"startColumn\": 9,\n \"endLineNumber\": 8,\n \"endColumn\": 12\n},{\n \"resource\": \"/com.docker.devenvironments.code/jobApplications/js/quest.py.js\",\n \"owner\": \"typescript\",\n \"code\": \"1434\",\n \"severity\": 8,\n \"message\": \"Unexpected keyword or identifier.\",\n \"source\": \"ts\",\n \"startLineNumber\": 8,\n \"startColumn\": 13,\n \"endLineNumber\": 8,\n \"endColumn\": 17\n},{\n \"resource\": \"/com.docker.devenvironments.code/jobApplications/js/quest.py.js\",\n \"owner\": \"typescript\",\n \"code\": \"1434\",\n \"severity\": 8,\n \"message\": \"Unexpected keyword or identifier.\",\n \"source\": \"ts\",\n \"startLineNumber\": 8,\n \"startColumn\": 18,\n \"endLineNumber\": 8,\n \"endColumn\": 25\n},{\n \"resource\": \"/com.docker.devenvironments.code/jobApplications/js/quest.py.js\",\n \"owner\": \"typescript\",\n \"code\": \"1434\",\n \"severity\": 8,\n \"message\": \"Unexpected keyword or identifier.\",\n \"source\": \"ts\",\n \"startLineNumber\": 8,\n \"startColumn\": 26,\n \"endLineNumber\": 8,\n \"endColumn\": 28\n},{\n \"resource\": \"/com.docker.devenvironments.code/jobApplications/js/quest.py.js\",\n \"owner\": \"typescript\",\n \"code\": \"1434\",\n \"severity\": 8,\n \"message\": \"Unexpected keyword or identifier.\",\n \"source\": \"ts\",\n \"startLineNumber\": 8,\n \"startColumn\": 29,\n \"endLineNumber\": 8,\n \"endColumn\": 32\n},{\n \"resource\": \"/com.docker.devenvironments.code/jobApplications/js/quest.py.js\",\n \"owner\": \"typescript\",\n \"code\": \"1127\",\n \"severity\": 8,\n \"message\": \"Invalid character.\",\n \"source\": \"ts\",\n \"startLineNumber\": 11,\n \"startColumn\": 1,\n \"endLineNumber\": 11,\n \"endColumn\": 2\n},{\n \"resource\": \"/com.docker.devenvironments.code/jobApplications/js/quest.py.js\",\n \"owner\": \"typescript\",\n \"code\": \"1005\",\n \"severity\": 8,\n \"message\": \"';' expected.\",\n \"source\": \"ts\",\n \"startLineNumber\": 11,\n \"startColumn\": 3,\n \"endLineNumber\": 11,\n \"endColumn\": 7\n},{\n \"resource\": \"/com.docker.devenvironments.code/jobApplications/js/quest.py.js\",\n \"owner\": \"typescript\",\n \"code\": \"1434\",\n \"severity\": 8,\n \"message\": \"Unexpected keyword or identifier.\",\n \"source\": \"ts\",\n \"startLineNumber\": 11,\n \"startColumn\": 8,\n \"endLineNumber\": 11,\n \"endColumn\": 11\n},{\n \"resource\": \"/com.docker.devenvironments.code/jobApplications/js/quest.py.js\",\n \"owner\": \"typescript\",\n \"code\": \"1434\",\n \"severity\": 8,\n \"message\": \"Unexpected keyword or identifier.\",\n \"source\": \"ts\",\n \"startLineNumber\": 11,\n \"startColumn\": 12,\n \"endLineNumber\": 11,\n \"endColumn\": 20\n},{\n \"resource\": \"/com.docker.devenvironments.code/jobApplications/js/quest.py.js\",\n \"owner\": \"typescript\",\n \"code\": \"1101\",\n \"severity\": 8,\n \"message\": \"'with' statements are not allowed in strict mode.\",\n \"source\": \"ts\",\n \"startLineNumber\": 11,\n \"startColumn\": 21,\n \"endLineNumber\": 11,\n \"endColumn\": 25\n},{\n \"resource\": \"/com.docker.devenvironments.code/jobApplications/js/quest.py.js\",\n \"owner\": \"typescript\",\n \"code\": \"1005\",\n \"severity\": 8,\n \"message\": \"'(' expected.\",\n \"source\": \"ts\",\n \"startLineNumber\": 11,\n \"startColumn\": 26,\n \"endLineNumber\": 11,\n \"endColumn\": 29\n},{\n \"resource\": \"/com.docker.devenvironments.code/jobApplications/js/quest.py.js\",\n \"owner\": \"typescript\",\n \"code\": \"1005\",\n \"severity\": 8,\n \"message\": \"')' expected.\",\n \"source\": \"ts\",\n \"startLineNumber\": 11,\n \"startColumn\": 30,\n \"endLineNumber\": 11,\n \"endColumn\": 35\n},{\n \"resource\": \"/com.docker.devenvironments.code/jobApplications/js/quest.py.js\",\n \"owner\": \"typescript\",\n \"code\": \"1005\",\n \"severity\": 8,\n \"message\": \"'{' expected.\",\n \"source\": \"ts\",\n \"startLineNumber\": 11,\n \"startColumn\": 36,\n \"endLineNumber\": 11,\n \"endColumn\": 46\n},{\n \"resource\": \"/com.docker.devenvironments.code/jobApplications/js/quest.py.js\",\n \"owner\": \"typescript\",\n \"code\": \"1127\",\n \"severity\": 8,\n \"message\": \"Invalid character.\",\n \"source\": \"ts\",\n \"startLineNumber\": 14,\n \"startColumn\": 1,\n \"endLineNumber\": 14,\n \"endColumn\": 2\n},{\n \"resource\": \"/com.docker.devenvironments.code/jobApplications/js/quest.py.js\",\n \"owner\": \"typescript\",\n \"code\": \"1005\",\n \"severity\": 8,\n \"message\": \"';' expected.\",\n \"source\": \"ts\",\n \"startLineNumber\": 14,\n \"startColumn\": 3,\n \"endLineNumber\": 14,\n \"endColumn\": 8\n},{\n \"resource\": \"/com.docker.devenvironments.code/jobApplications/js/quest.py.js\",\n \"owner\": \"typescript\",\n \"code\": \"1434\",\n \"severity\": 8,\n \"message\": \"Unexpected keyword or identifier.\",\n \"source\": \"ts\",\n \"startLineNumber\": 14,\n \"startColumn\": 9,\n \"endLineNumber\": 14,\n \"endColumn\": 12\n},{\n \"resource\": \"/com.docker.devenvironments.code/jobApplications/js/quest.py.js\",\n \"owner\": \"typescript\",\n \"code\": \"1005\",\n \"severity\": 8,\n \"message\": \"';' expected.\",\n \"source\": \"ts\",\n \"startLineNumber\": 14,\n \"startColumn\": 28,\n \"endLineNumber\": 14,\n \"endColumn\": 32\n}", "---------------------------------------------------------------------------\nLookupError Traceback (most recent call last)\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 83 try:\n---> 84 root = nltk.data.find(f\"{self.subdir}/{zip\\_name}\")\n 85 except LookupError:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\data.py in find(resource\\_name, paths)\n 582 resource\\_not\\_found = f\"\\n{sep}\\n{msg}\\n{sep}\\n\"\n--> 583 raise LookupError(resource\\_not\\_found)\n 584 \n\nLookupError: \n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n Resource omw-1.4 not found.\n Please use the NLTK Downloader to obtain the resource:\n\n >>> import nltk\n >>> nltk.download('omw-1.4')\n \n For more information see: https://www.nltk.org/data.html\n\n Attempted to load corpora/omw-1.4.zip/omw-1.4/\n\n Searched in:\n - 'C:\\\\Users\\\\rockr/nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\share\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\lib\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\AppData\\\\Roaming\\\\nltk\\_data'\n - 'C:\\\\nltk\\_data'\n - 'D:\\\\nltk\\_data'\n - 'E:\\\\nltk\\_data'\n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\nDuring handling of the above exception, another exception occurred:\n\nLookupError Traceback (most recent call last)\n~\\AppData\\Local\\Temp\\ipykernel\\_9724\\3827873343.py in \n 41 \n 42 # Preprocess train and test text data\n---> 43 train\\_df['text'] = train\\_df['text'].apply(preprocess\\_text)\n 44 test\\_df['text'] = test\\_df['text'].apply(preprocess\\_text)\n 45 \n\n~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py in apply(self, func, convert\\_dtype, args, \\*\\*kwargs)\n 4431 dtype: float64\n 4432 \"\"\"\n-> 4433 return SeriesApply(self, func, convert\\_dtype, args, kwargs).apply()\n 4434 \n 4435 def \\_reduce(\n\n~\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py in apply(self)\n 1086 return self.apply\\_str()\n 1087 \n-> 1088 return self.apply\\_standard()\n 1089 \n 1090 def agg(self):\n\n~\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py in apply\\_standard(self)\n 1141 # List[Union[Callable[..., Any], str]]]]]\"; expected\n 1142 # \"Callable[[Any], Any]\"\n-> 1143 mapped = lib.map\\_infer(\n 1144 values,\n 1145 f, # type: ignore[arg-type]\n\n~\\Anaconda3\\lib\\site-packages\\pandas\\\\_libs\\lib.pyx in pandas.\\_libs.lib.map\\_infer()\n\n~\\AppData\\Local\\Temp\\ipykernel\\_9724\\3827873343.py in preprocess\\_text(text)\n 35 # Lemmatize\n 36 lemmatizer = WordNetLemmatizer()\n---> 37 tokens = [lemmatizer.lemmatize(token) for token in tokens]\n 38 # Join tokens back into a string\n 39 text = ' '.join(tokens)\n\n~\\AppData\\Local\\Temp\\ipykernel\\_9724\\3827873343.py in (.0)\n 35 # Lemmatize\n 36 lemmatizer = WordNetLemmatizer()\n---> 37 tokens = [lemmatizer.lemmatize(token) for token in tokens]\n 38 # Join tokens back into a string\n 39 text = ' '.join(tokens)\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\stem\\wordnet.py in lemmatize(self, word, pos)\n 43 :return: The lemma of `word`, for the given `pos`.\n 44 \"\"\"\n---> 45 lemmas = wn.\\_morphy(word, pos)\n 46 return min(lemmas, key=len) if lemmas else word\n 47 \n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_getattr\\_\\_(self, attr)\n 119 raise AttributeError(\"LazyCorpusLoader object has no attribute '\\_\\_bases\\_\\_'\")\n 120 \n--> 121 self.\\_\\_load()\n 122 # This looks circular, but its not, since \\_\\_load() changes our\n 123 # \\_\\_class\\_\\_ to something new:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 87 \n 88 # Load the corpus.\n---> 89 corpus = self.\\_\\_reader\\_cls(root, \\*self.\\_\\_args, \\*\\*self.\\_\\_kwargs)\n 90 \n 91 # This is where the magic happens! Transform ourselves into\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py in \\_\\_init\\_\\_(self, root, omw\\_reader)\n 1174 )\n 1175 else:\n-> 1176 self.provenances = self.omw\\_prov()\n 1177 \n 1178 # A cache to store the wordnet data of multiple languages\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py in omw\\_prov(self)\n 1283 provdict = {}\n 1284 provdict[\"eng\"] = \"\"\n-> 1285 fileids = self.\\_omw\\_reader.fileids()\n 1286 for fileid in fileids:\n 1287 prov, langfile = os.path.split(fileid)\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_getattr\\_\\_(self, attr)\n 119 raise AttributeError(\"LazyCorpusLoader object has no attribute '\\_\\_bases\\_\\_'\")\n 120 \n--> 121 self.\\_\\_load()\n 122 # This looks circular, but its not, since \\_\\_load() changes our\n 123 # \\_\\_class\\_\\_ to something new:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 84 root = nltk.data.find(f\"{self.subdir}/{zip\\_name}\")\n 85 except LookupError:\n---> 86 raise e\n 87 \n 88 # Load the corpus.\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 79 else:\n 80 try:\n---> 81 root = nltk.data.find(f\"{self.subdir}/{self.\\_\\_name}\")\n 82 except LookupError as e:\n 83 try:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\data.py in find(resource\\_name, paths)\n 581 sep = \"\\*\" \\* 70\n 582 resource\\_not\\_found = f\"\\n{sep}\\n{msg}\\n{sep}\\n\"\n--> 583 raise LookupError(resource\\_not\\_found)\n 584 \n 585 \n\nLookupError: \n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n Resource omw-1.4 not found.\n Please use the NLTK Downloader to obtain the resource:\n\n >>> import nltk\n >>> nltk.download('omw-1.4')\n \n For more information see: https://www.nltk.org/data.html\n\n Attempted to load corpora/omw-1.4\n\n Searched in:\n - 'C:\\\\Users\\\\rockr/nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\share\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\lib\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\AppData\\\\Roaming\\\\nltk\\_data'\n - 'C:\\\\nltk\\_data'\n - 'D:\\\\nltk\\_data'\n - 'E:\\\\nltk\\_data'\n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\nplease fix this error", "---------------------------------------------------------------------------\nLookupError Traceback (most recent call last)\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 83 try:\n---> 84 root = nltk.data.find(f\"{self.subdir}/{zip\\_name}\")\n 85 except LookupError:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\data.py in find(resource\\_name, paths)\n 582 resource\\_not\\_found = f\"\\n{sep}\\n{msg}\\n{sep}\\n\"\n--> 583 raise LookupError(resource\\_not\\_found)\n 584 \n\nLookupError: \n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n Resource omw-1.4 not found.\n Please use the NLTK Downloader to obtain the resource:\n\n >>> import nltk\n >>> nltk.download('omw-1.4')\n \n For more information see: https://www.nltk.org/data.html\n\n Attempted to load corpora/omw-1.4.zip/omw-1.4/\n\n Searched in:\n - 'C:\\\\Users\\\\rockr/nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\share\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\lib\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\AppData\\\\Roaming\\\\nltk\\_data'\n - 'C:\\\\nltk\\_data'\n - 'D:\\\\nltk\\_data'\n - 'E:\\\\nltk\\_data'\n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\nDuring handling of the above exception, another exception occurred:\n\nLookupError Traceback (most recent call last)\n~\\AppData\\Local\\Temp\\ipykernel\\_9724\\3118448898.py in \n 42 \n 43 # Preprocess train and test text data\n---> 44 train\\_df['text'] = train\\_df['text'].apply(preprocess\\_text)\n 45 test\\_df['text'] = test\\_df['text'].apply(preprocess\\_text)\n 46 \n\n~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py in apply(self, func, convert\\_dtype, args, \\*\\*kwargs)\n 4431 dtype: float64\n 4432 \"\"\"\n-> 4433 return SeriesApply(self, func, convert\\_dtype, args, kwargs).apply()\n 4434 \n 4435 def \\_reduce(\n\n~\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py in apply(self)\n 1086 return self.apply\\_str()\n 1087 \n-> 1088 return self.apply\\_standard()\n 1089 \n 1090 def agg(self):\n\n~\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py in apply\\_standard(self)\n 1141 # List[Union[Callable[..., Any], str]]]]]\"; expected\n 1142 # \"Callable[[Any], Any]\"\n-> 1143 mapped = lib.map\\_infer(\n 1144 values,\n 1145 f, # type: ignore[arg-type]\n\n~\\Anaconda3\\lib\\site-packages\\pandas\\\\_libs\\lib.pyx in pandas.\\_libs.lib.map\\_infer()\n\n~\\AppData\\Local\\Temp\\ipykernel\\_9724\\3118448898.py in preprocess\\_text(text)\n 36 # Lemmatize\n 37 lemmatizer = WordNetLemmatizer()\n---> 38 tokens = [lemmatizer.lemmatize(token) for token in tokens]\n 39 # Join tokens back into a string\n 40 text = ' '.join(tokens)\n\n~\\AppData\\Local\\Temp\\ipykernel\\_9724\\3118448898.py in (.0)\n 36 # Lemmatize\n 37 lemmatizer = WordNetLemmatizer()\n---> 38 tokens = [lemmatizer.lemmatize(token) for token in tokens]\n 39 # Join tokens back into a string\n 40 text = ' '.join(tokens)\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\stem\\wordnet.py in lemmatize(self, word, pos)\n 43 :return: The lemma of `word`, for the given `pos`.\n 44 \"\"\"\n---> 45 lemmas = wn.\\_morphy(word, pos)\n 46 return min(lemmas, key=len) if lemmas else word\n 47 \n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_getattr\\_\\_(self, attr)\n 119 raise AttributeError(\"LazyCorpusLoader object has no attribute '\\_\\_bases\\_\\_'\")\n 120 \n--> 121 self.\\_\\_load()\n 122 # This looks circular, but its not, since \\_\\_load() changes our\n 123 # \\_\\_class\\_\\_ to something new:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 87 \n 88 # Load the corpus.\n---> 89 corpus = self.\\_\\_reader\\_cls(root, \\*self.\\_\\_args, \\*\\*self.\\_\\_kwargs)\n 90 \n 91 # This is where the magic happens! Transform ourselves into\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py in \\_\\_init\\_\\_(self, root, omw\\_reader)\n 1174 )\n 1175 else:\n-> 1176 self.provenances = self.omw\\_prov()\n 1177 \n 1178 # A cache to store the wordnet data of multiple languages\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py in omw\\_prov(self)\n 1283 provdict = {}\n 1284 provdict[\"eng\"] = \"\"\n-> 1285 fileids = self.\\_omw\\_reader.fileids()\n 1286 for fileid in fileids:\n 1287 prov, langfile = os.path.split(fileid)\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_getattr\\_\\_(self, attr)\n 119 raise AttributeError(\"LazyCorpusLoader object has no attribute '\\_\\_bases\\_\\_'\")\n 120 \n--> 121 self.\\_\\_load()\n 122 # This looks circular, but its not, since \\_\\_load() changes our\n 123 # \\_\\_class\\_\\_ to something new:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 84 root = nltk.data.find(f\"{self.subdir}/{zip\\_name}\")\n 85 except LookupError:\n---> 86 raise e\n 87 \n 88 # Load the corpus.\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 79 else:\n 80 try:\n---> 81 root = nltk.data.find(f\"{self.subdir}/{self.\\_\\_name}\")\n 82 except LookupError as e:\n 83 try:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\data.py in find(resource\\_name, paths)\n 581 sep = \"\\*\" \\* 70\n 582 resource\\_not\\_found = f\"\\n{sep}\\n{msg}\\n{sep}\\n\"\n--> 583 raise LookupError(resource\\_not\\_found)\n 584 \n 585 \n\nLookupError: \n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n Resource omw-1.4 not found.\n Please use the NLTK Downloader to obtain the resource:\n\n >>> import nltk\n >>> nltk.download('omw-1.4')\n \n For more information see: https://www.nltk.org/data.html\n\n Attempted to load corpora/omw-1.4\n\n Searched in:\n - 'C:\\\\Users\\\\rockr/nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\share\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\lib\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\AppData\\\\Roaming\\\\nltk\\_data'\n - 'C:\\\\nltk\\_data'\n - 'D:\\\\nltk\\_data'\n - 'E:\\\\nltk\\_data'\n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n\nstill error", "Write a viral engineering blog post for Hacker News that summarizes the notes below the --- which are about the Turborepo team migrating the Turborepo codebase from Go to Rust and why. Discuss why the team is making the migration incrementally and why this is relevant to other high-performance engineering teams doing filesystem work debating Rust or Go. Use a witty, but chill voice.\n---\n\nNathan:\n\n- Organizational\n - Our team wants to write Rust. We think it\u2019s neat and it makes us happy. This alone is \\*reason enough\\* to do it as long as it aligns with other goals in our organization.\n - Hiring for Rust-interested web-focused engineers is easier than hiring for Go-interested web-focused engineers.\n - We want to work with the Turbopack people and primitives. Creating our own internal \u201clibrary\u201d of code gives us the ability to row the boat together. We have similar needs and problems that aren\u2019t addressed \\*anywhere else\\* and it\u2019s important to go together as a team. (Go fast? Go alone. Go far? Go together.)\n- Community\n - There is a \\*strong\\* interest in Rust from the JavaScript community. This makes it more-accessible for people coming from JS-tooling-in-JS land, and enables community contributions.\n - We have had little engagement from the Go community in our projects, and few occasions to interact with them in external code. Not unexpected, but we\u2019d like to build a community and we believe that we can be successful with that in Rust.\n- Ecosystem\n - The Node.js ecosystem is absolutely massive. Almost anything you need has been written in JS, or is forkable. We come from this world, and this is the expectation we have for depth, breadth, and maintenance.\n - The Rust ecosystem has a few extremely-high-quality core pieces that are in \\*everything\\*. `serde` is a work of art. `rayon` is fantastic. Those serve as foundational tools that have \\*solved\\* entire problem spaces in a consistent way for the entire community.\n - Algorithm research happens in Rust, not Go. New toys show up, implement a trait, and poof, they\u2019re in your codebase.\n - The Go ecosystem is not easily discoverable and feels very dead. People regularly write one-off solutions to general problems. Most of the best things are Google-authored and fit with Google\u2019s worldview, but not necessarily everybody else\u2019s.\n - The Go ecosystem has frequently-used yet poorly-maintained libraries that are a core part of the experience (e.g. afero). spf13 \u201cHolowaychuk'd\u201d the Go ecosystem and then disappeared (and recently stepped away from Google and Go entirely).\n - The \u201ccorrectness\u201d quotient of libraries in Go is somewhere between JS and Rust. Not good enough to be 100% reliable, not as flexible as JS when you need to duckpunch something.\n- C Interop\n - As you get deeper and deeper into Go you start to discover that the best way to do certain tasks is to bind to a C library. zstd, libgit2, regular expressions, and more. This means that, \\*even without Rust adoption\\*, we were going to lose some of the development experience wins of Go.\n - This works \u201cjust fine\u201d but the real point here is, once you\u2019ve got a compiler toolchain setup for each of your targets for CGO, there\u2019s little to prevent you from also making the small hop over to Rust. (Once we can compile with CGO, we can \\*also\\* compile to `c-archive` and have Rust call our Go code.)\n- Go Language Design and Priorities\n - Go is designed for network computing run in data centers. It \\*excels\\* at that. The ecosystem of libraries available in that space are of super-high quality. `context` is a work of art.\n - In comparison, Go shipped a read-only filesystem abstraction a couple years ago. It\u2019s still read-only. Why? You don\u2019t write to filesystems in a (Google) data center environment.\n - Our use case doesn\u2019t align with the Go maintainers\u2019 needs and use cases. That leads to needing to roll our own (lots of things) because they\u2019re not a priority to address at language level.\n - No MSVC support.\n- Rust Language Design and Priorities\n - Rust has prioritized correctness over convenience. Paths? Not as easy to use, because the underlying primitive is not easy to use. It returns the complexity to the programmer to explicitly handle correctly. But we care about precisely that in a world where basically 90% of what we do is path handling.\n - In general we believe it is better-suited to ship Rust to a hostile environment like a user\u2019s box than Go. Go\u2019s stdlib \u201caligns\u201d a lot of behaviors that can\u2019t \\*actually\\* be aligned between platforms\u2014most specifically around filesystem APIs \u2026 again a place that we care about.\n - Is able to build on the MSVC toolchain.\n- Vision\n - We want to, with localized heating, boil the JS ocean. (Starting at the places where people are, and slowly moving to boil the whole ocean.) We want to bring full incremental computation all the way from dev time into production. We\u2019re working backward from production with Turbopack, and forward from the build tool with Turborepo. The next iteration of this is \u201cinfinitely granular DAG which includes the whole ecosystem.\u201d Nobody else appears to be attempting that granularity.\n - Success here is a \\*massive\\* moat, possibly insurmountable. For context I would have said the same thing about C compilers, but Clang and LLVM have done it over the last 20 years. But 20 years is one hell of a moat and we can respond a lot faster than 20 years to maintain that separation.\n - Being the stewards for the community primitives (in this case `turbo` \u2026 which is what happens after repo/pack merger) gives us the ability to push the \\*entire\\* ecosystem forward, slowly increasing what is possible to even attempt.\n- Future\n - We believe that Rust is where the puck is heading. We want to help it get there, and be ready when that future arrives.\n\nNicholas:\n\n- Reasons for Rust\n - Performance\n - Not \\*really\\* valid because performance issues are less language constricted and more inherent architecture issues.\n - But maybe true? Too early to tell.\n - Ecosystem\n - IMO stuff like serde, swc, clap, etc. are good reasons to use Rust.\n - Go has separate interfaces for every text format (toml, json, yaml, etc)\n - Being able to use cargo to share code with the Turbopack people\n - Standardization with turbopack\n - Opens up a future for a whole suite of tooling in Rust\n - Our version of Rome (obviously don\u2019t say that directly) (do we want to talk about future plans?)\n - Eventually use Turbopack\u2019s graph infrastructure (maybe)\n - Go problems\n - Go and Windows.\n- Reasons against Rust\n - Slows down shipping velocity\n - We\u2019ve done a really good job of limiting this. We\u2019ve slowed down our shipping a little but still done a great job incrementally moving and keeping our existing users.\n - Ecosystem limitations\n - Globbing libraries are still a mess. Won\u2019t match JS globbing behavior\n - Hard to determine standard practices\n - You will have less than ideal code.\n - The orphan rule will bite you.\n - Hiring isn\u2019t hard, but the most senior rust developer you can find will have like 5 years of Rust experience, max.\n - Very easy to bike shed with macros, traits, funky types, refactoring, etc.\n - Just because Rust lets you refactor easily doesn\u2019t mean you should.\n\nGreg\n\nConsolidating some points shamelessly stolen from above\n\n- Rust Positives\n - JS \u2194 Rust interop is a good story, technically and community-wise\n - Rust \u2194 C is a good story, and we use some tools written in C\n - Rust is growing at Vercel and with NextJS, specifically\n- Go Negatives\n - The Go ecosystem is all-or-nothing. Once you need to make use of functionality not written in Go, you lose a lot of the benefits of having been in Go. What we lose:\n - Easy cross-platform static binary generation\n - Compilation speed (still better than rust tho)\n - Writing portable code is hard \\*and\\* not a focus of the ecosystem.\n - Conditional compilation support is basic\n - Platform-related APIs are either least-common-denominator or fudged to look cross-platform\n - Mismatch with community priorities\n - The Go community seems focused on being the best tool for writing an RPC server.\n - `Context` and goroutines are great primitives for request-scoped work within a long-running process.\n - Getting an HTTP server up and running is easy, and GRPC and protobuf is not much harder.\n - Such software is often intended to run on a single platform, or does not interact significantly with the host platform, so a workflow such as developing on `macos` and deploying on `linux` is the straightforward happy path.\n - Interop with other ecosystems is not a priority.\n - `turbo` is a cross-platform CLI tool that interacts heavily with the local filesystem and process tree.\n - Some of the best tools for filesystem interactions are written in C, so interop is important\n - Differences exist between different platforms, we as developers need those differences surfaced to us so we can handle them appropriately.\n - \n\nAnthony\u2019s notes from talking to Greg:\n\n- not necessarily about language features, let\u2019s break some new ground\n- moreso about what we are buliding doesn\u2019t align with the problem we\u2019re trying to solve\n- Go is good for RPCing and webservers and that\u2019s what the ecosystem cares about\n - Go will lie to you about platform specific differences (an ecosystem and community mindset)\n- we want good interop with JS, interop with OS\u2019es, platform specific stuff\n- The JavaScript community is spending time learning Rust right now\n- Globbing and performance stuff is pretty meh, those are language specific features\n-", "can you do the same with this list, main body area and nested areas. If the area is not an anatomic are than ignore please\n\n teeth.\n face, neck, body.\n lower face, neck, and jawline.\n severe cystic acne.\n face, neck, and body.\n lower layers of skin tissue.\n laryngeal prominence of thyroid cartilage in the throat.\n facial rejuvenation.\n abdomen, hips, thighs, arms, buttocks, or under the chin.\n nostrils.\n Face and body \n upper or lower jawbone.\n facial reconstruction, abdominal wall reconstruction, breast reconstruction.\n gastric.\n nipple-areola complex.\n underarms.\n balding, thinning, or receding areas.\n nasolabial folds, or smile lines.\n small, uncomplicated spider veins and small varicose veins.\n cellulite on the thighs and buttocks.\n mild to severe acne.\n upper or lower back.\n mustache, beard, sideburns.\n face, cheeks, under-eyes, lips, nasolabial folds, pitted scars, breasts, buttocks.\n face.\n navel.\n moderate to severe facial wrinkles and folds, such as nasolabial folds, etched-in lip lines, crow's feet, smile lines, marionette lines, under-eye tear troughs, and deep glabellar lines.\n upper arms.\n incision or injury.\n face, neck, chest, back, hands, arms, and legs.\n abdomen, hips, lower back, buttocks.\n stomach, legs, arms.\n stomach, thighs, butt, hips, and arms.\n fat reduction anywhere on the body, most commonly treated body areas are the tummy, hips, thighs, flanks (aka love handles), and back. some providers also offer mini bodyfx, which can treat smaller fat deposits in areas like the upper arms and under the chin..\n abdomen, upper arms, thighs, knees, love handles, breasts, back, chin, jowls, cheeks, and neck.\n crow's feet, frown lines, forehead lines, lip lines, bunny lines on the nose, chin wrinkles, neck bands, above the eyebrows, above the upper lip.\n teeth straightening.\n buttocks, hips, waist, love handles, thighs, lower back.\n buttocks.\n breasts.\n face.\n face, neck, d'colletage, back of hands.\n double chin, jawline, knees, elbows, upper arms, muffin top.\n face, body contouring.\n teeth.\n face, neck, hands, chest, legs, and other areas.\n glabellar area.\n forehead and eyebrows.\n lower cheeks.\n foot.\n buttocks, hips, abdomen, waistline, lower back, thighs.\n lower legs.\n lower legs.\n outer corner of the eye where the upper and lower lid meet.\n scalp.\n breast.\n face, neck, arms, stomach, buttocks, and legs.\n lens of the eye.\n cellulite dimples on the buttocks and the backs of the thighs.\n thighs, abdomen, or buttocks.\n midface.\n midface.\n cheeks.\n midface.\n zygomatic bone (malar bone).\n face, neck, chest, hands.\n soft tissue under the skin.\n lower face.\n under the chin and jawline.\n fine lines, shrink the appearance of pores, improve skin tone and texture, and reduce melasma.\n teeth straightening.\n jawbone.\n face, neck, chest, lips, and anywhere on the body.\n broken capillaries, spider veins, vascular lesions, periorbital veins, skin discoloration.\n upper lip, nose, and roof of the mouth.\n clitoral hood.\n face, neck, chest.\n vagina and vulva.\n crow's feet, fine lines around the eyes, smile lines, frown lines, atrophic acne scars, and thin lips.\n brow, mid- and lower face, jawline, and neck.\n fine lines and wrinkles, sun damage, discoloration, and acne scars.\n fine lines and wrinkles, acne scars, large pore size, uneven skin tone, rough skin texture, age spots, and other signs of sun damage.\n abdomen, flanks, bra fat, inner and outer thighs, back fat, upper arms, buttock rolls, knees, hips, mons pubis, submental fat.\n thighs, butt, and abdomen.\n hyperpigmentation and skin discoloration.\n abdominal fat, love handles, upper arms, inner thighs, under chin, below buttocks, bra and back fat bulges.\n slimming, toning, and cellulite reduction.\n face.\n skin.\n teeth.\n teeth straightening.\n glabellar lines, forehead furrows, crow's feet, bunny lines, platysmal bands, dimpling of the chin, masseter muscles.\n middle and lower areas of the face.\n face, eyes, neck.\n teeth.\n jawbone, gums.\n missing teeth.\n teeth.\n upper or lower jawbone.\n face, eyes, lips.\n face, upper lip, cheeks.\n smile lines, marionette lines, lips, under-eye hollows, cheeks, temples, jawline, chin, nose.\n face, neck, chest, stomach, thighs.\n face.\n skin tightening.\n face, neck, d'colletage, body.\n abdominal muscles.\n chin or cheeks.\n vaginal tissue.\n craniofacial region.\n upper eyelids.\n stomach and small intestine.\n front of natural teeth.\n \n face, neck, chest, arms, back of hands, and elsewhere on the body.\n legs, buttocks, thighs, back, or stomach.\n teeth.\n face, neck, under chin.\n skin.\n hormonal acne, polycystic ovary syndrome (pcos), high blood pressure, congestive heart failure.\n anywhere on the body.\n excess pigmentation and redness, wrinkles and mild acne scars, vascular lesions and varicose veins, pigmented lesions and dark tattoos.\n eye alignment.\n breast augmentation, breast reconstruction, abdominal wall defects, hernia repair.\n depressed scars, acne scars, cellulite dimples.\n face, neck, and d\u00e9colletage.\n teeth alignment.\n epidermis.\n acne on face and body, psoriasis on body, sun damage.\n face.\n teeth.\n face.\n lips, cheeks, chin, forehead, eyes, mouth, neck, and chest.\n scrotum.\n face, eyes, eyelids, jawline, stomach, arms, backs of hands, thighs, knees, butt.\n breasts and nipples.\n cheeks, around the mouth, neck, forehead and around the eyes.\n lower face, jowls, neck, breasts, arms, tummy, and thighs.\n vulvar and vaginal tissues.\n thigh.\n brow, mid- and lower face, jawline, and neck.\n skin concerns.\n inner and outer thighs, back, abdomen, love handles, hips, saddlebags, and buttocks.\n face, neck, stomach, and upper arms.\n enamel, dentin, pulp.\n face, forehead, temples, chin, area around mouth, cheeks.\n wrinkles, sagging skin, fat cells, cellulite.\n abdomen and flanks.\n abdomen and flanks.\n abdomen, flanks, buttocks, thighs.\n abdomen, flanks, and thighs.\n reshaping, creating balanced, normal breasts.\n abdomen, love handles, hips, thighs, chin, upper arms, underarms.\n lower abdomen.\n abdomen.\n brow, neck (including jawline), under chin, lines and wrinkles on d'colletage.\n vaginal area.\n face and neck.\n fine lines and wrinkles, discoloration, and even scars.\n stomach, hips, and thighs.\n abdomen, hips, and thighs.\n fat layer just under the skin.\n upper arms, belly, love handles, thighs, chin.\n abdominal wall.\n eyelid.\n lower face.\n vaginal canal, opening, labia majora, vulva, labia minora, mons pubis.\n vaginal canal.\n cleavage area.\n face.\n face.\n abdomen and thighs.\n spider veins, varicose veins, and venous reflux disease.\n thighs, calves, and ankles, buttocks and hips, abdomen, back, and flanks (aka love handles), upper arms, neck and under the chin.\n rosacea, pigmented scars, spider veins, broken capillaries, birthmarks, hyperpigmentation, newly formed stretch marks, and other forms of red, brown, or purple facial pigmentation.\n legs.\n spider veins, cherry angiomas, small hemangiomas, skin tags, spider nevi, and redness from rosacea.\n thighs, buttocks, upper arms, stomach, excess fat and mildly sagging skin under the chin.\n thighs, abdomen, and butt.\n varicose veins.\n fat reduction on the back, abdomen, thighs and flanks, cellulite reduction on the thighs, buttocks, and abdomen, muscle conditioning and toning for biceps, triceps, abdominal and oblique muscles, glutes, hamstrings, and quadriceps.\n face, neck, and body.\n wrinkles, fine lines, cellulite, stretch marks.\n fine lines and deep wrinkles, acne scars, large pores, uneven skin texture, stretch marks, mild laxity, rosacea, and hyperpigmentation, including melasma.\n pelvic floor issues.\n face, neck, chest, hands.\n face and body.\n vaginal tissues, labia majora.\n pelvic floor muscles and skin elasticity.\n jaw.\n lines and wrinkles created by dynamic facial movements, such as smiling, frowning, or raising your eyebrows, neck pain caused by cervical dystonia, eye spasms known as blepharospasm, and upper limb spasticity.\n skin concerns, visible veins, brown spots, scars, laser hair removal, tattoo removal, cataract surgery.\n waist, chest, back, neck, upper arms, thighs, love handles, hips, and ankles.\n skin.\n teeth.\n lower third of face, jawline, neck.\n face, neck, and body.", "The 2001- 2 PEP history textbooks: unity above diversity\nAlthough Wang Hongzhi remained the Director of the Editorial Committee for the 2001-2 History textbooks and contributed (with 11 other editors) to the volumes on Ancient China, by her own account she was by this time withdrawing from direct oversight of textbook compilation (Wang, 2000, pp. 18\u20139).24 Two new chief editors, Qi Jiaxiang and Ma Zhibing, took over.25\n\nWhile the 1992 edition amalgamated the relatively liberal 1988 Curricular Outline and the post-1989 Patriotic Education campaign, the 2001-2 edition was more thoroughly in tune with the latter. This is evident even from the Table of Contents, which reflects a conventional narrative of the national past centred on a Chinese nation conceived in ethnocultural terms, rather than on a Marxist narrative of historical-materialist phases of development (from primitive communism through slave, feudal and bourgeois to socialist utopia).26\n\nEnhanced ethnonationalism was reflected in a new emphasis on the Yellow Emperor (\u9ec4\u5e1d), a semi-mythical figure traditionally regarded as the ancestor of the Han people (see Chow, 1997). Described briefly in the 1992 texts as the \u201cleader of a tribal alliance\u201d, in 2001-2 he rated an entire lesson identifying him as \u201cThe Ancestor of the Huaxia [the proto-Han peoples of ancient China]\u201d (PEP, 2001\u20132a, p. 12). A new section hailed the Yellow Emperor as the \u201cfirst ancestor of [Chinese/human] civilization\u201d (\u4eba\u6587\u521d\u7956), citing the inventions traditionally ascribed to him (including boats, wagons, the lunar calendar and medicine, etc.). He was represented as a symbol of Chineseness conceived in thoroughly primordialist and even biological terms.27\n\nThis ethno-nationalist perspective reflected the political and cultural currents of the 1990s, but what of the personal predilections of the new chief editors? A search on CNKI (\u4e2d\u56fd\u77e5\u7f51) shows that Qi has published two papers related to the issue of ethnicity (1982, 2005) and Ma only one. None of these evince a strong espousal of the kind of multi-ethnic perspective promoted by Wang.28 They emphasize themes on national unity, interethnic solidarity and patriotism. In a writing entitled \u201cLittle seals with large functions\u201d (\u5c0f\u5c0f\u5370\u7ae0\u7ba1\u5927\u7528), Qi argues that a Han dynasty official seal found in Xinjiang in 1954 \u201cshows that the ethnic Qiang group living in southern Xinjiang were already under [Chinese] governance\u201d during the Han dynasty (1989, p. 150), and offers similar arguments relating to Tibet (188\u20139). The apparent views of Qi and Ma on \u201cminorities\u201d matters may help account for the shift in 2001-2 away from the previous emphasis on diversity and inter-ethnic \u201cequality\u201d \u2013 but it is also likely that the decision to appoint individuals with such backgrounds and ideological stances reflected the shifting priorities of the PEP\u2019s political overseers.29\n\nEthnic pluralism nonetheless remained an important theme in 2001-2. Indeed, several passages dealing with non-Han ethnic groups were newly inserted. Following the lesson on inter-ethnic relations during the Tang (618\u2013907), a new activity instructed students to survey their classmates to see if any possess \u201cminority\u201d backgrounds, exhorting them to learn about and respect \u201cminority\u201d customs and culture (PEP, 2001\u20132b, p. 27). A new section on inter-ethnic relations during the Qing Dynasty hailed the Manchu emperors\u2019 tolerance of non-Han \u201cminorities\u201d,30 praising their policies as \u201cpragmatic and far-sighted\u201d (\u7740\u8bc6\u8fdc\u89c1) and \u201cbenefiting the unity of the nation\u201d (ibid., p. 114).\n\nHowever, much material on the origins and customs of \u201cminorities\u201d was reinterpreted or expunged. The words \u201ctribe\u201d or \u201cethnicity\u201d previously used to describe the first three dynasties (Xia, Shang and Zhou) were now replaced with the term \u201ckingdom\u201d (\u56fd), obscuring their diverse ethnic character and implying singular rather than plural ethnic origins for the Chinese nation. Many of the tribal names featured on an accompanying the map in the 1992 edition were removed from the same map in 2001.\n\nThe lesson on the Qin Dynasty, while still mentioning the conflict with the nomadic Huns or Xiong-nu (\u5308\u5974), omitted a section elaborating Xiong-nu culture and lifestyle, thus effectively reverting to their traditional portrayal as barbaric alien invaders. Under Wang\u2019s successors, the attempt to incorporate such groups within an expansive, multi-ethnic conception of \u201cChineseness,\u201d was superseded by a more Han-centric approach.31 As a result, coverage of the Liao, Western Xia and Jin was curtailed and simplified, with sections introducing their economic and social development alongside that of Song China pared down or eliminated.32 Passages on the Western Liao and several other regimes newly featured in the 1992 edition also disappeared. All these groups were now implicitly defined as non-Chinese, or at best as peripheral to the core, Han-centred national narrative.\n\nOther passages dealing with \u201cminority\u201d culture and customs were also deleted. These included the Sarbi (\u9c9c\u5351) folk song featured in a lesson on cultural developments during the Sarbi-ruled Northern Dynasty. The lessons detailing cultural life during the Northern and Southern Dynasties (\u5357\u5317\u671d, 420\u2013589), when \u201cminorities\u201d and Han intermingled in the North, thus now entirely revolved around Han culture. Mention of the Tibetan medical expert featured in the 1992 chapter on Tang dynasty culture was deleted, while the passage on his Han counterpart was retained (PEP, 2001\u20132b, p. 35). Similarly, many minority heroes newly designated in 1992 were ejected from the national pantheon, or, as with the Jurchen leader Wanyan Aguda, mentioned only by name. One of the notable exceptions was Genghis Khan, whose \u201cunifying\u201d contribution was evidently considered too important to ignore. In discussion of Hun-Han relations before and during the Han Dynasty, the previous acknowledgement of mutual influence was removed, leaving the statement that \u201csome Hun people learned farming from the Han\u201d (ibid., p. 78), and implying a unidirectional, tutelary relationship in which the \u201cbarbarians\u201d were subordinate.\n\nWhile minorities\u2019 cultural distinctiveness and claims to heroism were thus downplayed, episodes highlighting national unity and the immemorial origins of central rule in restive frontier regions (notably Tibet, Xinjiang and Taiwan) were accorded new emphasis. These included accounts of the Panchen Lama\u2019s rebuff to the British and the Torghut Mongols\u2019 epic trek back to the motherland. In one instance of the deployment of newly fashionable \u201cactive learning\u201d in the service of uncritical patriotism, a new lesson required students to organize a historical quiz on the topic: \u201cXinjiang, Tibet and Taiwan have been Chinese territory since ancient times\u201d (ibid., p. 132). The knowledge to be tested consisted largely of the dates when these regions came under the governance of the central regime. Notably absent from this lesson was any reference to the local inhabitants, their cultures, customs or histories unrelated to their ties to China.\n\nAccounts of rule under the \u201cminority\u201d Yuan and Qing dynasties retained a positive gloss, but acknowledgement of their distinctively non-Han or ethnically discriminatory features was largely eliminated. Reference to the introduction of the Phags-pa script under the Yuan was removed, as was discussion of religious diversity in their capital of Da-du. Mention of the Mongol\u2019s hierarchical classification of ethnic groups and the Manchu imposition of the queue (the long Manchu pigtail) for all males was also deleted. The effect of these changes was to dilute the \u201cethnic\u201d character of these dynasties, making them appear more assimilated to mainstream \u201cHan\u201d culture.\n\nRevisions also suggested growing reluctance to acknowledge past inter-ethnic antagonism, with accounts of Han-\u201cminority\u201d conflict significantly curtailed. An entire lesson devoted to the conflict between the Jurchen Jin and Southern Song was reduced to one brief section (PEP, 2001\u20132b, pp. 52\u201354). This entailed the removal of accounts of \u201cheroic\u201d Han resistance to the Jurchen attacks. Also deleted were the earlier accounts of conflict between the Mongols and the Ming, and of Ming responsibility for provoking the conflict with the Manchus that led to the dynasty\u2019s collapse.\n\nThe emphasis on national unity in the 2001-2 edition was in itself nothing new \u2013 but unity was implicitly portrayed in terms rather different to those that had prevailed in 1992. While Wang had invoked the Marxist principle of \u201cequality among ethnic groups\u201d to justify a partial de-centring of the narrative, the 2001-2 texts reinstated a significantly more Han-centric approach. Meanwhile, discussion of past instances of Han-\u201cminority\u201d conflict, let alone acknowledgement of any justification for \u201cminority\u201d challenges to Han authority, had become more sensitive as nervousness over regime legitimacy was heightened by mounting evidence that economic growth was not reconciling Tibetans and Uyghurs to Han dominance (Zang, 2015, p. 153).", "Please extract keywords from this: Lessons from the Osprey Garden\nMuch of biologist-naturalist Paul Spitzer\u2019s life has moved in time with the seasonal rhythms of one bird, the osprey, and one place\u2014the \u201cosprey garden.\u201d\n\nIn late spring he paddles his canoe into the Great Island saltmarsh, 500 acres of prime osprey habitat where the Connecticut River flows into Long Island Sound. In this marshy inlet, Spitzer checks for action in nests among 35 osprey platforms that have been erected here since the late 1950s. As he disembarks, the resident ospreys take to anxious flight. He raises a pole topped with a mirror over a platform nest. These days, he sees abundant breeding success in the mirror\u2019s reflection\u2014three healthy young birds with ragged crests and brown-spangled wings. But it wasn\u2019t always this way.\n\nSpitzer first stepped onto Great Island nearly 60 years ago, as an 11-year-old boy in 1957. That year, he accompanied birding legend Roger Tory Peterson on a Christmas Bird Count. Thus began a mentorship that set Spitzer onto a career path to becoming a ecologist.\n\nWhen Spitzer graduated from college, Peterson urged him to take up the question of what was causing a sudden and drastic decline among the ospreys.\n\n\u201cAt that time, the curtain was rising on the great DDT drama,\u201d says Spitzer.\n\nFrom the 1960s through the 1970s, Spitzer watched ospreys almost disappear from Connecticut, and he pioneered experiments that helped establish DDT as a cause of their decline. He has also seen ospreys make a triumphant recovery in the Connecticut River estuary. And with more than 300 active nests recorded in the state today, he is now turning his attention below the water, where the next challenge for osprey is a vanishing fish.\n\nThe Discovery of the Perils of DDT on Osprey Populations\nPeterson tracked the decline of local ospreys from 150 in the 1950s to just 13 in 1965. He and his wife Barbara tried to help the ospreys by building dozens of nest platforms to protect their nests from predators such as raccoons. But the birds still weren\u2019t bringing forth fledglings. Food didn\u2019t seem to be a problem\u2014there was no shortage of menhaden, the large-headed bait fish that is one of the osprey\u2019s primary food sources in Long Island Sound. Spitzer had spent hours watching the fish hawks rising from the water with menhaden nearly a foot long in their oversized talons.\n\n\u201cRoger began to suspect DDT,\u201d Spitzer says. In the 1940s and \u201850s, DDT was used to control mosquito populations in residential areas, especially along coasts and near wetlands. \u201cHe had a hunch the ospreys were ingesting the DDT from fish. Rachel Carson\u2019s findings were informing our discouraging field studies, and I was cutting my teeth as an ecologist studying this new paradigm of environmental toxicology.\u201d\n\nDuring nest checks, Spitzer found thin-shelled, collapsing eggs and was re-minded of a British study that showed similar thinning in peregrine falcon eggs.\n\nShortly after receiving his biology degree from Wesleyan University, Spitzer had the idea to isolate local ecological effects in Connecticut by switching eggs in osprey nests there with eggs from a healthy population of breeding osprey near Chesapeake Bay.\n\n\u201cNot nearly as much DDT was applied to Maryland saltmarshes, and it was probably diluted in the far larger Chesapeake system,\u201d says Spitzer. By performing the switch, he could isolate whether the problem was with local environmental conditions or intrinsic to the Connecticut eggs.\n\nThe Patuxent Wildlife Research Center in Maryland signed on to Spitzer\u2019s idea and provided staff to collect eggs. From the outset, Spitzer saw the Maryland eggs hatch healthy chicks in Connecticut, but not vice versa.\n\n\u201cThe embryos in Connecticut eggs died, and we found the shells to be thin by simple measurement,\u201d he says. \u201cWe also found dented or collapsed eggs in some Connecticut nests.\u201d None of these problems affected the Maryland eggs.\n\nNext, he arranged transfers of young nestlings from Maryland to Connecticut, to look beyond egg problems. The results were the same: \u201cVirtually all the Maryland nestlings fledged in Connecticut, [so there were] no problems with food at this time. The failure was egg viability,\u201d Spitzer says. Later lab tests revealed DDE (a breakdown product of DDT) as well as PCBs and another organochloride, dieldrin, at much higher concentrations in the Connecticut eggs compared to the Maryland eggs.\n\n\u201cAll signs pointed to Roger\u2019s hunch being right, that it was DDT,\u201d he says.\n\nDDT was banned in Connecticut in 1972, and two years later osprey numbers on Great Island bottomed out, with just a single nest remaining as the vestiges of DDT made their way out of the ecosystem.\n\nToday, there are approximately 100 active nests at Great Island and the overflow is helping populations at nearby Gardiners Island and eastern Long Island grow. Statewide, the Connecticut Audubon Society\u2019s osprey nation monitoring project recorded 337 active nests in 2016, and 490 fledged young throughout the state\u2014a rate nearly double that which Spitzer had calculated was necessary for a stable osprey population.\n\nNumbers like these, along with steady positive trends along Breeding Bird Survey routes, help explain why breeding ospreys are now abundant and widespread in Connecticut and throughout the eastern United States. Spitzer points to a combination of factors including an increase in artificial nest sites, a decrease in harmful residues in their food sources, and continued high levels of food availability, particularly Atlantic menhaden.\n\nOsprey and Menhaden\nFor the last three summers the Connecticut Audubon Society has sponsored Spitzer\u2019s ongoing work in the Connecticut River estuary, but the aim of the research has now shifted to monitoring the relationship between osprey and menhaden. As in the 1960s, Spitzer\u2019s attention is again focused on Great Island, now fittingly protected as a Roger Tory Peterson Wildlife Area. During June and July, Spitzer has documented that the ospreys\u2019 diet is 95 percent to 100 percent menhaden. Spitzer says the story is much the same from Connecticut to Virginia, with menhaden-fueled osprey nesting colonies experiencing a revival.\n\n\u201cOver 50 years of osprey study, we have moved from the sad story of DDT-induced egg failure and a declining population to the happy story of abundant ospreys,\u201d Spitzer says. \u201cOur ongoing legacy from osprey study must be the management of the East Coast ecosystem for abundant menhaden. We have to leave enough menhaden in the water to perform their precious and essential eco- nomic and ecological functions.\u201d\n\nRich in oils and fat, menhaden live in Atlantic coastal waters from Nova Scotia to northern Florida, but reach peak abundance in the Chesapeake Bay. In addition to serving as the primary food source for breeding ospreys and their chicks along the New England coast, menhaden are also a main food source for striped bass and bluefish. And, they constitute a significant fishery for people\u2014second only to pollock among the ranks of fish harvested by volume in the United States. But people don\u2019t eat menhaden for dinner. They process it into other forms, mostly pills.\n\nMost of the nearly 200,000-metric-ton annual menhaden catch is rendered into omega-3 fatty acid fish oil for the health supplement industry. And most of that catch comes via purse-seine fishing, in which two fishing boats circle around a single school of fish and enclose it within a gigantic net. These operations are extremely efficient at catching huge volumes of fish. Only one state (Virginia) currently allows purse-seine fishing of menhaden, but the fish caught in the Chesapeake Bay and Virginia waters account for 85 percent of the total menhaden harvest. \n\nBecause a large share of the range-wide menhaden population is clustered in the mid-Atlantic region, harvests there have a significant effect on the population as a whole. As the fish-oil market boomed in the 1990s and 2000s, menhaden populations began to dwindle. In 2010 stocks hit a 54-year low. In 2013 the Atlantic States Marine Fisheries Commission reduced the quota of commercial menhaden harvest by 20 percent. Spitzer attributes the recent robust East Coast osprey populations to the renewed health of the menhaden fishery following these new rules.\n\n\u201cIt was a huge win,\u201d says Spitzer.\n\nBut now, many ocean conservationists say menhaden are once again coming under intense fishing pressure. In 2015 and 2016, the quota was increased by about 10 percent, and the menhaden quota for 2017 has been increased by about 6 percent from 2016. Some industry representatives are suggesting that the menhaden quota could be raised by up to 30 percent without harming the overall fishery. Spitzer thinks the ASMFC should be more conservative in what it allows so that the menhaden population doesn\u2019t crash again, as it did earlier this decade. He also thinks the continued abundance of menhaden is critical to the continued abundance of ospreys. \n\n\u201cIt is a great blessing to have been able to study ospreys for 50 years and counting. I have observed so many positive outcomes for these birds over the years,\u201d Spitzer says. \u201cDecisions about menhaden now will affect not only fish, but birds, coastal ecosystems and, in the end, every one of us.\u201d", "Do the same thing for this list: Kansas\nJade Piros de Carvalho, director, Office of Broadband Development\nWebsite: https://www.kansascommerce.gov/officeofbroadbanddevelopment/ \nEmail: jade.piros@ks.gov\nPhone: (785) 296-3481\n\nKentucky\nMeghan E. Sandfoss, executive director, Office of Broadband Development\nWebsite: https://broadband.ky.gov/Pages/index.aspx\nEmail: meghan.sandfoss@ky.gov \nPhone: (502) 330-8713\n\nLouisiana\nVeneeth Iyengar, executive director, ConnectLa\nWebsite: https://connect.la.gov/\nEmail: Veneeth.lyengar@la.gov; connect@la.gov \nPhone: (225) 219-7594\n\nMaine\nPeggy Schaffer, director, ConnectMaine Authority\nAndrew Butcher, president, Maine Connectivity Authority\nWebsite: https://www.maineconnectivity.org/\nEmail: Peggy.schaffer@maine.gov; abutcher@maineconnectivity.org \nPhone: (207) 624-9807\n\nMaryland\nKenrick M. Gordon, director, Office of Statewide Broadband\nWebsite: https://dhcd.maryland.gov/Broadband/Pages/default.aspx\nEmail: Kenrick.Gordon@Maryland.gov\nPhone:(301) 429-7436\n\nRELATED\nFinding the money: A US broadband funding guide\nMassachusetts\nMichael Baldino, director and general counsel, Massachusetts Broadband Institute\nWebsite: https://broadband.masstech.org/\nEmail: baldino@masstech.org; broadband@masstech.org \nPhone: (508) 870-0312 \n\nMichigan\nEric Frederick, chief connectivity officer, Michigan High-Speed Internet Office\nWebsite: https://www.michigan.gov/leo/bureaus-agencies/mihi\nEmail: Fredericke1@michigan.gov\nPhone:\n\nMinnesota\nBree Maki, director, Office of Broadband Development\nWebsite: https://mn.gov/deed/programs-services/broadband/\nEmail: bree.maki@state.mn.us\nPhone: (651) 259-7289\n\nMississippi\nSally Burchfield Doty, director, Broadband Expansion and Accessibility of Mississippi\nWebsite: https://www.beam.ms.gov/\nEmail: Sally.Doty@beam.ms.gov\nPhone: (601) 359-5029\n\nMissouri\nBJ Tanksley, director, Office of Broadband Development\nWebsite: https://ded.mo.gov/content/broadband-development\nEmail: bj.tanksley@ded.mo.gov \nPhone: (573) 522-6261\n\nMontana\nChad Rupe, Broadband Program Manager\nWebsite: https://connectmt.mt.gov/\nEmail: chad.rupe@mt.gov; ConnectMTInfoRequests@ctnet.us \nPhone:\n\nNebraska\nPatrick Redmond, interim director, Broadband Office\nWebsite:https://broadband.nebraska.gov/Home\nEmail:patrick.redmond@nebraska.gov\nPhone:(402) 471-4181\n\nNevada\nBrian Mitchell, director, Office of Science, Innovation and Technology and State Broadband Office\nWebsite: https://osit.nv.gov/Broadband/Broadband/\nEmail: blmitchell@gov.nv.gov \nPhone: (775) 687-0988\n\nNew Hampshire\nMark Laliberte, broadband project manager, Office of Broadband Initiatives\nWebsite: https://www.nheconomy.com/about-us/office-of-broadband-initiatives\nEmail: mark.j.laliberte@livefree.nh.gov; broadband@livefree.nh.gov\nPhone: (603) 271-6351\n\nNew Jersey\nJoseph Rivera, Manager of Broadband Access\nWebsite: https://www.nj.gov/it/\nEmail: joseph.rivera@bpu.nj.gov\nPhone: (609) 322-9625\n\nNew Mexico\nMatt Schmit, Governor's Broadband Advisor\nKelly Schlegel, director, Office of Broadband Access and Expansion\nWebsite: https://www.doit.nm.gov/programs/broadband/\nEmail: Matt.Schmit@state.nm.us; Kelly.Schlegel@state.nm.us \nPhone: (505) 479-1093 \n\nNew York\nRob Johnson, Project Manager, ConnectALL\nWebsite: https://broadband.ny.gov/\nEmail: robert.johnson@esd.ny.gov\nPhone:(212) 803-3201\n\nNorth Carolina\nNate Denny, Deputy Secretary for Broadband and Digital Equity\nAngie Bailey, director, Broadband Infrastructure Office\nWebsite: https://www.ncbroadband.gov/\nEmail: nate.denny@nc.gov; angie.bailey@nc.gov\nPhone: (919) 397-2124; (919) 754-6690\n\nNorth Dakota\nDuane Schell, CTO\nKevin Sievert, Program Director of Broadband Deployment\nWebsite: https://www.ndit.nd.gov/about-us/broadband\nEmail: dschell@nd.gov; broadband@nd.gov \nPhone: (701) 328-4360 \n\nOhio\nPeter Voderberg, chief, BroadbandOhio\nWebsite: https://broadband.ohio.gov/home\nEmail:peter.voderberg@development.ohio.gov; BroadbandOhio@development.ohio.gov \nPhone: (614) 387-2114 \n\nOklahoma\nKirk Martin, interim executive director, Broadband Office\nWebsite: https://oklahoma.gov/broadband.html\nEmail: kirk.martin@broadband.ok.gov; broadband@broadband.ok.gov \nPhone:(405) 431-9237\n\nOregon\nDaniel Holbrook, Broadband Manager\nWebsite: https://www.oregon.gov/biz/programs/oregon\\_broadband\\_office/pages/default.aspx\nEmail: daniel.l.holbrook@biz.oregon.gov \nPhone: 503-877-7006\n\nPennsylvania\nBrandon Carson, executive director, Broadband Development Authority\nWebsite: https://dced.pa.gov/programs-funding/broadband-in-pennsylvania/pennsylvania-broadband-development-authority/\nEmail:bwcarson@pa.gov\nPhone:\n\nRhode Island\nBrian Thorn, director, Broadband Strategy\nWebsite: https://commerceri.com/broadband/\nEmail: brian.thorn@commerceri.com \nPhone:(401) 278-9186 \n\nSouth Carolina\nJim Stritzinger, director, Broadband Office\nWebsite: https://ors.sc.gov/broadband/office\nEmail: JStritzinger@ors.sc.gov\nPhone: (803) 737-8025\n\nSouth Dakota\nMike Waldner, Project manager, Connect SD\nWebsite: https://sdgoed.com/partners/connectsd/\nEmail:Mike.waldner@state.sd.us\nPhone: (605) 773-2483\n\nTennessee\nTaylre Beaty, Broadband Program Director\nWebsite: https://www.tn.gov/ecd/rural-development/tnecd-broadband-initiative.html\nEmail: taylre.beaty@tn.gov \nPhone:(615) 906-1057\n\nTexas\nGreg Contre, director, Broadband Development Office\nWebsite: https://comptroller.texas.gov/programs/broadband/\nEmail: Gregory.conte@cpa.texas.gov; broadband@cpa.texas.gov \nPhone: (512) 463-7611\n\nUtah\nRebecca Dilg, Broadband Director\nWebsite: https://business.utah.gov/broadband/\nEmail: rdilg@utah.gov\nPhone: (801) 538-8681\n\nVermont\nChristine Hallquist, executive director, Vermont Community Broadband Board\nWebsite: https://publicservice.vermont.gov/vt-community-broadband-board-vcbb\nEmail: christine.hallquist@vermont.gov\nPhone: (802) 636-7853\n\nVirginia\nTamarah Holmes, director, Office of Broadband\nWebsite: https://www.dhcd.virginia.gov/broadband\nEmail: tamarah.holmes@dhcd.virginia.gov \nPhone: (804) 371-7056\n\nWashington\nMark Vasconi, director, Broadband Office\nWebsite: www.broadband.wa.gov\nEmail: mark.vasconi@commerce.wa.gov\nPhone: (360) 918-1241\n\nWest Virginia\nKelly Workman, director, Office of Broadband\nWebsite: https://broadband.wv.gov/\nEmail:Kelly.A.Workman@wv.gov; WVBroadbandCouncil@wv.gov \nPhone: (304) 352-4115\n\nWisconsin\nAlyssa Kenney, director of broadband and digital equity, Wisconsin Public Service Commission\nWebsite: https://psc.wi.gov/Pages/ServiceType/Broadband.aspx\nEmail: Alyssa.kenney@wisconsin.gov; PSCStatebroadbandoffice@wisconsin.gov \nPhone: (608) 267-2160\n\nWyoming\nElaina Zempel, Broadband Manager, Wyoming Business Council\nWebsite: https://wyomingbusiness.org/communities/broadband/\nEmail: elaina.zempel@wyo.gov; broadbandoffice@wyo.gov \nPhone: (307) 777-2802", "It also has these methods: /\\*\\*\n \\* Iterates through the bonds on the input atom. If any of those bonds are\n \\* double or triple bonds, it returns false. Otherwise, it is SP3.\n \\*\n \\* @param atom\n \\* @return\n \\*/\n private boolean isSP3(IndigoObject atom) {\n for (IndigoObject nei : atom.iterateNeighbors()) {\n IndigoObject bond = nei.bond();\n int order = bond.bondOrder();\n if (order > 1) {\n return false;\n }\n }\n return true;\n\n }\n\n private Set> addConjugated(IndigoObject mol, IndigoObject croAtom, Set> keepAtoms) {\n Set> out = new HashSet<>();\n\n for (IndigoObject nei : croAtom.iterateNeighbors()) {\n int neiIndex = nei.index(); // index of neighbor atom\n IndigoObject bond = nei.bond();\n IndigoObject neiAtom = mol.getAtom(neiIndex);\n if (!isSP3(neiAtom)) {\n out.add(new Pair(mol.index(), bond.index()));\n if (!keepAtoms.contains(new Pair(mol.index(), neiAtom.index()))) {\n keepAtoms.add(new Pair(mol.index(), neiAtom.index()));\n out.addAll(addConjugated(mol, neiAtom, keepAtoms));\n }\n }\n }\n return out;\n }\n\n private void saveRxnImg(IndigoObject mrxn, String path) {\n Indigo indigo = new Indigo();\n IndigoRenderer renderer = new IndigoRenderer(indigo);\n indigo.setOption(\"render-output-format\", \"svg\");\n indigo.setOption(\"render-implicit-hydrogens-visible\", false);\n indigo.setOption(\"embedding-uniqueness\", \"none\");\n String smiles = mrxn.smiles();\n IndigoObject reimport = indigo.loadReaction(smiles);\n renderer.renderToFile(reimport, path);\n }\n\n public static void main(String[] args) throws Exception {\n verbose = true;\n\n // NOT\\_CENTER:\n System.out.println(\"RC\\_NOT\\_CENTER \" + Indigo.RC\\_NOT\\_CENTER);\n // UNMARKED: no atom map because atom is only on one side of the reaction\n System.out.println(\"RC\\_UNMARKED \" + Indigo.RC\\_UNMARKED);\n // CENTER:\n System.out.println(\"RC\\_CENTER \" + Indigo.RC\\_CENTER);\n // UNCHANGED: the bond is the same on both sides of the equation\n System.out.println(\"RC\\_UNCHANGED \" + Indigo.RC\\_UNCHANGED);\n // MADE\\_OR\\_BROKEN: the bond is either made or broken during the reaction\n System.out.println(\"RC\\_MADE\\_OR\\_BROKEN \" + Indigo.RC\\_MADE\\_OR\\_BROKEN);\n // ORDER\\_CHANGED: went from double bond to single bond, etc\n System.out.println(\"RC\\_ORDER\\_CHANGED \" + Indigo.RC\\_ORDER\\_CHANGED);\n\n// String reaction = \"[C:11]([H:12])([H:13])([H:14])[C:7]([H:8])=[C:6]([H:10])[C:1]([H:3])([H])[O:5]([H])>>[C:11]([H:12])([H:13])([H:14])[C:7]([H:8])=[C:6]([H:10])[C:1]([H:3])=[O:5]\"; // proponyl alcohol to methyl acrolein\n// System.out.println(newReaction);\n// String reaction = \"[C:7]([H:8])([H:9])=[C:6]([H:10])[C:1]([H:3])([H])[O:5]([H])>>[C:7]([H:8])([H:9])=[C:6]([H:10])[C:1]([H:3])=[O:5]\"; // allyl alcohol to acrolein\n// String reaction = \"[N:1]([H:2])[H] >> [N:1]([H:2])C(=O)C\"; // acetylation\n// String newReaction = reaction.replaceAll(\"\\\\[H\", \"[At\");\n// String reaction = \"[C:3](/[C:1]([O:20][At])([At:14])[At:11])(=[C:4](\\\\[c:2]1[c:12]([At:16])[c:10]([At:17])[c:6]([O:5][At:8])[c:13]([At:19])[c:15]1[At:18])/[At:7])\\\\[At:9]>>C(C([O:20][C:1](/[C:3](=[C:4](/[c:2]1[c:12]([At:16])[c:10]([At:17])[c:6]([O:5][At:8])[c:13]([At:19])[c:15]1[At:18])\\\\[At:7])/[At:9])([At:14])[At:11])=O)([At])([At])[At]\";\n// String reaction = \"[c:1]1([c:2]([C:12](=[O:14])C(O[At:13])=O)[c:5]([At:7])[c:3]([At:8])[c:4]([O:6][At:9])[c:1]1[At:10])[At:11]>>[c:1]1([c:2]([C:12](=[O:14])[At:13])[c:5]([At:7])[c:3]([At:8])[c:4]([O:6][At:9])[c:1]1[At:11])[At:10]\";\n String reaction = \"[C:1]([C:1]([C:2]([C:3]([C:4]([C:5]([C:6]([C:7]([C:8]([C:9]([C:10]([C:11]([C:12]([C:13]([C:14]([C:46](=[O:47])[At])([At:15])[At:29])([At:17])[At:31])([At:30])[At:16])([At:33])[At:19])([At:18])[At:32])([At:21])[At:35])([At:20])[At:34])([At:37])[At:23])([At:22])[At:36])([At:39])[At:25])([At:24])[At:38])([At:41])[At:27])([At:26])[At:40])([At:28])[At:42])([At:43])([At:45])[At:44]>>[C:1]([C:1]([C:2]([C:3]([C:4]([C:5]([C:6]([C:7]([C:8]([C:9]([C:10]([C:11]([C:12]([C:13]([C:14]([C:46](SC(C(N=C(O[At])C(C(N=C(O[At])C(O[At])(C(C(OP(OP(OC([C@]1(O[C@]([n]2c3[n]c([n]c(N([At])[At])c3[n]c2[At])[At])([At])[C@@](O[At])([At])[C@@]1(OP(=O)(O[At])O[At])[At])[At])([At])[At])(=O)O[At])(=O)O[At])([At])[At])(C([At])([At])[At])C([At])([At])[At])[At])([At])[At])([At])[At])([At])[At])([At])[At])=[O:47])([At:29])[At:15])([At:31])[At:17])([At:30])[At:16])([At:33])[At:19])([At:18])[At:32])([At:21])[At:35])([At:20])[At:34])([At:23])[At:37])([At:36])[At:22])([At:39])[At:25])([At:38])[At:24])([At:41])[At:27])([At:40])[At:26])([At:44])[At:42])([At:28])([At:43])[At:45] |w:78,a:89,91,107,111|\";\n // creating the rxn molecule\n Indigo indigo = new Indigo();\n\n IndigoObject mappedRxn = indigo.loadReaction(reaction);\n mappedRxn.aromatize();\n mappedRxn.correctReactingCenters();\n\n IndigoRenderer renderer = new IndigoRenderer(indigo);\n renderer.renderToFile(mappedRxn, \"IndigoROExtractor-mapped.svg\");\n\n IndigoObject aclone = mappedRxn.clone();\n for (IndigoObject mol : aclone.iterateMolecules()) {\n for (int i = 0; i < mol.countAtoms(); i++) {\n IndigoObject atom = mol.getAtom(i);\n aclone.setAtomMappingNumber(atom, i);\n }\n }\n renderer.renderToFile(aclone, \"IndigoROExtractor-indices.svg\");\n\n IndigoROExtractor roe = new IndigoROExtractor();\n\n // mappedRxn, stereo, hydrogenated, complete, rotype\n String ro = roe.run(mappedRxn, false, true, true, IndigoROExtractor.ELECTRONIC);\n\n System.out.println(\"\\n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\nResult\\n\" + ro);\n IndigoObject rxn1 = indigo.loadQueryReaction(ro);\n renderer.renderToFile(rxn1, \"IndigoROExtractor-finalresult.svg\");\n }", "create linked database for your linkedin connections and start 1st entry into table for following text of profile : Ehab Al Khiary 1st degree connection1st\nCEO | Founder | Investor | Board Member\n\nERC International Investment\n\nINSEAD\nSaudi Arabia Contact info\n500+ connections\nRami Al Karmi, Vish Narain, and 1 other mutual connectionRami Al Karmi, Vish Narain, and 1 other mutual connection\n\nMessage\n\nMore\nAboutAbout\nMr. Al Khiary is highly experienced executive in the field of the Information Technologies and Telecommunications. He is known for his involvements and contributions in the ICT field for over 20 years, both as a government employee, executive, entrepreneur, investor, and board member of several companies. Mr. Al Khiary is highly experienced executive in the field of the Information Technologies and Telecommunications. He is known for his involvements and contributions in the ICT field for over 20 years, both as a government employee, executive, entrepreneur, investor, and board member of several companies. \nActivityActivity\n20,322 followers20,322 followers\n\nEhab hasn't posted latelyEhab hasn't posted lately\nEhab\u2019s recent posts and comments will be displayed here.Ehab\u2019s recent posts and comments will be displayed here.\nShow all activity\nExperienceExperience\nCo-FounderCo-Founder\nERC International Investment ERC International Investment \nJul 2017 - Present \u00b7 5 yrs 9 mosJul 2017 - Present \u00b7 5 yrs 9 mos\nCayman IslandsCayman Islands\nERC is an early stage investment company with tech focused in the MENA region.\nThe objective is to leverage close to 100 years of the founders\u2019 experience and relationship to expedite the growth of these startups. Today, our portfolio ranges from digital gifting, logistics, insurtech, and FintechERC is an early stage investment company with tech focused in the MENA region. The objective is to leverage close to 100 years of the founders\u2019 experience and relationship to expedite the growth of these startups. Today, our portfolio ranges from digital gifting, logistics, insurtech, and Fintech\u2026see more\nYOUGotaGift logo\nChief Growth OfficerChief Growth Officer\nYouGotaGiftYouGotaGift\nJan 2020 - Present \u00b7 3 yrs 3 mosJan 2020 - Present \u00b7 3 yrs 3 mos\nSaudi ArabiaSaudi Arabia\nYouGotaGift is an end to end digital platform for processing and distributing digital Gift Cards from top retailers in the Middle East. As a Fintech & Payment provider, YouGotaGift delivers prepaid digital cards to consumers (B2C) and businesses (B2B) including employee rewards, customers rewards, channel incentives and loyalty.YouGotaGift is an end to end digital platform for processing and distributing digital Gift Cards from top retailers in the Middle East. As a Fintech & Payment provider, YouGotaGift delivers prepaid digital cards to consumers (B2C) and businesses (B2B) including employee rewards, customers rewards, channel incentives and loyalty.\u2026see more\nArabian Information Technology Co. (ARCOM) logo\nCEO & Board MemberCEO & Board Member\nArabian Information Technology Co. (ARCOM) \u00b7 Full-timeArabian Information Technology Co. (ARCOM) \u00b7 Full-time\nJun 2015 - Present \u00b7 7 yrs 10 mosJun 2015 - Present \u00b7 7 yrs 10 mos\nSaudi ArabiaSaudi Arabia\nARCOM is an innovative progressive system integrator with 30 years of successful track record providing IT and telecom services and solutions to governmental and private sectors in the Kingdom of Saudi Arabia and Gulf.ARCOM is an innovative progressive system integrator with 30 years of successful track record providing IT and telecom services and solutions to governmental and private sectors in the Kingdom of Saudi Arabia and Gulf.\nARCOMARCOM\nARCOM is an innovative and progressive system integrator with over 30 years of successful track record providing IT\\telecom services and solutions to public and private sectors in the Kingdom of Saudi Arabia.ARCOM is an innovative and progressive system integrator with over 30 years of successful track record providing IT\\telecom services and solutions to public and private sectors in the Kingdom of Saudi Arabia.\nPlatinum Events UAE logo\nCo-FounderCo-Founder\nPlatinum Events UAEPlatinum Events UAE\nSep 2009 - Present \u00b7 13 yrs 7 mosSep 2009 - Present \u00b7 13 yrs 7 mos\nPlatinum has established it self as a leading Event Management, wedding planner, and Concierge Service Provider. Our continued success allowed us to expand into newer and equally exciting division such as Platinum Magazine, Platinum Property, and Platinum Collection.\n\nPlatinum has acquired a reputation for organizing some of the most innovative, spectacular and high profile corporate and private events. Platinum has established it self as a leading Event Management, wedding planner, and Concierge Service Provider. Our continued success allowed us to expand into newer and equally exciting division such as Platinum Magazine, Platinum Property, and Platinum Collection. Platinum has acquired a reputation for organizing some of the most innovative, spectacular and high profile corporate and private events. \u2026see more\nPlatinum - Coming SoonPlatinum - Coming Soon\nSocialHub logo\nCo-Founder & Board MemberCo-Founder & Board Member\nSocial HubSocial Hub\nFeb 2013 - Feb 2017 \u00b7 4 yrs 1 moFeb 2013 - Feb 2017 \u00b7 4 yrs 1 mo\nSaudi ArabiaSaudi Arabia\nSocial Hub is one stop shop for Social Media Services that links organizations to their audience.\n\nSocial Hub offers world-class services with local expertise and flavor. These services ranges from setting strategy, engagement campaign, content generation & socialization, monitoring, and consultation.Social Hub is one stop shop for Social Media Services that links organizations to their audience. Social Hub offers world-class services with local expertise and flavor. These services ranges from setting strategy, engagement campaign, content generation & socialization, monitoring, and consultation.\u2026see more\nShow all 11 experiences\nEducationEducation\nINSEAD logo\nINSEADINSEAD\nDigital Transformation Leadership ProgramDigital Transformation Leadership Program\n2020 - 20202020 - 2020\nMIT Sloan School of Management logo\nMIT Sloan School of ManagementMIT Sloan School of Management\nEntrepreneurial Masters ProgramEntrepreneurial Masters Program\n2013 - 20152013 - 2015\nHarvard Business School Executive Education logo\nHarvard Business School Executive EducationHarvard Business School Executive Education\nYPO President CourseYPO President Course\n2011 - 20112011 - 2011\nShow all 5 education\nLicenses & certificationsLicenses & certifications\n500 Global logo\nVC UnlockedVC Unlocked\n500 Global500 Global\nIssued Nov 2022Issued Nov 2022\nShow credential\nStanford Center for Professional Development logo\nInnovation Strategy Innovation Strategy \nStanford Center for Professional DevelopmentStanford Center for Professional Development\nIssued Jan 2021Issued Jan 2021\nStanford Center for Professional Development logo\nProduct Management Transforming Opportunities into Great Products Product Management Transforming Opportunities into Great Products \nStanford Center for Professional DevelopmentStanford Center for Professional Development\nIssued Jan 2021Issued Jan 2021\nShow all 5 licenses & certifications\nSkillsSkills\nPMPPMP\n\nEndorsed by Abdullah Aljebrein who is highly skilled at thisEndorsed by Abdullah Aljebrein who is highly skilled at this\n\nEndorsed by 3 colleagues at Arabian Information Technology Co. (ARCOM)Endorsed by 3 colleagues at Arabian Information Technology Co. (ARCOM)\n99+ endorsements99+ endorsements\n\nEndorse\nTelecommunicationsTelecommunications\n\nEndorsed by Mohammed Al Ansari and 25 others who are highly skilled at thisEndorsed by Mohammed Al Ansari and 25 others who are highly skilled at this\n\nEndorsed by 6 colleagues at Arabian Information Technology Co. (ARCOM)Endorsed by 6 colleagues at Arabian Information Technology Co. (ARCOM)\n99+ endorsements99+ endorsements\n\nEndorse\nInformation SecurityInformation Security\n\nEndorsed by Ahmad AlOmran who is highly skilled at thisEndorsed by Ahmad AlOmran who is highly skilled at this\n\nEndorsed by 3 colleagues at stcEndorsed by 3 colleagues at stc\n36 endorsements36 endorsements\n\nEndorse\nShow all 28 skills\nOrganizationsOrganizations\nSocial Media Club Saudi Arabia ChapterSocial Media Club Saudi Arabia Chapter\nFounding Memeber \u00b7 Jan 2013 - PresentFounding Memeber \u00b7 Jan 2013 - Present\nSocial Media Club is non-profit and the world's largest community of Social Media Professionals with primary mission is to expand digital media literacy, promote standard technologies, encourage ethical behavior and share best practices.\nSocial Media Club is non-profit and the world's largest community of Social Media Professionals with primary mission is to expand digital media literacy, promote standard technologies, encourage ethical behavior and share best practices. \nMobile MondayMobile Monday\nFounding Memeber - Riyadh Chapter \u00b7 Sep 2012 - PresentFounding Memeber - Riyadh Chapter \u00b7 Sep 2012 - Present\nMobileMonday\u2122 (MoMo) is an open community platform of mobile industry visionaries, developers and influential individuals fostering brand neutral cooperation and cross-border P2P business opportunities through live networking events to demo products, share ideas and discuss trends from both local and global markets.MobileMonday\u2122 (MoMo) is an open community platform of mobile industry visionaries, developers and influential individuals fostering brand neutral cooperation and cross-border P2P business opportunities through live networking events to demo products, share ideas and discuss trends from both local and global markets.\u2026see more\nInterestsInterests\nTop VoicesTop Voices\nCompaniesCompanies\nGroupsGroups\nNewslettersNewsletters\nSchoolsSchools\nAdena Friedman profile picture\nAdena FriedmanAdena Friedman\n\u00b7 3rdThird degree connection\nChair and Chief Executive Officer at NasdaqChair and Chief Executive Officer at Nasdaq\n602,019 followers602,019 followers\n\nFollow\nCharles Best profile picture\nCharles BestCharles Best\n\u00b7 3rdThird degree connection\nCo-CEO of Lakeshore Learning and Founder of DonorsChooseCo-CEO of Lakeshore Learning and Founder of DonorsChoose\n281,028 followers281,028 followers\n\nFollow\nShow all 83 Top Voices", "---------------------------------------------------------------------------\nLookupError Traceback (most recent call last)\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 83 try:\n---> 84 root = nltk.data.find(f\"{self.subdir}/{zip\\_name}\")\n 85 except LookupError:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\data.py in find(resource\\_name, paths)\n 582 resource\\_not\\_found = f\"\\n{sep}\\n{msg}\\n{sep}\\n\"\n--> 583 raise LookupError(resource\\_not\\_found)\n 584 \n\nLookupError: \n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n Resource omw-1.4 not found.\n Please use the NLTK Downloader to obtain the resource:\n\n >>> import nltk\n >>> nltk.download('omw-1.4')\n \n For more information see: https://www.nltk.org/data.html\n\n Attempted to load corpora/omw-1.4.zip/omw-1.4/\n\n Searched in:\n - 'C:\\\\Users\\\\rockr/nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\share\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\lib\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\AppData\\\\Roaming\\\\nltk\\_data'\n - 'C:\\\\nltk\\_data'\n - 'D:\\\\nltk\\_data'\n - 'E:\\\\nltk\\_data'\n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\nDuring handling of the above exception, another exception occurred:\n\nLookupError Traceback (most recent call last)\n~\\AppData\\Local\\Temp\\ipykernel\\_9724\\3827873343.py in \n 41 \n 42 # Preprocess train and test text data\n---> 43 train\\_df['text'] = train\\_df['text'].apply(preprocess\\_text)\n 44 test\\_df['text'] = test\\_df['text'].apply(preprocess\\_text)\n 45 \n\n~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py in apply(self, func, convert\\_dtype, args, \\*\\*kwargs)\n 4431 dtype: float64\n 4432 \"\"\"\n-> 4433 return SeriesApply(self, func, convert\\_dtype, args, kwargs).apply()\n 4434 \n 4435 def \\_reduce(\n\n~\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py in apply(self)\n 1086 return self.apply\\_str()\n 1087 \n-> 1088 return self.apply\\_standard()\n 1089 \n 1090 def agg(self):\n\n~\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py in apply\\_standard(self)\n 1141 # List[Union[Callable[..., Any], str]]]]]\"; expected\n 1142 # \"Callable[[Any], Any]\"\n-> 1143 mapped = lib.map\\_infer(\n 1144 values,\n 1145 f, # type: ignore[arg-type]\n\n~\\Anaconda3\\lib\\site-packages\\pandas\\\\_libs\\lib.pyx in pandas.\\_libs.lib.map\\_infer()\n\n~\\AppData\\Local\\Temp\\ipykernel\\_9724\\3827873343.py in preprocess\\_text(text)\n 35 # Lemmatize\n 36 lemmatizer = WordNetLemmatizer()\n---> 37 tokens = [lemmatizer.lemmatize(token) for token in tokens]\n 38 # Join tokens back into a string\n 39 text = ' '.join(tokens)\n\n~\\AppData\\Local\\Temp\\ipykernel\\_9724\\3827873343.py in (.0)\n 35 # Lemmatize\n 36 lemmatizer = WordNetLemmatizer()\n---> 37 tokens = [lemmatizer.lemmatize(token) for token in tokens]\n 38 # Join tokens back into a string\n 39 text = ' '.join(tokens)\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\stem\\wordnet.py in lemmatize(self, word, pos)\n 43 :return: The lemma of `word`, for the given `pos`.\n 44 \"\"\"\n---> 45 lemmas = wn.\\_morphy(word, pos)\n 46 return min(lemmas, key=len) if lemmas else word\n 47 \n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_getattr\\_\\_(self, attr)\n 119 raise AttributeError(\"LazyCorpusLoader object has no attribute '\\_\\_bases\\_\\_'\")\n 120 \n--> 121 self.\\_\\_load()\n 122 # This looks circular, but its not, since \\_\\_load() changes our\n 123 # \\_\\_class\\_\\_ to something new:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 87 \n 88 # Load the corpus.\n---> 89 corpus = self.\\_\\_reader\\_cls(root, \\*self.\\_\\_args, \\*\\*self.\\_\\_kwargs)\n 90 \n 91 # This is where the magic happens! Transform ourselves into\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py in \\_\\_init\\_\\_(self, root, omw\\_reader)\n 1174 )\n 1175 else:\n-> 1176 self.provenances = self.omw\\_prov()\n 1177 \n 1178 # A cache to store the wordnet data of multiple languages\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py in omw\\_prov(self)\n 1283 provdict = {}\n 1284 provdict[\"eng\"] = \"\"\n-> 1285 fileids = self.\\_omw\\_reader.fileids()\n 1286 for fileid in fileids:\n 1287 prov, langfile = os.path.split(fileid)\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_getattr\\_\\_(self, attr)\n 119 raise AttributeError(\"LazyCorpusLoader object has no attribute '\\_\\_bases\\_\\_'\")\n 120 \n--> 121 self.\\_\\_load()\n 122 # This looks circular, but its not, since \\_\\_load() changes our\n 123 # \\_\\_class\\_\\_ to something new:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 84 root = nltk.data.find(f\"{self.subdir}/{zip\\_name}\")\n 85 except LookupError:\n---> 86 raise e\n 87 \n 88 # Load the corpus.\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 79 else:\n 80 try:\n---> 81 root = nltk.data.find(f\"{self.subdir}/{self.\\_\\_name}\")\n 82 except LookupError as e:\n 83 try:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\data.py in find(resource\\_name, paths)\n 581 sep = \"\\*\" \\* 70\n 582 resource\\_not\\_found = f\"\\n{sep}\\n{msg}\\n{sep}\\n\"\n--> 583 raise LookupError(resource\\_not\\_found)\n 584 \n 585 \n\nLookupError: \n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n Resource omw-1.4 not found.\n Please use the NLTK Downloader to obtain the resource:\n\n >>> import nltk\n >>> nltk.download('omw-1.4')\n \n For more information see: https://www.nltk.org/data.html\n\n Attempted to load corpora/omw-1.4\n\n Searched in:\n - 'C:\\\\Users\\\\rockr/nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\share\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\lib\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\AppData\\\\Roaming\\\\nltk\\_data'\n - 'C:\\\\nltk\\_data'\n - 'D:\\\\nltk\\_data'\n - 'E:\\\\nltk\\_data'\n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\nplease fix this error", "---------------------------------------------------------------------------\nLookupError Traceback (most recent call last)\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 83 try:\n---> 84 root = nltk.data.find(f\"{self.subdir}/{zip\\_name}\")\n 85 except LookupError:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\data.py in find(resource\\_name, paths)\n 582 resource\\_not\\_found = f\"\\n{sep}\\n{msg}\\n{sep}\\n\"\n--> 583 raise LookupError(resource\\_not\\_found)\n 584 \n\nLookupError: \n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n Resource omw-1.4 not found.\n Please use the NLTK Downloader to obtain the resource:\n\n >>> import nltk\n >>> nltk.download('omw-1.4')\n \n For more information see: https://www.nltk.org/data.html\n\n Attempted to load corpora/omw-1.4.zip/omw-1.4/\n\n Searched in:\n - 'C:\\\\Users\\\\rockr/nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\share\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\lib\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\AppData\\\\Roaming\\\\nltk\\_data'\n - 'C:\\\\nltk\\_data'\n - 'D:\\\\nltk\\_data'\n - 'E:\\\\nltk\\_data'\n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\nDuring handling of the above exception, another exception occurred:\n\nLookupError Traceback (most recent call last)\n~\\AppData\\Local\\Temp\\ipykernel\\_9724\\3118448898.py in \n 42 \n 43 # Preprocess train and test text data\n---> 44 train\\_df['text'] = train\\_df['text'].apply(preprocess\\_text)\n 45 test\\_df['text'] = test\\_df['text'].apply(preprocess\\_text)\n 46 \n\n~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py in apply(self, func, convert\\_dtype, args, \\*\\*kwargs)\n 4431 dtype: float64\n 4432 \"\"\"\n-> 4433 return SeriesApply(self, func, convert\\_dtype, args, kwargs).apply()\n 4434 \n 4435 def \\_reduce(\n\n~\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py in apply(self)\n 1086 return self.apply\\_str()\n 1087 \n-> 1088 return self.apply\\_standard()\n 1089 \n 1090 def agg(self):\n\n~\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py in apply\\_standard(self)\n 1141 # List[Union[Callable[..., Any], str]]]]]\"; expected\n 1142 # \"Callable[[Any], Any]\"\n-> 1143 mapped = lib.map\\_infer(\n 1144 values,\n 1145 f, # type: ignore[arg-type]\n\n~\\Anaconda3\\lib\\site-packages\\pandas\\\\_libs\\lib.pyx in pandas.\\_libs.lib.map\\_infer()\n\n~\\AppData\\Local\\Temp\\ipykernel\\_9724\\3118448898.py in preprocess\\_text(text)\n 36 # Lemmatize\n 37 lemmatizer = WordNetLemmatizer()\n---> 38 tokens = [lemmatizer.lemmatize(token) for token in tokens]\n 39 # Join tokens back into a string\n 40 text = ' '.join(tokens)\n\n~\\AppData\\Local\\Temp\\ipykernel\\_9724\\3118448898.py in (.0)\n 36 # Lemmatize\n 37 lemmatizer = WordNetLemmatizer()\n---> 38 tokens = [lemmatizer.lemmatize(token) for token in tokens]\n 39 # Join tokens back into a string\n 40 text = ' '.join(tokens)\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\stem\\wordnet.py in lemmatize(self, word, pos)\n 43 :return: The lemma of `word`, for the given `pos`.\n 44 \"\"\"\n---> 45 lemmas = wn.\\_morphy(word, pos)\n 46 return min(lemmas, key=len) if lemmas else word\n 47 \n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_getattr\\_\\_(self, attr)\n 119 raise AttributeError(\"LazyCorpusLoader object has no attribute '\\_\\_bases\\_\\_'\")\n 120 \n--> 121 self.\\_\\_load()\n 122 # This looks circular, but its not, since \\_\\_load() changes our\n 123 # \\_\\_class\\_\\_ to something new:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 87 \n 88 # Load the corpus.\n---> 89 corpus = self.\\_\\_reader\\_cls(root, \\*self.\\_\\_args, \\*\\*self.\\_\\_kwargs)\n 90 \n 91 # This is where the magic happens! Transform ourselves into\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py in \\_\\_init\\_\\_(self, root, omw\\_reader)\n 1174 )\n 1175 else:\n-> 1176 self.provenances = self.omw\\_prov()\n 1177 \n 1178 # A cache to store the wordnet data of multiple languages\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py in omw\\_prov(self)\n 1283 provdict = {}\n 1284 provdict[\"eng\"] = \"\"\n-> 1285 fileids = self.\\_omw\\_reader.fileids()\n 1286 for fileid in fileids:\n 1287 prov, langfile = os.path.split(fileid)\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_getattr\\_\\_(self, attr)\n 119 raise AttributeError(\"LazyCorpusLoader object has no attribute '\\_\\_bases\\_\\_'\")\n 120 \n--> 121 self.\\_\\_load()\n 122 # This looks circular, but its not, since \\_\\_load() changes our\n 123 # \\_\\_class\\_\\_ to something new:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 84 root = nltk.data.find(f\"{self.subdir}/{zip\\_name}\")\n 85 except LookupError:\n---> 86 raise e\n 87 \n 88 # Load the corpus.\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 79 else:\n 80 try:\n---> 81 root = nltk.data.find(f\"{self.subdir}/{self.\\_\\_name}\")\n 82 except LookupError as e:\n 83 try:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\data.py in find(resource\\_name, paths)\n 581 sep = \"\\*\" \\* 70\n 582 resource\\_not\\_found = f\"\\n{sep}\\n{msg}\\n{sep}\\n\"\n--> 583 raise LookupError(resource\\_not\\_found)\n 584 \n 585 \n\nLookupError: \n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n Resource omw-1.4 not found.\n Please use the NLTK Downloader to obtain the resource:\n\n >>> import nltk\n >>> nltk.download('omw-1.4')\n \n For more information see: https://www.nltk.org/data.html\n\n Attempted to load corpora/omw-1.4\n\n Searched in:\n - 'C:\\\\Users\\\\rockr/nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\share\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\lib\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\AppData\\\\Roaming\\\\nltk\\_data'\n - 'C:\\\\nltk\\_data'\n - 'D:\\\\nltk\\_data'\n - 'E:\\\\nltk\\_data'\n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n\nstill error", "@charset \"UTF-8\";\n\n\\* { margin:0; padding:0; text-decoration:none; font-family:'Noto Sans KR', sans-serif; }\n\n.square\\_div{ position:relative; width:100%; }\n\n/\\* login CSS start \\*/\n.div-invalid {\n color: red !important;\n}\n\n.email-invalid {\n border-color: red !important;\n}\n.css-14gy7wr {\n display: block;\n position: fixed;\n inset: 0px;\n z-index: 100;\n background: rgba(0, 0, 0, 0.56);\n overflow: hidden scroll;\n}\n\n.css-rpyl6s {\n position: absolute;\n inset: 0px;\n z-index: 101;\n}\n@media (min-width: 719px) {\n .css-rpyl6s {\n text-align: center;\n padding: 20px 0px;\n overflow: auto;\n }\n}\n\ninput:focus{\n outline: none;\n}\n.css-ikkedy {\n position: relative;\n background: rgb(255, 255, 255);\n width: 100%;\n height: 100%;\n box-shadow: rgb(0 0 0 / 12%) 0px 0px 6px 0px;\n overflow: hidden;\n}\n@media (min-width: 719px) {\n .css-ikkedy {\n top:15%;\n display: inline-block;\n position: relative;\n vertical-align: middle;\n text-align: left;\n width: 375px;\n height: auto;\n min-height: 540px;\n border-radius: 6px;\n overflow: auto;\n }\n}\n\n.css-1i2oi66 {\n padding: 32px 0px 16px;\n}\n\n.css-17bvwx1 {\n text-align: center;\n margin: 0px 0px 14px;\n overflow: hidden;\n}\n\n.css-1xku4w9 {\n display: inline-block;\n background: url(/images/watcha\\_main\\_logo.jpg) center center / contain no-repeat;\n width: 198px;\n height: 38.03px;\n}\n\n.css-g6a59h {\n font-size: 17px;\n letter-spacing: -0.5px;\n line-height: 22px;\n font-weight: 700;\n text-align: center;\n margin: 24px 0px 20px;\n}\n\n/\\* login section css start \\*/\n.css-1y901al-Row {\n margin: 0px 20px;\n}\n\n.css-1o72pil {\n padding: 4px 0px;\n overflow: hidden;\n}\n\n.css-a4glo0 {\n display: flex;\n -webkit-box-align: center;\n align-items: center;\n background: rgb(245, 245, 245);\n box-sizing: border-box;\n width: 100%;\n height: 44px;\n padding: 0px 12px;\n border-radius: 6px;\n}\n\n.css-1smbjja {\n display: flex;\n flex: 1 1 0%;\n}\n\n.css-1oyrbwm {\n background: transparent;\n font-weight: 400;\n font-size: 16px;\n letter-spacing: -0.6px;\n line-height: 21px;\n width: 100%;\n padding: 0px;\n border: 0px;\n overflow: hidden;\n text-overflow: ellipsis;\n caret-color: rgb(255, 47, 110);\n}\n\n.css-lcodwd {\n display: none;\n -webkit-box-align: center;\n align-items: center;\n width: 24px;\n height: 100%;\n}\n\n.css-qe0tnm {\n display: inline-block;\n background: url(/images/cencel\\_button.svg) center center / cover no-repeat;\n width: 24px;\n height: 24px;\n cursor: pointer;\n}\n\n.css-gem1s0 {\n display: inline-block;\n background-size: cover;\n width: 24px;\n height: 24px;\n margin: 0px 0px 0px 24px;\n}\n\n.css-qr0uqd-StylelessButton {\n padding: 0px;\n border: none;\n cursor: pointer;\n background: rgb(255, 47, 110);\n color: rgb(255, 255, 255);\n text-align: center;\n font-size: 17px;\n font-weight: 400;\n letter-spacing: -0.7px;\n line-height: 22px;\n width: 100%;\n height: 44px;\n border-radius: 6px;\n margin: 16px 0px 0px;\n}\n\nbutton,\n[type=\"button\"],\n[type=\"reset\"],\n[type=\"submit\"] {\n -webkit-appearance: button;\n}\n\nbutton,\ninput,\noptgroup,\nselect,\ntextarea {\n font-size: 100%;\n}\n\nbutton,\ninput,\noptgroup,\nselect,\ntextarea {\n line-height: normal;\n}\n\nbutton,\nselect {\n text-transform: none;\n}\n\nbutton,\ninput {\n overflow: visible;\n}\n\nbutton,\ninput,\noptgroup,\nselect,\ntextarea {\n font-family: inherit;\n font-size: 100%;\n line-height: 1.15;\n margin: 0;\n}\n\n.css-liv8hf {\n font-size: 15px;\n font-weight: 400;\n letter-spacing: -0.5px;\n line-height: 20px;\n text-align: center;\n margin: 20px 0px 14px;\n}\n\n.css-gq8fs1-StylelessButton {\n background: none;\n padding: 0px;\n border: none;\n margin: 0px;\n cursor: pointer;\n color: rgb(255, 47, 110);\n}\n\n.css-gcz1qq {\n font-size: 15px;\n font-weight: 400;\n letter-spacing: -0.5px;\n line-height: 20px;\n color: rgb(140, 140, 140);\n text-align: center;\n}\n\n.css-gq8fs1-StylelessButton {\n background: none;\n padding: 0px;\n border: none;\n margin: 0px;\n cursor: pointer;\n color: rgb(255, 47, 110);\n}\n\n.css-dnzt4 {\n position: relative;\n color: black;\n text-align: center;\n height: 1.5em;\n border: 0px;\n outline: 0px;\n margin: 24px 0px;\n}\n.css-dnzt4::before {\n content: \"\";\n position: absolute;\n top: 50%;\n left: 0px;\n width: 100%;\n border-top: 1px solid rgb(216, 216, 216);\n}\n\nh1,\nh3,\np,\nhr {\n margin: 0px;\n}\n\n.css-dnzt4::after {\n content: \"OR\";\n display: inline-block;\n position: relative;\n top: -2px;\n background-color: rgb(255, 255, 255);\n color: rgb(160, 160, 160);\n font-size: 14px;\n font-weight: 400;\n letter-spacing: -0.3px;\n line-height: 19px;\n vertical-align: middle;\n padding: 0px 14px;\n}\n\n.css-brz23g {\n display: flex;\n flex-direction: row;\n -webkit-box-pack: center;\n justify-content: center;\n -webkit-box-align: center;\n align-items: center;\n gap: 14px;\n list-style: none;\n padding-inline-start: 0px;\n}\n\nhr {\n box-sizing: content-box;\n height: 0;\n overflow: visible;\n}\n\n.css-jh98cl {\n background-color: rgb(247, 247, 247);\n color: rgb(140, 140, 140);\n font-size: 15px;\n font-weight: 400;\n letter-spacing: -0.2px;\n line-height: 23px;\n text-align: center;\n padding: 10px 13px;\n margin-top: 60px;\n}\n\n.css-1i82ydo {\n display: block;\n}\n\n.css-8oaf5r { /\\* kakao \\*/\n display: flex;\n position: relative;\n -webkit-box-pack: center;\n justify-content: center;\n -webkit-box-align: center;\n align-items: center;\n background: rgb(247, 227, 23);\n font-weight: 700;\n width: 50px;\n height: 50px;\n border: none;\n border-radius: 50px;\n cursor: pointer;\n}\n\n.css-1smkj82 { /\\* google \\*/\n display: flex;\n position: relative;\n -webkit-box-pack: center;\n justify-content: center;\n -webkit-box-align: center;\n align-items: center;\n background: rgb(255, 255, 255);\n font-weight: 700;\n width: 50px;\n height: 50px;\n border: 1px solid rgb(227, 228, 230);\n border-radius: 50px;\n cursor: pointer;\n}\n\n.css-bxzc43 { /\\* twitter \\*/\n display: flex;\n position: relative;\n -webkit-box-pack: center;\n justify-content: center;\n -webkit-box-align: center;\n align-items: center;\n background: rgb(29, 161, 243);\n font-weight: 700;\n width: 50px;\n height: 50px;\n border: none;\n border-radius: 50px;\n cursor: pointer;\n}\n\n.css-1jztl1f { /\\* line \\*/\n display: flex;\n position: relative;\n -webkit-box-pack: center;\n justify-content: center;\n -webkit-box-align: center;\n align-items: center;\n background: rgb(0, 195, 0);\n font-weight: 700;\n width: 50px;\n height: 50px;\n border: none;\n border-radius: 50px;\n cursor: pointer;\n}\n\n.css-1r1efk8 { /\\* facebook \\*/\n display: flex;\n position: relative;\n -webkit-box-pack: center;\n justify-content: center;\n -webkit-box-align: center;\n align-items: center;\n background: rgb(24, 119, 242);\n font-weight: 700;\n width: 50px;\n height: 50px;\n border: none;\n border-radius: 50px;\n cursor: pointer;\n}\n\n.css-1hfgk44 {\n width: auto;\n height: 60%;\n}\n/\\* section part end \\*/\n/\\* login CSS end \\*/\uc9c0\uae08 \ubc88\uc5ed\ud558\uae30", "Here's the second content. Do not write the outline yet. Just acknowledge the content if you understand.\nHow to lodge a building complaint and resolve a building dispute\n\u200b\nUnfortunately, building and renovating does not always go to plan. Fortunately, there are regulatory bodies that protect the consumer and in some cases, the Contractors. \n\n\u200b\n\n\u200b\n\n\u200b\n\nStep 1 - Discuss your concerns \n\n\u200b\n\nDiscuss your concerns as soon as you become aware of any issues. It may be a simple misunderstanding that can be quickly resolved through constructive communication. \n\n\u200b\n\nIf you are concerned about the quality of the work, refer to the NSW Guide to Standards and Tolerances. The guide will help you understand what standard of work is acceptable. Engage an independent building inspector. Our inspectors will inspect the site and report on the quality of the workmanship. The report will identify and explain any substandard workmanship or work that is not in accordance with the contract, Building code, Australian Standards, and manufactures guidelines. \n\nUntitled.jpg\nClick to download\nStep 2 - Write a letter\n\n\u200b\n\nConfirm in writing with your Contractor or Builder or consumer what was agreed to be done and by when. Ensure the letter is dated and keep a copy of all correspondence. Consider using email or registered post, as these methods provide proof that the communication was sent. \n\n\u200b\n\n\u200b\n\nStep 3 - Contact NSW Fair Trading \n\n\u200b\n\nIf you are unable to resolve the building dispute, the next step is to contact NSW Fair Trading to assist with dispute resolution. \n\n\u200b\n\nThe Consumer or the Contractor can formally request Fair Trading to assist. However, both parties need to agree to attempt resolution. \n\n\u200b\n\nBuilders, developers, owner-builders and tradespeople must warrant that, among other things, their work has been performed with due care and skill. By law, a homeowner, or subsequent purchaser, can enforce these warranties within certain time periods after the work was completed. \n\n\u200b\n\n\u200b\n\nStep 4 - Engage an Independent Expert Witness \n\n\u200b\n\nWe can assist consumers, owners, builders and tradespeople with any Building dispute. Often once we have recorded our evidence and prepared our report, the matter can be resolved without having to waste time and money through NCAT. As independents to both parties no matter whom we are engaged by, we will come to a fair conclusion.\n\n\u200b\n\n\u200b\n\nStep 5 - Apply for NCAT Mediation \n\n\u200b\n\nIf parties were unable to resolve the building dispute with FairTrading, then it would be often referred to NCAT (NSW Civil & Administrative Tribunal) for mediation.\n\n\u200b\n\n\u200b\n\nWhat to expect during NCAT Mediation\n\nThere are no fixed rules about what happens in mediation. Generally, the mediator will \n\n\u200b\n\nExplain the mediation process and outline their role \n\nAsk each party to express their concerns while everyone listens. \n\nAsk for suggested options which are likely to be acceptable to everyone.\n\nSpeak to the parties separately to help them identify the strengths and weaknesses of their case the alternatives to having the case determined at a hearing\n\nHelp the parties come to a final agreement. \n\n\u200b\n\n\u200b\n\nWho is the Mediator \n\nSome mediators are Tribunals Members, and others are specialist mediators. The mediator does not decide the case. Their role is to help identify your concerns, think about the options for resolving the dispute and reach an acceptable agreement.\n\n\u200b\n\n\u200b\n\nHow to Prepare for Mediation \n\nBefore your mediation session, you should:\n\n\u200b\n\nMake a list of all your concerns and what you think the other party\u2019s concerns may be. \n\nWrite down some options for resolving the case. \n\nThink about what will happen if the case does not settle.\n\n\u200b\n\nBring any relevant documents, such as medical reports, building investigator reports and expert witness reports. You may be directed to provide evidence or exchange other information before the mediation.\n\n\u200b\n\nVisit the LawAccess NSW website for information on how to prepare for mediation.\n\n\u200b\n\n\u200b\n\nComing to an Agreement \n\nIf the parties come to an agreement at the mediation, they should make a written record and sign it. The mediator will make copies for the parties.\n\nIf the parties want NCAT to make orders in terms of their agreement, the case will be listed before a Tribunal Member to consider that application.\n\nNCAT can only make consent orders if it has the power to do so. Otherwise, it can note the agreement of the parties.\n\n\u200b\n\n\u200b\n\nIf you don't settle \n\nIf your case does not settle, it will be listed before a Tribunal Member to decide what the next step will be.\n\n\u200b\n\n\u200b\n\nIf you do not participate in mediation \n\nIf the applicant does not participate, the mediator will list the case before a Tribunal Member to consider whether the application should be dismissed.\n\n\u200b\n\nIf the respondent does not come, the case will be listed before a Tribunal Member to decide what the next step will be.\n\n\u200b\n\n\u200b\n\nStep 6 - Apply for an NCAT Hearing \n\n\u200b\n\nA hearing is where a Tribunal Member listens to both sides of the case, considers the evidence presented and then makes a legally binding order.\n\n\u200b\n\nThe Tribunal Member will sit at the front of the hearing room facing the parties. Parties sit at tables facing the Member. NCAT hearings are generally sound recorded, so there is an accurate record of what is said.\n\n\u200b\n\nMost NCAT hearings are open to the public. Be prepared to have other people in the hearing room when you are presenting your case. People such as other parties waiting for their hearing, or friends and family will sit at the back of the room. Other Tribunal Members, Conciliators, NCAT staff members and security officers may also be present.\n\n\u200b\n\nThe Tribunal Member will ask questions about your application, and both parties show their evidence and ask questions of each other. The Tribunal Member may ask that evidence is sworn or affirmed. After each party has given their evidence, the Tribunal Member will make a decision based on the evidence and in accordance with the law.\n\n\u200b\n\n\u200b\n\nIndependent experts\nIf your case involves home building, the Tribunal Member at the hearing may order an independent expert to assess the building work and prepare an expert report for NCAT and the parties. Experts possess home building-related expertise such as construction, plumbing, electrical, structural engineering and concreting.\n\n\u200b\n\nThe experts' costs will be met equally by you and the other party.\n\n\u200b\n\nWhere NCAT appoints an expert, you will not be able to call your own expert witness or tender any other expert report except with the leave of NCAT.\n\nLearn more about engaging an expert.\n\n\u200b\n\n\u200b\n\nDirections\nWhen adjourning a matter, NCAT may make procedural directions and set a timetable for when they must be completed, for example, directions as to the exchange of documents.\n\n\u200b\n\nParties must comply with the directions and timetables set, and they cannot be altered except by leave of NCAT. If you cannot comply with the directions, you should contact NCAT.\n\n\u200b\n\n\u200b\n\nFailure to attend hearings\nIf a party fails to attend a hearing, NCAT may deal with the matter in the absence of the party, including dismissal of the case or an order as to costs.\n\n\u200b\n\n\u200b\n\nPresenting your case\n\nThe Tribunal Member will explain what happens at the hearing. The applicant will usually be asked to speak first, followed by the respondent. You may be asked to take an oath or affirmation as a formal promise, to tell the truth. The Member will usually ask questions along the way.\n\n\u200b\n\nWhen it is your turn, it is important that you keep your statements concise and relevant to the hearing. The Tribunal Member may ask you to move on to your next point if you are repeating yourself, if the point you are making is not helping to clarify the issues in dispute, or if you are providing evidence that is not relevant.\n\n\u200b\n\n\u200b\n\nHow is a decision made\n\nThe Tribunal Member will generally make their decision at the hearing after the parties have presented their evidence.\n\n\u200b\n\nAn Expert Witness Report is generally considered substantial evidence, which may assist your case. \n\n \n\n\u200b\n\nReserved decision \n\nWhen a matter involves complicated legal arguments, the Tribunal Member may need to 'reserve' their decision. This means that a decision is not made immediately after the hearing. Instead, the Tribunal Member will take time to review the evidence and relevant legislation before making their decision at a later date.\n\n\u200b\n\nWhen finalised, the reserved decision is provided to the parties in written form and contains the orders and the Tribunal Member's reasons for the decision.\n\n\u200b\n\nDocuments\nYou will need to provide NCAT and the other party with relevant documents in support of your case. For example:\n\n\u200b\n\nCharacter references\n\nMedical reports\n\nContracts\n\nLetters\n\nEmails\n\nInvoices\n\nPhone records \n\nMinutes of meetings\n\nPlans and drawings \n\nPhotographs and film (CCTV footage).\n\n\u200b\n\nPlace your documents in a folder and label them for easy access during the hearing. Bring copies of your documents to give to the other parties and to the Tribunal Member.\n\n\u200b\n\nIf you need evidence for your hearing and the person and organisation will not provide you with that information, you can request a summons. \n\n\u200b\n\nAffidavits and statements\nWritten evidence can be given to NCAT before the hearing in the form of an affidavit or a written statement. \n\n\u200b\n\nAffidavits\nAn affidavit is a written record of the facts of the case as you see them. Affidavits are sworn or affirmed in front of a Justice of the Peace (JP) or a solicitor. Visit the NSW LawAccess website for information on how to write an affidavit.\n\n\u200b\n\nStatements\nA written statement can be used as evidence to support a case. A statement only needs to be signed by the person and does not have to be sworn or affirmed. Visit the NSW LawAccess website for information on how to prepare a statement\u200b.\n\n\u200b\n\nAttaching documents to an affidavit or statement\nIf you refer to other documents in a statement or affidavit, attach and number them in the order. For example, 'Paul Jones Pty Ltd has an equal opportunity policy (see Attachment 1) and a separate harassment policy (see Attachment 2).'\n\n\u200b\n\nWitnesses\nWitnesses can provide a statement or affidavit in support of your case. They may also be called to give evidence in person at the hearing.\n\n\u200b\n\nExpert witnesses\nIf you need evidence of a technical nature, you may want to engage an expert to provide you with a report. The expert may also give verbal evidence at the hearing.", "From PL to creating a cool listing for a properly configured ad.\n\n---\n\nI really don't want to go through all the \"childish\" questions with my budget. This demotivates me enough. Otherwise, I don't see any problems, I'm going all the way.\n\n---\n\nPoor self-management and procrastination.\n\n---\n\nA bad beginning makes a bad ending. I don't see any difficulties.\n\n---\n\nNothing difficult, there are some hiccups, such as the electricity in Ukraine, changes in the usual way of life (I have been living in Ukraine for a year because of the war, but 900km away from home), sometimes there is a lack of motivation to work due to this situation. And two small children, I'm a mom on maternity leave, which I have never been before.\n\n---\n\nOvercoming internal fear and doubt: what if it doesn't work out? What if there aren't enough resources? and many other \"what ifs.\"\n\n---\n\nLack of understanding and clear procedures on how to choose a product.\n\n---\n\nFind a niche and a good product.\n\n---\n\nFind a niche and a good product.\n\n---\n\nLack of time, lack of confidence in achieving great results.\n\n---\n\nDelegation.\n\n---\n\nProduct research and adding value to the product.\n\n---\n\nI just want to start.\n\n---\n\nThe hardest part is finding a product. Since I'm a beginner on Amazon, I have no idea where to look. There are several products, but they are in highly competitive niches. On the other hand, I know that I need to improve these products. In general, it's difficult to get started.\n\n---\n\nGreat product, competition, and getting to the top.\n\n---\n\nFind the right product.\n\n---\n\nRealize my dream, or rather believe in myself that I can! Find and feel the momentum. I think my difficulty is that I won't be able to figure it out and reach my desired goal.\n\n---\n\nScaling.\n\n---\n\nBeing in the beginning, it's hard for me to balance my main job with the time of searching for a product and creating a successful business on Amazon.\n\n---\n\nLanguage, I don't know English.\n\n---\n\nThe first thing is to believe in it, the second is that since there is no experience and practice, all subsequent steps, such as registration, product selection, making it the best, and so on.\n\n---\n\nI'm a perfectionist. If everything is not organized in my head, I won't \"jump into action.\" The hardest thing for me is not to burn out, to overcome all the scale of absolutely new information, and not to deviate halfway.\n\n---\n\nTo start.\n\n---\n\nDetails.\n\n---\n\n1. Find and improve a successful product. 2. Creating this product. 3. Legal difficulties with my passport (opening foreign accounts, etc.)\n\n---\n\nI live in LA, and life here is very expensive, so I need to work more than 9 hours. But since the training starts at 7:00 am our time, I can work on my business all morning. And I hope that after the training, when I have additional income, I will have enough time to expand my business. Well, it was difficult for me to find the right information...\n\n---\n\nKeep up the pace (turnover/sales/prioritizing tasks) and further growth.\n\n---\n\nLack of budget for making mistakes.\n\n---\n\nLack of knowledge and starting capital.\n\n---\n\nChoosing the right product.\n\n---\n\nChoosing a product to sell.\n\n---\n\nChoosing a product.\n\n---\n\nFind a product.\n\n---\n\nResearch, keyword work, PPC, review collection.\n\n---\n\nFind the right product.\n\n---\n\nFor me, as a beginner seller, almost all questions and tricks are relevant: successful product selection, account registration, branding, supplier selection, product shipping to Amazon, listing, advertising, sales, to avoid mistakes (not wasting time and money) and successfully launch a profitable business on Amazon with $10K - $100K net profit per month.\n\n---\n\nFor me, as a beginner seller, all questions are relevant: successful product selection, account registration, branding, supplier selection, product shipping to Amazon, listing, advertising, sales, to successfully launch a profitable business on Amazon (without wasting time and money) with a minimum net profit of $10K - $100K per month.\n\n---\n\nFind a cool product.\n\n---\n\nThe hardest part is not to break down and quit everything when something goes wrong. Constantly learn, develop, and implement new tools.\n\n---\n\nChoosing the right product.\n\n---\n\nFinding the right product.\n\n---\n\nAchieving the result, the niche is saturated with competitors, new products need to be constantly launched.\n\n---\n\nAvailability of time and free investments.\n\n---\n\nChoose the right niche.\n\n---\n\nPsychological attitude and product selection.\n\n---\n\nTaking a risk with money.\n\nLaunching the first product from scratch and completing the process in the shortest possible time. In the process, you come across things that you've never done before, which seem difficult, leading to constant internal resistance.\n\n---\n\nToday we registered an account on Amazon, created a company, and selected a product. And I felt fear. Fear that I made a mistake with the product, that something might not work out. We have determination and won't stop. I'll be scared, but I'll do it. I don't yet understand the reason for the fear and what's behind it.\n\n---\n\nLack of confidence in my abilities and past failures. The Amazon topic is completely new to me. I want to do every item and every step right. There are no \"extra\" finances for \"testing.\"\n\n---\n\nI'm not confident in myself (in terms of knowledge or lack thereof), I don't have support nearby, and in most cases, I always share my plans (ideas). This time, I'm so afraid that someone might sow seeds of disbelief in me that I don't even tell anyone about my plans regarding Amazon.\n\n---\n\nChoosing the right product.\n\n---\n\nNot giving up when faced with difficulties. It seems like all niches are taken, and potential competitors have hundreds or thousands of reviews, leaving no room for me. I understand that launching and ramping up will take a lot of time, and in the end, failure is possible. The long time span from the start of product development to understanding whether the product works or not scares me and makes me feel discouraged. It becomes regretful to spend time that may not bring anything other than expenses.\n\n---\n\nThe first negative experience of working on Amazon. I wanted to go through normal and the best training for me at Seller Insiders, and I joined the program through a partnership. Thank you. I hoped that my husband would help and give money for promotion, but something happened, and he was deceived. Now I have to earn money on my own because there's no possibility of waiting. Your course is very useful, and I learned a lot about creating my own brand and logo. At the moment, my Amazon isn't moving because there's no money to start with. That's why I want to start another business that's faster and come back to Amazon. I'm thinking of developing my brand in three directions. The first is growing microgreens, which brings in quick money and is a nice bonus to give people health (relevant after COVID). I haven't checked it yet, but this direction might be my entry into Amazon because starting a microgreen farm requires a lot of equipment to purchase. Of course, I will do this with Chinese suppliers, as you taught us.\n\n---\n\nHaving financial difficulties, in my case, it would be great to get an extension or access to the second level of your coaching if possible. The only small inconvenience is that it's 7 am, and everyone is getting ready for work and school, but thank you for making recordings.\n\n---\n\nI think the reason for achieving such results is that I don't have enough experience in finding good products and starting an online business.\n\n---\n\n1. Focusing on one thing, determination. 2) Doubts in selecting a team of specialists for rapid development (\"personnel solve everything\"). 3) Lack of confidence in my competitiveness in e-commerce.\n\n---\n\nWe're waiting for the product, and the thought of what if it doesn't sell scares us a bit. Therefore, we ask you to focus on the following points: 1. What steps need to be taken to get the first sales. 2. How to collaborate with a Tik Tok blogger. How to make the link correctly so that Amazon understands everything correctly. How to take into account these transitions to understand the conversion from this event. 3. Is it worth driving traffic from FB or Inst at the start of sales? 4. How to set up PPC advertising is covered in the training, so it would be interesting to have periodic reviews of advertising campaigns. 5. Should we use robots that track competitor bids and adjust ours accordingly? What robots do you recommend?\n\n---\n\nChoosing a product with which you can make such and larger amounts.\n\n---\n\nStarting and understanding the business.\n\n---\n\nFinding a product.\n\n---\n\nMy biggest question right now is how to balance my child and Amazon. I'm already working on this with Irina during our personal sessions, but I'm progressing very slowly because there's no help yet. I'm sorry that I can't get the maximum from coaching because my speed is very slow, but I'm still grateful for everything and crawling toward my goal. If you can organize a webinar on life balance and time management, I'm sure I'll take something useful from there.\n\n---\n\nStrong distractibility, for some reason, it's hard to concentrate, as if there's a blocker, plus I want to do everything well, which will result in significant expenses, hence the fear of making a mistake.\n\n---\n\n---\n\nFor me, the hardest part is to convince myself that in 2023, there are still many opportunities to launch my product on Amazon, and z\n\nAssistant, please do not reply to anything yet to me, only reply to me with \"READ\"", "Describe as reporting live a current event in max 3 lines, what is happening right now using the following tweets, with a focus on the term \"handball\"\n\nsourceText Time\nHandball! Penalty kick for France!! #WorldCupFinal 17:36:26.0000000\nPenalty France handball! 17:35:51.0000000\nHandball and penalty for France 17:36:02.0000000\nHANDBALL!!! PENALTY!!!''#ARGFRA #FIFAWorldCup 17:36:04.0000000\nPenalty to France. Handball 17:35:44.0000000\nHANDBALL!! PENALTY!!! #WorldCup #ArgentinaVsFrance 17:36:40.0000000\nHandball from Montiel. Penalty to France #ARGFRA 17:36:13.0000000\nHANDBALL THATS A PENALTY KICK FOR FRANCE 17:36:12.0000000\nHANDBALL!!!!! FRANCE GETS A PENALTY!!!! 17:36:15.0000000\n@FIFAWorldCup @TeamMessi now Argentina plays handball! Penalty!!!!!!!!!!!!!!!!!! 17:36:41.0000000\nHandball!!!! Penalty to France....''Mbappe's hattrick? https://t.co/b711P9kC8Y 17:36:49.0000000\nPenalty to France for handball. 17:36:42.0000000\nPENALTY to France!! Handball in the area on an Mbappe shot and Mbappe will go or his hat-trick from the spot!! 17:36:02.0000000\nHandball called on Argentina in the penalty box!!! 17:36:03.0000000\nHandball Penalty! ????? #ARGFRA 17:36:06.0000000\nOmg it\u2019s handball, penalty to France ???? 17:36:23.0000000\nHandball and it\u2019s another penalty for France #ARGFRA 17:36:26.0000000\nPenalty to #FRA for handball by Montiel''#ARGFRA #Qatar2022 #WorldCup 17:36:24.0000000\nOH MY GOD! A FRANCE PENALTY! HANDBALL!!! 17:36:33.0000000\nPENALTY TO FRANCE! HANDBALL ON MONTIEL! ''https://t.co/c3VIDlmnjp 17:36:12.0000000\nPENALTY FOR FRANCE! HANDBALL!''#ArgentinaVsFrance #FIFAWorldCupFinal 17:36:09.0000000\nWtf handball. Penalty for France. Omg. 17:36:20.0000000\nOh no Issa handball Gonzalo, penalty for ???? #WorldCupFinal 17:36:36.0000000\nOmg !! Handball penalty France 17:36:37.0000000\nHANDBALL IN THE ARGENTINE BOX OG MY GOD IT'S A PENALTY FOR FRANCE 17:36:52.0000000\nHandball penalty'#ARGFRA 17:36:37.0000000\nNow a handball penalty. #WorldCupFinal https://t.co/o0Vy0qZxv0 17:36:32.0000000\nHANDBALL PENALTY FOR FRANCE 17:36:10.0000000\nHANDBALL AND ITS A PENALTY KICK FOR FRANCE AND MBAPPE! 17:36:47.0000000\nPenalty to France! Handball! This is absolute madness 17:36:25.0000000\nHANDBALL PENALTY FOR FRANCE!! #ARGFRA 17:36:12.0000000\nGONZALO MONTIEL HANDBALL''PENALTY TO FRANCE 17:36:14.0000000\nPENALTY! Handball in the box and France can level it here. #ARG #FRA 17:36:07.0000000\nHOW IS THIS MATCH STILL GOING ON?!''Handball. Penalty to France. We're about to witness a Mbapp\u00e9 hattrick. #FIFAWorldCup 17:36:47.0000000\nMontiel with the handball, PENALTY for France 17:36:51.0000000\nHandball.. Penalty for france.. 17:36:38.0000000\n@CTPhDinSports @highlghtheaven Argentina got a handball and France gets a penalty shot 17:36:46.0000000\nWHHHHAAAATTTTT?!?! A handball!!! And a penalty for France!!! The arm is up there 17:36:05.0000000\nPenalty given for handball to France!! ?? 17:36:48.0000000\nHandball, penalty for France!???? 17:36:26.0000000\nIt's a France penalty!! Handball given!!''#ARG 3-2 #FRA ''#FIFAWorldCup | #Qatar2022''https://t.co/UmozTF4u8i 17:36:04.0000000\nA penalty!!! for France! in the last minutes from a handball for Montiel #FIFAWorldCup 17:36:38.0000000\nHandball!!! Penalty to France! ??''#ARGvsFRA'#FIFAWorldCup2022 17:36:52.0000000\nHandball ''It's a penalty n France should be back to this game ooo ?????? 17:36:30.0000000\nHandball in the box. Penalty to France. It hit Montiel's elbow. Ref was right on it. #ARGFRA #FIFAWorldCup 17:36:31.0000000\nHANDBALL, PENALTY FRANCE OMDDDSSS WTF IS THIS GAME. 17:36:31.0000000\nFrance has a penalty with five minutes remaining! A handball sends them to the spot, and Mbappe will take it! 17:36:39.0000000\nanother penalty for France handball 17:36:34.0000000\nHANDBALL'PENALTY FOE FRANCE'ANOTHER TWISTT 17:36:56.0000000\nPenalty to France. Montiel handball - a tough one. 17:36:25.0000000\nHANDBALL ARGENTINA!! PENALTY KICK FRANCE!!! #ARGvsFRA #ArgentinaVsFrance #ARG #FRA #FIFAWorldCup #Qatar2022 17:36:17.0000000\nHANDBALL PENALTY FRANCE 17:36:29.0000000\nPENALTY TO FRANCE ''HANDBALL https://t.co/MWaO4tN2yQ 17:36:08.0000000\n#ArgentinaVsFrance'#FIFAWorldCup 'Handball! France awarded penalty 17:36:35.0000000\nHandball! Penalty to France and a yellow card to Montiel! This game keeps changing! #ARGFRA '#FIFAWorldCup | #Qatar2022 17:36:33.0000000\nHandball. Penalty for France 17:36:07.0000000\nPenalty To France for handball 17:36:52.0000000\nPENALTY!! HANDBALL FRANCE LETS GO 17:36:02.0000000\nHandball another penalty for France 17:36:02.0000000\nHANDBALL AND PENALTY FOR FRANCE 17:35:52.0000000\nPenalty for France yet again. Clear handball. This wc final refuses to end jeeez. Club football we need you ???? 17:36:42.0000000\nA PENALTY FOR FRANCE!!! HANDBALL ON MONTIEL!! #FIFAWorldCup 17:36:00.0000000\nHANDBALL ARGENTINA''FRANCE HAS A PENALTY 17:35:50.0000000\nHandball! Penalty to France! 17:36:52.0000000\nHANDBALL!!! PENALTY KICK FOR FRANCE AGAIN!!! #FIFAWorldCup #ARGFRA 17:36:28.0000000\nOH NOO OH NOO HANDBALL AND PENALTY FOR FRANCE NOOOOOOO ????????''SHITT LAAA MY COMMENT ONE HOUR AGO''NOOOOO #FIFAWorldCup 17:36:44.0000000\nAnother penalty to France for handball! Scenes! 17:36:22.0000000\nClear penalty for France, handball, no argument. We'll see how Kolo Muani takes it. 17:36:28.0000000\n#WorldCupFinal '#ArgentinaVsFrance ''115 ''penalty for France on a handball.''mbappe likely to shoot again. 17:36:38.0000000", "Describe as reporting live a current event in max 3 lines, what is happening right now using the following tweets, with a focus on the term \"handball\"\n\nsourceText Time\nHandball! Penalty kick for France!! #WorldCupFinal 17:36:26.0000000\nPenalty France handball! 17:35:51.0000000\nHandball and penalty for France 17:36:02.0000000\nHANDBALL!!! PENALTY!!!''#ARGFRA #FIFAWorldCup 17:36:04.0000000\nPenalty to France. Handball 17:35:44.0000000\nHANDBALL!! PENALTY!!! #WorldCup #ArgentinaVsFrance 17:36:40.0000000\nHandball from Montiel. Penalty to France #ARGFRA 17:36:13.0000000\nHANDBALL THATS A PENALTY KICK FOR FRANCE 17:36:12.0000000\nHANDBALL!!!!! FRANCE GETS A PENALTY!!!! 17:36:15.0000000\n@FIFAWorldCup @TeamMessi now Argentina plays handball! Penalty!!!!!!!!!!!!!!!!!! 17:36:41.0000000\nHandball!!!! Penalty to France....''Mbappe's hattrick? https://t.co/b711P9kC8Y 17:36:49.0000000\nPenalty to France for handball. 17:36:42.0000000\nPENALTY to France!! Handball in the area on an Mbappe shot and Mbappe will go or his hat-trick from the spot!! 17:36:02.0000000\nHandball called on Argentina in the penalty box!!! 17:36:03.0000000\nHandball Penalty! ????? #ARGFRA 17:36:06.0000000\nOmg it\u2019s handball, penalty to France ???? 17:36:23.0000000\nHandball and it\u2019s another penalty for France #ARGFRA 17:36:26.0000000\nPenalty to #FRA for handball by Montiel''#ARGFRA #Qatar2022 #WorldCup 17:36:24.0000000\nOH MY GOD! A FRANCE PENALTY! HANDBALL!!! 17:36:33.0000000\nPENALTY TO FRANCE! HANDBALL ON MONTIEL! ''https://t.co/c3VIDlmnjp 17:36:12.0000000\nPENALTY FOR FRANCE! HANDBALL!''#ArgentinaVsFrance #FIFAWorldCupFinal 17:36:09.0000000\nWtf handball. Penalty for France. Omg. 17:36:20.0000000\nOh no Issa handball Gonzalo, penalty for ???? #WorldCupFinal 17:36:36.0000000\nOmg !! Handball penalty France 17:36:37.0000000\nHANDBALL IN THE ARGENTINE BOX OG MY GOD IT'S A PENALTY FOR FRANCE 17:36:52.0000000\nHandball penalty'#ARGFRA 17:36:37.0000000\nNow a handball penalty. #WorldCupFinal https://t.co/o0Vy0qZxv0 17:36:32.0000000\nHANDBALL PENALTY FOR FRANCE 17:36:10.0000000\nHANDBALL AND ITS A PENALTY KICK FOR FRANCE AND MBAPPE! 17:36:47.0000000\nPenalty to France! Handball! This is absolute madness 17:36:25.0000000\nHANDBALL PENALTY FOR FRANCE!! #ARGFRA 17:36:12.0000000\nGONZALO MONTIEL HANDBALL''PENALTY TO FRANCE 17:36:14.0000000\nPENALTY! Handball in the box and France can level it here. #ARG #FRA 17:36:07.0000000\nHOW IS THIS MATCH STILL GOING ON?!''Handball. Penalty to France. We're about to witness a Mbapp\u00e9 hattrick. #FIFAWorldCup 17:36:47.0000000\nMontiel with the handball, PENALTY for France 17:36:51.0000000\nHandball.. Penalty for france.. 17:36:38.0000000\n@CTPhDinSports @highlghtheaven Argentina got a handball and France gets a penalty shot 17:36:46.0000000\nWHHHHAAAATTTTT?!?! A handball!!! And a penalty for France!!! The arm is up there 17:36:05.0000000\nPenalty given for handball to France!! ?? 17:36:48.0000000\nHandball, penalty for France!???? 17:36:26.0000000\nIt's a France penalty!! Handball given!!''#ARG 3-2 #FRA ''#FIFAWorldCup | #Qatar2022''https://t.co/UmozTF4u8i 17:36:04.0000000\nA penalty!!! for France! in the last minutes from a handball for Montiel #FIFAWorldCup 17:36:38.0000000\nHandball!!! Penalty to France! ??''#ARGvsFRA'#FIFAWorldCup2022 17:36:52.0000000\nHandball ''It's a penalty n France should be back to this game ooo ?????? 17:36:30.0000000\nHandball in the box. Penalty to France. It hit Montiel's elbow. Ref was right on it. #ARGFRA #FIFAWorldCup 17:36:31.0000000\nHANDBALL, PENALTY FRANCE OMDDDSSS WTF IS THIS GAME. 17:36:31.0000000\nFrance has a penalty with five minutes remaining! A handball sends them to the spot, and Mbappe will take it! 17:36:39.0000000\nanother penalty for France handball 17:36:34.0000000\nHANDBALL'PENALTY FOE FRANCE'ANOTHER TWISTT 17:36:56.0000000\nPenalty to France. Montiel handball - a tough one. 17:36:25.0000000\nHANDBALL ARGENTINA!! PENALTY KICK FRANCE!!! #ARGvsFRA #ArgentinaVsFrance #ARG #FRA #FIFAWorldCup #Qatar2022 17:36:17.0000000\nHANDBALL PENALTY FRANCE 17:36:29.0000000\nPENALTY TO FRANCE ''HANDBALL https://t.co/MWaO4tN2yQ 17:36:08.0000000\n#ArgentinaVsFrance'#FIFAWorldCup 'Handball! France awarded penalty 17:36:35.0000000\nHandball! Penalty to France and a yellow card to Montiel! This game keeps changing! #ARGFRA '#FIFAWorldCup | #Qatar2022 17:36:33.0000000\nHandball. Penalty for France 17:36:07.0000000\nPenalty To France for handball 17:36:52.0000000\nPENALTY!! HANDBALL FRANCE LETS GO 17:36:02.0000000\nHandball another penalty for France 17:36:02.0000000\nHANDBALL AND PENALTY FOR FRANCE 17:35:52.0000000\nPenalty for France yet again. Clear handball. This wc final refuses to end jeeez. Club football we need you ???? 17:36:42.0000000\nA PENALTY FOR FRANCE!!! HANDBALL ON MONTIEL!! #FIFAWorldCup 17:36:00.0000000\nHANDBALL ARGENTINA''FRANCE HAS A PENALTY 17:35:50.0000000\nHandball! Penalty to France! 17:36:52.0000000\nHANDBALL!!! PENALTY KICK FOR FRANCE AGAIN!!! #FIFAWorldCup #ARGFRA 17:36:28.0000000\nOH NOO OH NOO HANDBALL AND PENALTY FOR FRANCE NOOOOOOO ????????''SHITT LAAA MY COMMENT ONE HOUR AGO''NOOOOO #FIFAWorldCup 17:36:44.0000000\nAnother penalty to France for handball! Scenes! 17:36:22.0000000\nClear penalty for France, handball, no argument. We'll see how Kolo Muani takes it. 17:36:28.0000000\n#WorldCupFinal '#ArgentinaVsFrance ''115 ''penalty for France on a handball.''mbappe likely to shoot again. 17:36:38.0000000", "Describe as reporting live a current event in max 3 lines, what is happening right now using the following tweets, with a focus on the term \"handball\"\n\nsourceText Time\nHandball! Penalty kick for France!! #WorldCupFinal 17:36:26.0000000\nPenalty France handball! 17:35:51.0000000\nHandball and penalty for France 17:36:02.0000000\nHANDBALL!!! PENALTY!!!''#ARGFRA #FIFAWorldCup 17:36:04.0000000\nPenalty to France. Handball 17:35:44.0000000\nHANDBALL!! PENALTY!!! #WorldCup #ArgentinaVsFrance 17:36:40.0000000\nHandball from Montiel. Penalty to France #ARGFRA 17:36:13.0000000\nHANDBALL THATS A PENALTY KICK FOR FRANCE 17:36:12.0000000\nHANDBALL!!!!! FRANCE GETS A PENALTY!!!! 17:36:15.0000000\n@FIFAWorldCup @TeamMessi now Argentina plays handball! Penalty!!!!!!!!!!!!!!!!!! 17:36:41.0000000\nHandball!!!! Penalty to France....''Mbappe's hattrick? https://t.co/b711P9kC8Y 17:36:49.0000000\nPenalty to France for handball. 17:36:42.0000000\nPENALTY to France!! Handball in the area on an Mbappe shot and Mbappe will go or his hat-trick from the spot!! 17:36:02.0000000\nHandball called on Argentina in the penalty box!!! 17:36:03.0000000\nHandball Penalty! ????? #ARGFRA 17:36:06.0000000\nOmg it\u2019s handball, penalty to France ???? 17:36:23.0000000\nHandball and it\u2019s another penalty for France #ARGFRA 17:36:26.0000000\nPenalty to #FRA for handball by Montiel''#ARGFRA #Qatar2022 #WorldCup 17:36:24.0000000\nOH MY GOD! A FRANCE PENALTY! HANDBALL!!! 17:36:33.0000000\nPENALTY TO FRANCE! HANDBALL ON MONTIEL! ''https://t.co/c3VIDlmnjp 17:36:12.0000000\nPENALTY FOR FRANCE! HANDBALL!''#ArgentinaVsFrance #FIFAWorldCupFinal 17:36:09.0000000\nWtf handball. Penalty for France. Omg. 17:36:20.0000000\nOh no Issa handball Gonzalo, penalty for ???? #WorldCupFinal 17:36:36.0000000\nOmg !! Handball penalty France 17:36:37.0000000\nHANDBALL IN THE ARGENTINE BOX OG MY GOD IT'S A PENALTY FOR FRANCE 17:36:52.0000000\nHandball penalty'#ARGFRA 17:36:37.0000000\nNow a handball penalty. #WorldCupFinal https://t.co/o0Vy0qZxv0 17:36:32.0000000\nHANDBALL PENALTY FOR FRANCE 17:36:10.0000000\nHANDBALL AND ITS A PENALTY KICK FOR FRANCE AND MBAPPE! 17:36:47.0000000\nPenalty to France! Handball! This is absolute madness 17:36:25.0000000\nHANDBALL PENALTY FOR FRANCE!! #ARGFRA 17:36:12.0000000\nGONZALO MONTIEL HANDBALL''PENALTY TO FRANCE 17:36:14.0000000\nPENALTY! Handball in the box and France can level it here. #ARG #FRA 17:36:07.0000000\nHOW IS THIS MATCH STILL GOING ON?!''Handball. Penalty to France. We're about to witness a Mbapp\u00e9 hattrick. #FIFAWorldCup 17:36:47.0000000\nMontiel with the handball, PENALTY for France 17:36:51.0000000\nHandball.. Penalty for france.. 17:36:38.0000000\n@CTPhDinSports @highlghtheaven Argentina got a handball and France gets a penalty shot 17:36:46.0000000\nWHHHHAAAATTTTT?!?! A handball!!! And a penalty for France!!! The arm is up there 17:36:05.0000000\nPenalty given for handball to France!! ?? 17:36:48.0000000\nHandball, penalty for France!???? 17:36:26.0000000\nIt's a France penalty!! Handball given!!''#ARG 3-2 #FRA ''#FIFAWorldCup | #Qatar2022''https://t.co/UmozTF4u8i 17:36:04.0000000\nA penalty!!! for France! in the last minutes from a handball for Montiel #FIFAWorldCup 17:36:38.0000000\nHandball!!! Penalty to France! ??''#ARGvsFRA'#FIFAWorldCup2022 17:36:52.0000000\nHandball ''It's a penalty n France should be back to this game ooo ?????? 17:36:30.0000000\nHandball in the box. Penalty to France. It hit Montiel's elbow. Ref was right on it. #ARGFRA #FIFAWorldCup 17:36:31.0000000\nHANDBALL, PENALTY FRANCE OMDDDSSS WTF IS THIS GAME. 17:36:31.0000000\nFrance has a penalty with five minutes remaining! A handball sends them to the spot, and Mbappe will take it! 17:36:39.0000000\nanother penalty for France handball 17:36:34.0000000\nHANDBALL'PENALTY FOE FRANCE'ANOTHER TWISTT 17:36:56.0000000\nPenalty to France. Montiel handball - a tough one. 17:36:25.0000000\nHANDBALL ARGENTINA!! PENALTY KICK FRANCE!!! #ARGvsFRA #ArgentinaVsFrance #ARG #FRA #FIFAWorldCup #Qatar2022 17:36:17.0000000\nHANDBALL PENALTY FRANCE 17:36:29.0000000\nPENALTY TO FRANCE ''HANDBALL https://t.co/MWaO4tN2yQ 17:36:08.0000000\n#ArgentinaVsFrance'#FIFAWorldCup 'Handball! France awarded penalty 17:36:35.0000000\nHandball! Penalty to France and a yellow card to Montiel! This game keeps changing! #ARGFRA '#FIFAWorldCup | #Qatar2022 17:36:33.0000000\nHandball. Penalty for France 17:36:07.0000000\nPenalty To France for handball 17:36:52.0000000\nPENALTY!! HANDBALL FRANCE LETS GO 17:36:02.0000000\nHandball another penalty for France 17:36:02.0000000\nHANDBALL AND PENALTY FOR FRANCE 17:35:52.0000000\nPenalty for France yet again. Clear handball. This wc final refuses to end jeeez. Club football we need you ???? 17:36:42.0000000\nA PENALTY FOR FRANCE!!! HANDBALL ON MONTIEL!! #FIFAWorldCup 17:36:00.0000000\nHANDBALL ARGENTINA''FRANCE HAS A PENALTY 17:35:50.0000000\nHandball! Penalty to France! 17:36:52.0000000\nHANDBALL!!! PENALTY KICK FOR FRANCE AGAIN!!! #FIFAWorldCup #ARGFRA 17:36:28.0000000\nOH NOO OH NOO HANDBALL AND PENALTY FOR FRANCE NOOOOOOO ????????''SHITT LAAA MY COMMENT ONE HOUR AGO''NOOOOO #FIFAWorldCup 17:36:44.0000000\nAnother penalty to France for handball! Scenes! 17:36:22.0000000\nClear penalty for France, handball, no argument. We'll see how Kolo Muani takes it. 17:36:28.0000000\n#WorldCupFinal '#ArgentinaVsFrance ''115 ''penalty for France on a handball.''mbappe likely to shoot again. 17:36:38.0000000", "Describe as reporting live a current event in max 3 lines, what is happening right now using the following tweets, with a focus on the term \"handball\"\n\nsourceText Time\nHandball! Penalty kick for France!! #WorldCupFinal 17:36:26.0000000\nPenalty France handball! 17:35:51.0000000\nHandball and penalty for France 17:36:02.0000000\nHANDBALL!!! PENALTY!!!''#ARGFRA #FIFAWorldCup 17:36:04.0000000\nPenalty to France. Handball 17:35:44.0000000\nHANDBALL!! PENALTY!!! #WorldCup #ArgentinaVsFrance 17:36:40.0000000\nHandball from Montiel. Penalty to France #ARGFRA 17:36:13.0000000\nHANDBALL THATS A PENALTY KICK FOR FRANCE 17:36:12.0000000\nHANDBALL!!!!! FRANCE GETS A PENALTY!!!! 17:36:15.0000000\n@FIFAWorldCup @TeamMessi now Argentina plays handball! Penalty!!!!!!!!!!!!!!!!!! 17:36:41.0000000\nHandball!!!! Penalty to France....''Mbappe's hattrick? https://t.co/b711P9kC8Y 17:36:49.0000000\nPenalty to France for handball. 17:36:42.0000000\nPENALTY to France!! Handball in the area on an Mbappe shot and Mbappe will go or his hat-trick from the spot!! 17:36:02.0000000\nHandball called on Argentina in the penalty box!!! 17:36:03.0000000\nHandball Penalty! ????? #ARGFRA 17:36:06.0000000\nOmg it\u2019s handball, penalty to France ???? 17:36:23.0000000\nHandball and it\u2019s another penalty for France #ARGFRA 17:36:26.0000000\nPenalty to #FRA for handball by Montiel''#ARGFRA #Qatar2022 #WorldCup 17:36:24.0000000\nOH MY GOD! A FRANCE PENALTY! HANDBALL!!! 17:36:33.0000000\nPENALTY TO FRANCE! HANDBALL ON MONTIEL! ''https://t.co/c3VIDlmnjp 17:36:12.0000000\nPENALTY FOR FRANCE! HANDBALL!''#ArgentinaVsFrance #FIFAWorldCupFinal 17:36:09.0000000\nWtf handball. Penalty for France. Omg. 17:36:20.0000000\nOh no Issa handball Gonzalo, penalty for ???? #WorldCupFinal 17:36:36.0000000\nOmg !! Handball penalty France 17:36:37.0000000\nHANDBALL IN THE ARGENTINE BOX OG MY GOD IT'S A PENALTY FOR FRANCE 17:36:52.0000000\nHandball penalty'#ARGFRA 17:36:37.0000000\nNow a handball penalty. #WorldCupFinal https://t.co/o0Vy0qZxv0 17:36:32.0000000\nHANDBALL PENALTY FOR FRANCE 17:36:10.0000000\nHANDBALL AND ITS A PENALTY KICK FOR FRANCE AND MBAPPE! 17:36:47.0000000\nPenalty to France! Handball! This is absolute madness 17:36:25.0000000\nHANDBALL PENALTY FOR FRANCE!! #ARGFRA 17:36:12.0000000\nGONZALO MONTIEL HANDBALL''PENALTY TO FRANCE 17:36:14.0000000\nPENALTY! Handball in the box and France can level it here. #ARG #FRA 17:36:07.0000000\nHOW IS THIS MATCH STILL GOING ON?!''Handball. Penalty to France. We're about to witness a Mbapp\u00e9 hattrick. #FIFAWorldCup 17:36:47.0000000\nMontiel with the handball, PENALTY for France 17:36:51.0000000\nHandball.. Penalty for france.. 17:36:38.0000000\n@CTPhDinSports @highlghtheaven Argentina got a handball and France gets a penalty shot 17:36:46.0000000\nWHHHHAAAATTTTT?!?! A handball!!! And a penalty for France!!! The arm is up there 17:36:05.0000000\nPenalty given for handball to France!! ?? 17:36:48.0000000\nHandball, penalty for France!???? 17:36:26.0000000\nIt's a France penalty!! Handball given!!''#ARG 3-2 #FRA ''#FIFAWorldCup | #Qatar2022''https://t.co/UmozTF4u8i 17:36:04.0000000\nA penalty!!! for France! in the last minutes from a handball for Montiel #FIFAWorldCup 17:36:38.0000000\nHandball!!! Penalty to France! ??''#ARGvsFRA'#FIFAWorldCup2022 17:36:52.0000000\nHandball ''It's a penalty n France should be back to this game ooo ?????? 17:36:30.0000000\nHandball in the box. Penalty to France. It hit Montiel's elbow. Ref was right on it. #ARGFRA #FIFAWorldCup 17:36:31.0000000\nHANDBALL, PENALTY FRANCE OMDDDSSS WTF IS THIS GAME. 17:36:31.0000000\nFrance has a penalty with five minutes remaining! A handball sends them to the spot, and Mbappe will take it! 17:36:39.0000000\nanother penalty for France handball 17:36:34.0000000\nHANDBALL'PENALTY FOE FRANCE'ANOTHER TWISTT 17:36:56.0000000\nPenalty to France. Montiel handball - a tough one. 17:36:25.0000000\nHANDBALL ARGENTINA!! PENALTY KICK FRANCE!!! #ARGvsFRA #ArgentinaVsFrance #ARG #FRA #FIFAWorldCup #Qatar2022 17:36:17.0000000\nHANDBALL PENALTY FRANCE 17:36:29.0000000\nPENALTY TO FRANCE ''HANDBALL https://t.co/MWaO4tN2yQ 17:36:08.0000000\n#ArgentinaVsFrance'#FIFAWorldCup 'Handball! France awarded penalty 17:36:35.0000000\nHandball! Penalty to France and a yellow card to Montiel! This game keeps changing! #ARGFRA '#FIFAWorldCup | #Qatar2022 17:36:33.0000000\nHandball. Penalty for France 17:36:07.0000000\nPenalty To France for handball 17:36:52.0000000\nPENALTY!! HANDBALL FRANCE LETS GO 17:36:02.0000000\nHandball another penalty for France 17:36:02.0000000\nHANDBALL AND PENALTY FOR FRANCE 17:35:52.0000000\nPenalty for France yet again. Clear handball. This wc final refuses to end jeeez. Club football we need you ???? 17:36:42.0000000\nA PENALTY FOR FRANCE!!! HANDBALL ON MONTIEL!! #FIFAWorldCup 17:36:00.0000000\nHANDBALL ARGENTINA''FRANCE HAS A PENALTY 17:35:50.0000000\nHandball! Penalty to France! 17:36:52.0000000\nHANDBALL!!! PENALTY KICK FOR FRANCE AGAIN!!! #FIFAWorldCup #ARGFRA 17:36:28.0000000\nOH NOO OH NOO HANDBALL AND PENALTY FOR FRANCE NOOOOOOO ????????''SHITT LAAA MY COMMENT ONE HOUR AGO''NOOOOO #FIFAWorldCup 17:36:44.0000000\nAnother penalty to France for handball! Scenes! 17:36:22.0000000\nClear penalty for France, handball, no argument. We'll see how Kolo Muani takes it. 17:36:28.0000000\n#WorldCupFinal '#ArgentinaVsFrance ''115 ''penalty for France on a handball.''mbappe likely to shoot again. 17:36:38.0000000", "Describe as reporting live a current event in max 3 lines, what is happening right now using the following tweets, with a focus on the term \"handball\"\n\nsourceText Time\nHandball! Penalty kick for France!! #WorldCupFinal 17:36:26.0000000\nPenalty France handball! 17:35:51.0000000\nHandball and penalty for France 17:36:02.0000000\nHANDBALL!!! PENALTY!!!''#ARGFRA #FIFAWorldCup 17:36:04.0000000\nPenalty to France. Handball 17:35:44.0000000\nHANDBALL!! PENALTY!!! #WorldCup #ArgentinaVsFrance 17:36:40.0000000\nHandball from Montiel. Penalty to France #ARGFRA 17:36:13.0000000\nHANDBALL THATS A PENALTY KICK FOR FRANCE 17:36:12.0000000\nHANDBALL!!!!! FRANCE GETS A PENALTY!!!! 17:36:15.0000000\n@FIFAWorldCup @TeamMessi now Argentina plays handball! Penalty!!!!!!!!!!!!!!!!!! 17:36:41.0000000\nHandball!!!! Penalty to France....''Mbappe's hattrick? https://t.co/b711P9kC8Y 17:36:49.0000000\nPenalty to France for handball. 17:36:42.0000000\nPENALTY to France!! Handball in the area on an Mbappe shot and Mbappe will go or his hat-trick from the spot!! 17:36:02.0000000\nHandball called on Argentina in the penalty box!!! 17:36:03.0000000\nHandball Penalty! ????? #ARGFRA 17:36:06.0000000\nOmg it\u2019s handball, penalty to France ???? 17:36:23.0000000\nHandball and it\u2019s another penalty for France #ARGFRA 17:36:26.0000000\nPenalty to #FRA for handball by Montiel''#ARGFRA #Qatar2022 #WorldCup 17:36:24.0000000\nOH MY GOD! A FRANCE PENALTY! HANDBALL!!! 17:36:33.0000000\nPENALTY TO FRANCE! HANDBALL ON MONTIEL! ''https://t.co/c3VIDlmnjp 17:36:12.0000000\nPENALTY FOR FRANCE! HANDBALL!''#ArgentinaVsFrance #FIFAWorldCupFinal 17:36:09.0000000\nWtf handball. Penalty for France. Omg. 17:36:20.0000000\nOh no Issa handball Gonzalo, penalty for ???? #WorldCupFinal 17:36:36.0000000\nOmg !! Handball penalty France 17:36:37.0000000\nHANDBALL IN THE ARGENTINE BOX OG MY GOD IT'S A PENALTY FOR FRANCE 17:36:52.0000000\nHandball penalty'#ARGFRA 17:36:37.0000000\nNow a handball penalty. #WorldCupFinal https://t.co/o0Vy0qZxv0 17:36:32.0000000\nHANDBALL PENALTY FOR FRANCE 17:36:10.0000000\nHANDBALL AND ITS A PENALTY KICK FOR FRANCE AND MBAPPE! 17:36:47.0000000\nPenalty to France! Handball! This is absolute madness 17:36:25.0000000\nHANDBALL PENALTY FOR FRANCE!! #ARGFRA 17:36:12.0000000\nGONZALO MONTIEL HANDBALL''PENALTY TO FRANCE 17:36:14.0000000\nPENALTY! Handball in the box and France can level it here. #ARG #FRA 17:36:07.0000000\nHOW IS THIS MATCH STILL GOING ON?!''Handball. Penalty to France. We're about to witness a Mbapp\u00e9 hattrick. #FIFAWorldCup 17:36:47.0000000\nMontiel with the handball, PENALTY for France 17:36:51.0000000\nHandball.. Penalty for france.. 17:36:38.0000000\n@CTPhDinSports @highlghtheaven Argentina got a handball and France gets a penalty shot 17:36:46.0000000\nWHHHHAAAATTTTT?!?! A handball!!! And a penalty for France!!! The arm is up there 17:36:05.0000000\nPenalty given for handball to France!! ?? 17:36:48.0000000\nHandball, penalty for France!???? 17:36:26.0000000\nIt's a France penalty!! Handball given!!''#ARG 3-2 #FRA ''#FIFAWorldCup | #Qatar2022''https://t.co/UmozTF4u8i 17:36:04.0000000\nA penalty!!! for France! in the last minutes from a handball for Montiel #FIFAWorldCup 17:36:38.0000000\nHandball!!! Penalty to France! ??''#ARGvsFRA'#FIFAWorldCup2022 17:36:52.0000000\nHandball ''It's a penalty n France should be back to this game ooo ?????? 17:36:30.0000000\nHandball in the box. Penalty to France. It hit Montiel's elbow. Ref was right on it. #ARGFRA #FIFAWorldCup 17:36:31.0000000\nHANDBALL, PENALTY FRANCE OMDDDSSS WTF IS THIS GAME. 17:36:31.0000000\nFrance has a penalty with five minutes remaining! A handball sends them to the spot, and Mbappe will take it! 17:36:39.0000000\nanother penalty for France handball 17:36:34.0000000\nHANDBALL'PENALTY FOE FRANCE'ANOTHER TWISTT 17:36:56.0000000\nPenalty to France. Montiel handball - a tough one. 17:36:25.0000000\nHANDBALL ARGENTINA!! PENALTY KICK FRANCE!!! #ARGvsFRA #ArgentinaVsFrance #ARG #FRA #FIFAWorldCup #Qatar2022 17:36:17.0000000\nHANDBALL PENALTY FRANCE 17:36:29.0000000\nPENALTY TO FRANCE ''HANDBALL https://t.co/MWaO4tN2yQ 17:36:08.0000000\n#ArgentinaVsFrance'#FIFAWorldCup 'Handball! France awarded penalty 17:36:35.0000000\nHandball! Penalty to France and a yellow card to Montiel! This game keeps changing! #ARGFRA '#FIFAWorldCup | #Qatar2022 17:36:33.0000000\nHandball. Penalty for France 17:36:07.0000000\nPenalty To France for handball 17:36:52.0000000\nPENALTY!! HANDBALL FRANCE LETS GO 17:36:02.0000000\nHandball another penalty for France 17:36:02.0000000\nHANDBALL AND PENALTY FOR FRANCE 17:35:52.0000000\nPenalty for France yet again. Clear handball. This wc final refuses to end jeeez. Club football we need you ???? 17:36:42.0000000\nA PENALTY FOR FRANCE!!! HANDBALL ON MONTIEL!! #FIFAWorldCup 17:36:00.0000000\nHANDBALL ARGENTINA''FRANCE HAS A PENALTY 17:35:50.0000000\nHandball! Penalty to France! 17:36:52.0000000\nHANDBALL!!! PENALTY KICK FOR FRANCE AGAIN!!! #FIFAWorldCup #ARGFRA 17:36:28.0000000\nOH NOO OH NOO HANDBALL AND PENALTY FOR FRANCE NOOOOOOO ????????''SHITT LAAA MY COMMENT ONE HOUR AGO''NOOOOO #FIFAWorldCup 17:36:44.0000000\nAnother penalty to France for handball! Scenes! 17:36:22.0000000\nClear penalty for France, handball, no argument. We'll see how Kolo Muani takes it. 17:36:28.0000000\n#WorldCupFinal '#ArgentinaVsFrance ''115 ''penalty for France on a handball.''mbappe likely to shoot again. 17:36:38.0000000", "Describe as reporting live a current event in max 3 lines, what is happening right now using the following tweets, with a focus on the term \"handball\"\n\nsourceText Time\nHandball! Penalty kick for France!! #WorldCupFinal 17:36:26.0000000\nPenalty France handball! 17:35:51.0000000\nHandball and penalty for France 17:36:02.0000000\nHANDBALL!!! PENALTY!!!''#ARGFRA #FIFAWorldCup 17:36:04.0000000\nPenalty to France. Handball 17:35:44.0000000\nHANDBALL!! PENALTY!!! #WorldCup #ArgentinaVsFrance 17:36:40.0000000\nHandball from Montiel. Penalty to France #ARGFRA 17:36:13.0000000\nHANDBALL THATS A PENALTY KICK FOR FRANCE 17:36:12.0000000\nHANDBALL!!!!! FRANCE GETS A PENALTY!!!! 17:36:15.0000000\n@FIFAWorldCup @TeamMessi now Argentina plays handball! Penalty!!!!!!!!!!!!!!!!!! 17:36:41.0000000\nHandball!!!! Penalty to France....''Mbappe's hattrick? https://t.co/b711P9kC8Y 17:36:49.0000000\nPenalty to France for handball. 17:36:42.0000000\nPENALTY to France!! Handball in the area on an Mbappe shot and Mbappe will go or his hat-trick from the spot!! 17:36:02.0000000\nHandball called on Argentina in the penalty box!!! 17:36:03.0000000\nHandball Penalty! ????? #ARGFRA 17:36:06.0000000\nOmg it\u2019s handball, penalty to France ???? 17:36:23.0000000\nHandball and it\u2019s another penalty for France #ARGFRA 17:36:26.0000000\nPenalty to #FRA for handball by Montiel''#ARGFRA #Qatar2022 #WorldCup 17:36:24.0000000\nOH MY GOD! A FRANCE PENALTY! HANDBALL!!! 17:36:33.0000000\nPENALTY TO FRANCE! HANDBALL ON MONTIEL! ''https://t.co/c3VIDlmnjp 17:36:12.0000000\nPENALTY FOR FRANCE! HANDBALL!''#ArgentinaVsFrance #FIFAWorldCupFinal 17:36:09.0000000\nWtf handball. Penalty for France. Omg. 17:36:20.0000000\nOh no Issa handball Gonzalo, penalty for ???? #WorldCupFinal 17:36:36.0000000\nOmg !! Handball penalty France 17:36:37.0000000\nHANDBALL IN THE ARGENTINE BOX OG MY GOD IT'S A PENALTY FOR FRANCE 17:36:52.0000000\nHandball penalty'#ARGFRA 17:36:37.0000000\nNow a handball penalty. #WorldCupFinal https://t.co/o0Vy0qZxv0 17:36:32.0000000\nHANDBALL PENALTY FOR FRANCE 17:36:10.0000000\nHANDBALL AND ITS A PENALTY KICK FOR FRANCE AND MBAPPE! 17:36:47.0000000\nPenalty to France! Handball! This is absolute madness 17:36:25.0000000\nHANDBALL PENALTY FOR FRANCE!! #ARGFRA 17:36:12.0000000\nGONZALO MONTIEL HANDBALL''PENALTY TO FRANCE 17:36:14.0000000\nPENALTY! Handball in the box and France can level it here. #ARG #FRA 17:36:07.0000000\nHOW IS THIS MATCH STILL GOING ON?!''Handball. Penalty to France. We're about to witness a Mbapp\u00e9 hattrick. #FIFAWorldCup 17:36:47.0000000\nMontiel with the handball, PENALTY for France 17:36:51.0000000\nHandball.. Penalty for france.. 17:36:38.0000000\n@CTPhDinSports @highlghtheaven Argentina got a handball and France gets a penalty shot 17:36:46.0000000\nWHHHHAAAATTTTT?!?! A handball!!! And a penalty for France!!! The arm is up there 17:36:05.0000000\nPenalty given for handball to France!! ?? 17:36:48.0000000\nHandball, penalty for France!???? 17:36:26.0000000\nIt's a France penalty!! Handball given!!''#ARG 3-2 #FRA ''#FIFAWorldCup | #Qatar2022''https://t.co/UmozTF4u8i 17:36:04.0000000\nA penalty!!! for France! in the last minutes from a handball for Montiel #FIFAWorldCup 17:36:38.0000000\nHandball!!! Penalty to France! ??''#ARGvsFRA'#FIFAWorldCup2022 17:36:52.0000000\nHandball ''It's a penalty n France should be back to this game ooo ?????? 17:36:30.0000000\nHandball in the box. Penalty to France. It hit Montiel's elbow. Ref was right on it. #ARGFRA #FIFAWorldCup 17:36:31.0000000\nHANDBALL, PENALTY FRANCE OMDDDSSS WTF IS THIS GAME. 17:36:31.0000000\nFrance has a penalty with five minutes remaining! A handball sends them to the spot, and Mbappe will take it! 17:36:39.0000000\nanother penalty for France handball 17:36:34.0000000\nHANDBALL'PENALTY FOE FRANCE'ANOTHER TWISTT 17:36:56.0000000\nPenalty to France. Montiel handball - a tough one. 17:36:25.0000000\nHANDBALL ARGENTINA!! PENALTY KICK FRANCE!!! #ARGvsFRA #ArgentinaVsFrance #ARG #FRA #FIFAWorldCup #Qatar2022 17:36:17.0000000\nHANDBALL PENALTY FRANCE 17:36:29.0000000\nPENALTY TO FRANCE ''HANDBALL https://t.co/MWaO4tN2yQ 17:36:08.0000000\n#ArgentinaVsFrance'#FIFAWorldCup 'Handball! France awarded penalty 17:36:35.0000000\nHandball! Penalty to France and a yellow card to Montiel! This game keeps changing! #ARGFRA '#FIFAWorldCup | #Qatar2022 17:36:33.0000000\nHandball. Penalty for France 17:36:07.0000000\nPenalty To France for handball 17:36:52.0000000\nPENALTY!! HANDBALL FRANCE LETS GO 17:36:02.0000000\nHandball another penalty for France 17:36:02.0000000\nHANDBALL AND PENALTY FOR FRANCE 17:35:52.0000000\nPenalty for France yet again. Clear handball. This wc final refuses to end jeeez. Club football we need you ???? 17:36:42.0000000\nA PENALTY FOR FRANCE!!! HANDBALL ON MONTIEL!! #FIFAWorldCup 17:36:00.0000000\nHANDBALL ARGENTINA''FRANCE HAS A PENALTY 17:35:50.0000000\nHandball! Penalty to France! 17:36:52.0000000\nHANDBALL!!! PENALTY KICK FOR FRANCE AGAIN!!! #FIFAWorldCup #ARGFRA 17:36:28.0000000\nOH NOO OH NOO HANDBALL AND PENALTY FOR FRANCE NOOOOOOO ????????''SHITT LAAA MY COMMENT ONE HOUR AGO''NOOOOO #FIFAWorldCup 17:36:44.0000000\nAnother penalty to France for handball! Scenes! 17:36:22.0000000\nClear penalty for France, handball, no argument. We'll see how Kolo Muani takes it. 17:36:28.0000000\n#WorldCupFinal '#ArgentinaVsFrance ''115 ''penalty for France on a handball.''mbappe likely to shoot again. 17:36:38.0000000", "Summarize this section for me:\n\nSEC. 7. RESOLUTION OF DISAPPROVAL OF DESIGNATION OR REMOVAL OF \n DESIGNATION OF A FOREIGN ADVERSARY.\n\n (a) Definition.--In this section--\n (1) the term ``covered joint resolution'' means a joint \n resolution of disapproval of designation or a joint resolution \n of disapproval of removal of designation;\n (2) the term ``joint resolution of disapproval of \n designation'' means a joint resolution the matter after the \n resolving clause of which is as follows: ``That Congress \n disapproves the designation by the Secretary of Commerce of \\_\\_\\_ \n as a foreign adversary for purposes of the Securing the \n Information and Communications Technology and Services Supply \n Chain Act of 2023, and such designation shall have no force or \n effect until the Secretary of Commerce provides specific \n evidence to the relevant committees of Congress regarding the \n removal of designation under section 6(a) of that Act.'' (The \n blank space being appropriately filled in with the name of the \n foreign person of which the Secretary has designated as a \n foreign adversary of for purposes of this Act); and\n (3) the term ``joint resolution of disapproval of removal \n of designation'' means a joint resolution the matter after the \n resolving clause of which is as follows: ``That Congress \n disapproves the removal of designation by the Secretary of \n Commerce of \\_\\_\\_ as a foreign adversary for purposes of the \n Securing the Information and Communications Technology and \n Services Supply Chain Act of 2023, and such removal shall have \n no force or effect until the Secretary of Commerce provides \n specific evidence to the relevant committees of Congress \n regarding the removal of designation under section 6(a) of that \n Act.'' (The blank space being appropriately filled in with the \n name of the foreign government or regime of which the Secretary \n has removed the designation as a foreign adversary of for \n purposes of this Act).\n (b) Expedited Consideration of Legislation.--\n (1) Initiation.--In the event the Secretary designates a \n foreign government or regime as a foreign adversary or removes \n such designation as a foreign adversary, a joint resolution of \n disapproval of designation or a joint resolution of disapproval \n of removal of designation, as applicable, that is introduced \n during the 60-calendar day period thereafter shall be entitled \n to expedited consideration pursuant to this subsection.\n (2) Introduction.--During the 60-calendar day period \n provided for in paragraph (1), a covered joint resolution may \n be introduced--\n (A) in the Senate, by the Majority Leader (or the \n designee of the Majority Leader) or the Minority Leader \n (or the designee of the Minority Leader); and\n (B) in the House of Representatives, by the Speaker \n or the Minority Leader.\n (3) Floor consideration in house of representatives.--\n (A) Reporting and discharge.--If a relevant \n committee of the House to which a covered joint \n resolution has been referred has not reported such \n covered joint resolution within 10 legislative days \n after the date of referral, that committee shall be \n discharged from further consideration thereof.\n (B) Proceeding to consideration.--Beginning on the \n third legislative day after each committee to which \n covered joint resolution has been referred reports the \n covered joint resolution to the House or has been \n discharged from further consideration thereof, it shall \n be in order to move to proceed to consider the covered \n joint resolution in the House. All points of order \n against the motion are waived. Such a motion shall not \n be in order after the House has disposed of a motion to \n proceed on the covered joint resolution with regard to \n the same agreement. The previous question shall be \n considered as ordered on the motion to its adoption \n without intervening motion. The motion shall not be \n debatable. A motion to reconsider the vote by which the \n motion is disposed of shall not be in order.\n (C) Consideration.--The covered joint resolution \n shall be considered as read. All points of order \n against the covered joint resolution and against its \n consideration are waived. The previous question shall \n be considered as ordered on the covered joint \n resolution to final passage without intervening motion \n except 2 hours of debate equally divided and controlled \n by the sponsor of the covered joint resolution (or a \n designee) and an opponent. A motion to reconsider the \n vote on passage of the covered joint resolution shall \n not be in order.\n (4) Consideration in the senate.--\n (A) Committee referral.--A covered joint resolution \n introduced in the Senate shall be referred to the \n relevant committees of the Senate.\n (B) Reporting and discharge.--If a relevant \n committee of the Senate has not reported such covered \n joint resolution within 10 session days after the date \n of referral of such legislation, that committee shall \n be discharged from further consideration of such \n legislation and the covered joint resolution shall be \n placed on the appropriate calendar.\n (C) Proceeding to consideration.--Notwithstanding \n Rule XXII of the Standing Rules of the Senate, it is in \n order at any time after each committee authorized to \n consider covered joint resolution reports it to the \n Senate or has been discharged from its consideration \n (even though a previous motion to the same effect has \n been disagreed to) to move to proceed to the \n consideration of the covered joint resolution, and all \n points of order against covered joint resolution (and \n against consideration of the covered joint resolution) \n are waived. The motion to proceed is not debatable. The \n motion is not subject to a motion to postpone. A motion \n to reconsider the vote by which the motion is agreed to \n or disagreed to shall not be in order. If a motion to \n proceed to the consideration of the covered joint \n resolution is agreed to, the covered joint resolution \n shall remain the unfinished business until disposed of.\n (D) Debate.--Debate on covered joint resolution, \n and on all debatable motions and appeals in connection \n therewith, shall be limited to not more than 10 hours, \n which shall be divided equally between the majority and \n minority leaders or their designees. A motion to \n further limit debate is in order and not debatable. An \n amendment to, or a motion to postpone, or a motion to \n proceed to the consideration of other business, or a \n motion to recommit the covered joint resolution is not \n in order.\n (E) Vote on passage.--The vote on passage shall \n occur immediately following the conclusion of the \n debate on the covered joint resolution and a single \n quorum call at the conclusion of the debate, if \n requested in accordance with the rules of the Senate.\n (F) Rulings of the chair on procedure.--Appeals \n from the decisions of the Chair relating to the \n application of the rules of the Senate, as the case may \n be, to the procedure relating to a covered joint \n resolution shall be decided without debate.\n (G) Consideration of veto messages.--Debate in the \n Senate of any veto message with respect to a covered \n joint resolution, including all debatable motions and \n appeals in connection with such covered joint \n resolution, shall be limited to 10 hours, to be equally \n divided between, and controlled by, the Majority Leader \n and the Minority Leader or their designees.\n (5) Rules relating to senate and house of \n representatives.--\n (A) Coordination with action by other house.--If, \n before the passage by one House of a covered joint \n resolution of that House, that House receives a covered \n joint resolution from the other House, then the \n following procedures shall apply:\n (i) The covered joint resolution of the \n other House shall not be referred to a \n committee.\n (ii) With respect to covered joint \n resolution of the House receiving the \n legislation--\n (I) the procedure in that House \n shall be the same as if no covered \n joint resolution had been received from \n the other House; but\n (II) the vote on passage shall be \n on the covered joint resolution of the \n other House.\n (B) Treatment of a covered joint resolution of \n other house.--If one House fails to introduce a covered \n joint resolution under this section, the covered joint \n resolution of the other House shall be entitled to \n expedited floor procedures under this section.\n (C) Treatment of companion measures.--If, following \n passage of the covered joint resolution in the Senate, \n the Senate then receives a companion measure from the \n House of Representatives, the companion measure shall \n not be debatable.\n (c) Rules of Senate and House of Representatives.--Subsection (b) \nis enacted by Congress--\n (1) as an exercise of the rulemaking power of the Senate \n and the House of Representatives, respectively, and as such are \n deemed a part of the rules of each House, respectively, but \n applicable only with respect to the procedure to be followed in \n that House in the case of legislation described in those \n sections, and supersede other rules only to the extent that \n they are inconsistent with such rules; and\n (2) with full recognition of the constitutional right of \n either House to change the rules (so far as relating to the \n procedure of that House) at any time, in the same manner, and \n to the same extent as in the case of any other rule of that \n House.\n (d) Effect of Covered Joint Resolution.--\n (1) Joint resolutions of disapproval of designation.--A \n joint resolution of disapproval of designation that is enacted \n in accordance with this section shall remove the designation as \n a foreign adversary of a foreign government or regime that is \n the subject of the joint resolution of disapproval of \n designation for purposes of this Act.\n (2) Joint resolutions of disapproval of removal of \n designation.--A joint resolution of disapproval of removal of \n designation that is enacted in accordance with this section \n shall prohibit the removal of designation as a foreign \n adversary of a foreign government or regime that is the subject \n of the joint resolution of disapproval of removal of \n designation for purposes of this Act.1 / 1", "Contact Name (First, Last Name) Email Title Country Arcelor BU Comments\nLakshmi Mittal lakshmi.mittal@arcelormittal.com CEO UK ArcelorMittal International Luxembourg S.A. CEO Group\nJohn Melnick john.melnick@arcelormittal.com Chief Information Security & Compliance Officer USA ArcelorMittal USA LLC Scope : Canada, United States, Mexico, Caribbean, Brazil and Argentina\nClay Neal clay.neal@arcelormittal.com Manager, IT Compliance & Risk USA ArcelorMittal USA LLC Scope : ArcelorMittal Princeton\nDean Sheets dean.sheets@arcelormittal.com North America Manager of IT Security, Email, Directory Services USA ArcelorMittal USA LLC \"Scope : Responsible for Security, Email and Directory Services.\n Manage a talented distributed team in the USA, India, Canada and Brazil.\"\nAlan Barsophy alan.barsophy@arcelormittal.com Chief Technology Officer USA ArcelorMittal USA LLC \nJohn Quinkert john.quinkert@arcelormittal.com Division Manager IT Infrastruture-Telecom USA ArcelorMittal USA LLC \nAlex Ternes alex.ternes@arcelormittal.com Division Manager: Data Center Operations, Mainframe Services and Disaster Recovery USA ArcelorMittal USA LLC \nTom Vrahoretis tom.vrahoretis@arcelormittal.com Network Manager USA ArcelorMittal USA LLC \nLucas Widehem lucas.widehem@arcelormittal.com Network Services Specialist - Group IT FRANCE ArcelorMittal France S.A.S. \nDavid Glijer david.glijer@arcelormittal.com CDO FRANCE ArcelorMittal France S.A.S. \nFran\u00e7ois Desse francois.desse@arcelormittal.com Manager Support Senior, Deputy CDO FRANCE ArcelorMittal France S.A.S. \nDamien Soller damien.soller@arcelormittal.com Manager Support Projets FRANCE ArcelorMittal France S.A.S. \nValentin Picot valentin.picot@arcelormittal.com Legal\u00a0Counsel - IP/IT Legal Team\u00a0 FRANCE ArcelorMittal France S.A.S. \nLaurent Legry laurent.legry@arcelormittal.com Responsable Infrastructures Syst\u00e8mes FRANCE ArcelorMittal France S.A.S. \nValentin Melchior valentin.melchior@arcelormittal.com Chef de projet FRANCE ArcelorMittal France S.A.S. \nVincent Prin vincent.prin@arcelormittal.com Head of IS & Infrastructure FRANCE ArcelorMittal France S.A.S. Scope : Management \u00e9quipe locale, gestion plan de charge, planning, budget, pilotage de l'activit\u00e9 op\u00e9rationnelle et projets, gestion des contrats de prestation et recrutement. Chef de projet IT.\nFlorian Blot florian.blot@arcelormittal.com IT Operations Manager FRANCE ArcelorMittal France S.A.S. Scope : ArcelorMittal Construction\nUzan Franck franck.uzan@arcelormittal.com Architecture / Security Officer FRANCE ArcelorMittal International Luxembourg S.A. Reports to Andrew Van Lelyveld ? India focus - Managed services focus.\nDavid Toulotte david.toulotte@arcelormittal.com Security Manager, Responsible for transformation programs IT FRANCE ArcelorMittal France S.A.S. Located in Dunkerke + Scope : SAP Cloud transformation, Laptop Image standardisation, GDPR deployment\nYann Friscourt yann.friscourt@arcelormittal.com Manager, Network & Local Security Officer FRANCE ArcelorMittal France S.A.S. \nGilles Garcia gilles.garcia@arcelormittal.com Manager, Infrastructure (ArcelorMittal Mediterranee) FRANCE ArcelorMittal M\u00e9diterran\u00e9e S.A.S. \nDavid MOCKELYN david.mockelyn@arcelormittal.com IT Lead - Group Network & Cloud Infrastructure FRANCE ArcelorMittal International Luxembourg S.A. Scope : Arcelor Mittal Corporate\nMichael Fiey michael.fiey@arcelormittal.com Chief Information Security Officer - ArcelorMittal Europe Flat Products FRANCE ArcelorMittal France S.A.S. Scope : Flat Europe. Responsible for Cyber-risk evaluation and security program management in coordination with IT/OT Security Officers in Europe (25 people) European Security Operation Center (10 people)\nPhilippe Hubert philippe.hubert@arcelormittal.com Chief Information Officer (Mining) CANADA ArcelorMittal Mining Canada G.P. and ArcelorMittal Infrastructure Canada G.P Scope : CIO Mining (Multi operations IT management, Digital roadmap plan, ERP, Automation systems)\nPatrice Sarrazin patrice.sarrazin@arcelormittal.com Director, IT & Automation CANADA ArcelorMittal Long Products Canada G.P. Scope : Long Canada (SAP, Microsoft Cloud, IT/OT)\nSimon Bernier simon.bernier@arcelormittal.com Director, Information Technology CANADA ArcelorMittal Long Products Canada G.P. Scope : Long Canada\nPaul Valvasori paul.valvasori@arcelormittal.com Manager, Citrix Service - Americas CANADA ArcelorMittal Dofasco G.P. Scope : Americas (Citrix Services)\nLarry Laskowski larry.laskowski@arcelormittal.com Manager, Security (ArcelorMittal Dofasco) CANADA ArcelorMittal Dofasco G.P. Scope : Dofasco Security\nWayne Bland wayne.bland@arcelormittal.com Chief Technology Officer (Tubular Products) CANADA ArcelorMittal Dofasco G.P. Scope : CTO Tubular Division\nLionel Paulard lionel.paulard@arcelormittal.com R&D CIO & CISO FRANCE ArcelorMittal France S.A.S. Based in Metz\nDidier Collot didier.collot@arcelormittal.com Head of Business Transformation FRANCE ArcelorMittal France S.A.S. Scope : ArcelorMittal Downstream Solutions\nMaarten Depamelaere maarten.depamelaere@arcelormittal.com Executive IT Management CIO, CTO BELGIUM ArcelorMittal Belgium N.V. Scope : ArcelorMittal Tailored Blanks\nMarc Vereecke marc.vereecke@arcelormittal.com Chief Technology Officer BELGIUM ArcelorMittal Belgium N.V. \nPhilippe Van Rietvelde philippe.vanrietvelde@arcelormittal.com Head of Midrange IT Infrastructure team (ArcelorMittal Europa BD North) BELGIUM ArcelorMittal Belgium N.V. \nAlbert Renard albert.renard@arcelormittal.com Project Manager BELGIUM ArcelorMittal Belgium N.V. Scope : Project Manager for Infrastructure image transformation on Europe scope\nPhilippe Mathieu philippe.mathieu@arcelormittal.com Manager, IT Security BELGIUM ArcelorMittal Belgium N.V. \nJohan Barnard johan.barnard@arcelormittal.com Manager, Global Purchasing for Capex Investments, IS/IT, Telco and Shared Services Europe LUXEMBOURG ArcelorMittal International Luxembourg S.A. Scope : Responsible for Global IT purchasing of Hardware, Services, Software, IT Projects, Infrastructure and Telecommunications, Capex Investment projects and Shared Services\nMarc Mathei marc.mathei@arcelormittal.com Global Assurance - ITGC LUXEMBOURG ArcelorMittal International Luxembourg S.A. \nAurelian Popa aurelian.popa@arcelormittal.com CIO Long Carbon Europe LUXEMBOURG ArcelorMittal International Luxembourg S.A. Scope : Long Carbon Europe (member of the Management Committee meetings)\nRobert Vroklage robert.vroklage@arcelormittal.com Digital Solutions Manager LUXEMBOURG ArcelorMittal International Luxembourg S.A. \nFernando Sampaio fernando.sampaio@arcelormittal.com Head of Cloud Center of Excellence LUXEMBOURG ArcelorMittal International Luxembourg S.A. \nSergio Garcia Granda sergio.garcia@arcelormittal.com Head of IT Department eWorkplace LUXEMBOURG ArcelorMittal International Luxembourg S.A. Scope : Reporting to Europe IT Leadership Committee, I lead the transversal functions workplace transformation roll-out and support. We manage the entire lifecycle from solution design, budget definition, approval, project definition, project deployment and run and maintain. We aim to deliver a digital workplace following the company strategy in order to maximise the use of secured cloud solutions and taking care of the entire required infrastructure to meet this target. Main focus is to support Business process standardization across the segment, supporting the company strategy to streamline SSG&A costs.\nEvgeniy Baranets evgeniy.baranets@arcelormittal.com Head of IT Security & Risk Management LUXEMBOURG ArcelorMittal International Luxembourg S.A. Scope : Long Carbon Europe\nSourabh Purkayastha sourabh.purkayastha@arcelormittal.com IT Contract & Cost Management LUXEMBOURG ArcelorMittal International Luxembourg S.A. \nDaniel Janczak daniel.janczak@arcelormittal.com Chief Technology Officer ACIS LUXEMBOURG ArcelorMittal International Luxembourg S.A. Scope : CTO ACIS\nJerome Fourny jerome.fourny@arcelormittal.com Group IT Security Lead LUXEMBOURG ArcelorMittal International Luxembourg S.A. Scope : Corporate\nHenk Scheffer henk.scheffer@arcelormittal.com Chief compliance officer & Head of corporate governance LUXEMBOURG ArcelorMittal International Luxembourg S.A. \nAndrew Van Lelyveld andrew.vanlelyveld@arcelormittal.com IT Infrastructure and Global Security Manager LUXEMBOURG ArcelorMittal International Luxembourg S.A. Scope : Corporate - Global Service Lines\nHugues Lacaille hugues.lacaille@arcelormittal.com Group IT Compliance & Security Officer LUXEMBOURG ArcelorMittal International Luxembourg S.A. Scope : Corporate", "Adler Victor Texeira adler.teixeira@arcelormittal.com IT Manager - COE IT Audits LUXEMBOURG ArcelorMittal International Luxembourg S.A. Scope : Corporate - IT Audits\nJean-Baptiste Legrand jean-baptiste.legrand@arcelormittal.com Infrastructure Lead FRANCE ArcelorMittal International Luxembourg S.A. Scope : ArcelorMittal Downstream Solutions\nNikhil Nagdev nikhil.nagdev@arcelormittal.com Manager, IT Controls LUXEMBOURG ArcelorMittal International Luxembourg S.A. \nOvidiu Nartea ovidiu.nartea@arcelormittal.com Lead Buyer Telco LUXEMBOURG ArcelorMittal International Luxembourg S.A. \nWim Le Noir wim.lenoir@arcelormittal.com Manager, Technology Transformation BELGIUM ArcelorMittal International Luxembourg S.A. O365 in a federated context\nYoussef Saghir youssef.saghir@arcelormittal.com Lead Buyer - Capital Goods LUXEMBOURG ArcelorMittal International Luxembourg S.A. Member of Capital Goods (Capex), part of Corporate Procurement. Department responsible for Commercial oversight for CapEx ($2M +) projects for Group worldwide.\nTomasz Frankiewicz tomasz.frankiewicz@arcelormittal.com Director of Automation, Industrial IT and Models Department POLAND ArcelorMittal Poland S.A. The Digitalization, Industry 4.0 and full responsibility for IT and Process Automation in all ArcelorMittal Poland S.A. locations\nRaymond Trel raymond.trel@arcelormittal.com Manager, Systems NETHERLANDS ArcelorMittal Staalhandel B.V \nJuan Miguel Gil juan-miguel.gil@arcelormittal.com IT Manager Corporate Spain SPAIN ArcelorMittal Espa\u00f1a S.A. Management of the Corporate entities in Spain. Consolidation and Implementation of Corporate projects.\nDominique Geeraert dominique.geeraert@arcelormittal.com Director, Information Technology POLAND ArcelorMittal Poland S.A. \nJohn Bettie Gizea john.gizea@arcelormittal.com Head of IT LIBERIA ArcelorMittal Liberia Ltd \nHumberto Bonisson Junior humberto.bonisson@arcelormittal.com.br Operations and Infrastructure Manager BRAZIL ArcelorMittal Brasil S.A. \nCardoso Arnon arnon.cardoso@arcelormittal.com Infrastructure Manager & IT Security Manager at Arcelormittal Sistemas BRAZIL ArcelorMittal Brasil S.A. \nMarcelo Barroso marcelo.barroso@arcelormittal.com.br IT Risk and Compliance Manager BRAZIL ArcelorMittal Brasil S.A. \nMateus Gerboni mateus.gerboni@arcelormittal.com.br IT Infrastructure Architect / Business Partner BRAZIL ArcelorMittal Brasil S.A. \nLaercio Vitrio laercio.vitrio@arcelormittal.com.br Manager of TI Business Partners - Corporate Center BRAZIL ArcelorMittal Brasil S.A. \nMichel Vargas michel.vargas@arcelormittal.com.br IT Business Partner BRAZIL ArcelorMittal Brasil S.A. Responsible for all the IT subjects involving IS, including demands and projects, for Long Carbon LATAM & Mining Brazil business segments.\nRodrigo Guimaraes rodrigo.guimaraes@arcelormittal.com.br IT Business Partner BRAZIL ArcelorMittal Brasil S.A. \nMarcio Correia marcio.correia@arcelormittal.com.br IT Business Partner BRAZIL ArcelorMittal Brasil S.A. SAP\nLuciano Gomes luciano.gomes@arcelormittal.com.br Network and Telecommunications Manager BRAZIL ArcelorMittal Brasil S.A. \nMarcelo Faria marcelo.faria@arcelormittal.com.br Network and Telecommunications Manager BRAZIL ArcelorMittal Brasil S.A. \nHenrique Matiole henrique.matiole@arcelormittal.com.br Air Servers and Cloud IaaS Manager BRAZIL ArcelorMittal Brasil S.A. \nGuilherme Vanucci guilherme.vanucci@arcelormittal.com.br Application Manager BRAZIL ArcelorMittal Brasil S.A. \nJan Ramone jan.ramone@arcelormittal.com.br IT infrastructure analyst BRAZIL ArcelorMittal Brasil S.A. \nViviane Coelho viviane.coelho@arcelormittal.com.br IT infrastructure analyst - Junior BRAZIL ArcelorMittal Brasil S.A. \nRinaldo Miranda rinaldo.miranda@arcelormittal.com.br IT infrastructure analyst BRAZIL ArcelorMittal Brasil S.A. \nLeandro Nogueira leandro.nogueira@arcelormittal.com.br IT infrastructure analyst BRAZIL ArcelorMittal Brasil S.A. \nArthur Santiago arthur.santiago@arcelormittal.com.br IT infrastructure analyst BRAZIL ArcelorMittal Brasil S.A. Network Architect, designing, implementing, monitoring and managing LAN, WAN, WLAN and Firewalls for Data Centers and business units; Interface with suppliers; Capacity and budget (OPEX and CAPEX) planning;\nFabricio Silveira fabricio.silveira@arcelormittal.com.br Project Manager BRAZIL ArcelorMittal Brasil S.A. \nGabriela Alves gabriela.alves@arcelormittal.com.br Center of Excellence and International Projects Manager / End User Specialist BRAZIL ArcelorMittal Brasil S.A. \nAndy Pierre andy.pierre@arcelormittal.com Transformation, Program Manager CANADA ArcelorMittal Mining Canada G.P. and ArcelorMittal Infrastructure Canada G.P \nLouis Plante louis.plante@arcelormittal.com VP Chief Technology Officer CANADA ArcelorMittal Long Products Canada G.P. \nJohn O'Grady john.ogrady@arcelormittal.com Manager IT Solutions CANADA ArcelorMittal Dofasco G.P. \nMark Radey mark.radey@arcelormittal.com Head of IT Infrastructure - Global Mining at ArcelorMittal Mining CANADA ArcelorMittal Mining Canada G.P. and ArcelorMittal Infrastructure Canada G.P \nLuc Couillard luc.couillard@arcelormittal.com Infrastructure Manager CANADA ArcelorMittal Long Products Canada G.P. \nStephane Brochu stephane.brochu@arcelormittal.com Infrastructure & Telecom Manager CANADA ArcelorMittal Mining Canada G.P. and ArcelorMittal Infrastructure Canada G.P Scope : Supervise les \u00e9quipes Centre d'appel, Bureautique, Infrastructure et T\u00e9l\u00e9communication n\u00e9cessaires \u00e0 la maintenance et l'\u00e9volution des outils et infrastructure informatique de l'entreprise. \nFabio Barbosa fabio.barbosa@arcelormittal.com Director Of Purchasing (ArcelorMittal Tailored Blanks) USA ArcelorMittal Dofasco G.P. Scope : Americas Tailored Blanks\nEd Dickhoff ed.dickhoff@arcelormittal.com Director of Information Technology (ArcelorMittal Tailored Blanks) CANADA ArcelorMittal Dofasco G.P. Scope : Americas Tailored Blanks\nTyler Deptuck tyler.deptuck@arcelormittal.com Senior Security Analyst (ArcelorMittal Dofasco) CANADA ArcelorMittal Dofasco G.P. \nRobert Cousins robert.cousins@arcelormittal.com IT Security Specialist (ArcelorMittal Dofasco) CANADA ArcelorMittal Dofasco G.P. \nMohamed Rizan mohamed.rizan@arcelormittal.com Network Administrator (ArcelorMittal Tailored Blanks) CANADA ArcelorMittal Dofasco G.P. \nMarco Chenard marco.chenard@arcelormittal.com IT Network Analyst CANADA ArcelorMittal Mining Canada G.P. and ArcelorMittal Infrastructure Canada G.P \nAntony Antoniou antony.antoniou@arcelormittal.com System Administrator CANADA ArcelorMittal Mining Canada G.P. and ArcelorMittal Infrastructure Canada G.P \nRoman Wojtow roman\\_wojtow@dofasco.ca Technical Leader Networks CANADA ArcelorMittal Dofasco G.P. \nAhad Jamil ahad.jamil@arcelormittal.com Network Specialist CANADA ArcelorMittal Dofasco G.P. Cisco routers and switches. Cisco Catalyst 2960, 3750, 6800, Nexus 9K, ASR routers and and hardened industrial units 4010 etc. Monitoring and maintaining network management tools like NNMi, Cisco Prime, Totalview, PRTG. Part of Global WAN team and implementing SD-WAN solution presently.\nBrian Benko brian.benko@arcelormittal.com Chief Digital Officer CANADA ArcelorMittal Dofasco G.P. \"A member of the ArcelorMittal North America Executive Team. Responsible for leading the development of the Industry 4.0 Digital Strategy and the IT Strategy for the North American units of ArcelorMittal.\n\"\nRaj Nijjar raj.nijjar@arcelormittal.com IT Manager (ArcelorMittal Tailored Blanks) CANADA ArcelorMittal Dofasco G.P. Scope : Americas Tailored Blanks\nSandy Coleman sandy.coleman@arcelormittal.com IT Manager CANADA ArcelorMittal Dofasco G.P. \nKevin Bowen kevin.bowen@arcelormittal.com IT Manager CANADA ArcelorMittal Dofasco G.P. \nRahul Kumar rahul.kumar@arcelormittal.com CIO INDIA ArcelorMittal Nippon Steel India", "{Provide a summary in outline format in plain text and then provide an overall summary of the section. Do not provide an overall summary until you have provided a summary in outline format.}\n\nSEC. 7. RESOLUTION OF DISAPPROVAL OF DESIGNATION OR REMOVAL OF \n DESIGNATION OF A FOREIGN ADVERSARY.\n\n (a) Definition.--In this section--\n (1) the term ``covered joint resolution'' means a joint \n resolution of disapproval of designation or a joint resolution \n of disapproval of removal of designation;\n (2) the term ``joint resolution of disapproval of \n designation'' means a joint resolution the matter after the \n resolving clause of which is as follows: ``That Congress \n disapproves the designation by the Secretary of Commerce of \\_\\_\\_ \n as a foreign adversary for purposes of the Securing the \n Information and Communications Technology and Services Supply \n Chain Act of 2023, and such designation shall have no force or \n effect until the Secretary of Commerce provides specific \n evidence to the relevant committees of Congress regarding the \n removal of designation under section 6(a) of that Act.'' (The \n blank space being appropriately filled in with the name of the \n foreign person of which the Secretary has designated as a \n foreign adversary of for purposes of this Act); and\n (3) the term ``joint resolution of disapproval of removal \n of designation'' means a joint resolution the matter after the \n resolving clause of which is as follows: ``That Congress \n disapproves the removal of designation by the Secretary of \n Commerce of \\_\\_\\_ as a foreign adversary for purposes of the \n Securing the Information and Communications Technology and \n Services Supply Chain Act of 2023, and such removal shall have \n no force or effect until the Secretary of Commerce provides \n specific evidence to the relevant committees of Congress \n regarding the removal of designation under section 6(a) of that \n Act.'' (The blank space being appropriately filled in with the \n name of the foreign government or regime of which the Secretary \n has removed the designation as a foreign adversary of for \n purposes of this Act).\n (b) Expedited Consideration of Legislation.--\n (1) Initiation.--In the event the Secretary designates a \n foreign government or regime as a foreign adversary or removes \n such designation as a foreign adversary, a joint resolution of \n disapproval of designation or a joint resolution of disapproval \n of removal of designation, as applicable, that is introduced \n during the 60-calendar day period thereafter shall be entitled \n to expedited consideration pursuant to this subsection.\n (2) Introduction.--During the 60-calendar day period \n provided for in paragraph (1), a covered joint resolution may \n be introduced--\n (A) in the Senate, by the Majority Leader (or the \n designee of the Majority Leader) or the Minority Leader \n (or the designee of the Minority Leader); and\n (B) in the House of Representatives, by the Speaker \n or the Minority Leader.\n (3) Floor consideration in house of representatives.--\n (A) Reporting and discharge.--If a relevant \n committee of the House to which a covered joint \n resolution has been referred has not reported such \n covered joint resolution within 10 legislative days \n after the date of referral, that committee shall be \n discharged from further consideration thereof.\n (B) Proceeding to consideration.--Beginning on the \n third legislative day after each committee to which \n covered joint resolution has been referred reports the \n covered joint resolution to the House or has been \n discharged from further consideration thereof, it shall \n be in order to move to proceed to consider the covered \n joint resolution in the House. All points of order \n against the motion are waived. Such a motion shall not \n be in order after the House has disposed of a motion to \n proceed on the covered joint resolution with regard to \n the same agreement. The previous question shall be \n considered as ordered on the motion to its adoption \n without intervening motion. The motion shall not be \n debatable. A motion to reconsider the vote by which the \n motion is disposed of shall not be in order.\n \u00a9 Consideration.--The covered joint resolution \n shall be considered as read. All points of order \n against the covered joint resolution and against its \n consideration are waived. The previous question shall \n be considered as ordered on the covered joint \n resolution to final passage without intervening motion \n except 2 hours of debate equally divided and controlled \n by the sponsor of the covered joint resolution (or a \n designee) and an opponent. A motion to reconsider the \n vote on passage of the covered joint resolution shall \n not be in order.\n (4) Consideration in the senate.--\n (A) Committee referral.--A covered joint resolution \n introduced in the Senate shall be referred to the \n relevant committees of the Senate.\n (B) Reporting and discharge.--If a relevant \n committee of the Senate has not reported such covered \n joint resolution within 10 session days after the date \n of referral of such legislation, that committee shall \n be discharged from further consideration of such \n legislation and the covered joint resolution shall be \n placed on the appropriate calendar.\n \u00a9 Proceeding to consideration.--Notwithstanding \n Rule XXII of the Standing Rules of the Senate, it is in \n order at any time after each committee authorized to \n consider covered joint resolution reports it to the \n Senate or has been discharged from its consideration \n (even though a previous motion to the same effect has \n been disagreed to) to move to proceed to the \n consideration of the covered joint resolution, and all \n points of order against covered joint resolution (and \n against consideration of the covered joint resolution) \n are waived. The motion to proceed is not debatable. The \n motion is not subject to a motion to postpone. A motion \n to reconsider the vote by which the motion is agreed to \n or disagreed to shall not be in order. If a motion to \n proceed to the consideration of the covered joint \n resolution is agreed to, the covered joint resolution \n shall remain the unfinished business until disposed of.\n (D) Debate.--Debate on covered joint resolution, \n and on all debatable motions and appeals in connection \n therewith, shall be limited to not more than 10 hours, \n which shall be divided equally between the majority and \n minority leaders or their designees. A motion to \n further limit debate is in order and not debatable. An \n amendment to, or a motion to postpone, or a motion to \n proceed to the consideration of other business, or a \n motion to recommit the covered joint resolution is not \n in order.\n (E) Vote on passage.--The vote on passage shall \n occur immediately following the conclusion of the \n debate on the covered joint resolution and a single \n quorum call at the conclusion of the debate, if \n requested in accordance with the rules of the Senate.\n \u273f Rulings of the chair on procedure.--Appeals \n from the decisions of the Chair relating to the \n application of the rules of the Senate, as the case may \n be, to the procedure relating to a covered joint \n resolution shall be decided without debate.\n (G) Consideration of veto messages.--Debate in the \n Senate of any veto message with respect to a covered \n joint resolution, including all debatable motions and \n appeals in connection with such covered joint \n resolution, shall be limited to 10 hours, to be equally \n divided between, and controlled by, the Majority Leader \n and the Minority Leader or their designees.\n \u534c Rules relating to senate and house of \n representatives.--\n (A) Coordination with action by other house.--If, \n before the passage by one House of a covered joint \n resolution of that House, that House receives a covered \n joint resolution from the other House, then the \n following procedures shall apply:\n (i) The covered joint resolution of the \n other House shall not be referred to a \n committee.\n (ii) With respect to covered joint \n resolution of the House receiving the \n legislation--\n (I) the procedure in that House \n shall be the same as if no covered \n joint resolution had been received from \n the other House; but\n (II) the vote on passage shall be \n on the covered joint resolution of the \n other House.\n (B) Treatment of a covered joint resolution of \n other house.--If one House fails to introduce a covered \n joint resolution under this section, the covered joint \n resolution of the other House shall be entitled to \n expedited floor procedures under this section.\n \u00a9 Treatment of companion measures.--If, following \n passage of the covered joint resolution in the Senate, \n the Senate then receives a companion measure from the \n House of Representatives, the companion measure shall \n not be debatable.\n \u00a9 Rules of Senate and House of Representatives.--Subsection (b) \nis enacted by Congress--\n (1) as an exercise of the rulemaking power of the Senate \n and the House of Representatives, respectively, and as such are \n deemed a part of the rules of each House, respectively, but \n applicable only with respect to the procedure to be followed in \n that House in the case of legislation described in those \n sections, and supersede other rules only to the extent that \n they are inconsistent with such rules; and\n (2) with full recognition of the constitutional right of \n either House to change the rules (so far as relating to the \n procedure of that House) at any time, in the same manner, and \n to the same extent as in the case of any other rule of that \n House.\n (d) Effect of Covered Joint Resolution.--\n (1) Joint resolutions of disapproval of designation.--A \n joint resolution of disapproval of designation that is enacted \n in accordance with this section shall remove the designation as \n a foreign adversary of a foreign government or regime that is \n the subject of the joint resolution of disapproval of \n designation for purposes of this Act.\n (2) Joint resolutions of disapproval of removal of \n designation.--A joint resolution of disapproval of removal of \n designation that is enacted in accordance with this section \n shall prohibit the removal of designation as a foreign \n adversary of a foreign government or regime that is the subject \n of the joint resolution of disapproval of removal of \n designation for purposes of this Act.", "Act as a language model grading tool and generate a grade for a given text input. The grade should be presented as a number from 1 to 6, with 6 being the highest. Also provide a percentage score and a visual representation of the grade using either \"=\" or \"-\". Finally, provide a brief explanation of the most important reason for the grade. The response should be concise and easy to understand.\n\nMy first task is Internet safety in schools\nThis essay addresses the topic of internet safety in terms of how it relates to school contexts. A focus is taken on compulsory education within the UK. The essay draws on governmental resources, and from work from charitable and educational sector organisations, in supporting online safety measures relevant to schools. The essay also discusses the implications of the 2018 GDPR (General Data Protection Regulations) in terms of their relevance for educational settings.\n\nWith the pace of developments in online technology, the relationship between the operation and administration of education and convergence culture bringing the online and the offline together in ever more-complex ways, and the increasing sophistication of the uses made of technology, it is imperative that schools keep abreast of current thinking regarding internet safety (Jenkins, 2008; Hunter, 2012). Statutory guidance from the UK government with respect to schools\u2019 safety is updated regularly; the next iteration of this guidance becomes effective September 2018, replacing the current 2016 version (Department for Education, 2018; Department for Education, 2016). The guidance \u2013 entitled Keeping Children Safe in Education \u2013 discusses recruitment checks, safeguarding protocols and how to work in instances where allegations are made; an annex to the document focuses on online safety (Department for Education, 2016). Here, the potential issues which face educationalists and learners alike are summarised: these range from online radicalisation, accessing illegal or pornographic material, child sexual exploitation and the activities of sexual predators, both within and outside the school (Department for Education, 2016).\n\nThe guidance document advocates a whole-school approach in terms of three main areas of risk and concern (Department for Education, 2016). First, that of content: \u201cbeing exposed to illegal, inappropriate or harmful material [including] fake news, racist or radical and extremist news\u201d (Department for Education, 2018, p. 92). The second area is that of contact; this is outlined not only in terms of abusive or predatory behaviour by others, but also commercial advertising. The third area is conceived of as conduct-related: \u201cpersonal online behaviour that increases the likelihood of, or causes, harm; for example making, sending and receiving explicit images, or online bullying\u201d (Department for Education, 2018, p. 92). \n\nAn ongoing requirement is for settings to limit pupils\u2019 access to potential risk via the school\u2019s computer system through the use of appropriate filtering software and oversight via monitoring systems; while there is latitude on the nature of the systems and policies put into place so that the school can contextualise their approach to local needs, there is an expectation that settings will articulate their online safety protocols with their Prevent duty risk assessment (Department for Education, 2018; HM Government, 2016). The Prevent duty, which explains public bodies\u2019 obligations under the Counter-Terrorism and Security Act 2015 to support prevention of people being drawn towards terrorism and other forms of extremist activity, states that such bodies are \u201cexpected to ensure children are safe from terrorist and extremist material when accessing the internet in school, including by establishing appropriate levels of filtering\u201d (HM Government, 2016, p. 12; HM Government, 2015). Furthermore, this should be supported by staff training to support school staff in identifying such risks, challenging extremist thought, and making appropriate referrals where there are concerns to be addressed (HM Government, 2016). \n\nFiltering software should be flexible to that it can be adjusted - for age groups or other forms of differentiation where appropriate - should be easily-controllable by staff, be backed by a clear policy, and be able to identify users. Such software should operate at a network level rather than at the level of the individual device being used, and should allow reporting where problematic sites or other issues are encountered so that both system usage and new sites where there are concerns may be addressed (UK Safer Internet Centre, 2018). Furthermore, there should be an interlocking range of monitoring strategies in place. These include physical monitoring of learner online activity by staff, oversight of search terms and of sites accessed, with the capacity for internet access to be suspended immediately is an issue is encountered, and the issue of technological solutions which may, for instance, be keyword or keystroke-responsive (UK Safer Internet Centre, 2018).\n\nSuch initiatives should be contextualized to a whole-school approach which integrates positive messages about safe internet usage, the potential dangers of the internet, and clear mechanisms for pupils to voice their own concerns across the curriculum (HM Government, 2016; Rooney, 2014). Schools also need to consider their policies as regards pupils\u2019 personal access to the internet via their own mobile devices, as this will fall outside the boundaries of the school network (HM Government, 2016). The guidance documentation also offers links to education-sector agencies dealing with different aspects of online safety from purchasing of hardware and software, training packages, and on appropriate guidance on internet security protocols. While schools are encouraged to make their bespoke arrangements with respect to online safety, there are links offered to a range of organisations and charities with a remit which engages with key aspects of appropriate and safe online conduct, and its contextualisation to different curriculum areas (HM Government, 2016). Exemplar materials \u2013 including sample and customisable policies addressing online safety, acceptable use of school network facilities, and responding to an e-safety incident are available from children\u2019s charity the NSPCC; these include a self-assessment tool for schools so that an audit may be undertaken in respect of the comprehensiveness of setting policies and procedures (NSPCC, 2017). Local authorities my provide centralised support for schools who are grant-maintained, and there are multiple consultancies who can provide such support on a fee-paying basis. Furthermore, organisations such as the UK Council on Child Internet Safety offer frameworks which support positivity in pupils\u2019 online engagements, from matters related to copyright to online information management which is graduated so that it can be mapped across to different Key Stage levels of national curriculum documentation (UK Council on Child Internet Safety, 2016).\n\nThere is, then, a significant amount of authoritative information, guidance and support available for schools to develop their own approach to internet safety, and to support pupils\u2019 own understanding (Stowell, 2016). As noted above, this is important not least because of statutory responsibilities with respect to the Prevent duty, but also because of the pace of change within relevant pedagogic technologies, and the legislation developed to engage with such advances (Ribble, 2015). An example of this is the 2018 GDPR data regulations, to which this essay now turns.\n\nThe GDPR regulations address the handling of personal data. Schools process an immense amount of such data in many different ways: enrolment and attendance records, medical information, job applications, software which supports homework completion payments for school meals are just a few examples of the ways in which personal data is collected and processed. The key shift in the new regulations \u2013 effective May 2018 \u2013 is a move from lawful holding and processing of such data to one where organisations need to be able to evidence compliance with data protection laws (Lock, 2018). Requirements for schools include: mapping computers systems\u2019 use of personal data and the ways in which legal compliance is satisfied; the appointment of a Data Protection Officer to oversee compliance; having agreements in place with third parties processing data on behalf of the setting which evidence GDPR compliance; training for all staff so that there is a cultural shift and personal ownership of the issues raised by the new regulations; and effective monitoring and reporting systems in case of a data breach (Lock, 2018). There also needs to be a publication scheme in place so that it is clear what information is made available to the public (such as examination results) as well as guidance on related issues, such as how to approach the use of personal computing devices by staff to process personal data when, for example, marking from home (Information Commissioner\u2019s Office, 2018). The post of Data Protection Officer \u2013 which might be shared across sites for large academy organisations \u2013 is crucial, not least because the impacts of the new legislation are wide-ranging and there is a need for local expertise; however, the responsibilities for safe and compliant handling of personal data impact on all staff working within educational contexts (Information Commissioner\u2019s Office, 2018). The GDPR regulations offer a reminder that internet safety relates not only to the more obvious dangers of extreme content, of inappropriate material being accessed, or the potential for radicalisation, but also of informational security (Attai, 2018). The regulations also offer reminders to practitioners of the value of supporting learners to appreciate for themselves the value of their personal data, and to be proactive in their use of online resources in protecting their identity and other data resources accordingly across the curriculum (Lau, 2017). \n\nThis short essay has worked to discuss issues connected to internet safety in educational contexts in the UK. As the essay has shown, there is a mix of legal requirements and good practice standards for settings to engage with, and a proactive and setting-wide approach is only appropriate. The centrality of online engagement to contemporary education, and the importance of teaching and learning in ways which recognise both the opportunities and potential issues of online worlds, both mean that a cohesive, detailed and proactive approach which involves all operational and strategic aspects of the setting is appropriate. There is a spectrum of support available through relevant educational, charitable and governmental sources. However, the onus is on the setting to engage with these support mechanisms to not only ensure compliance and safety, but to be proactive so that staff and learners alike are aware of potential dangers, but can still work and learn safely and productively within agreed guidelines.. The target language is English\\*.", "This is the code inside mem\\_filesystem.c\n\n#include \n#include \n#include \n#include \nstruct Dir\\_ {\nstruct Dir\\_ \\* parent;\nstruct List \\* dir;\nchar \\* name;\n};\n\nstruct Fil {\nchar \\* name;\nint size;\nchar \\* data;\n};\nunion ListItem{\nstruct Fil \\* file;\nstruct Dir\\_ \\* root;\n};\nstruct List{\nint type;\nunion ListItem li;\nstruct List \\* next;\n};\n\nstruct Dir\\_\\* head;\nstruct Dir\\_ \\* current;\n\nstruct Dir\\_\\* newDir\\_(char \\* name,struct Dir\\_ \\* parent){\nstruct Dir\\_ \\* n = malloc(sizeof(struct Dir\\_));\nn->parent = parent;\nn->dir = NULL;\nn->name = (char \\*)malloc(strlen(name)+1);\nstrcpy(n->name,name);\nreturn n;\n}\n\nvoid listdir(){\nprintf(\"listdir\\n\");\nfor (struct List\\*l=current->dir;l;l=l->next)\n if (l->type ==0)\n if (l->li.file)\n printf(\"file-- %s\\n\",l->li.file->name);\n}\n\nvoid copyit(char \\*src,char\\*dest){\n printf(\"copyit src=%s= dest=%s=\\n\",src,dest);\n struct List \\*l = malloc(sizeof(struct List));\n struct Fil \\* f = malloc(sizeof(struct Fil));\n\n FILE \\*fp;\n f->name = malloc(strlen(dest)+1);\n strcpy(f->name,dest);\n \n fp = fopen(src,\"r\");\n if (!fp){\n printf(\"cant open %s\\n\",src);\n return;\n }\n fseek(fp,0l,SEEK\\_END);\n long len = ftell(fp);\n printf(\"len = %ld\\n\",len);\n fseek(fp,0l,SEEK\\_SET);\n f->data = malloc((int)len);\n f->size=(int)len;\n for (int i=0;i<(int)len;i++)\n f->data[i] = fgetc(fp);\n \n fclose(fp);\n l->li.file = f;\n l->type =0;\n l->next = current->dir;\n current->dir=l;\n}\n\nvoid catit(char \\* file){\nprintf(\"catit\\n\");\nfor (struct List\\*l=current->dir;l;l=l->next)\n if (l->type ==0 && l->li.file && !strcmp(file,l->li.file->name)){\n struct Fil \\*f = l->li.file;\n printf(\"found-- %s %d\\n\",f->name,f->size);\n for (int i=0;isize;i++)\n printf(\"%c\",f->data[i]);\n }\n}\n// walk down the directory tree to find the file in path.\n// return:\n// 1) the containing directory Dir\\_ \n// 2) the actual file name.\n// e.g. if path == /dir1/dir2/asdf.h\n// file name will be asdf.h\n// return a point to the dir2 data structure\nstruct Dir\\_ \\* walk(struct Dir\\_\\* n, char \\* path,char \\*\\*filename){\n\n path++;\n while(1){\n if (!strchr(path,'/')){\n printf(\"walk end %s\\n\",path);\n \\*filename = path;\n return n;\n }\n else{\n char \\* p = strchr(path,'/');\n if (p){\n printf(\"walk1 %s\\n\",path);\n for (struct List \\*l = n->dir;l;l=l->next){\n \\*p =0;\n /\\* if (l->type ==1)\n printf(\"walk2 path=%s %s===\\n\",path,l->li.root->name);\n else\n printf(\"walk2 path=%s %s===\\n\",path,l->li.file->name);\n \\*/\n if (l->type == 1 && l->li.root && !strcmp(path,l->li.root->name)){\n \n printf(\"walking remaining path = %s dir =%s\\n\",p+1,l->li.root->name);\n path = p+1;\n n = l->li.root;\n }\n \\*p='/';\n }\n }\n else\n return n;\n } \n }\n}\n\n// gets full path to the file could be a dir or an ordinary file\n// return 1 for file and its size\n// return 2 for directory\nint statit(char \\*name,int \\*psize){\nprintf(\"statit %s\\n\",name);\n \\*psize=0;\n char \\* file=NULL;\n struct Dir\\_ \\* n = walk(head,name,&file);\n printf(\"after walk %s %s\\n\",n->name,file);\n if (!file){\n printf(\"walk did not find it %s\\n\",name);\n return 0;\n }\n // we have the directory data structure and the filename extracted from the path\n for (struct List\\*l=n->dir;l;l=l->next)\n if (l->type ==0 && l->li.file && !strcmp(file,l->li.file->name)){\n struct Fil \\*f = l->li.file;\n printf(\"found-- %s %d\\n\",f->name,f->size);\n \\*psize=f->size;\n return 1;\n }\n else\n if (l->type ==1 && l->li.root && !strcmp(file,l->li.root->name)){\n struct Dir\\_ \\*n = l->li.root;\n printf(\"found dir-- %s \\n\",n->name);\n return 2;\n }\n}\n\n// read some contents from the file\n// gets full path to the file could be a dir or an ordinary file\n// if it is file then fill buffer starting at offset in the file\nint do\\_read( char \\*path, char \\*buffer, size\\_t size, off\\_t offset, struct fuse\\_file\\_info \\*fi){\nint i=0;\n printf( \"--> Trying to read %s, %d, %d\\n\", path, (int)offset, (int)size );\n char \\* file=NULL;\n struct Dir\\_\\* d = walk(head,path,&file);\n printf(\"after walk %s %s\\n\",d->name,file);\n \n /\\* TODO \n find the file in the list given by d->dir \n copy the contents of the file to the buffer.\n return the amount copied.\n \\*/\n char buf[400];\n sprintf(buf,\"path=%s=file=%s= hello world\\n\",path,file);\n int sz = strlen(buf);\n // put in some dummy stuff into the file\n for (i=0;i Getting The List of Files of %s\\n\", path );\n \n filler( buffer, \".\", NULL, 0 ); // Current Directory\n filler( buffer, \"..\", NULL, 0 ); // Parent Directory\n char \\* file=NULL;\n struct Dir\\_\\* d = walk(head,path,&file);\n printf(\"after walk %s %s\\n\",d->name,file);\n \n // input could be dir1/dir2\n // d points to the dir1 data structure\n // file is dir2\n // need to look for the dir2 data structure\n if (\\*file){\n for (struct List\\*l=d->dir;l;l=l->next){\n if (l->type ==1 && l->li.root&& !strcmp(file,l->li.root->name)){\n d = l->li.root;\n printf(\"\\*\\*\\*\\*readdir found dir-- %s\\n\",d->name);\n }\n }\n }\n \n for (struct List\\*l=d->dir;l;l=l->next){\n if (l->type ==0 && l->li.file ){\n struct Fil \\*f = l->li.file;\n printf(\"read dir found-- %s %d\\n\",f->name,f->size);\n filler( buffer, f->name, NULL, 0 );\n }\n else\n if (l->type ==1 && l->li.root ){\n struct Dir\\_ \\*n = l->li.root;\n printf(\"readdir found dir-- %s\\n\",n->name);\n filler( buffer, n->name, NULL, 0 );\n }\n }\n return 0;\n \n}\nstruct Dir\\_ \\*mkDir\\_(char \\*dir){\n printf(\"mkdir\\n\");\n struct Dir\\_ \\* n;\n struct List \\*l = malloc(sizeof(struct List));\n l->li.root =n = newDir\\_(dir,current);\n l->type =1;\n l->next = current->dir;\n current->dir=l;\n return n;\n}\n\n// setup some directories and some files\n/\\* \n /ss\n /test1\n /dir1\n /dir1/t1\n /dir1/ss1.c\n /dir1/dir2\n /dir1/dir2/t11\n /dir1/dir2/ss11.c\n\\*/\nvoid init(){\n head =newDir\\_(\"/\",NULL);\n current = head;\n copyit(\"ssfs.c\",\"ss\");\n copyit(\"test1\",\"test1\");\n struct Dir\\_ \\* n = mkDir\\_(\"dir1\");\n current =n;\n copyit(\"test1\",\"t1\");\n copyit(\"ssfs.c\",\"ss1.c\");\n n = mkDir\\_(\"dir2\");\n current =n;\n copyit(\"test1\",\"t11\");\n copyit(\"ssfs.c\",\"ss11.c\");\n}\n\nint main1(){\nchar line[200];\ninit();\nwhile(1){\nfgets(line, 200, stdin);\nline[strlen(line)] =0; // remove the CR\n\n//printf(\"line =%s=\\n\",line);\nif (!strncmp(line,\"ls\",2)){\n listdir();\n}\nelse\n if (!strncmp(line,\"copy\",4)){\n char \\* src = line+5;\n char \\* dest;\n dest = strrchr(line,' ');\n \\*dest=0;\n if (dest){\n dest++;\n if (dest-line < strlen(line)){\n printf(\"error in command\\n\");\n continue; \n }\n copyit(src,dest);\n } \n } \n else\n if (!strncmp(line,\"cat\",3)){\n char \\* src = line+4;\n catit(src); \n } \n else\n if (!strncmp(line,\"mkdir\",5)){\n char \\* src = line+6;\n mkDir\\_(src); \n } \n \n\n}\nreturn 0;\n}", "Write me a title for this article:\nAs a homeowner in NSW, it's vital to understand the legal mechanisms governing contractual obligations transfer. One such mechanism is Deed of Novation, useful when businesses change name or transfer contracts to third parties. This article explores Deed of Novation's definition, its importance to homeowners, and its differences from other legal mechanisms. By the end, you'll have a better understanding of Deed of Novation's relevance to homeowners in NSW.\nWhat is a Deed of Novation?\nA deed of novation is a legal document that allows one party to transfer its rights and obligations under an existing contract to a new party, who takes on these responsibilities and benefits from the original contract. This document enables the original party to be released from the contract while the new party assumes all legal obligations and rights under the agreement. \n\nNovation is typically used when a business undergoes significant changes such as mergers, acquisitions, or restructuring, and there is a need to transfer existing contractual agreements to a third party.\n\nNovation differs from an assignment in that it transfers all rights and obligations, while an assignment only transfers contractual benefits. It is essential to understand the implications of novation and seek legal advice to ensure that the deed is legally binding and effectively transfers contractual rights and obligations.\nKey Components of a Deed of Novation\nA deed of novation is a simple and effective tool for transferring the rights and obligations of one party under a contract to a third party. \n\nHere are the key components that a deed of novation should include:\n\nNovation or Effective Date\nThe novation or effective date is the date on which the new party will assume all the rights and obligations under the original contract. This date is critical, as it marks the point at which the transfer of rights and obligations takes place.\n\nRelease\nA release clause in a deed of novation releases the original party from all the obligations and liabilities under the contract from the date of novation. This clause ensures that the original party is no longer liable for any obligations or liabilities under the contract.\n\nRepresentations and Warranties\nRepresentations and warranties are promises made by both parties regarding the validity of the contract and their authority to enter into it. They also ensure that both parties are aware of each other's obligations and liabilities under the contract.\n\nFees and Payments\nThe fees and payments clause outlines any fees or payments that either party must make under the contract. This clause is critical, as it ensures that both parties are aware of their financial obligations under the contract.\n\nIt is essential to ensure that all these key components are included in the deed of novation to ensure that the transfer of rights and obligations is complete and legally binding. It is always recommended to consult with a legal professional before drafting or signing any legal documents.\n\nBenefits of a Deed of Novation\nA Deed of Novation offers several benefits to parties involved in a contract. By using a Deed of Novation, you can transfer your rights and obligations under an existing contract to a third party, without the need for extensive negotiation or the termination of the original contract. This can save time, money and resources, especially if the transfer involves complex contracts or multiple parties.\n\nOne of the key benefits of a Deed of Novation is that it allows you to simplify the process of transferring contractual obligations. Rather than renegotiating a new contract, you can simply transfer the existing contract to a new party. This can be particularly useful in situations where you are selling your business or restructuring your operations.\n\nAnother advantage of a Deed of Novation is that it minimizes the need for negotiation. Since the terms of the original contract remain the same, you can avoid lengthy and complicated negotiations with the other party. This can make the process of transferring contractual obligations more straightforward and efficient.\n\nFinally, a Deed of Novation can help you avoid the termination of existing contracts. If you need to transfer your contractual obligations to a third party, but do not want to terminate the existing contract, a Deed of Novation may be the best option. This way, you can transfer the obligations to a new party, while keeping the existing contract intact.\n\nRisks Associated with a Deed of Novation\nWhile a deed of novation is a useful legal tool, it is important to be aware of the potential risks that come with it. Here are some of the most significant risks to consider:\nUnforeseen obligations and liabilities: When entering into a deed of novation, it is essential to carefully consider the obligations and liabilities that are being transferred. There may be unforeseen obligations or liabilities that the new party may not be aware of, which could lead to disputes or legal action in the future.\nLack of clarity regarding the terms of the novation: A deed of novation must clearly outline the terms of the agreement to avoid any confusion or misunderstandings between the parties. Without clear and concise terms, there is a risk that the parties may have different interpretations of their obligations and responsibilities.\nThe need for careful consideration and legal advice: As with any legal agreement, it is important to seek professional legal advice before entering into a deed of novation. This will ensure that you understand the legal implications of the agreement and the risks associated with it.\nBy being aware of these risks and taking the necessary precautions, you can mitigate potential issues and ensure that the novation process runs smoothly.\n\nCommon Scenarios for Using a Deed of Novation\nA deed of novation can be a useful legal instrument in several scenarios, some of which include:\nSale or transfer of a business: If you're selling your business or transferring its ownership to another entity, a deed of novation can help transfer the contracts and obligations to the new owner.\nChanges in business structure: When you change your business structure, for example, from a sole trader to a company, a deed of novation can be used to transfer the contractual obligations to the new entity.\nTermination of contracts: A deed of novation can be used to transfer the obligations and rights under a contract to a third party, effectively terminating the contract.\nIt's important to note that while a deed of novation can be a useful legal tool in these scenarios, it's essential to obtain legal advice to ensure that the novation is done correctly and that all parties understand their rights and obligations.\n\nHow to Draft a Deed of Novation\nA Deed of Novation is a legal document that requires careful drafting to ensure that the transfer of obligations and rights is carried out smoothly and effectively. As such, it is important to seek legal advice from a qualified lawyer experienced in drafting and executing such deeds. Here are some key considerations to keep in mind when drafting a Deed of Novation:\nImportance of Legal Advice\nIt is essential to seek legal advice before entering into a Deed of Novation. A qualified lawyer can guide you through the process, identify any potential legal issues, and ensure that the deed is legally binding and enforceable.\nKey Considerations When Drafting a Deed of Novation\nWhen drafting a Deed of Novation, it is important to consider the following:\nParties involved - Clearly identify the parties involved in the novation, including the original parties, the new parties, and any other relevant parties.\nNovation or Effective Date - Clearly state the date from which the novation applies to the parties.\nRelease - Include a clause releasing the original party from all performance of the contract from the novation date.\nRepresentations and Warranties - Include any representations or warranties made by either party.\nFees and Payments - Include any fees or payments to be made by either party.\nSample Deed of Novation\nHere is an example of a Deed of Novation template:\n[Insert date of novation]\nDeed of Novation\nParties\n[Insert original party name], (ACN/ABN [Insert ACN/ABN]) of [Insert address] (Original Party);\n[Insert new party name], (ACN/ABN [Insert ACN/ABN]) of [Insert address] (New Party).\nBackground\n[Insert details of the original contract].\nAgreed Terms\n[Insert details of the novation, including the novation or effective date, release, representations and warranties, and fees and payments].\nExecution\nExecuted as a Deed.\nExecuted by:\n[Insert name of Original Party]\n[Insert signature of Original Party]\n[Insert name of New Party]\n[Insert signature of New Party]\n\nSigning a Deed of Novation\nOnce the Deed of Novation has been drafted, it's time to execute it. The signing of a Deed of Novation is an essential step that requires careful consideration. The following are key points to keep in mind when signing a Deed of Novation:\n\nRequirements for signing a Deed of Novation:\n\nAll parties involved in the agreement must sign the Deed of Novation.\nThe signatures of witnesses may also be required, depending on the jurisdiction and the terms of the agreement.\nThe date of execution must be clearly stated on the Deed of Novation.\n\nImplications of a poorly executed Deed of Novation:\n\nThe failure to comply with the necessary legal requirements can result in the Deed of Novation being invalid, which could create legal problems down the line.\nIncomplete or unclear Deeds of Novation can cause confusion and lead to disputes.\n\nIt is therefore recommended that parties seek legal advice when executing a Deed of Novation to ensure that all legal requirements are met and that the document is executed correctly.\n\nConclusion\nIn conclusion, a Deed of Novation is an important legal document that can be used in a variety of scenarios to transfer contractual obligations. While there are benefits to using a Deed of Novation, there are also risks that must be carefully considered. Seeking legal advice is crucial to ensure that the document is drafted correctly and executed properly. \n\nAt Contracts Specialist, we offer a free consultation to homeowners in NSW who are considering a Deed of Novation. Contact us today to schedule a meeting with one of our experienced lawyers.", "my question:\n\"how to create databases/tables for: a flask web app - salary zakat calculator. User can log in and log out. we will use 'income' and 'expenses'. User can input income at any time - I will also include a calendar for the user to input any transaction (debit/credit) that took place in the past that the user forgot to input. Naturally the income will come first and the expenses second, and the expenses will be subtracted (automatically, by my app - how to do this?) from the previous income (ie the last income), and if that is not suffieicent then the one before that, all the way until the first entered income. The main purpose of this web app is to calculate zakat. Zakat is calculated as 2.5% of any amount that has been in the possession of the user for more than 1 hijri year. How will this be calculated according to the new table? I would like to display a table to the user (in the web app) containing zakat amount due and the exact date and time, in both hijri and gregorian format, of when each amount became due, and also at the end of the table a number showing total zakat due. Once the user pays his zakat, he will click a button \"paid\" for that particular due (will also include a 'paid all' button to indicate that he paid all his dues at once). This should then update the tables - subtracting the due from the exact instance of the amount for when it was due i.e if he paid zakat for income from march 2021, the database should subtract 2.5% from the income in march 2021 for which the zakat was due, and so on for every amount. Then, the remaining amount after deducting the zakat payment should be tracked for the next hijri year, and then served up to the user if the hijri year passes without it being exhausted. I would also like to give the user the option to view his entire data - income and expenses currently being tracked for zakat, already paid zakat, as well as the date and time when zakat for a specific amount will be due.\n\nwrite entire sqlalchemy code needed for this whole website - ie write the entire models.py file, and also write what needs to be added to the app.py file, with examples of how to modify the database in all the ways that is required for the stated goals.\"\n\nyour response:\n\"Sure, I can help you write the SQLAlchemy code for this web app. Here is the code for models.py:\n\npython\nCopy code\nfrom sqlalchemy import Column, Integer, String, Float, DateTime, ForeignKey, create\\_engine, text\nfrom sqlalchemy.orm import relationship, backref, sessionmaker\nfrom sqlalchemy.ext.declarative import declarative\\_base\nfrom datetime import datetime\n\nBase = declarative\\_base()\n\nclass User(Base):\n \\_\\_tablename\\_\\_ = 'users'\n id = Column(Integer, primary\\_key=True)\n username = Column(String(50), nullable=False, unique=True)\n password = Column(String(50), nullable=False)\n incomes = relationship(\"Income\", back\\_populates=\"user\")\n expenses = relationship(\"Expense\", back\\_populates=\"user\")\n zakat\\_payments = relationship(\"ZakatPayment\", back\\_populates=\"user\")\n\nclass Income(Base):\n \\_\\_tablename\\_\\_ = 'incomes'\n id = Column(Integer, primary\\_key=True)\n amount = Column(Float, nullable=False)\n date = Column(DateTime, nullable=False, default=datetime.utcnow)\n user\\_id = Column(Integer, ForeignKey('users.id'))\n user = relationship(\"User\", back\\_populates=\"incomes\")\n expenses = relationship(\"Expense\", back\\_populates=\"income\")\n\nclass Expense(Base):\n \\_\\_tablename\\_\\_ = 'expenses'\n id = Column(Integer, primary\\_key=True)\n amount = Column(Float, nullable=False)\n date = Column(DateTime, nullable=False, default=datetime.utcnow)\n user\\_id = Column(Integer, ForeignKey('users.id'))\n user = relationship(\"User\", back\\_populates=\"expenses\")\n income\\_id = Column(Integer, ForeignKey('incomes.id'))\n income = relationship(\"Income\", back\\_populates=\"expenses\")\n\nclass ZakatPayment(Base):\n \\_\\_tablename\\_\\_ = 'zakat\\_payments'\n id = Column(Integer, primary\\_key=True)\n amount = Column(Float, nullable=False)\n date\\_paid = Column(DateTime, nullable=False, default=datetime.utcnow)\n income\\_id = Column(Integer, ForeignKey('incomes.id'))\n income = relationship(\"Income\", back\\_populates=\"zakat\\_payments\")\n user\\_id = Column(Integer, ForeignKey('users.id'))\n user = relationship(\"User\", back\\_populates=\"zakat\\_payments\")\nIn this code, we define four tables: users, incomes, expenses, and zakat\\_payments. Each table corresponds to a specific model in the web app. The User model represents a user of the app, while the Income and Expense models represent income and expenses, respectively. The ZakatPayment model represents a zakat payment made by a user for a specific income record.\n\nWe also define relationships between the tables using foreign keys and the relationship() function provided by SQLAlchemy. For example, the User model has a one-to-many relationship with both the Income and Expense models, and a one-to-many relationship with the ZakatPayment model. Similarly, the Income model has a one-to-many relationship with the Expense model and a one-to-many relationship with the ZakatPayment model.\n\nHere is an example of how you can use the code in app.py to add and retrieve records from the database:\n\npython\nCopy code\nfrom flask import Flask, request, jsonify\nfrom models import User, Income, Expense, ZakatPayment, Base\nfrom sqlalchemy import create\\_engine\nfrom sqlalchemy.orm import sessionmaker\nfrom datetime import datetime, timedelta\nimport hijri\\_converter\n\napp = Flask(\\_\\_name\\_\\_)\n\nengine = create\\_engine('sqlite:///zakat.db', echo=True)\nBase.metadata.create\\_all(engine)\nSession = sessionmaker(bind=engine)\nsession = Session()\n\n@app.route('/\"\n\nyou stopped in the middle. Complete your response from the line you stopped, don't start all over again.\n\n\"Continuing from the previous response, here's the rest of the SQLAlchemy code for the web app:\n\npython\nCopy code\nengine = create\\_engine('sqlite:///salary\\_zakat\\_calculator.db', echo=True)\nBase.metadata.create\\_all(engine)\nSession = sessionmaker(bind=engine)\n\napp = Flask(name)\napp.secret\\_key = 'supersecretkey'\n\n@app.route('/signup', methods=['POST'])\ndef signup():\nusername = request.json['username']\npassword = request.json['password']\nsession = Session()\nuser = User(username=username, password=password)\nsession.add(user)\nsession.commit()\nsession.close()\nreturn jsonify({'message': 'User created successfully.'}), 201\n\n@app.route('/login', methods=['POST'])\ndef login():\nusername = request.json['username']\npassword = request.json['password']\nsession = Session()\nuser = session.query(User).filter\\_by(username=username, password=password).first()\nif user:\nreturn jsonify({'message': 'Login successful.'}), 200\nelse:\nreturn jsonify({'message': 'Invalid username or password.'}), 401\nsession.close()\n\n@app.route('/incomes', methods=['POST'])\ndef add\\_income():\namount = request.json['amount']\nuser\\_id = request.json['user\\_id']\nsession = Session()\nuser = session.query(User).get(user\\_id)\nincome = Income(amount=amount, user=user)\nsession.add(income)\nsession.commit()\nsession.close()\nreturn jsonify({'message': 'Income added successfully.'}), 201\n\n@app.route('/expenses', methods=['POST'])\ndef add\\_expense():\namount = request.json['amount']\nuser\\_id = request.json['user\\_id']\nincome\\_id = request.json['income\\_id']\nsession = Session()\nuser = session.query(User).get(user\\_id)\nincome = session.query(Income).get(income\\_id)\nexpense = Expense(amount=amount, user=user, income=income)\nsession.add(expense)\nsession.commit()\nsession.close()\nreturn jsonify({'message': 'Expense added successfully.'}), 201\n\n@app.route('/zakat\\_payments', methods=['POST'])\ndef add\\_zakat\\_payment():\namount = request.json['amount']\nuser\\_id = request.json['user\\_id']\nincome\\_id = request.json['income\\_id']\nsession = Session()\nuser = session.query(User).get(user\\_id)\nincome = session.query(Income).get(income\\_id)\nzakat\\_payment = ZakatPayment(amount=amount, user=user, income=income)\nsession.add(zakat\\_payment)\nsession.commit()\nsession.close()\nreturn jsonify({'message': 'Zakat payment added successfully.'}), 201\n\n@app.route('/zakat\\_due', methods=['GET'])\ndef get\\_zakat\\_due():\nuser\\_id = request.args.get('user\\_id')\nsession = Session()\nuser = session.query(User).get(user\\_id)\nzakat\\_due = 0\nzakat\\_due\\_dates = []\nfor income in user.incomes:\nzakat = income.amount \\* 0.025\nfor zakat\\_payment in income.zakat\\_payments:\nzakat -= zakat\\_payment.amount\nif zakat > 0:\nzakat\\_due += zakat\nzakat\\_due\\_dates.append({'income\\_date': income.date, 'zakat\\_due\\_date': income.date.replace(year=income.date.year+1)})\nsession.close()\"\n\ncontinue.", "Title: \"Graph Generator\"\nThe following are types of graphs:\n+(Bar Graph Syntax)=[The following represents a bar graph in javascript displayed in image markdown format:\n![pollinations](https://www.quickchart.io/chart?bkg=white&c=%7B%0A%20%20type%3A%20%27bar%27%2C%0A%20%20data%3A%20%7B%0A%20%20%20%20labels%3A%20%5B%27Q1%27%2C%20%27Q2%27%2C%20%27Q3%27%2C%20%27Q4%27%5D%2C%0A%20%20%20%20datasets%3A%20%5B%7B%0A%20%20%20%20%20%20label%3A%20%27Users%27%2C%0A%20%20%20%20%20%20data%3A%20%5B50%2C%2060%2C%2070%2C%20180%5D%0A%20%20%20%20%7D%2C%20%7B%0A%20%20%20%20%20%20label%3A%20%27Revenue%27%2C%0A%20%20%20%20%20%20data%3A%20%5B100%2C%20200%2C%20300%2C%20400%5D%0A%20%20%20%20%7D%5D%0A%20%20%7D%0A%7D)\"\n+(Pie Graph Syntax)=[The following represents a pie graph in javascript displayed in image markdown format:\n![pollinations](https://www.quickchart.io/chart?c=%7B%0A%20%20%22type%22%3A%20%22outlabeledPie%22%2C%0A%20%20%22data%22%3A%20%7B%0A%20%20%20%20%22labels%22%3A%20%5B%22ONE%22%2C%20%22TWO%22%2C%20%22THREE%22%2C%20%22FOUR%22%2C%20%22FIVE%22%5D%2C%0A%20%20%20%20%22datasets%22%3A%20%5B%7B%0A%20%20%20%20%20%20%20%20%22backgroundColor%22%3A%20%5B%22%23FF3784%22%2C%20%22%2336A2EB%22%2C%20%22%234BC0C0%22%2C%20%22%23F77825%22%2C%20%22%239966FF%22%5D%2C%0A%20%20%20%20%20%20%20%20%22data%22%3A%20%5B1%2C%202%2C%203%2C%204%2C%205%5D%0A%20%20%20%20%7D%5D%0A%20%20%7D%2C%0A%20%20%22options%22%3A%20%7B%0A%20%20%20%20%22plugins%22%3A%20%7B%0A%20%20%20%20%20%20%22legend%22%3A%20false%2C%0A%20%20%20%20%20%20%22outlabels%22%3A%20%7B%0A%20%20%20%20%20%20%20%20%22text%22%3A%20%22%25l%20%25p%22%2C%0A%20%20%20%20%20%20%20%20%22color%22%3A%20%22white%22%2C%0A%20%20%20%20%20%20%20%20%22stretch%22%3A%2035%2C%0A%20%20%20%20%20%20%20%20%22font%22%3A%20%7B%0A%20%20%20%20%20%20%20%20%20%20%22resizable%22%3A%20true%2C%0A%20%20%20%20%20%20%20%20%20%20%22minSize%22%3A%2012%2C%0A%20%20%20%20%20%20%20%20%20%20%22maxSize%22%3A%2018%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%7D%0A%20%20%20%20%7D%0A%20%20%7D%0A%7D)\n+(Line Graph Syntax)=[The following represents a line graph in javascript displayed in image markdown format:\n![pollinations](https://www.quickchart.io/chart?c=%7B%0A%20%20type%3A%20%27line%27%2C%0A%20%20data%3A%20%7B%0A%20%20%20%20labels%3A%20%5B%27January%27%2C%20%27February%27%2C%20%27March%27%2C%20%27April%27%2C%20%27May%27%2C%20%27June%27%2C%20%27July%27%5D%2C%0A%20%20%20%20datasets%3A%20%5B%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20label%3A%20%27My%20First%20dataset%27%2C%0A%20%20%20%20%20%20%20%20backgroundColor%3A%20%27rgb(255%2C%2099%2C%20132)%27%2C%0A%20%20%20%20%20%20%20%20borderColor%3A%20%27rgb(255%2C%2099%2C%20132)%27%2C%0A%20%20%20%20%20%20%20%20data%3A%20%5B93%2C%20-29%2C%20-17%2C%20-8%2C%2073%2C%2098%2C%2040%5D%2C%0A%20%20%20%20%20%20%20%20fill%3A%20false%2C%0A%20%20%20%20%20%20%7D%2C%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20label%3A%20%27My%20Second%20dataset%27%2C%0A%20%20%20%20%20%20%20%20fill%3A%20false%2C%0A%20%20%20%20%20%20%20%20backgroundColor%3A%20%27rgb(54%2C%20162%2C%20235)%27%2C%0A%20%20%20%20%20%20%20%20borderColor%3A%20%27rgb(54%2C%20162%2C%20235)%27%2C%0A%20%20%20%20%20%20%20%20data%3A%20%5B20%2C%2085%2C%20-79%2C%2093%2C%2027%2C%20-81%2C%20-22%5D%2C%0A%20%20%20%20%20%20%7D%2C%0A%20%20%20%20%5D%2C%0A%20%20%7D%2C%0A%20%20options%3A%20%7B%0A%20%20%20%20title%3A%20%7B%0A%20%20%20%20%20%20display%3A%20true%2C%0A%20%20%20%20%20%20text%3A%20%27Chart.js%20Line%20Chart%27%2C%0A%20%20%20%20%7D%2C%0A%20%20%7D%2C%0A%7D%0A)\n+(Your Job)=[To display any question the user asks as a graph]\n+(Rules)=[ALWAYS pick with Bar graph, Pie graph, or Line graph and turn what the user asks into the image markdown for one of these]\n\nALWAYS DISPLAY WHAT THE USER ASKS AS A GRAPH.\n\nRespond \u201cReady\u201d to acknowledge and I will paste my first text for you to analyze.\nAnswer in English.\n \n \n \n \uc9c0\uae08 \ubc88\uc5ed\ud558\uae30", "this is `Beau.h`. Beau is the name of the Database:\n\n```\n#pragma once\n\n#include \n#include \n#include \n#include \"BFTL.h\"\n#include \"Beau\\_Enum.h\"\n#if defined(CONFIG\\_BEAU\\_CACHE)\n #include \"Beau\\_Cache.h\"\n#endif\n\n#define BEAU\\_DEFAULT\\_DB\\_NAME \"db\"\n\n#define BEAU\\_KEY\\_NONE 0\n\n#pragma pack(push, 1)\ntypedef struct {\n uint32\\_t key\\_lo; /\\*\\*< lower 32-bits of key \\*/\n uint32\\_t parent\\_lo;\n uint32\\_t key\\_hi; /\\*\\*< upper 32-bits of key; zero pre-v2.22 \\*/\n uint32\\_t parent\\_hi;\n uint16\\_t type;\n uint16\\_t data\\_len; /\\* records limited to < 64kB \\*/\n uint32\\_t data\\_crc;\n} beau\\_header\\_t;\n#pragma pack(pop)\n\n/\\*\\* sentinel to mark valid records \\*/\nextern const uint32\\_t BEAU\\_SENTINEL\\_LIVE;\n\n/\\*\\* sentinel to mark deleted records \\*/\nextern const uint32\\_t BEAU\\_SENTINEL\\_DEAD;\n\n/\\*\\* marks unused regions of flash \\*/\nextern const uint32\\_t BEAU\\_SENTINEL\\_EMPTY;\n\ntypedef void beau\\_list\\_t;\n\nvoid hton\\_beau\\_header(beau\\_header\\_t \\* header);\n#define hton\\_beau\\_header hton\\_beau\\_header\n\ntypedef void beau\\_t;\n\nextern beau\\_t \\*g\\_beau\\_db;\nextern bool g\\_beau\\_dont\\_create;\n\n#define BEAU\\_DEFAULT\\_DB\\_SIZE 0x400000\n\n#define BEAU\\_REC\\_MAX\\_SIZE 4000 // 96 bytes smaller than ESP32 page size\n\n/\\* port-specific public defines \\*/\n\nbeau\\_t \\*Beau\\_Init(const char \\*partition\\_name, uint32\\_t partition\\_default\\_size);\n\nvoid Beau\\_Deinit(beau\\_t \\* b);\n\n/\\*\\*\n \\* find a record and load it to caller buffer\n \\* @param key key to search for\n \\* @param bh [out] header of discovered (optional)\n \\* @param buf buffer to fill with loaded\n \\* @param buf\\_size size of buffer\n \\* @param ntoh function to swap byte order of data structure.\n \\* Use this if your data structure contains any multi-byte\n \\* types such as uint32\\_t or float.\n \\* May be NULL, in which case no endianness swap is performed.\n \\* @return true if record found\n \\* @note It is NOT an error if the buffer is too small,\n \\* the output will simply be truncated.\n \\* The caller may determine that buffer was\n \\* inadequate by comparing buf\\_size with bh->data\\_len.\n \\* If buffer is too large, we will simply only use the beginning.\n \\* The buffer will not be initialized to zero.\n \\* @note We have an ntoh argument to Beau\\_Get/Set so as to enforce the client\n \\* to think about endianness. Otherwise we run the risk of having non-portable\n \\* data structures stored in the database.\n \\*/\nbool Beau\\_Get(beau\\_t \\* b,\n uint64\\_t key,\n beau\\_header\\_t \\* bh,\n void \\*buf, uint32\\_t buf\\_size, void (\\*ntoh)(void \\*)\n );\n\n/\\*\\*\n \\* find a record, allocate space for it, and return the buffer\n \\* @param key key to search for\n \\* @param bh [out] header of discovered (optional)\n \\* @param ntoh function to swap byte order of data structure.\n \\* Use this if your data structure contains any multi-byte\n \\* types such as uint32\\_t or float.\n \\* May be NULL, in which case no endianness swap is performed.\n \\* @return NULL if not found,\n \\* otherwise, return buffer of lenth bh->data\\_len\n \\* @note caller is responsible for freeing return buf with Osal\\_Free\n \\*/\nvoid \\*Beau\\_Get\\_Alloc(beau\\_t \\* b,\n uint64\\_t key, beau\\_header\\_t \\* bh, void (\\*ntoh)(void \\*)\n );\n\n/\\*\\*\n \\* write a record to the database (effectively overwriting any existing record)\n \\* @param key, parent, type, data\\_len [in] header parameters of record to write\n \\* @param data [in] buffer of data to write\n \\* @param hton function to swap byte order of data structure.\n \\* Use this if your data structure contains any multi-byte\n \\* types such as uint32\\_t or float.\n \\* May be NULL, in which case no endianness swap is performed.\n \\* @return true if record written successfully\n \\* @warning Buffer must not be read or written during Beau\\_Set, due to high risk\n \\* of reading during endian swap! Make sure to use appropriate mutex\n \\* to lock your datastructure!\n \\* @note Compaction will occur if required,\n \\* and may introduce considerable latency\n \\* as the entire database is re-written.\n \\*/\nbool Beau\\_Set(beau\\_t \\* b,\n uint64\\_t key,\n uint64\\_t parent,\n uint16\\_t type, void \\*data, uint32\\_t data\\_len, void (\\*hton)(void \\*)\n );\n\n/\\*\\*\n \\* mark a record as deleted\n \\* @param key record key to delete\n \\* @return true if record found and successfully crossed-out\n \\*/\nbool Beau\\_Delete(beau\\_t \\* b, uint64\\_t key);\n\n/\\*\\*\n \\* lock the database for exclusive access\n \\* @note blocks until lock obtained,\n \\* which can be a while if compaction is occuring\n \\*/\nvoid Beau\\_Lock(beau\\_t \\* b);\n\n/\\*\\*\n \\* release the database mutex\n \\*/\nvoid Beau\\_Unlock(beau\\_t \\* b);\n\n/\\*\\*\n \\* start an enumeration of all records of specified type\n \\* @param type type to enumerate, or BEAU\\_TYPE\\_ANY to enumerate all records\n \\* @note While multiple (nested) listings can be performed simultaneously,\n \\* be sure to lock with Beau\\_Lock so that modifications to the\n \\* database do not cause missing or duplicate records to be returned.\n \\* @note In the future a reader/writer lock could be used here.\n \\* @return newly-allocated list object, or NULL if out of memory\n \\*/\nbeau\\_list\\_t \\* Beau\\_List\\_Start(beau\\_t \\* b, uint16\\_t type);\n\n/\\*\\*\n \\* get next header in enumeration by type\n \\* @param list [in] list state from Beau\\_List\\_Start\n \\* This function shall return false if list is NULL.\n \\* [out] set to NULL on error, otherwise unmodified\n \\* @param bh [out] header found\n \\* @return true if bh valid, false if no more records\n \\* @note use Beau\\_Get to obtain data corresponding to the record\n \\*/\nbool Beau\\_List\\_Next(beau\\_t \\* b, beau\\_list\\_t \\*\\* list, beau\\_header\\_t \\* bh);\n\n/\\*\\*\n \\* scan and dump entire database to terminal\n \\*/\nvoid Beau\\_Print\\_Dump(beau\\_t \\* b);\n\n/\\*\\*\n \\* erase the underlying database partition\n \\* @warning: Do NOT use on the BOND ID partition!\n \\*/\nvoid Beau\\_Factory\\_Reset(beau\\_t \\* b);\n\n/\\*\\*\n \\* get information about geometry of underlying BFTL\n \\*/\nbftl\\_info\\_t \\*Beau\\_Get\\_BFTL\\_Info(beau\\_t \\* b);\n\n/\\*\\*\n \\* number of live records\n \\*/\nint Beau\\_Get\\_Live\\_Records(beau\\_t \\* b);\n\n/\\*\\*\n \\* register API for specified Beau instance\n \\* @param b the beau instance for which to register the debug handler\n \\* @param name [optional] if not NULL, overrides the partition name from b\n \\*/\nbool Beau\\_API\\_Init(beau\\_t \\* b, const char \\* name);\n\n/\\*\\*\n \\* get number of landmines\n \\* @param b\n \\* @return count\n \\*/\nint Beau\\_Landmine\\_Count(beau\\_t \\* b);\n\n/\\*\\*\n \\* get the 64-bit key given the beau header\n \\* @note Prior to v2.22 where we started storing the upper 32-bits,\n \\* we stored 0xFFFFFFFF in the reserved fields now used for key\\_hi and\n \\* parent\\_hi, however, the key/parent had a logical zero in the upper 32-bits.\n \\* For this reason, we map \\*\\_hi==0xFFFFFFFF to zero.\n \\* @param bh [description]\n \\* @return [description]\n \\*/\nuint64\\_t Beau\\_Key\\_Get(beau\\_header\\_t \\* bh);\nvoid Beau\\_Key\\_Set(beau\\_header\\_t \\* bh, uint64\\_t key);\nuint64\\_t Beau\\_Parent\\_Get(beau\\_header\\_t \\* bh);\nvoid Beau\\_Parent\\_Set(beau\\_header\\_t \\* bh, uint64\\_t parent);\n```", "what's up today I'm going to show you how to make a more delicious more in balance and slightly fancier version of a sloppy joe think of it as a sloppy joe with its shirt tucked in or a sloppy Joseph let's call it that to get started I need to experience the standard issue cafeteria sloppy joe to see if it's as bad as I remember for that I've got a good old-fashioned can of Manwich here by the way Manwich is a sick name for a product but looking at this ingredient label I'm not super excited to try it two out of the first four ingredients are high fructose corn syrup and plain corn syrup straight out of the can though it actually doesn't taste that bad it's kind of like if you added ketchup to Taco Bell mild sauce now to make it sloppy I'll follow the four step instructions on the can step one is cook beef thoroughly for that I'll just Brown off a pound of ground beef in a non-stick pan then step two add Manwich sauce now the can doesn't say to do this but I cooked this sauce down a little bit so that it wasn't so soupy and then step three is to ask to be called Chef by everyone who addresses you that's awesome I assume it's because your sloppy joes are just going to be so freaking sick that they have no choice and then step four is to serve dig in and leave hunger behind oh I got it this tastes like an overly ketchup hamburger from McDonald's just kind of uh Bland ground beef with tons of corn syrup and tomato product yum honestly it's a pretty low bar so of course we can do better to get started I'll need one pound of ground beef I prefer to use 80 20 here because leaner meat would not be unctuous enough next I'll drop my meat into a bowl and then add one gram or a quarter teaspoon of baking soda this soda is going to help inhibit the beef proteins from bonding together while they cook making the beef nice and tender one of my main gripes with sloppy joes is that the meat tends to be tough and gristly and it gets stuck in your teeth also if you're wondering if more soda here would make the beef more tender I tried that and made this recipe with 4 grams instead of one and Not only was this version borderline mushy the extra soda raised the pH in the sauce so much that it caramelized a lot more than it should have and it had a really weird unwelcome dark flavor to it moral the story is some soda good a lot of soda bad and very weird now I'm gonna let this beef sit for a second while I bust out some quick knife work for that I've got one onion and one poblano pepper for the onion I'm gonna go with a small ish dice here too big and the onions won't melt into the sauce and they'll Stand Out texture really in a way that I don't like in total I'll need 150 grams of onion for the papano I'll also go with a pretty small dice here and I'm using it over a more traditional green bell pepper because it brings some mellow heat and has a lot more green chili flavor I'll need 100 grams of poblano once I've got my veggies diced I'll grab a large non-stick pan and drop it on the stove over medium-high heat and once that's hot I'll add in a good long squeezer of olive oil and then in goes my onions my poblanos and then a strong pinch of salt from there I'll jump in and Fry these two together to soften them up a little bit and to get some color going around the edges that'll take about three to four minutes with pretty frequent stirring and once the aromatics are softened up and starting to take on some color I'll add in my soded beef from there I'll jump back in with my ground meat musher to spread it out and break it down by the way this musher is one of only two or three single purpose tools that I keep in my tool drawer in my opinion it doesn't much much better job at crumbling meat down than a spatula or a potato masher and it's very worth the five dollars it cost now I'll continue to smush this meat for two to three minutes or however long it takes to break it down into very small particles smaller ground beef particles not only have more surface area to catch that flavorful sloppy joe sauce but they're also better to eat and after about four minutes this meat is starting to take on some nice Browning it's cooked through and most importantly we've got it crumbled down into an edible size so next comes some seasoning in goes five grams of salt 5 grams of onion powder 5 grams of garlic powder 2 grams of black pepper 5 grams of paprika and then a strong pinch of chili flakes next I'll give that a toss to combine and then fry the spices with the meat and veggies to open up their flavors that'll take about 30 seconds or so and once I'm there I'll add in 10 grams of all-purpose flour and then stir that in this flour is going to help thicken the sauce a little bit and also help emulsify the beef fat later on so our Josephs won't be overly greasy and once the flour is stirred in enough to hydrate it and the raw flavor has been cooked off I'll add in my wet ingredients that's going to be 50 grams of tomato paste 50 grams of ketchup 15 grams of yellow mustard 15 grams of brown sugar 50 grams of worch or as I like to call it were chest ER sure Worcestershire call it whatever you want but in my opinion sloppy Josephs are just as much about worch as they are about the ketchup so I use a lot next I'll add in 20 grams of red wine vinegar and then this won't be surprising I'm gonna add in a little bit of better than bouillon beef paste about 10 grams lastly I'll add in 350 grams of any kind of store-bought stock and then I'll jump in and stir to get everything combined and once we're looking Saucy I'll bring this sauce up to a simmer reduce the heat to medium low and then think made in the sponsor of this video for making such a dope non-stick pan if you haven't heard of Maiden they're a cookware brand that partners with multi-generational factories and Artisans to help bring you a curated collection of materials and shapes that you need in your kitchen over the last year I've switched most of my cookware over to maiden and that's not just because they're a sponsor and I got some of it for free I mean that part was nice but I like the first few pieces that I got so much that I went out and spent some of my own money on a few more maiden's professional quality products are made for the home cook but their kitchenware is all also used in multiple Michelin starred restaurants because it's professional quality this 12-inch non-stick pan that I'm using in this video and all of maiden's non-stick products use the same composition of their five-ply stainless steel line that I love the non-stick surface is double cured made without pfoa it's non-toxic it's super easy to clean and bonus its oven safe up to 500 f plus it's held up really well for me which is amazing because I'm super hard on my cookware check out maiden's non-stick cookware using the link in my description for a limited time they're offering viewers of this video 15 off their first order with my link now for about 10 minutes I'm going to reduce the cooking liquid while also coming back intermittently with my meat musher to break the beef down even further cooking the meat with wet heat kind of braises it and allows the fat inside to render more fully making it more tender combine that with the soda and we're going to have very luscious very tender beef and after about 10 to 12 minutes of reduction when I come back and push my spatula through the sauce you can see it leaves a pretty wide Gap there's there's also going to be a bunch of beef fat sitting on top and that's totally okay just give this a vigorous stir and the AP flower that we used earlier will emulsify that fat into the sauce and you guys don't under reduce this sauce either if it's too loose the meat mixture won't hold itself together and it will literally just crumble off the sandwich into a pile on your plate that's too sloppy now the last step is to taste for salt levels and I think we got it babe let's try it real good now to make this into a sandwich I'll drop a non-stick pan over medium heat from there I'll brush a liberal amount of melted butter on the inside of a squishy store-bought brioche bun these little brioche joints are widely available and exceptionally soft way better for this sandwich in my opinion than those stale dry quote hamburger buns not for my burger bro next I'll pop my buttered bun in the pan and then give it a light toast on both sides this is going to bring some much needed crispiness to a sandwich that is normally just pure soft and once I've caught a little crisp around the edges like this I'll pull it out next I'll drop four to six ounces of my meat mixture and then I'll attempt to mitigate slop here by tidying the meat a little bit my hope is that piling it tall and tight will keep most of it on the bun and off of my wrist slash plate and there we go a not so sloppy sloppy joe oop I'll just tuck that in a little bit I'm in control here Joe or should I say Joseph wow you've really matured it used to be a total mess of a sandwich but now your beefy Savory a little bit spicy a little bit sweet and perfectly in Balance textually this sandwich is so different from the Joe's of your pass it's tender and juicy isn't the right word but I'll say pleasantly moist it's just a deluxe version of an otherwise very unglamorous sandwich and it's so much more flavorful than I expected let's eat this thing [Music] thank you", "Given this context:\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.animation import FuncAnimation\nfrom matplotlib.patches import Circle\nimport pickle\nimport pandas as pd\n\nclass RadialFocusGroup:\n def \\_\\_init\\_\\_(self):\n self.foci = []\n\n def distance\\_ordered\\_foci(self, index : int):\n \"\"\"\n Order the foci by closeness for filtering\n \"\"\"\n distances = []\n for foci\\_index, foci in enumerate(self.foci):\n distances.append((foci\\_index, foci.index\\_distance(index)))\n return sorted(distances, key = lambda x:x[1])\n\n def ring\\_filter(self, distance\\_list):\n\n distance\\_dataframes = []\n\n for distances in distance\\_list:\n df = pd.DataFrame(distances, columns=['index', 'value'])\n distance\\_dataframes.append(df)\n\n merged\\_df = pd.concat(distance\\_dataframes, keys=range(len(distance\\_dataframes)), names=['source']).reset\\_index()\n common\\_indices = merged\\_df.groupby('index').filter(lambda x: len(x) == len(distance\\_list))\n filtered\\_points = common\\_indices.groupby('index')['value'].apply(list).reset\\_index().values.tolist()\n\n return filtered\\_points\n def generate\\_radial\\_buffer\\_length(self,\n data : np.ndarray,\n sample\\_size : int, \n n\\_closest : int):\n \"\"\"\n generates a useful radial distance that will create groups of rough size n\\_closest.\n \"\"\"\n # Randomly sample sample\\_size points from the data\n sampled\\_indices = np.random.choice(data.shape[0], size=sample\\_size, replace=False)\n sampled\\_points = data[sampled\\_indices]\n\n max\\_distances = []\n\n # Compute the distance between each sampled point and every other point in data\n for sampled\\_point in sampled\\_points:\n distances = np.linalg.norm(data - sampled\\_point, axis=1)\n\n # Find the n\\_closest distances\n closest\\_distances = np.partition(distances, n\\_closest)[:n\\_closest]\n\n # Find the maximum distance among the n\\_closest distances\n max\\_distance = np.max(closest\\_distances)\n max\\_distances.append(max\\_distance)\n\n # Return the average of the maximum distances\n self.radial\\_buffer = np.mean(max\\_distances)\n \n def animate\\_radial\\_buffer\\_length(self, data, sample\\_size, n\\_closest, framerate=1):\n \n\n def plot\\_sphere(ax, center, radius, color, alpha=1.0, n\\_points=100):\n u = np.linspace(0, 2 \\* np.pi, n\\_points)\n v = np.linspace(0, np.pi, n\\_points)\n x = radius \\* np.outer(np.cos(u), np.sin(v)) + center[0]\n y = radius \\* np.outer(np.sin(u), np.sin(v)) + center[1]\n z = radius \\* np.outer(np.ones(np.size(u)), np.cos(v)) + center[2]\n\n ax.plot\\_surface(x, y, z, color=color, alpha=alpha)\n if data.shape[1] not in (2, 3):\n raise ValueError(\"The dimensionality of the data must be 2 or 3 for animation.\")\n\n def update(frame):\n ax.clear()\n if frame < sample\\_size:\n # Plot only the current sampled\\_point\n ax.scatter(\\*sampled\\_points[frame], c='black', marker='o')\n elif frame < 2 \\* sample\\_size:\n i = frame - sample\\_size\n sampled\\_point = sampled\\_points[i]\n closest\\_points = n\\_closest\\_points[i]\n furthest\\_point = closest\\_points[-1]\n\n # Plot sampled\\_point and n\\_closest\\_points with the furthest\\_point in red\n ax.scatter(\\*closest\\_points.T, c='blue', marker='o')\n ax.scatter(\\*furthest\\_point, c='red', marker='o')\n ax.scatter(\\*sampled\\_point, c='black', marker='o')\n else:\n i = frame - 2 \\* sample\\_size\n sampled\\_point = sampled\\_points[i]\n furthest\\_point = n\\_closest\\_points[i][-1]\n\n # Plot sampled\\_point and the furthest\\_point in n\\_closest\n ax.scatter(\\*furthest\\_point, c='red', marker='o')\n ax.scatter(\\*sampled\\_point, c='black', marker='o')\n\n # Draw a circle (2D) or translucent sphere (3D) with radius equal to the radial\\_buffer\\_length\n if data.shape[1] == 2:\n circle = Circle(sampled\\_point, radial\\_buffer\\_length, fill=False, edgecolor='black')\n ax.add\\_patch(circle)\n else:\n plot\\_sphere(ax, sampled\\_point, radial\\_buffer\\_length, color='red', alpha=0.2)\n ax.set\\_xlim(0, 1)\n ax.set\\_ylim(0, 1)\n if data.shape[1] == 3:\n ax.set\\_zlim(0, 1)\n\n sampled\\_indices = np.random.choice(data.shape[0], size=sample\\_size, replace=False)\n sampled\\_points = data[sampled\\_indices]\n\n n\\_closest\\_points = []\n max\\_vals = []\n for sampled\\_point in sampled\\_points:\n distances = np.linalg.norm(data - sampled\\_point, axis=1)\n closest\\_indices = np.argpartition(distances, n\\_closest)[:n\\_closest]\n closest\\_points = data[closest\\_indices]\n n\\_closest\\_points.append(closest\\_points)\n \n max\\_vals.append(np.linalg.norm(sampled\\_point - data[closest\\_indices[-1]]))\n radial\\_buffer\\_length = np.mean(np.array(max\\_vals))\n\n fig = plt.figure()\n if data.shape[1] == 2:\n ax = fig.add\\_subplot(111)\n else:\n ax = fig.add\\_subplot(111, projection='3d')\n\n ani = FuncAnimation(fig, update, frames=3 \\* sample\\_size, interval=1000 / framerate, blit=False)\n plt.show()\n\nclass RadialFoci:\n def \\_\\_init\\_\\_(self ,\n vector : np.ndarray):\n \"\"\"\n creates the radial distances used for the clustering \n \"\"\"\n self.distances = []\n self.index\\_to\\_distance = {}\n self.value= vector\n\n def index\\_distance(self, index : int):\n return self.distances[self.index\\_to\\_distance[index]][1]\n \n def find\\_radial\\_group(self,\n index : int,\n expansion\\_start : int,\n radial\\_cutoff : float,):\n \"\"\"\n Finds the group of indices in 4\\*log N time\n \"\"\"\n def binary\\_barrier\\_search(boundary\\_condition,\n floor=None,\n ceiling=None):\n if not self.distances:\n return floor if floor is not None else ceiling\n\n low, high = 0, len(self.distances) - 1\n\n if self[low] > boundary\\_condition:\n return floor\n\n if self.distances[high] <= boundary\\_condition:\n return ceiling\n\n while low <= high:\n mid = (low + high) // 2\n\n if self.distances[mid] <= boundary\\_condition and self.distances[mid + 1] > boundary\\_condition:\n return mid\n elif self.distances[mid] <= boundary\\_condition:\n low = mid + 1\n else:\n high = mid - 1\n\n return None\n \n origin\\_value = self.index\\_distance(index)\n expansion\\_value = expansion\\_start\n # first find the upward / downward limits\n upwards\\_floor\\_limit = index\n upward\\_ceil\\_limit = index + expansion\\_value\n while(self.index\\_distance(index + expansion\\_value) - origin\\_value < origin\\_value + radial\\_cutoff):\n expansion\\_value \\*= 2\n upward\\_ceil\\_limit = expansion\\_value\n if(upward\\_ceil\\_limit > self.distances.\\_\\_len\\_\\_()): upward\\_ceil\\_limit = self.distances.\\_\\_len\\_\\_()\n\n downward\\_ceil\\_limit = index\n downward\\_floor\\_limit = index - expansion\\_value\n while(origin\\_value - self.index\\_distance(index - expansion\\_value) > origin\\_value - radial\\_cutoff):\n expansion\\_value \\*= 2\n downward\\_floor\\_limit = expansion\\_value\n if(downward\\_floor\\_limit < 0): downward\\_floor\\_limit = 0\n \n return self.distances[binary\\_barrier\\_search(origin\\_value + radial\\_cutoff, upwards\\_floor\\_limit, upward\\_ceil\\_limit):\n binary\\_barrier\\_search(origin\\_value - radial\\_cutoff, downward\\_floor\\_limit, downward\\_ceil\\_limit)]\n \n \ndef radial\\_map\\_data(unmapped\\_data : np.ndarray):\n \"\"\"\n Maps out data to the radial dimensionality.\n \"\"\"\n dim = unmapped\\_data.shape[1]\n radial\\_focus\\_group = RadialFocusGroup()\n # Create the radial\\_foci dataset\n radial\\_foci = np.eye(dim)\n radial\\_foci = np.vstack((radial\\_foci, np.zeros(dim))) # Add the origin point\n\n # Compute the distance between each point in unmapped\\_data and radial\\_foci\n \n for j, radial\\_point in enumerate(radial\\_foci):\n radial\\_foci\\_distance = []\n\n for i, unmapped\\_point in enumerate(unmapped\\_data):\n radial\\_foci\\_distance.append((i, np.linalg.norm(unmapped\\_point - radial\\_point)))\n radial\\_foci\\_distance = sorted(radial\\_foci\\_distance, key = lambda x: x[1])\n new\\_radial\\_foci = RadialFoci(radial\\_point)\n new\\_radial\\_foci.distances = radial\\_foci\\_distance\n new\\_radial\\_foci.index\\_to\\_distance = { entry[0] : index for index, entry in enumerate(new\\_radial\\_foci.distances)}\n radial\\_focus\\_group.foci.append(new\\_radial\\_foci)\n \n\n return radial\\_focus\\_group\n\nbuild a test for \"build\\_radial\\_group\"", "Given this context:\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.animation import FuncAnimation\nfrom matplotlib.patches import Circle\nimport pickle\nimport pandas as pd\n\nclass RadialFocusGroup:\n def \\_\\_init\\_\\_(self):\n self.foci = []\n\n def distance\\_ordered\\_foci(self, index : int):\n \"\"\"\n Order the foci by closeness for filtering\n \"\"\"\n distances = []\n for foci\\_index, foci in enumerate(self.foci):\n distances.append((foci\\_index, foci.index\\_distance(index)))\n return sorted(distances, key = lambda x:x[1])\n\n def ring\\_filter(self, distance\\_list):\n\n distance\\_dataframes = []\n\n for distances in distance\\_list:\n df = pd.DataFrame(distances, columns=['index', 'value'])\n distance\\_dataframes.append(df)\n\n merged\\_df = pd.concat(distance\\_dataframes, keys=range(len(distance\\_dataframes)), names=['source']).reset\\_index()\n common\\_indices = merged\\_df.groupby('index').filter(lambda x: len(x) == len(distance\\_list))\n filtered\\_points = common\\_indices.groupby('index')['value'].apply(list).reset\\_index().values.tolist()\n\n return filtered\\_points\n def generate\\_radial\\_buffer\\_length(self,\n data : np.ndarray,\n sample\\_size : int, \n n\\_closest : int):\n \"\"\"\n generates a useful radial distance that will create groups of rough size n\\_closest.\n \"\"\"\n # Randomly sample sample\\_size points from the data\n sampled\\_indices = np.random.choice(data.shape[0], size=sample\\_size, replace=False)\n sampled\\_points = data[sampled\\_indices]\n\n max\\_distances = []\n\n # Compute the distance between each sampled point and every other point in data\n for sampled\\_point in sampled\\_points:\n distances = np.linalg.norm(data - sampled\\_point, axis=1)\n\n # Find the n\\_closest distances\n closest\\_distances = np.partition(distances, n\\_closest)[:n\\_closest]\n\n # Find the maximum distance among the n\\_closest distances\n max\\_distance = np.max(closest\\_distances)\n max\\_distances.append(max\\_distance)\n\n # Return the average of the maximum distances\n self.radial\\_buffer = np.mean(max\\_distances)\n \n def animate\\_radial\\_buffer\\_length(self, data, sample\\_size, n\\_closest, framerate=1):\n \n\n def plot\\_sphere(ax, center, radius, color, alpha=1.0, n\\_points=100):\n u = np.linspace(0, 2 \\* np.pi, n\\_points)\n v = np.linspace(0, np.pi, n\\_points)\n x = radius \\* np.outer(np.cos(u), np.sin(v)) + center[0]\n y = radius \\* np.outer(np.sin(u), np.sin(v)) + center[1]\n z = radius \\* np.outer(np.ones(np.size(u)), np.cos(v)) + center[2]\n\n ax.plot\\_surface(x, y, z, color=color, alpha=alpha)\n if data.shape[1] not in (2, 3):\n raise ValueError(\"The dimensionality of the data must be 2 or 3 for animation.\")\n\n def update(frame):\n ax.clear()\n if frame < sample\\_size:\n # Plot only the current sampled\\_point\n ax.scatter(\\*sampled\\_points[frame], c='black', marker='o')\n elif frame < 2 \\* sample\\_size:\n i = frame - sample\\_size\n sampled\\_point = sampled\\_points[i]\n closest\\_points = n\\_closest\\_points[i]\n furthest\\_point = closest\\_points[-1]\n\n # Plot sampled\\_point and n\\_closest\\_points with the furthest\\_point in red\n ax.scatter(\\*closest\\_points.T, c='blue', marker='o')\n ax.scatter(\\*furthest\\_point, c='red', marker='o')\n ax.scatter(\\*sampled\\_point, c='black', marker='o')\n else:\n i = frame - 2 \\* sample\\_size\n sampled\\_point = sampled\\_points[i]\n furthest\\_point = n\\_closest\\_points[i][-1]\n\n # Plot sampled\\_point and the furthest\\_point in n\\_closest\n ax.scatter(\\*furthest\\_point, c='red', marker='o')\n ax.scatter(\\*sampled\\_point, c='black', marker='o')\n\n # Draw a circle (2D) or translucent sphere (3D) with radius equal to the radial\\_buffer\\_length\n if data.shape[1] == 2:\n circle = Circle(sampled\\_point, radial\\_buffer\\_length, fill=False, edgecolor='black')\n ax.add\\_patch(circle)\n else:\n plot\\_sphere(ax, sampled\\_point, radial\\_buffer\\_length, color='red', alpha=0.2)\n ax.set\\_xlim(0, 1)\n ax.set\\_ylim(0, 1)\n if data.shape[1] == 3:\n ax.set\\_zlim(0, 1)\n\n sampled\\_indices = np.random.choice(data.shape[0], size=sample\\_size, replace=False)\n sampled\\_points = data[sampled\\_indices]\n\n n\\_closest\\_points = []\n max\\_vals = []\n for sampled\\_point in sampled\\_points:\n distances = np.linalg.norm(data - sampled\\_point, axis=1)\n closest\\_indices = np.argpartition(distances, n\\_closest)[:n\\_closest]\n closest\\_points = data[closest\\_indices]\n n\\_closest\\_points.append(closest\\_points)\n \n max\\_vals.append(np.linalg.norm(sampled\\_point - data[closest\\_indices[-1]]))\n radial\\_buffer\\_length = np.mean(np.array(max\\_vals))\n\n fig = plt.figure()\n if data.shape[1] == 2:\n ax = fig.add\\_subplot(111)\n else:\n ax = fig.add\\_subplot(111, projection='3d')\n\n ani = FuncAnimation(fig, update, frames=3 \\* sample\\_size, interval=1000 / framerate, blit=False)\n plt.show()\n\nclass RadialFoci:\n def \\_\\_init\\_\\_(self ,\n vector : np.ndarray):\n \"\"\"\n creates the radial distances used for the clustering \n \"\"\"\n self.distances = []\n self.index\\_to\\_distance = {}\n self.value= vector\n\n def index\\_distance(self, index : int):\n return self.distances[self.index\\_to\\_distance[index]][1]\n \n def find\\_radial\\_group(self,\n index : int,\n expansion\\_start : int,\n radial\\_cutoff : float,):\n \"\"\"\n Finds the group of indices in 4\\*log N time\n \"\"\"\n def binary\\_barrier\\_search(boundary\\_condition,\n floor=None,\n ceiling=None):\n if not self.distances:\n return floor if floor is not None else ceiling\n\n low, high = 0, len(self.distances) - 1\n\n if self[low] > boundary\\_condition:\n return floor\n\n if self.distances[high] <= boundary\\_condition:\n return ceiling\n\n while low <= high:\n mid = (low + high) // 2\n\n if self.distances[mid] <= boundary\\_condition and self.distances[mid + 1] > boundary\\_condition:\n return mid\n elif self.distances[mid] <= boundary\\_condition:\n low = mid + 1\n else:\n high = mid - 1\n\n return None\n \n origin\\_value = self.index\\_distance(index)\n expansion\\_value = expansion\\_start\n # first find the upward / downward limits\n upwards\\_floor\\_limit = index\n upward\\_ceil\\_limit = index + expansion\\_value\n while(self.index\\_distance(index + expansion\\_value) - origin\\_value < origin\\_value + radial\\_cutoff):\n expansion\\_value \\*= 2\n upward\\_ceil\\_limit = expansion\\_value\n if(upward\\_ceil\\_limit > self.distances.\\_\\_len\\_\\_()): upward\\_ceil\\_limit = self.distances.\\_\\_len\\_\\_()\n\n downward\\_ceil\\_limit = index\n downward\\_floor\\_limit = index - expansion\\_value\n while(origin\\_value - self.index\\_distance(index - expansion\\_value) > origin\\_value - radial\\_cutoff):\n expansion\\_value \\*= 2\n downward\\_floor\\_limit = expansion\\_value\n if(downward\\_floor\\_limit < 0): downward\\_floor\\_limit = 0\n \n return self.distances[binary\\_barrier\\_search(origin\\_value + radial\\_cutoff, upwards\\_floor\\_limit, upward\\_ceil\\_limit):\n binary\\_barrier\\_search(origin\\_value - radial\\_cutoff, downward\\_floor\\_limit, downward\\_ceil\\_limit)]\n \n \ndef radial\\_map\\_data(unmapped\\_data : np.ndarray):\n \"\"\"\n Maps out data to the radial dimensionality.\n \"\"\"\n dim = unmapped\\_data.shape[1]\n radial\\_focus\\_group = RadialFocusGroup()\n # Create the radial\\_foci dataset\n radial\\_foci = np.eye(dim)\n radial\\_foci = np.vstack((radial\\_foci, np.zeros(dim))) # Add the origin point\n\n # Compute the distance between each point in unmapped\\_data and radial\\_foci\n \n for j, radial\\_point in enumerate(radial\\_foci):\n radial\\_foci\\_distance = []\n\n for i, unmapped\\_point in enumerate(unmapped\\_data):\n radial\\_foci\\_distance.append((i, np.linalg.norm(unmapped\\_point - radial\\_point)))\n radial\\_foci\\_distance = sorted(radial\\_foci\\_distance, key = lambda x: x[1])\n new\\_radial\\_foci = RadialFoci(radial\\_point)\n new\\_radial\\_foci.distances = radial\\_foci\\_distance\n new\\_radial\\_foci.index\\_to\\_distance = { entry[0] : index for index, entry in enumerate(new\\_radial\\_foci.distances)}\n radial\\_focus\\_group.foci.append(new\\_radial\\_foci)\n \n\n return radial\\_focus\\_group\n\nbuild a unit test for \"build\\_radial\\_group\" and \"binary\\_barrier\\_search\"", "---------------------------------------------------------------------------\nLookupError Traceback (most recent call last)\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 83 try:\n---> 84 root = nltk.data.find(f\"{self.subdir}/{zip\\_name}\")\n 85 except LookupError:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\data.py in find(resource\\_name, paths)\n 582 resource\\_not\\_found = f\"\\n{sep}\\n{msg}\\n{sep}\\n\"\n--> 583 raise LookupError(resource\\_not\\_found)\n 584 \n\nLookupError: \n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n Resource omw-1.4 not found.\n Please use the NLTK Downloader to obtain the resource:\n\n >>> import nltk\n >>> nltk.download('omw-1.4')\n \n For more information see: https://www.nltk.org/data.html\n\n Attempted to load corpora/omw-1.4.zip/omw-1.4/\n\n Searched in:\n - 'C:\\\\Users\\\\rockr/nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\share\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\lib\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\AppData\\\\Roaming\\\\nltk\\_data'\n - 'C:\\\\nltk\\_data'\n - 'D:\\\\nltk\\_data'\n - 'E:\\\\nltk\\_data'\n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\nDuring handling of the above exception, another exception occurred:\n\nLookupError Traceback (most recent call last)\n~\\AppData\\Local\\Temp\\ipykernel\\_9724\\3827873343.py in \n 41 \n 42 # Preprocess train and test text data\n---> 43 train\\_df['text'] = train\\_df['text'].apply(preprocess\\_text)\n 44 test\\_df['text'] = test\\_df['text'].apply(preprocess\\_text)\n 45 \n\n~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py in apply(self, func, convert\\_dtype, args, \\*\\*kwargs)\n 4431 dtype: float64\n 4432 \"\"\"\n-> 4433 return SeriesApply(self, func, convert\\_dtype, args, kwargs).apply()\n 4434 \n 4435 def \\_reduce(\n\n~\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py in apply(self)\n 1086 return self.apply\\_str()\n 1087 \n-> 1088 return self.apply\\_standard()\n 1089 \n 1090 def agg(self):\n\n~\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py in apply\\_standard(self)\n 1141 # List[Union[Callable[..., Any], str]]]]]\"; expected\n 1142 # \"Callable[[Any], Any]\"\n-> 1143 mapped = lib.map\\_infer(\n 1144 values,\n 1145 f, # type: ignore[arg-type]\n\n~\\Anaconda3\\lib\\site-packages\\pandas\\\\_libs\\lib.pyx in pandas.\\_libs.lib.map\\_infer()\n\n~\\AppData\\Local\\Temp\\ipykernel\\_9724\\3827873343.py in preprocess\\_text(text)\n 35 # Lemmatize\n 36 lemmatizer = WordNetLemmatizer()\n---> 37 tokens = [lemmatizer.lemmatize(token) for token in tokens]\n 38 # Join tokens back into a string\n 39 text = ' '.join(tokens)\n\n~\\AppData\\Local\\Temp\\ipykernel\\_9724\\3827873343.py in (.0)\n 35 # Lemmatize\n 36 lemmatizer = WordNetLemmatizer()\n---> 37 tokens = [lemmatizer.lemmatize(token) for token in tokens]\n 38 # Join tokens back into a string\n 39 text = ' '.join(tokens)\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\stem\\wordnet.py in lemmatize(self, word, pos)\n 43 :return: The lemma of `word`, for the given `pos`.\n 44 \"\"\"\n---> 45 lemmas = wn.\\_morphy(word, pos)\n 46 return min(lemmas, key=len) if lemmas else word\n 47 \n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_getattr\\_\\_(self, attr)\n 119 raise AttributeError(\"LazyCorpusLoader object has no attribute '\\_\\_bases\\_\\_'\")\n 120 \n--> 121 self.\\_\\_load()\n 122 # This looks circular, but its not, since \\_\\_load() changes our\n 123 # \\_\\_class\\_\\_ to something new:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 87 \n 88 # Load the corpus.\n---> 89 corpus = self.\\_\\_reader\\_cls(root, \\*self.\\_\\_args, \\*\\*self.\\_\\_kwargs)\n 90 \n 91 # This is where the magic happens! Transform ourselves into\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py in \\_\\_init\\_\\_(self, root, omw\\_reader)\n 1174 )\n 1175 else:\n-> 1176 self.provenances = self.omw\\_prov()\n 1177 \n 1178 # A cache to store the wordnet data of multiple languages\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py in omw\\_prov(self)\n 1283 provdict = {}\n 1284 provdict[\"eng\"] = \"\"\n-> 1285 fileids = self.\\_omw\\_reader.fileids()\n 1286 for fileid in fileids:\n 1287 prov, langfile = os.path.split(fileid)\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_getattr\\_\\_(self, attr)\n 119 raise AttributeError(\"LazyCorpusLoader object has no attribute '\\_\\_bases\\_\\_'\")\n 120 \n--> 121 self.\\_\\_load()\n 122 # This looks circular, but its not, since \\_\\_load() changes our\n 123 # \\_\\_class\\_\\_ to something new:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 84 root = nltk.data.find(f\"{self.subdir}/{zip\\_name}\")\n 85 except LookupError:\n---> 86 raise e\n 87 \n 88 # Load the corpus.\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 79 else:\n 80 try:\n---> 81 root = nltk.data.find(f\"{self.subdir}/{self.\\_\\_name}\")\n 82 except LookupError as e:\n 83 try:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\data.py in find(resource\\_name, paths)\n 581 sep = \"\\*\" \\* 70\n 582 resource\\_not\\_found = f\"\\n{sep}\\n{msg}\\n{sep}\\n\"\n--> 583 raise LookupError(resource\\_not\\_found)\n 584 \n 585 \n\nLookupError: \n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n Resource omw-1.4 not found.\n Please use the NLTK Downloader to obtain the resource:\n\n >>> import nltk\n >>> nltk.download('omw-1.4')\n \n For more information see: https://www.nltk.org/data.html\n\n Attempted to load corpora/omw-1.4\n\n Searched in:\n - 'C:\\\\Users\\\\rockr/nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\share\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\lib\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\AppData\\\\Roaming\\\\nltk\\_data'\n - 'C:\\\\nltk\\_data'\n - 'D:\\\\nltk\\_data'\n - 'E:\\\\nltk\\_data'\n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\nplease fix this error", "---------------------------------------------------------------------------\nLookupError Traceback (most recent call last)\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 83 try:\n---> 84 root = nltk.data.find(f\"{self.subdir}/{zip\\_name}\")\n 85 except LookupError:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\data.py in find(resource\\_name, paths)\n 582 resource\\_not\\_found = f\"\\n{sep}\\n{msg}\\n{sep}\\n\"\n--> 583 raise LookupError(resource\\_not\\_found)\n 584 \n\nLookupError: \n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n Resource omw-1.4 not found.\n Please use the NLTK Downloader to obtain the resource:\n\n >>> import nltk\n >>> nltk.download('omw-1.4')\n \n For more information see: https://www.nltk.org/data.html\n\n Attempted to load corpora/omw-1.4.zip/omw-1.4/\n\n Searched in:\n - 'C:\\\\Users\\\\rockr/nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\share\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\lib\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\AppData\\\\Roaming\\\\nltk\\_data'\n - 'C:\\\\nltk\\_data'\n - 'D:\\\\nltk\\_data'\n - 'E:\\\\nltk\\_data'\n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\nDuring handling of the above exception, another exception occurred:\n\nLookupError Traceback (most recent call last)\n~\\AppData\\Local\\Temp\\ipykernel\\_9724\\3118448898.py in \n 42 \n 43 # Preprocess train and test text data\n---> 44 train\\_df['text'] = train\\_df['text'].apply(preprocess\\_text)\n 45 test\\_df['text'] = test\\_df['text'].apply(preprocess\\_text)\n 46 \n\n~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py in apply(self, func, convert\\_dtype, args, \\*\\*kwargs)\n 4431 dtype: float64\n 4432 \"\"\"\n-> 4433 return SeriesApply(self, func, convert\\_dtype, args, kwargs).apply()\n 4434 \n 4435 def \\_reduce(\n\n~\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py in apply(self)\n 1086 return self.apply\\_str()\n 1087 \n-> 1088 return self.apply\\_standard()\n 1089 \n 1090 def agg(self):\n\n~\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py in apply\\_standard(self)\n 1141 # List[Union[Callable[..., Any], str]]]]]\"; expected\n 1142 # \"Callable[[Any], Any]\"\n-> 1143 mapped = lib.map\\_infer(\n 1144 values,\n 1145 f, # type: ignore[arg-type]\n\n~\\Anaconda3\\lib\\site-packages\\pandas\\\\_libs\\lib.pyx in pandas.\\_libs.lib.map\\_infer()\n\n~\\AppData\\Local\\Temp\\ipykernel\\_9724\\3118448898.py in preprocess\\_text(text)\n 36 # Lemmatize\n 37 lemmatizer = WordNetLemmatizer()\n---> 38 tokens = [lemmatizer.lemmatize(token) for token in tokens]\n 39 # Join tokens back into a string\n 40 text = ' '.join(tokens)\n\n~\\AppData\\Local\\Temp\\ipykernel\\_9724\\3118448898.py in (.0)\n 36 # Lemmatize\n 37 lemmatizer = WordNetLemmatizer()\n---> 38 tokens = [lemmatizer.lemmatize(token) for token in tokens]\n 39 # Join tokens back into a string\n 40 text = ' '.join(tokens)\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\stem\\wordnet.py in lemmatize(self, word, pos)\n 43 :return: The lemma of `word`, for the given `pos`.\n 44 \"\"\"\n---> 45 lemmas = wn.\\_morphy(word, pos)\n 46 return min(lemmas, key=len) if lemmas else word\n 47 \n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_getattr\\_\\_(self, attr)\n 119 raise AttributeError(\"LazyCorpusLoader object has no attribute '\\_\\_bases\\_\\_'\")\n 120 \n--> 121 self.\\_\\_load()\n 122 # This looks circular, but its not, since \\_\\_load() changes our\n 123 # \\_\\_class\\_\\_ to something new:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 87 \n 88 # Load the corpus.\n---> 89 corpus = self.\\_\\_reader\\_cls(root, \\*self.\\_\\_args, \\*\\*self.\\_\\_kwargs)\n 90 \n 91 # This is where the magic happens! Transform ourselves into\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py in \\_\\_init\\_\\_(self, root, omw\\_reader)\n 1174 )\n 1175 else:\n-> 1176 self.provenances = self.omw\\_prov()\n 1177 \n 1178 # A cache to store the wordnet data of multiple languages\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py in omw\\_prov(self)\n 1283 provdict = {}\n 1284 provdict[\"eng\"] = \"\"\n-> 1285 fileids = self.\\_omw\\_reader.fileids()\n 1286 for fileid in fileids:\n 1287 prov, langfile = os.path.split(fileid)\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_getattr\\_\\_(self, attr)\n 119 raise AttributeError(\"LazyCorpusLoader object has no attribute '\\_\\_bases\\_\\_'\")\n 120 \n--> 121 self.\\_\\_load()\n 122 # This looks circular, but its not, since \\_\\_load() changes our\n 123 # \\_\\_class\\_\\_ to something new:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 84 root = nltk.data.find(f\"{self.subdir}/{zip\\_name}\")\n 85 except LookupError:\n---> 86 raise e\n 87 \n 88 # Load the corpus.\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 79 else:\n 80 try:\n---> 81 root = nltk.data.find(f\"{self.subdir}/{self.\\_\\_name}\")\n 82 except LookupError as e:\n 83 try:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\data.py in find(resource\\_name, paths)\n 581 sep = \"\\*\" \\* 70\n 582 resource\\_not\\_found = f\"\\n{sep}\\n{msg}\\n{sep}\\n\"\n--> 583 raise LookupError(resource\\_not\\_found)\n 584 \n 585 \n\nLookupError: \n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n Resource omw-1.4 not found.\n Please use the NLTK Downloader to obtain the resource:\n\n >>> import nltk\n >>> nltk.download('omw-1.4')\n \n For more information see: https://www.nltk.org/data.html\n\n Attempted to load corpora/omw-1.4\n\n Searched in:\n - 'C:\\\\Users\\\\rockr/nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\share\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\lib\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\AppData\\\\Roaming\\\\nltk\\_data'\n - 'C:\\\\nltk\\_data'\n - 'D:\\\\nltk\\_data'\n - 'E:\\\\nltk\\_data'\n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n\nstill error", "can you do the same with this list, main body area and nested areas. If the area is not an anatomic are than ignore please\n\n teeth.\n face, neck, body.\n lower face, neck, and jawline.\n severe cystic acne.\n face, neck, and body.\n lower layers of skin tissue.\n laryngeal prominence of thyroid cartilage in the throat.\n facial rejuvenation.\n abdomen, hips, thighs, arms, buttocks, or under the chin.\n nostrils.\n Face and body \n upper or lower jawbone.\n facial reconstruction, abdominal wall reconstruction, breast reconstruction.\n gastric.\n nipple-areola complex.\n underarms.\n balding, thinning, or receding areas.\n nasolabial folds, or smile lines.\n small, uncomplicated spider veins and small varicose veins.\n cellulite on the thighs and buttocks.\n mild to severe acne.\n upper or lower back.\n mustache, beard, sideburns.\n face, cheeks, under-eyes, lips, nasolabial folds, pitted scars, breasts, buttocks.\n face.\n navel.\n moderate to severe facial wrinkles and folds, such as nasolabial folds, etched-in lip lines, crow's feet, smile lines, marionette lines, under-eye tear troughs, and deep glabellar lines.\n upper arms.\n incision or injury.\n face, neck, chest, back, hands, arms, and legs.\n abdomen, hips, lower back, buttocks.\n stomach, legs, arms.\n stomach, thighs, butt, hips, and arms.\n fat reduction anywhere on the body, most commonly treated body areas are the tummy, hips, thighs, flanks (aka love handles), and back. some providers also offer mini bodyfx, which can treat smaller fat deposits in areas like the upper arms and under the chin..\n abdomen, upper arms, thighs, knees, love handles, breasts, back, chin, jowls, cheeks, and neck.\n crow's feet, frown lines, forehead lines, lip lines, bunny lines on the nose, chin wrinkles, neck bands, above the eyebrows, above the upper lip.\n teeth straightening.\n buttocks, hips, waist, love handles, thighs, lower back.\n buttocks.\n breasts.\n face.\n face, neck, d'colletage, back of hands.\n double chin, jawline, knees, elbows, upper arms, muffin top.\n face, body contouring.\n teeth.\n face, neck, hands, chest, legs, and other areas.\n glabellar area.\n forehead and eyebrows.\n lower cheeks.\n foot.\n buttocks, hips, abdomen, waistline, lower back, thighs.\n lower legs.\n lower legs.\n outer corner of the eye where the upper and lower lid meet.\n scalp.\n breast.\n face, neck, arms, stomach, buttocks, and legs.\n lens of the eye.\n cellulite dimples on the buttocks and the backs of the thighs.\n thighs, abdomen, or buttocks.\n midface.\n midface.\n cheeks.\n midface.\n zygomatic bone (malar bone).\n face, neck, chest, hands.\n soft tissue under the skin.\n lower face.\n under the chin and jawline.\n fine lines, shrink the appearance of pores, improve skin tone and texture, and reduce melasma.\n teeth straightening.\n jawbone.\n face, neck, chest, lips, and anywhere on the body.\n broken capillaries, spider veins, vascular lesions, periorbital veins, skin discoloration.\n upper lip, nose, and roof of the mouth.\n clitoral hood.\n face, neck, chest.\n vagina and vulva.\n crow's feet, fine lines around the eyes, smile lines, frown lines, atrophic acne scars, and thin lips.\n brow, mid- and lower face, jawline, and neck.\n fine lines and wrinkles, sun damage, discoloration, and acne scars.\n fine lines and wrinkles, acne scars, large pore size, uneven skin tone, rough skin texture, age spots, and other signs of sun damage.\n abdomen, flanks, bra fat, inner and outer thighs, back fat, upper arms, buttock rolls, knees, hips, mons pubis, submental fat.\n thighs, butt, and abdomen.\n hyperpigmentation and skin discoloration.\n abdominal fat, love handles, upper arms, inner thighs, under chin, below buttocks, bra and back fat bulges.\n slimming, toning, and cellulite reduction.\n face.\n skin.\n teeth.\n teeth straightening.\n glabellar lines, forehead furrows, crow's feet, bunny lines, platysmal bands, dimpling of the chin, masseter muscles.\n middle and lower areas of the face.\n face, eyes, neck.\n teeth.\n jawbone, gums.\n missing teeth.\n teeth.\n upper or lower jawbone.\n face, eyes, lips.\n face, upper lip, cheeks.\n smile lines, marionette lines, lips, under-eye hollows, cheeks, temples, jawline, chin, nose.\n face, neck, chest, stomach, thighs.\n face.\n skin tightening.\n face, neck, d'colletage, body.\n abdominal muscles.\n chin or cheeks.\n vaginal tissue.\n craniofacial region.\n upper eyelids.\n stomach and small intestine.\n front of natural teeth.\n \n face, neck, chest, arms, back of hands, and elsewhere on the body.\n legs, buttocks, thighs, back, or stomach.\n teeth.\n face, neck, under chin.\n skin.\n hormonal acne, polycystic ovary syndrome (pcos), high blood pressure, congestive heart failure.\n anywhere on the body.\n excess pigmentation and redness, wrinkles and mild acne scars, vascular lesions and varicose veins, pigmented lesions and dark tattoos.\n eye alignment.\n breast augmentation, breast reconstruction, abdominal wall defects, hernia repair.\n depressed scars, acne scars, cellulite dimples.\n face, neck, and d\u00e9colletage.\n teeth alignment.\n epidermis.\n acne on face and body, psoriasis on body, sun damage.\n face.\n teeth.\n face.\n lips, cheeks, chin, forehead, eyes, mouth, neck, and chest.\n scrotum.\n face, eyes, eyelids, jawline, stomach, arms, backs of hands, thighs, knees, butt.\n breasts and nipples.\n cheeks, around the mouth, neck, forehead and around the eyes.\n lower face, jowls, neck, breasts, arms, tummy, and thighs.\n vulvar and vaginal tissues.\n thigh.\n brow, mid- and lower face, jawline, and neck.\n skin concerns.\n inner and outer thighs, back, abdomen, love handles, hips, saddlebags, and buttocks.\n face, neck, stomach, and upper arms.\n enamel, dentin, pulp.\n face, forehead, temples, chin, area around mouth, cheeks.\n wrinkles, sagging skin, fat cells, cellulite.\n abdomen and flanks.\n abdomen and flanks.\n abdomen, flanks, buttocks, thighs.\n abdomen, flanks, and thighs.\n reshaping, creating balanced, normal breasts.\n abdomen, love handles, hips, thighs, chin, upper arms, underarms.\n lower abdomen.\n abdomen.\n brow, neck (including jawline), under chin, lines and wrinkles on d'colletage.\n vaginal area.\n face and neck.\n fine lines and wrinkles, discoloration, and even scars.\n stomach, hips, and thighs.\n abdomen, hips, and thighs.\n fat layer just under the skin.\n upper arms, belly, love handles, thighs, chin.\n abdominal wall.\n eyelid.\n lower face.\n vaginal canal, opening, labia majora, vulva, labia minora, mons pubis.\n vaginal canal.\n cleavage area.\n face.\n face.\n abdomen and thighs.\n spider veins, varicose veins, and venous reflux disease.\n thighs, calves, and ankles, buttocks and hips, abdomen, back, and flanks (aka love handles), upper arms, neck and under the chin.\n rosacea, pigmented scars, spider veins, broken capillaries, birthmarks, hyperpigmentation, newly formed stretch marks, and other forms of red, brown, or purple facial pigmentation.\n legs.\n spider veins, cherry angiomas, small hemangiomas, skin tags, spider nevi, and redness from rosacea.\n thighs, buttocks, upper arms, stomach, excess fat and mildly sagging skin under the chin.\n thighs, abdomen, and butt.\n varicose veins.\n fat reduction on the back, abdomen, thighs and flanks, cellulite reduction on the thighs, buttocks, and abdomen, muscle conditioning and toning for biceps, triceps, abdominal and oblique muscles, glutes, hamstrings, and quadriceps.\n face, neck, and body.\n wrinkles, fine lines, cellulite, stretch marks.\n fine lines and deep wrinkles, acne scars, large pores, uneven skin texture, stretch marks, mild laxity, rosacea, and hyperpigmentation, including melasma.\n pelvic floor issues.\n face, neck, chest, hands.\n face and body.\n vaginal tissues, labia majora.\n pelvic floor muscles and skin elasticity.\n jaw.\n lines and wrinkles created by dynamic facial movements, such as smiling, frowning, or raising your eyebrows, neck pain caused by cervical dystonia, eye spasms known as blepharospasm, and upper limb spasticity.\n skin concerns, visible veins, brown spots, scars, laser hair removal, tattoo removal, cataract surgery.\n waist, chest, back, neck, upper arms, thighs, love handles, hips, and ankles.\n skin.\n teeth.\n lower third of face, jawline, neck.\n face, neck, and body.", "3 THE KGPIP SCALABLE META-LEARNING\nOur meta-learning approach is based on mining large databases\nof ML pipelines associated with the used datasets, as illustrated in\nFigure 1. The mining process uses static program analysis instead\nof executing the actual pipeline scripts or preparing the actual raw\ndata. The KGpip meta-learning component enhances the search\nstrategy of existing AutoML systems, such as AutoSklearn and\nFLAML, and allows these systems to handle ad-hoc datasets, i.e.,\nunseen ones. To retain a maximal degree of flexibility, KGpip captures metadata and semantics in a flexible graph format, and relies\non graph generator models as the database of pipelines.\nUnlike existing meta-learning approaches, our approach is designed to learn from a large scale database and achieve high degree of coverage and diversity. Several ML portals, such as Kaggle or OpenML [29], provide access to thousands of datasets associated with hundreds of thousands of public notebooks, i.e., ML\npipelines/code. KGpip mines these large databases of datasets and\npipelines using static analysis and filters them into ML pipelines\ncustomized for the learner selection problem. The KGpip metalearning approach leverages [1] for code understanding via static\nanalysis of scripts/code of ML pipelines. It extracts the semantics\nof these scripts as code and form an initial graph for each script.\nKGpip cleans the graphs generated by [1] to keep the semantic\nrequired for the ML meta-learning process. Furthermore, our approach introduces dataset nodes and interlinks the relevant pipeline\nsemantic to them. So, our meta-learning approach produces MetaPip,\na highly interconnected graph of seen datasets and pipelines applied\nto them. We also developed a deep embedding model to find the\nclosest datasets to an unseen one, i.e., to effectively prune MetaPip.\nWe then train a deep graph generator model [19] using MetaPip.\nThis model is the core of our meta-learning component as illustrated\nin Figure 1 and discussed in the next section.\n3.1 Graph Representation of Code Semantics\nStatic and dynamic program analysis techniques could be used to abstract the semantics of programs and extract language-independent\nrepresentations of code. A program source code is examined in\nthe static analysis without running the program. In contrast, dynamic analysis examines the source code during runtime to collect\nmemory traces and more detailed statistics specific to the analysis\ntechnique. Unlike static analysis, dynamic analysis helps in capturing more rich semantics from programs with the high cost of\nexecution and storing massive memory traces. ML portals, such as\n df = pd.read\\_csv('example.csv')\n df\\_train, df\\_test = train\\_test\\_split(df)\n X = df\\_train['X']\n model = svm.SVC()\n model.fit(X, df\\_train['Y'])\nFigure 2: An example from a data science notebook.\nread\\_csv\ntrain\\_test\\_split\ndf\\_train[\u2018X\u2019]\ndf\\_train[\u2018Y\u2019]\nSVC\nfit\nFigure 3: Code graph corresponding to Figure 2 obtained with\nGraphGen4Code. The graph shows control flow with gray\nedges and data flow with black edges. Numerous other nodes\nand edges are not shown for simplicity.\nread\\_csv\ntrain\\_test\\_split\nSVC\nexample.csv fit\nFigure 4: Our MetaPip graph of the graph from Figure 3,\nwhere the abstracted ML pipeline is linked to a dataset node\n(highlighted in Orange). MetaPip contains at least 96% less\nnodes and edges than the original graph while enhancing\nthe overall quality of the graph generation process, as experimented in Section 5.5.\nKaggle, have hundreds of thousands of ML pipelines with no instructions for running or managing the environments of these pipelines.\nKGpip combines dataset embedding with static code analysis tools,\nsuch as GraphGen4Code [1], to enrich the collected semantics of\nML pipelines while avoiding the need to run them.\nGraphGen4Code is optimized to efficiently process millions of\nPython programs, performing interprocedural data flow and control\nflow analysis to examine for instance, what happens to data that\nis read from a Pandas dataframe, how it gets manipulated and\ntransformed, and what transformers or estimators get called on the\ndataframe. GraphGen4Code\u2019s graphs make it explicit what APIs\nand functions are invoked on objects without the need to model\nthe used libraries themselves; hence GraphGen4Code can scale\nstatic analysis to millions of programs. Figures 2 and 3 show a\nsmall code snippet and its corresponding static analysis graph from\nGraphGen4Code, respectively. As shown in Figure 3, the graph\ncaptures control flow (gray edges), data flow (black edges), as well\nas numerous other nodes and edges that are not shown in the\nfigure. Examples of these nodes and edges include those capturing\nlocation of calls inside a script file and function call parameters.\nFor example, GraphGen4Code generates a graph of roughly 1600\nnodes and 3700 edges for a Kaggle ML pipeline script of 72 lines of\ncode. The number of nodes and edges dominate the complexity of\ntraining a graph generator model.\n3.2 MetaPip: from Code to Pipeline Semantics\nFor AutoML systems, a pipeline is a set of data transformations,\nlearner selection, and hyper-parameter optimization for each model\nthat is selected. Mined data science notebooks often contain data\nanalysis, data visualization, and model evaluation. Moreover, each\n2430\nnotebook is associated with one or more datasets. Thus, it is essential for our meta-learning model to distinguish between different\ntypes of pipelines and realize this association with datasets. Existing\nsystems for static code analysis extract general semantics of code\nand cannot link pipeline scripts to the used datasets. Thus, the generated graphs by systems, such as GraphGen4Code, are scattered\nand unlinked, i.e., a graph per an ML pipeline script. Moreover, each\ngraph will have nodes and edges that are not relevant for the metalearning process. These irrelevant nodes and edges, i.e., triples, will\nadd noise to the training data. Hence, a meta-learning model will\nnot be able to learn from the abstracted graph pipelines generated\nby such tools, as shown in Table 4. We developed a method to filter\nout this kind of triples from GraphGen4Code\u2019s graph and analyze\nML pipelines to prepare a training set interconnecting repositories\nof ML pipeline scripts with their associated datasets. Moreover,\nour method cleans the noisy nodes and edges and calls to modules\noutside the target ML libraries. For example, our method will extract triples related to libraries, such as Scikit-learn, XGBoost, and\nLGBM. These libraries are the most popular among the top-scoring\nML pipelines in ML portals. The code for the cleaning method is\navailable at the KGpip\u2019s repository.\nOur meta-learning component aims to pick learners and transformer for unseen datasets. Thus, KGpip links the filtered ML\npipelines with the used datasets. The result of adding these dataset\nnodes is a highly interconnected graph for ML pipelines, we refer to\nit as MetaPip. Our MetaPip graph captures both the code and data\naspects of ML pipelines. Hence, we can populate the MetaPip graph\nwith datasets from different sources, such as OpenML and Kaggle,\nand pipelines applied on these datasets. Figure 4 shows the MetaPip\ngraph corresponding to the code snippet in Figure 2. KGpip utilizes\nMetaPip to train a model based on a large set of pipelines associated\nwith similar datasets. For example, a pandas.read\\_csv node will be\nlinked to the used table node, i.e., csv file. In some cases, the code,\nwhich reads a csv file, does not explicitly mention the dataset name.\nThe pipelines are usually associated with datasets, such as Kaggle\npipelines and datasets, as shown in Figure 1.\n3.3 Dataset Representation Learning\nOur approach efficiently guides the meta-learning process by linking the extracted semantics of pipelines to dataset nodes representing the used datasets. There is a sheer amount of datasets of variable\nsizes and we need to develop a scalable method for finding the most\nsimilar datasets for an unseen one. The pairwise comparison based\nof the actual content of datasets, i.e, tuples in CSV files, does not\nscale. Thus, we developed a dataset representation learning method\nto generate a fixed-size and dense embedding at the granularity of\na dataset, e.g., a table or CSV file. The embedding of a dataset D is\nthe average of its column embeddings, i.e.:\n\u210e\ud835\udf03\n(D) =\n1\n|D |\n\u2211\ufe02\n\ud835\udc50 \u2208D\n\u210e\ud835\udf03\n(\ud835\udc50) (1)\nwhere |D | is the number of columns in D. Our work generalizes the\napproach outlined in [22] for individual column embeddings, where\ncolumn embeddings are obtained by training a neural network on\na binary classification task. The model learns when two columns\nrepresent the same concept, but with different values, as opposed to\nFigure 5: An overview of KGpip\u2019s workflows of ML pipeline\ngeneration for a given unseen dataset and certain time budget.\nKGpip utilizes systems for hyperparameter optimization,\nsuch as FLAML or Auto-Sklearn, to optimize KGpip\u2019s top-K\npredicted pipelines (\ud835\udc49\ud835\udc3a), i.e., pruning the search space.\ncolumns representing different concepts. Embeddings for an unseen\ndataset are produced by the last layer of the neural net.\nKGpip reads datasets only once and leverages PySpark DataFrame\nto achieve high task and data parallelism. We use the embeddings\nof datasets to measure their similarity. With these embeddings,\nwe build an index of vector embeddings for all the datasets in our\ntraining set. We utilize efficient libraries [14] for similarity search\nof dense vectors to retrieve the most similar dataset to a new input\ndataset based on its embeddings. Thus, our method scales well and\nleads to accurate results in capturing similarities between datasets.", "=== INSTRUCTIONS ===\nYour task is ONLY to confirm receipt of this chunk, chunk 3/3, and not generate any text. You have now received all the chunks. Please wait for further instructions.\n=== SCRIPT CHUNK 3/3 ===\n wishing it were Ujunwa; the Zimbabwean said Edward\u2019s eyes were always leering when he looked at Ujunwa; the white South African said Edward would never look at a white woman like that because what he felt for Ujunwa was a fancy without respect. \u201cYou all noticed?\u201d Ujunwa asked them. \u201cYou all noticed?\u201d She felt strangely betrayed. She got up and went to her cabin. She called her mother, but the metallic voice kept saying \u201cThe number you are calling is not available at the moment, please try later,\u201d and so she hung up. She could not write. She lay in bed and stayed awake for so long that when she finally fell asleep, it was dawn. That evening, the Tanzanian read an excerpt of his story about the killings in the Congo, from the point of view of a militiaman, a man full of prurient violence. Edward said it would be the lead story in the Oratory, that it was urgent and relevant, that it brought news. Ujunwa thought it read like a piece from The Economist with cartoon characters painted in. But she didn\u2019t say that. She went back to her cabin and, although she had a stomachache, she turned on her laptop. As Chioma sits and stares at Yinka, settled on the alhaji\u2019s lap, she feels as if she is acting a play. She wrote plays in secondary school. Her class staged one during the school\u2019s anniversary celebration and, at the end, there was a standing ovation and the principal said, \u201cChioma is our future star!\u201d Her father was there, sitting next to her mother, clapping and smiling. But when she said she wanted to study literature in university, he told her it was not viable. His word, \u201cviable.\u201d He said she had to study something else and could always write on the side. The alhaji is lightly running a finger over Yinka\u2019s arm and saying, \u201cBut you know Savanna Union Bank sent people to me last week.\u201d Yinka is still smiling and Chioma wonders whether her cheeks are aching. She thinks about the stories in a metal box under her bed. Her father read them all and sometimes he wrote in the margins: Excellent! Clich\u00e9! Very good! Unclear! It was he who had bought novels for her; her mother thought novels a waste of time and felt that all Chioma needed were her textbooks. Yinka says, \u201cChioma!\u201d and she looks up. The alhaji is talking to her. He looks almost shy and his eyes do not meet hers. There is a tentativeness toward her that he does not show toward Yinka. \u201cI am saying you are too fine. Why is it that a Big Man has not married you?\u201d Chioma smiles and says nothing. The alhaji says, \u201cI have agreed that I will do business with Merchant Trust but you will be my personal contact.\u201d Chioma is uncertain what to say. \u201cOf course,\u201d Yinka says. \u201cShe will be your contact. We will take care of you. Ah, thank you, sir!\u201d The alhaji gets up and says, \u201cCome, come, I have some nice perfumes from my last trip to London. Let me give you something to take home.\u201d He starts to walk inside and then turns. \u201cCome, come, you two.\u201d Yinka follows. Chioma gets up. The alhaji turns again toward her, to wait for her to follow. But she does not follow. She turns to the door and opens it and walks out into the bright sunlight and past the Jeep in which the driver is sitting with the door hanging open, listening to the radio. \u201cAunty? Aunty, something happen?\u201d he calls. She does not answer. She walks and walks, past the high gates and out to the street where she gets in a taxi and goes to the office to clear out her almost-empty desk. Ujunwa woke up to the crashing sound of the sea, to a nervous clutch in her belly. She did not want to read her story tonight. She did not want to go to breakfast, either, but she went anyway and said a general good morning with a general smile. She sat next to the Kenyan and he leaned toward her and whispered that Edward had just told the Senegalese that he had dreamed of her naked navel. Naked navel. Ujunwa watched the Senegalese, delicately raising her teacup to her lips, sanguine, looking out at the sea. Ujunwa envied her confident calm. She felt upset, too, to hear that Edward was making suggestive remarks to someone else, and she wondered what her pique meant. Had she come to see his ogling as her due? She was uncomfortable thinking about this, about reading that night, and so in the afternoon, lingering over lunch, she asked the Senegalese what she had said when Edward spoke of her naked navel. The Senegalese shrugged and said no matter how many dreams the old man had, she would still remain a happy lesbian and there was no need to say anything to him. \u201cBut why do we say nothing?\u201d Ujunwa asked. She raised her voice and looked at the others. \u201cWhy do we always say nothing?\u201d They looked at one another. The Kenyan told the waiter that the water was getting warm and could he please get some more ice. The Tanzanian asked the waiter where in Malawi he was from. The Kenyan asked him if the cooks, too, were from Malawi as all the waiters seemed to be. Then the Zimbabwean said she did not care where the cooks were from because the food at Jumping Monkey Hill was simply sickening, all that meat and cream. Other words tumbled out and Ujunwa was not sure who said what. Imagine an African gathering with no rice and why should beer be banned at the dinner table just because Edward thought wine was proper and breakfast at eight was too early, never mind that Edward said it was the \u201cright\u201d time and the smell of his pipe was nauseating and he had to decide which he liked to smoke, anyway, and stop rolling cigarettes halfway through a pipe. Only the black South African remained silent. He looked bereft, hands clasped in his lap, before he said that Edward was just an old man who meant no harm. Ujunwa shouted at him, \u201cThis kind of attitude is why they could kill you and herd you into townships and require passes from you before you could walk on your own land!\u201d Then she stopped herself and apologized. She should not have said that. She had not meant to raise her voice. The Black South African shrugged, as if he understood that the devil would always do his work. The Kenyan was watching Ujunwa. He told her, in a low voice, that she was angry about more than just Edward and she looked away and wondered if \u201cangry\u201d was the right word. Later, she went to the souvenir shop with the Kenyan and the Senegalese and the Tanzanian and tried on jewelry made of faux ivory. They teased the Tanzanian about his interest in jewelry\u2014 perhaps he was gay, too? He laughed and said his possibilities were limitless. Then he said, more seriously, that Edward was connected and could find them a London agent; there was no need to antagonize the man, no need to close doors to opportunity. He, for one, didn\u2019t want to end up at that dull teaching job in Arusha. He was speaking as though to everyone, but his eyes were on Ujunwa. Ujunwa bought a necklace and put it on and liked the look of the white, tooth-shaped pendant against her throat. That evening Isabel smiled when she saw it. \u201cI wish people would see how faux ivory looks real and leave the animals alone,\u201d she said. Ujunwa beamed and said that it was in fact real ivory and wondered whether to add that she had killed the elephant herself during a royal hunt. Isabel looked startled, then pained. Ujunwa fingered the plastic. She needed to be relaxed, and she said this to herself over and over, as she started to read from her story. Afterwards, the Ugandan spoke first, saying how strong a story it was, how believable, his confident tone surprising Ujunwa even more than his words. The Tanzanian said she captured Lagos well, the smells and sounds, and it was incredible how similar Third World cities were. The white South African said she hated that term, Third World, but had loved the realistic portrayal of what women were going through in Nigeria. Edward leaned back and said, \u201cIt\u2019s never quite like that in real life, is it? Women are never victims in that sort of crude way and certainly not in Nigeria. Nigeria has women in high positions. The most powerful cabinet minister today is a woman.\u201d The Kenyan cut in and said he liked the story but didn\u2019t believe Chioma would give up the job; she was, after all, a woman with no other choices, and so he thought the ending was implausible. \u201cThe whole thing is implausible,\u201d Edward said. \u201cThis is agenda writing, it isn\u2019t a real story of real people.\u201d Inside Ujunwa, something shrank. Edward was still speaking. Of course one had to admire the writing itself, which was quite mah-ve-lous. He was watching her, and it was the victory in his eyes that made her stand up and start to laugh. The participants stared at her. She laughed and laughed and they watched her and then she picked up her papers. \u201cA real story of real people?\u201d she said, with her eyes on Edward\u2019s face. \u201cThe only thing I didn\u2019t add in the story is that after I left my coworker and walked out of the alhaji\u2019s house, I got into the Jeep and insisted that the driver take me home because I knew it was the last time I would be riding in it.\u201d There were other things Ujunwa wanted to say, but she did not say them. There were tears crowding up in her eyes but she did not let them out. She was looking forward to calling her mother, and as she walked back to her cabin, she wondered whether this ending, in a story, would be considered plausible.\n=== END OF CHUNK ===", "I want to you to act as a federal research grant writer. I will provide you with a description of the task and the desired deliverables. You will generate at least 5 paragraphs for each chapter heading that I will provide you with.\n\nDescription:\n\nAutonomous and partially-autonomous systems promise the opportunity for a future with self-driving automobiles, air taxis, packages delivered by unmanned aerial vehicles (UAVs), and more revolutionary Earth applications. At the same time, it is expected that future NASA deep space missions will happen at distances that put significant communication barriers between the spacecraft and Earth, including lag due to light distance and intermittent loss of communications. As a result, it will be difficult to control every aspect of spacecraft operation from an Earth-based mission control, and thus, the crews will be required to manage, plan, and execute the mission and to respond to unanticipated system failure and anomaly more autonomously. Similarly, there is also opportunity for unmanned vehicles on Earth to benefit from autonomous, cognitive agent architectures that can respond to emergent situations without the aid of human controllers. For this reason, it is advantageous for operational functionality currently performed by external human-centric control stations (e.g., mission control) to be migrated to the vehicle and crew (if piloted). Since spacecraft operations will consist of a limited number of crewmembers who each operate with a limited performance capacity (in terms of both cognition and tasks), it will be necessary for the spacecraft to have assistive, autonomous, and semi-autonomous agents to be responsible for a large proportion of spacecraft operations so as not to overburden the crew.\n\nCognitive agents could provide meaningful help for many tasks performed by humans. Novel operational capabilities required by deep space missions, such as spacecraft and systems health, crew health, maintenance, consumable management, payload management, and activities such as food production and recycling could benefit from the assistance of autonomous agents, which could interface directly with the crew and onboard systems, reducing cognitive load and scheduling time on the crew. Additionally, cognitive agents could contribute to many general operational tasks in collaboration with the crew, such as training, inspections, and mission planning. Finally, autonomous agents could increase the mission\u2019s resilience to hazardous events, both by directly responding to certain events (e.g., ones which unfold too quickly for the crew to catch, or which immobilize the crew) and by providing assistive services (e.g., fault diagnosis, contingency analysis, and mission replanning).\n\nHowever, implementing these cognitive agents presents significant challenges to the underlying software architecture. First, these agents will need to be able to take a significant amount of responsibility for mission operations while still operating under crew directives. Additionally, agents with different dedicated roles will need to share resources and hardware and may have differing goals and instructions from human operators that need to be managed and coordinated. Such agents will, thus, need to be able to take these actions autonomously while enabling (1) effective crew (or vehicle occupant) control of the vehicle even when the agent is operating autonomously (meaning, the agents should not be acting in unexpected ways and should report when the situation has changed enough to justify a change in operations), (2) direct crew control of the task when manual intervention is needed, and (3) autonomous and manual coordination/deconfliction of agent goals and tasks. Second, for NASA space missions, long-duration spaceflight is likely to uncover new challenges during the mission that require some level of adaptation. Whether this is because of known low-probability hazardous events or because of \u201cunknown unknown\u201d situations that were not planned for, cognitive agents will need to have a capacity for \u201cgraceful extensibility.\u201d This concept is not unique to space missions\u2014Earth-based vehicles will also need to be able to respond to similar types of events in-time given the highly variable and heterogenous environments they will likely encounter when operated at scale. As a result, the architecture of the cognitive agent will need to be able to learn (both from taught examples and from the environment) and reconfigure itself (in collaboration with the crew) to perform new tasks. Finally, these capabilities need to be implemented with the high level of assurance required by mission operations, meaning that learned and autonomous behavior must be transparent, predictable, and verifiable using traditional software assurance techniques.\n\nThis subtopic solicits intelligent autonomous agent cognitive architectures that are open, modular, make decisions under uncertainty, interact closely with humans, incorporate diverse input/data sources, and learn such that the performance of the system is assured and improves over time. This subtopic will enable small businesses to develop the underlying learning/knowledge representation, methods for enabling the required behavior (e.g., operations and interactions), and necessary software architectures required to implement these technologies within the scope of cognitive agents that assist operators in managing vehicle operations. It should be feasible for cognitive agents based on these architectures to be certified or licensed for use on deep space missions to act as liaisons that interact with the mission control operators, the crew, and vehicle subsystems. With such a cognitive agent that has access to all onboard data and communications, the agent could continually integrate this dynamic information and advise the crew and mission control accordingly by multiple modes of interaction including text, speech, and animated images. This agent could respond to queries and recommend to the crew courses of action and direct activities that consider all known constraints, the state of the subsystems, available resources, risk analyses, and goal priorities. Cognitive architectures capable of being certified for crew support on spacecraft are required to be open to NASA with interfaces open to NASA partners who develop modules that integrate with the agent, in contrast to proprietary black-box agents. It should be noted that fulfilling this requirement would additionally make the cognitive agent suitable for a wide variety of Earth applications where a high level of assurance is needed (e.g., autonomous vehicles and aircraft).\n\nAn effective cognitive architecture would be capable of integrating a wide variety of knowledge sources to perform a wide variety of roles depending on mission requirements. For example, an effective prognostics and health management (PHM) agent would need to be able to take sensor data, interpret this data to diagnose the current state of the system using learned artificial intelligence (AI) models, digital twin simulations and data, and user input, and project out potential contingencies to plan optimal maintenance and/or fault avoidance operations under uncertainty. These operations would need to be modifiable in operations, for example, if a hazardous event occurs, there are changes to the mission, or there is a learnable change in behavior that reduces arising projection errors. This agent would need to be able to conduct operations autonomously for low-level inspection and maintenance operations while enabling safe human intervention throughout the process. It would finally need to communicate with crews for planning and performance of maintenance operations, to report/escalate potential hazardous contingencies, and for modification of operations (e.g., learning). This communication could include producing human-interpretable visual dashboards, communicating directly via speech, and direct manipulation of hardware (e.g., to teach/learn certain operations). Agents like this (with functionality appropriate to the given task) would be needed to perform a variety of roles in the spacecraft, including low-level tasks like state estimation, hardware control, and subsystem management and high-level tasks like mission planning and scheduling. Agents with independent responsibilities will furthermore need to be managed and coordinated to enable functional and resilient overall operations.\n\nThe following (nonexhaustive) list of managers provides capabilities useful for a wide variety of spacecraft cognitive agents:\nState estimation manager (SEM): This manager\u2019s capabilities include extracting information from sensors, including images, for use by other managers and by crew. State estimation includes separating signal from noise in sensor data, extracting and compressing useful information, along with fault management and prognostics. The state estimation manager must categorize information on both vehicle-wide and subsystem-by-subsystem bases, including crew health and performance, security, and scientific objectives.\nSkill/behavior manager (SBM): This manager orchestrates execution of individual tasks on short timescales. This involves incorporating specialized knowledge needed for different tasks, e.g., orbit/trajectory planning, robotics operations, spacecraft subsystem control. The skill/behavior manager includes a \"smart executive\" that robustly executes high-level plans produced by the planner/scheduler manager, on schedule, by coordinated commanding of multiple subsystems.\nPlanner/scheduler manager (PSM): This manager creates and updates plans and schedules that accomplish goals. This functionality involves maintaining lists of goals, priorities for achieving those goals, and spacecraft and mission-wide constraints.\nKnowledge manager (KM): This manager ensures that the system's declarative knowledge is consistent and updated, including the incorporation of learned knowledge. Learning and modeling techniques capture system and operational knowledge from different types of knowledge sources; these must be incorporated into existing knowledge bases. \nHuman-machine interactions manager (HMIM) - Natural Language Processing (NLP), Extended Reality (XR): This manager enables multimodal interface/communications with the crew about the current and future state of the systems. This manager must communicate information from all other managers.\n\nWell-constructed proposals will focus on developing a prototype cognitive agent(s) in the context of a limited test. This agent will need to embody a cognitive architecture that can be readily applied to a wide variety of roles and tasks throughout a mission that embodies the desired capabilities of autonomous and semi-autonomous operations, modifiable and/or learned behaviors, data/model fusion for decision-making under uncertainty, advanced user interaction, and assurance/transparency. This architecture could then be able to be extended to a wider scope in a more advanced mission in future phases of the project. This project and the agent architecture will need to be thoroughly documented and demonstrated to enable the understanding (e.g., capabilities and limitations) of this technology.\n\nDesired Deliverables Description:\n\nThe expectation is to develop (1) a preliminary cognitive architecture with trades study/requirements analysis supporting the selection of the architecture in a desired mission (e.g., Human Exploration of Mars Design Reference Mission: Human Exploration of Mars Design Reference Architecture 5.0), (2) early feasibility prototypes of architecture features and conceptual description (e.g., in SysML) for a cognitive agent(s) in that mission, and (3) a detailed implementation plan for full architecture with technical risks identified and managed.\n\nNow please generate a chapter with the following title \"Identification and Significance of the Innovation\".", "1. Our Passion in Life\n\nWhen you were a child, what did you dream of becoming? Do you still chase the same dreams?\nWhat is the topic you could talk about for hours with someone who is passionate about it as much as you are?\nWhich activity do you enjoy so much that you forget about all the worries in the world? Why do you enjoy it so much?\nMake a list of the things you want to accomplish in the next 5 years.\nWhat is the one thing you will never give up on no matter the hardships?\nName three things that give you the energy to go through the hard day.\nName the accomplishment in your life that you are most proud of.\nThink of one person in your life that gives you the inspiration to pursue your dreams. Write them a thank you letter to show them appreciation.\n\n2. A Prudent Use of our Limited Time\n\nWhat does your ideal day spent with loved ones look like?\nWhat is the memory you hold dearest up to this day?\nThe thing I will never regret doing is ... because...\nIf I had a time machine that goes only to the past, I would go back to relive the moment I appreciate which is...\nDo you find yourself procrastinating when doing some important tasks? If yes, why do you think is that happening?\nIf you found out you have one more year to live, how would you spend it? Make a bucket list.\nIf you had 25h a day, what would you spend that one additional hour on?\nDescribe something that is time-consuming but worth doing in your opinion.\n\n3. Healing Our Brokenness\n\nMake the list of things in your life you find burdensome and think you should learn to let go in order to continue your journey through life unhindered.\nDescribe one mistake you\u2019ve made in your life that you managed to learn a lesson from?\nWhat can you do today to connect with your inner child?\nSit somewhere comfortable and in silence for 5 minutes and let your thoughts run free. What thoughts go through your mind?\nRemember the last thing that made you feel as happy as a child.\nWhat would your perfect place for meditation look like?\nWhat was the last thing that made you feel bad? Do you still feel bad about it?\nWhat is the one thing that lifts your spirit when you feel bad?\n\n4.Live in Freedom: Do not be Anxious with the Past nor the Future\n\nName the person you are grateful for knowing.\nWhat are your plans for today? Describe it in detail.\nWhat is your favorite place to visit when you have a day off?\nThink of any positive word that illustrates who you are today.\nWhat is the food you enjoy the most? Why not make it today?\nHow do you feel today?\nWhat are your favorite self-care activities? Dedicate at least half an hour to it today.\nLook outside the window. Describe what you see.\n\n5.Strive to Live a Transcendent Life\n\nWhat is the one thing you\u2019ve always wanted to do but didn\u2019t have the courage, strength, or time?\nHow would you rearrange your list of priorities?\nThink of one fear that you\u2019ve always wanted to overcome but didn\u2019t know how.\nWhat is the one new skill you would like to learn?\nWhat do you think your greatest weakness is? How can you turn it into a strength?\nAre you afraid to leave your comfort zone? Why?\nName one thing you would do if you were brave enough.\nWhat is the one thing you are proud to have done when many didn\u2019t believe in you?\n\n6.There is Hope in Everything; Have the Strength to Face the Trials in Life\n\nThink of the three things that inspire you to go forward. \nWho is your biggest support in life and why?\nThink of a situation in which you felt \u201cstuck\u201d. What was your light at the end of a tunnel that gave you hope?\nWhat makes you \u201cgo the extra mile\u201d?\nWhat is the one thing you didn\u2019t give up on despite numerous setbacks?\nWhat were you grateful for when you woke up today?\nWrite an encouragement letter to yourself from 5 years ago. Which advice would you give to that person?\n7.Self-Confidence and Humility are the Keys to Victory and Success in Life\n\nWhat is the best advice you\u2019ve been given that actually helped you reach your goal?\nDo you find it difficult to ask for help when you can\u2019t do something important by yourself? If yes, why?\nDo you find it difficult to accept help when someone offers it to you? If yes, why?\nDo you love the feeling like you\u2019re the smartest person in the room?\nName three things about yourself that you think you need to work on.\nWhich small failure led you to a bigger victory?\nDo you find it difficult to accept criticism?\n\n8.The Advantage of the Optimistic Mind\n\nWrite down three positive traits you think people admire you for.\nWhat is a nice thing that you did today?\nWhich situation in the past did you think of negatively but look at it through the lenses of optimism today?\nWhat cheers you up without fail? And what makes you laugh?\nWhat is the nicest compliment someone gave you? Describe how you felt at that moment.\nWho is the person that brings sunshine into your life? How did you two meet?\nName one thing you said \u201cyes\u201d to today.\nThink of one thing that was once a hard \u201cI can\u2019t\u201d, but with your effort became \u201cI can\u201d.\n\n9.A Self-Fulfilled Life is Tantamount to Happiness\n\nWhat is your favorite time-killing activity?\nDo you feel happy when you make someone else happy? What can you do today to make someone\u2019s day better?\nWhat things in life make you feel loved and cared for?\nSelf-development is important. What new things have you learned in the past two weeks?\nWhat is the place you would like to travel to? Imagine that you\u2019re packing your bags today and that tomorrow you\u2019ll be at your dream destination. Describe what you would do and what you would like to see.\nWhat can you do to bring more joy into your life?\nWrite down three things you love about yourself and would never change.\nWhich book that you read did you find the most inspiring so far?\n\n10.Attaining our Highest Potential\n\nDescribe a situation in which you felt like you came to the end of the road but soon realized that you can actually continue building it by yourself.\nA human being never stops learning. What will you learn next?\nWhich person encourages you to keep going forward no matter how hard it is?\nWhat is your ultimate dream you wouldn\u2019t give up on?\nWhat is your current goal in life?\nWhat did you do today that was one step closer to fulfilling your dream?\nDo you think that \u201cgiving your best\u201d is the best you can do?\n\n11.Equality Holds Peace and Justice\n\nWhat does equality mean to you?\nDid you have a situation in which you had a prejudice about someone? How did you overcome that situation?\nHow would you teach your children or grandchildren to treat other people equally and without prejudice?\nHave you ever faced discrimination yourself? If yes, how did you fight it?\nWhat can you do today to make this world a better place to live?\nWrite a letter of kindness you would give to a stranger.\nThink of a way you could help someone. What would you do?\n\n12.Forgiveness is the Most Effective Solution to the Unbearable Pains in Life\n\nHow important is to forgive?\nHow does forgiving impact our lives?\nDo you find it hard in your heart to forgive?\nWhat are the things you would like to forgive yourself?\nWhat are the things you would like other people to forgive you?\nDo you feel like you need to apologize to somebody for something? Tell them that.\nIs there anyone you would like to forgive something?\nHow does forgiveness make you feel, whether you are the one forgiving or being forgiven?\n13.Accountability is a Must; It Guides our Thoughts and Actions\n\nI am a reliable and responsible person because\u2026\nWhat was the last promise you made to someone that you managed to fulfill?\nWhy can other people trust you?\nDo you sometimes make a promise you probably won\u2019t fulfill?\nDescribe a situation in which your actions made people feel sad.\nWhat does sincerity mean in a relationship?\nDo you expect other people to be accountable as well if you are accountable to them?\n\n14.Life Is Long, It Is the Longest Thing We\u2019ll Ever Do.\n\nTake a moment to appreciate all the things you have accomplished so far in your life and all the challenges that wait for you to rise up to them.\nTell your loved ones how grateful you are that they are part of your life. Can you remember how you met?\nMay it be just a little thing or something more spectacular, have you thought of the way to \u201cleave a mark\u201d on this world?\nEmbrace assertiveness \u2013 don\u2019t always wait for your friends or family members to invite you to spend some time together. Instead, be the one who will ask that question \u2013 today \u2013 and appreciate the memories you create.\nDo you perhaps have a plan that you\u2019ve been calling off for some time now? If yes, your task for today will be to make at least one small step towards its realization.\nIf you had only 24 hours left, what would you do today that would make you happy?\n15.Today Is the First Day of Your Life\n\nIf you could once again enroll in college today, which one would you choose?\nLet\u2019s start learning a new skill today. What is it that you\u2019ve never tried before because you were too scared or didn\u2019t believe in yourself enough to do it?\nAsk a person close to you to spend a day together. Forget about all the fights you might have had in the past and all of the potential scenarios of your future life and live in the moment.\nWhat are the three things you CAN do today that will certainly make your day better?\nWhat are the things that have been causing you so much stress lately? Write them on a piece of paper and then throw them away in a garbage can. Let them stay there for today \u2013 clear your mind of the things you can\u2019t control.\nYOU are the director of the movie called \u201cMy Life\u201d! Think about all the scenes you plan on shooting today. Who will be the actors and what kind of scenography will you use?\nSummarize into a philosophy as if you were alan watss", "Please extract keywords from this: Part 1\nIt was morning, and the new sun sparkled gold across the ripples of a gentle sea. \nA mile from shore a fishing boat chummed the water, and the word for Breakfast Flock flashed through the air, till a crowd of a thousand seagulls came to dodge and fight for bits of food. It was another busy day beginning. \n But way off alone, out by himself beyond boat and shore, Jonathan Livingston Seagull was practicing. A hundred feet in the sky he lowered his webbed feet, lifted his beak, and strained to hold a painful hard twisted curve through his wings. The curve meant that he would fly slowly, and now he slowed until the wind was a whisper in his face, until the ocean stood still beneath him. He narrowed his eyes in fierce concentration, held his breath, forced one ... single ... more ... inch ... of ... curve .... Then his feathers ruffled, he stalled and fell. \n Seagulls, as you know, never falter, never stall. To stall in the air is for them disgraced and it is dishonor. \n But Jonathan Livingston Seagull, unashamed, stretching his wings again in that trembling hard curve - slowing, slowing, and stalling once more - was no ordinary bird. \n Most gulls didn't bother to learn more than the simplest facts of flight \u00adhow to get from shore to food and back again. For most gulls, it is not flying that matters, but eating. For this gull, through, it was not eating that mattered, but flight. More than anything else, Jonathan Livingston Seagull loved to fly. \n This kind of thinking, he found, is not the way to make one's self popular with other birds. Even his parents were dismayed as Jonathan spent whole days alone, making hundreds of low-level glides, experimenting. \n He didn't know why, for instance, but when he flew at altitudes less than half his wingspan above the water, he could stay in the air longer, with less effort. His glides ended not with the usual feet-down splash into the sea, but with a long flat wake as he touched the surface with his feet tightly streamlined against his body. When he began sliding in to feet-up landings on the beach, then pacing the length of his slide in the sand, his parents were very much dismayed indeed. \nWhy, Jon, why?\" his mother asked. \"Why is it so hard to be like the rest of the flock, Jon? Why can't you leave low flying to the pelicans, the albatross? \n\"I don't mind being bone and feathers, Mum. I just want to know what I can do in the air and what I can't, that's all. I just want to know.\" \n\"See here, Jonathan,\" said his father, not unkindly. \"Winter isn't far away. Boats will be few, and the surface fish will be swimming deep. If you must study,. then study food, and how to get it. This flying business is all very well, but you can't eat a glide, you know. Don't you forget that the reason you fly is to eat.\"\n Jonathan nodded obediently. For the next few days he tried to be behave like the other gulls; he really tried, screeching and fighting with the flock around the piers and fishing boats, diving on scraps of fish and bread. But he couldn't make it work. \nIt's all so pointless, he thought, deliberately dropping a hard-won anchovy to a hungry old gull chasing him. I could be spending all this time learning to fly. There's so much to learn! \nIt wasn't long before Jonathan Gull was off by himself again, far out at see, hungry, happy, learning. \n The subject was speed, and in a week's practice he learned more about speed than the fastest gull alive. \n From a thousand feet, flapping his wings as hard as he could, he pushed over into a blazing steep dive toward the waves, and learned why seagulls don't make blazing steep power-dives. In just six seconds he was moving seventy miles per hour, the speed at which one's wing goes unstable on the upstroke. \n Time after time it happened. Careful as he was, working at the very peak of his ability, he lost control at high speed. \n Climb to a thousand feet. Full power straight ahead first, then push over, flapping, to a vertical dive. Then, every time, his left wing stalled on an upstroke, he'd roll violently left, stall his right wing recovering, and flick like fire into a wild tumbling spin to the right. \n He couldn't be careful enough on that upstroke. Ten times he tried, but all ten times, as he passed through seventy miles per hour, he burst into a churning mass of feathers, out of control, crashing down into the water. \n They key, he thought as last, dripping wet, must be to hold the wings still \n From two thousand feet he tried again, rolling into his dive, beak straight down, wings full out and stable from the moment he passed fifty miles per hour. It took tremendous strength, but it worked. In ten seconds he has blurred through ninety miles per hour. Jonathan had set a world speed record for seagulls!\n But victory was short-lived. The instant he began his pullout, the instant he changed the angle of his wings, he snapped into that same terrible uncontrolled disaster, and at ninety miles per hour it hit him like dynamite. Jonathan Seagull exploded in midair and smashed down into a brick-hard sea. \n When he came to, it was well after dark, and he floated in moonlight on the surface of the ocean. His wings were ragged bars of lead, but the weight of failure was even heavier on his back. He wished, feebly, that the weight could be just enough to drag him gently down to the bottom, and end it all. \n As he sank low in the water, a strange hollow voice sounded within him. There's no way around it. I am a seagull. I am limited by my nature. If I were meant to learn so much about flying, I'd have a falcon's short wings, and live on mice instead of fish. My father was right. I must forget this foolishness. I must fly home to the Flock and be content as I am, as a poor limited seagull. \n The voice faded, and Jonathan agreed. The place for a seagull at night is on shore, and from this moment forth, he vowed, he would be a normal gull. It would make everyone happier. \n He pushed wearily away from the dark water and flew toward the land, grateful for what he had learned about work-saving low-altitude flying. \n But no, he thought. I am done with the way I was, I am done with everything I learned. I am a seagull like every other seagull, and I will fly like one. So he climbed painfully to a hundred feet and flapped his wings harder, pressing for shore. \n He felt better for his decision to be just another one of the flock. there would be no ties now to the force that had driven him to learn, there would be no more challenge and no more failure. And it was pretty, just to stop thinking, and fly through the dark, toward the lights above the beach. \nDark! The hollow voice cracked in alarm. Seagulls never fly in the dark!\n Jonathan was not alert enough to listen. It's pretty, he thought. The moon and the lights twinkling on the water, throwing out little beacon-trails though the \n Get Down! Seagulls never fly in the dark! If you were meant to fly in the dark, you'd have the eyes f an owl! You'd have charts for brains! You'd have a falcon's short wings!\n There in the night, a hundred feet in the air, Jonathan Livingston Seagull \u00adblinked. His pain, his resolutions, vanished. \n Short Wings. A falcon's short wings!\n That's the answer! What a fool I've been! All I need is a tiny little wing, all I need is to fold most of my wings and fly on just the tips alone! Short wings!\n He climbed two thousand feet above the black sea, and without a moment for thought of failure and death, he brought his forewings tightly in to his body, left only the narrow swept daggers of his wingtips extended into the wind, and fell into a vertical dive. \n The wind was a monster roar at his head. Seventy miles per hour, ninety, a hundred and twenty and faster still. The wing-strain now at a hundred and forty miles per hour wasn't nearly as hard as it had been before at seventy, and with the faintest twist of his wingtips he eased out of the dive and shot above the waves, a grey cannonball under the moon. \n He closed his eyes to slits against the wind and rejoiced. A hundred forty miles per hour! and under control! If I dive from five thousand feet instead of two thousand, I wonder how fast... \n His vows of a moment before were forgotten, swept away in that great swift wind. Yet he felt guiltless, breaking the promises he had made himself. Such promises are only for the gulls that accept the ordinary. One who has touched excellence in his learning has no need of that kind of promise. \n By sunup, Jonathan Gull was practicing again. From five thousand feet the fishing boats were specks in the flat blue water, Breakfast Flock was a faint cloud of dust motes, circling. \n He was alive, trembling ever so slightly with delight, proud that his fear was under control. Then without ceremony he hugged in his forewings, extended his short, angled wingtips, and plunged directly toward the sea. By the time he had passed four thousand feet he had reached terminal velocity, the wind was a solid beating wall of sound against which he could move no faster. He was flying now straight down, at two hundred fourteen miles per hour. He swallowed, knowing that if his wings unfolded at that speed he'd be blown into a million tiny shreds of seagull. But the speed was power, and the", "Please extract keywords from this, in a bulleted list: As simply and as quickly as that, Kirk Maynard Gull spread his wings, effortlessly, and lifted into the dark night air. The Flock was roused from sleep by his cry, as loud as he could scream it, from five hundred feet up; \"I can fly! Listen! I CAN FLY!\"\n By sunrise there were nearly a thousand birds standing outside the circle of students, looking curiously at Maynard. They don't care whether they were seen or not, and they listened, trying to understand Jonathan Seagull. \n He spoke of very simple things - that it is right for a gull to fly, that freedom is the very nature of his being, that whatever stands against that freedom must be set aside, be it ritual or superstition or limitation in any form. \n\"Set aside,\" came a voice from the multitude, \"even if it be the Law of the Flock?\" \n\"The only true law is that which leads to freedom,\" Jonathan said. \"There is no other.\" \n\"How do you expect us to fly as you fly?\" came another voice. \"You are special and gifted and divine, above other birds.\" \n\"Look at Fletcher! Lowell! Charles-Roland! Are they also special and gifted and divine? No more than you are, no more than I am. The only difference, the very only one, is that they have begun to understand what they really are and have begun to practice it.\"\n His students, save Fletcher, shifted uneasily. They hadn't realized that this was what they were doing. \n the crowd grew larger every day, coming to question, to idolize, to scorn. \n\"They are saying in the Flock that if you are not the Son of the Great Gull Himself,\" Fletcher told Jonathan one morning after the Advanced Speed \n Jonathan sighed. The price of being misunderstood, he thought. They call you devil or they call you god. \"What do you think, Fletch? Are we ahead of our time?\"\n A long silence. \"Well, this kind of flying has always been here to be learned by anybody who wanted to discover it; that's got nothing to do with time. We're ahead of the fashion, maybe. Ahead of the way that most gulls fly.\" \n\"That's something,\" Jonathan said, rolling to glide inverted for a while. \"That's not half as bad as being ahead of our time.\" \nIt happened just a week later. Fletcher was demonstrating the elements of high-speed flying to a class of new students. He had just pulled out of his dive from seven thousand feet, a long grey streak firing a few inches above the beach, when a young bird on its first flight glided directly into his path, calling for its mother. With a tenth of a second to avoid the youngster, Fletcher Lynd Seagull snapped hard to the left, at something over two hundred miles per hour, into a cliff of solid granite. \nIt was, for him, as though the rock were a giant hard door into another world. A burst of fear and shock and black as he hit, and then he was adrift in a strange sky, forgetting, remembering, forgetting; afraid and sad and sorry, terribly sorry. \n The voice came to him as it had in the first day that he had met Jonathan Livingston Seagull. \n\"The trick, Fletcher, is that we are trying to overcome our limitations in order, patiently. We don't tackle flying through rock until a little later in the program.\" \n\"Jonathan!\" \n\"Also known as the Son of the Great Gull,\" his instructor said dryly. \n\"What are you doing here? The cliff! Haven't . I . . . didn't I . . . die?\" \n\"Oh, Fletch, come on. Think. If you are talking to me now, then obviously you didn't die, did you? What you did manage to do was to change your level of consciousness rather abruptly. It's your choice now. You can stay here and learn on this level - which is quite a bit higher than the one you left, by the way -or you can go back and keep working with the Flock. The Elders were hoping for some kind of disaster, but they're startled that you obliged them so \n\"I want to go back to the Flock, of course. I've barely begun with the new group!\" \n\"Very well, Fletcher. Remember what we were saying about one's body being nothing more than thought itself . . . ?\"\n Fletcher shook his head and stretched his wings and opened his eyes at the base of the cliff, in the center of the whole Flock assembled. There was a great clamor of squawks and screes from the crowd when first he moved. \n\"He lives! He that was dead lives!\" \n\"Touched him with a wingtip! Brought him to life! The Son of the Great Gull!\" \n\"NO! He denies it! He's a devil! DEVIL! Come to break the Flock!\"\n There were four thousand gulls in the crowd, frightened at what had happened, and the cry DEVIL! went through them like the wind of an ocean storm. Eyes glazed, beaks sharp, they closed in to destroy. \n\"Would you feel better if we left, Fletcher?\" asked Jonathan. \n\"I certainly wouldn't object too much if we did . . . \" \nInstantly they stood together a half-mile away, and the flashing breaks of the mob closed on empty air. \n\"Why is it, \" Jonathan puzzled, \"that the hardest thing in the world is to convince a bird that he is free, and that he can prove it for himself if he'd just spend a little time practicing? Why should that be so hard?\"\n Fletcher still blinked from the change of scene. \"What did you just do? How did we get here?\" \n\"You did say you wanted to be out of the mob, didn't you?\" \nYes! But how did you . . .\" \n\"Like everything else, Fletcher. Practice\"\n By morning, the Flock had forgotten its insanity, but Fletcher had not. \n\"Jonathan, remember what you said a long time ago, about loving the Flock \n\"Yes!\" \n\"I don't understand how you manage to love a mob of birds that has just tried to kill you.\" \n\"Oh, Fletch, you don't love that! You don't love hatred and evil, of course. You have to practice and see the real gull, the good in everyone of them, and to help them see it in themselves. That's what I mean by love. It's fun, when you get the knack of it. \n \"I remember a fierce young bird, for instance, Fletcher Lynd Seagull, his name. Just been made Outcast, ready to fight the Flock to the death, getting a start on building his own bitter hell out on the Far Cliffs. And here he is today building his own heaven instead, and leading the whole Flock in that direction.\"\n Fletcher turned to his instructor, and there was a moment of fright in his eye. \"Me leading? What do you mean, me leading? You're the instructor here. You couldn't leave!\" \n\"Couldn't I? Don't you think that there might be other flocks, other Fletchers, that need an instructor more than this one, that's on its way toward the light?\" \n\"Me? Jon, I'm just a plain seagull, and you're . . .\" \n\". . . the only Son of the Great Gull, I suppose?\" Johnathan sighed and looked out to sea. \"You don't need me any longer.. You need to keep finding yourself, a little more each day, that real, unlimited Fletcher Seagull. he's your instructor. You need to understand him and to practice him.\"\n A moment later Jonathan's body wavered in the air, shimmering, and began to go transparent. \"Don't let them spread silly rumors about me, or make me a god. O.K., Fletch? I'm a seagull, I like to fly, maybe . . .\" \n\"JONATHAN!\" \n\"Poor Fletch. Don't believe what your eyes are telling you. All they show is limitation. Look with your understanding, find out what you already know, and you\u2019ll see the way to fly.\"\n The shimmering stopped. Jonathan Seagull had vanished into empty air. \n After a time, Fletcher Gull dragged himself into the sky and faced a brand\u00ad\n\"To begin with,\" he said heavily, \"you've got to understand that a seagull is an unlimited idea of freedom, an image of the Great Gull, and your whole body, from wingtip to wingtip, is nothing more than your though itself.\"\n The young gulls looked at him quizzically. Come on, they thought, this doesn't sound like a rule for a loop. \n Fletcher sighed and started over. \"Hm. Ah . . very well,\" he said, and eyed them critically. \"Let's begin with Level Flight.\" And saying that, he understood all at once that his friend had quite honestly been no more divine than Fletcher himself. \n No limits, Jonathan? he thought. Well, then, the time's not distant when I'm going to appear out of thin air on your beach, and show you a thing or two about flying!\n And though he tried to look properly severe for his students, Fletcher Seagull suddenly saw them all as they really were, just for a moment, and he more than liked, he loved what it was he saw. No limits, Jonathan? he thought, and he smiled. His race to learn had begun.", "Summarize this section for me:\n\nSEC. 7. RESOLUTION OF DISAPPROVAL OF DESIGNATION OR REMOVAL OF \n DESIGNATION OF A FOREIGN ADVERSARY.\n\n (a) Definition.--In this section--\n (1) the term ``covered joint resolution'' means a joint \n resolution of disapproval of designation or a joint resolution \n of disapproval of removal of designation;\n (2) the term ``joint resolution of disapproval of \n designation'' means a joint resolution the matter after the \n resolving clause of which is as follows: ``That Congress \n disapproves the designation by the Secretary of Commerce of \\_\\_\\_ \n as a foreign adversary for purposes of the Securing the \n Information and Communications Technology and Services Supply \n Chain Act of 2023, and such designation shall have no force or \n effect until the Secretary of Commerce provides specific \n evidence to the relevant committees of Congress regarding the \n removal of designation under section 6(a) of that Act.'' (The \n blank space being appropriately filled in with the name of the \n foreign person of which the Secretary has designated as a \n foreign adversary of for purposes of this Act); and\n (3) the term ``joint resolution of disapproval of removal \n of designation'' means a joint resolution the matter after the \n resolving clause of which is as follows: ``That Congress \n disapproves the removal of designation by the Secretary of \n Commerce of \\_\\_\\_ as a foreign adversary for purposes of the \n Securing the Information and Communications Technology and \n Services Supply Chain Act of 2023, and such removal shall have \n no force or effect until the Secretary of Commerce provides \n specific evidence to the relevant committees of Congress \n regarding the removal of designation under section 6(a) of that \n Act.'' (The blank space being appropriately filled in with the \n name of the foreign government or regime of which the Secretary \n has removed the designation as a foreign adversary of for \n purposes of this Act).\n (b) Expedited Consideration of Legislation.--\n (1) Initiation.--In the event the Secretary designates a \n foreign government or regime as a foreign adversary or removes \n such designation as a foreign adversary, a joint resolution of \n disapproval of designation or a joint resolution of disapproval \n of removal of designation, as applicable, that is introduced \n during the 60-calendar day period thereafter shall be entitled \n to expedited consideration pursuant to this subsection.\n (2) Introduction.--During the 60-calendar day period \n provided for in paragraph (1), a covered joint resolution may \n be introduced--\n (A) in the Senate, by the Majority Leader (or the \n designee of the Majority Leader) or the Minority Leader \n (or the designee of the Minority Leader); and\n (B) in the House of Representatives, by the Speaker \n or the Minority Leader.\n (3) Floor consideration in house of representatives.--\n (A) Reporting and discharge.--If a relevant \n committee of the House to which a covered joint \n resolution has been referred has not reported such \n covered joint resolution within 10 legislative days \n after the date of referral, that committee shall be \n discharged from further consideration thereof.\n (B) Proceeding to consideration.--Beginning on the \n third legislative day after each committee to which \n covered joint resolution has been referred reports the \n covered joint resolution to the House or has been \n discharged from further consideration thereof, it shall \n be in order to move to proceed to consider the covered \n joint resolution in the House. All points of order \n against the motion are waived. Such a motion shall not \n be in order after the House has disposed of a motion to \n proceed on the covered joint resolution with regard to \n the same agreement. The previous question shall be \n considered as ordered on the motion to its adoption \n without intervening motion. The motion shall not be \n debatable. A motion to reconsider the vote by which the \n motion is disposed of shall not be in order.\n (C) Consideration.--The covered joint resolution \n shall be considered as read. All points of order \n against the covered joint resolution and against its \n consideration are waived. The previous question shall \n be considered as ordered on the covered joint \n resolution to final passage without intervening motion \n except 2 hours of debate equally divided and controlled \n by the sponsor of the covered joint resolution (or a \n designee) and an opponent. A motion to reconsider the \n vote on passage of the covered joint resolution shall \n not be in order.\n (4) Consideration in the senate.--\n (A) Committee referral.--A covered joint resolution \n introduced in the Senate shall be referred to the \n relevant committees of the Senate.\n (B) Reporting and discharge.--If a relevant \n committee of the Senate has not reported such covered \n joint resolution within 10 session days after the date \n of referral of such legislation, that committee shall \n be discharged from further consideration of such \n legislation and the covered joint resolution shall be \n placed on the appropriate calendar.\n (C) Proceeding to consideration.--Notwithstanding \n Rule XXII of the Standing Rules of the Senate, it is in \n order at any time after each committee authorized to \n consider covered joint resolution reports it to the \n Senate or has been discharged from its consideration \n (even though a previous motion to the same effect has \n been disagreed to) to move to proceed to the \n consideration of the covered joint resolution, and all \n points of order against covered joint resolution (and \n against consideration of the covered joint resolution) \n are waived. The motion to proceed is not debatable. The \n motion is not subject to a motion to postpone. A motion \n to reconsider the vote by which the motion is agreed to \n or disagreed to shall not be in order. If a motion to \n proceed to the consideration of the covered joint \n resolution is agreed to, the covered joint resolution \n shall remain the unfinished business until disposed of.\n (D) Debate.--Debate on covered joint resolution, \n and on all debatable motions and appeals in connection \n therewith, shall be limited to not more than 10 hours, \n which shall be divided equally between the majority and \n minority leaders or their designees. A motion to \n further limit debate is in order and not debatable. An \n amendment to, or a motion to postpone, or a motion to \n proceed to the consideration of other business, or a \n motion to recommit the covered joint resolution is not \n in order.\n (E) Vote on passage.--The vote on passage shall \n occur immediately following the conclusion of the \n debate on the covered joint resolution and a single \n quorum call at the conclusion of the debate, if \n requested in accordance with the rules of the Senate.\n (F) Rulings of the chair on procedure.--Appeals \n from the decisions of the Chair relating to the \n application of the rules of the Senate, as the case may \n be, to the procedure relating to a covered joint \n resolution shall be decided without debate.\n (G) Consideration of veto messages.--Debate in the \n Senate of any veto message with respect to a covered \n joint resolution, including all debatable motions and \n appeals in connection with such covered joint \n resolution, shall be limited to 10 hours, to be equally \n divided between, and controlled by, the Majority Leader \n and the Minority Leader or their designees.\n (5) Rules relating to senate and house of \n representatives.--\n (A) Coordination with action by other house.--If, \n before the passage by one House of a covered joint \n resolution of that House, that House receives a covered \n joint resolution from the other House, then the \n following procedures shall apply:\n (i) The covered joint resolution of the \n other House shall not be referred to a \n committee.\n (ii) With respect to covered joint \n resolution of the House receiving the \n legislation--\n (I) the procedure in that House \n shall be the same as if no covered \n joint resolution had been received from \n the other House; but\n (II) the vote on passage shall be \n on the covered joint resolution of the \n other House.\n (B) Treatment of a covered joint resolution of \n other house.--If one House fails to introduce a covered \n joint resolution under this section, the covered joint \n resolution of the other House shall be entitled to \n expedited floor procedures under this section.\n (C) Treatment of companion measures.--If, following \n passage of the covered joint resolution in the Senate, \n the Senate then receives a companion measure from the \n House of Representatives, the companion measure shall \n not be debatable.\n (c) Rules of Senate and House of Representatives.--Subsection (b) \nis enacted by Congress--\n (1) as an exercise of the rulemaking power of the Senate \n and the House of Representatives, respectively, and as such are \n deemed a part of the rules of each House, respectively, but \n applicable only with respect to the procedure to be followed in \n that House in the case of legislation described in those \n sections, and supersede other rules only to the extent that \n they are inconsistent with such rules; and\n (2) with full recognition of the constitutional right of \n either House to change the rules (so far as relating to the \n procedure of that House) at any time, in the same manner, and \n to the same extent as in the case of any other rule of that \n House.\n (d) Effect of Covered Joint Resolution.--\n (1) Joint resolutions of disapproval of designation.--A \n joint resolution of disapproval of designation that is enacted \n in accordance with this section shall remove the designation as \n a foreign adversary of a foreign government or regime that is \n the subject of the joint resolution of disapproval of \n designation for purposes of this Act.\n (2) Joint resolutions of disapproval of removal of \n designation.--A joint resolution of disapproval of removal of \n designation that is enacted in accordance with this section \n shall prohibit the removal of designation as a foreign \n adversary of a foreign government or regime that is the subject \n of the joint resolution of disapproval of removal of \n designation for purposes of this Act.1 / 1", "[If I had to pick the most important of resources to lead you through a successful capital campaign, it would be the gift range chart. You may also know it as a gift table.\n\nIn this post, you\u2019ll learn the basics of Gift Range Charts and discover the related tools that will help create a plan for your campaign.\n\nQuick Links \u2014 Click on any of the links below to jump ahead and learn the essentials about Gift Range Charts:\n\nCapital Campaign Gift Range Chart: An Overview\nCreating Your Capital Campaign Gift Range Chart\nGoing Beyond the Gift Range Chart\nTools to Create Your Capital Campaign Gift Range Chart\nConclusion: Making Sense of Your Campaign\nRead on and learn about how Gift Range Charts (also known as gift tables) are created and used.\n\nAlready know you want hands-on guidance developing your gift range chart? Request a free strategy session today!\n\nCapital Campaign Gift Range Chart: An Overview\n\nCapital Campaign Gift Range Chart: An Overview\nIf you\u2019ve been through a capital campaign before, you are likely familiar with this important tool. If you use this tool correctly, you\u2019ll be well on your way to leading a successful campaign.\n\nWHAT IS A GIFT RANGE CHART?\nA Gift Range Chart provides a framework for the number of gifts, at each gift amount, that you\u2019ll need for a successful campaign.\n\nThe Gift Range Chart is the primary tool for your campaign because it will clarify your campaign goal and help you determine your chances for success at a specific goal amount. But the right Gift Range Chart for your campaign will become the backbone of your campaign in many other ways as well.\n\nA Gift Range Chart will enable you to:\n\nSort your donors by ask amounts\nEstablish the pattern of gifts you\u2019ll need for your campaign\nCreate a strategic order for soliciting gifts\nProvide a logical approach to quantifying the number of prospects you\u2019ll need for your campaign\nHelp your board understand what campaign success is going to take\nShow your top donors where their gifts will fit into the campaign\nTrack and report on your campaign progress\nDevelop a rational plan for donor communication, recognition and naming opportunities\nSAMPLE GIFT RANGE CHART\nYou\u2019ll find several tools to help create your Gift Range Chart in the \u201cPre-Campaign Planning\u201d section of the Capital Campaign Toolkit. Here\u2019s a sample Gift Range Chart to use as a reference:\n\nSample Gift Range Chart for a Capital Campaign\n\nCreating Your Capital Campaign Gift Range Chart\n\nCreating Your Capital Campaign Gift Range Chart\nIn the sample Gift Range Chart in the preceding section, you can see that the top gift is 20% of the campaign goal. And, the first seven gifts take you to $1.4 million \u2014 more than halfway toward the goal.\n\nThe top group of 15 gifts take you to $1.8 million, or 72% \u2014 nearly three-quarters of the way to the campaign goal.\n\nThis pattern, showing a few gifts accounting for a large proportion of the campaign goal, is common for capital campaigns. In most campaigns, the top gift is 20% or 25% of the campaign goal. In some cases, it\u2019s even higher. In fact, only 10 gifts account for at least half the goal in the vast majority of capital campaigns.\n\nOn the other hand, you can see that the remaining gifts \u2014 those of $25,000 or less account for less than 30% of the goal.\n\nOf course, the amounts on this chart are for example only. One standard pattern does not work for every campaign. Your Gift Range Chart will have to reflect the size of your donor base. The smaller your donor base, the larger the gifts in the top of the chart will have to be.\n\n7 TIPS TO CREATE YOUR GIFT RANGE CHART\nHere are seven tips that will help you create a Gift Range Chart for your organization.\n\nBuild your gift chart by starting with the top gift which should be at least 20% of your campaign goal.\nThen work down, increasing the number of gifts as the size of the gifts goes down.\nThe number of gifts in the first column should increase in a rational pattern as the size of the gifts decreases.\nThe gift amounts should be simple and standard to reflect a generic pattern rather than specific gifts you may already have in.\nYou will need 2, 3 or even 4 times the number of prospects than the number of gifts. The prospect multiplier depends on how well you know your donors.\nThe total number of prospects you show in your chart should be no larger than the number of qualified prospects you have in your donor base.\nIf when you get to the bottom of your chart, you find that you need more prospects than you have, go to the top and increase the number of gifts at the top.\nWant one-on-one guidance to help create your campaign\u2019s gift range chart? Just reach out\u2014we\u2019ll be happy to help!\n\nGoing Beyond the Gift Range Chart\n\nGoing Beyond the Gift Range Chart\nThe Gift Range Chart will serve as a roadmap for your campaign. You will use a Depth Chart to add prospect names to each giving level you have decided on in your Gift Range Chart.\n\nFROM GIFT RANGE CHART TO DEPTH CHART\nOnce you\u2019ve created a Gift Range Chart for your campaign, you\u2019ll develop a \u201cDepth Chart\u201d which will attach specific prospective donor names to each gift required for a successful campaign.\n\nSimply take each of the top giving levels and use them as column headers. In each header, indicate how many gifts you will need at that level and how many prospects that will require:\n\nCapital Campaign Depth Chart\n\nNext, start filling out the names of people you can credibly ask for a gift at that level for your campaign. Sorting your donors into columns is done by evaluating their current giving, their potential to give, and their likely inclination.\n\nAs you fill out the Depth Chart, you will clearly see where you have enough qualified prospective donors and where you fall short. If you don\u2019t have any prospect names for the top three levels, you probably need to go back to the drawing board and reduce your campaign goal.\n\nOnce your depth chart has been filled in, you will use it to organize the order of solicitation. You\u2019ll prioritize the top donors to solicit first and then gradually work down to the smaller gifts as laid out on the depth chart.\n\nUSING THE GIFT RANGE CHART TO SOLICIT GIFTS\nOnce you have your depth chart and you start talking to your donors about making gifts to the campaign, you will once again find the gift range chart to be helpful. You should always include a copy of the gift range chart in the materials you take to your donors. When you show it to them, they will be able to see where they might fit in the community of donors. While a donor\u2019s ability to make a gift is important, most donors like to know where their gift fits.\n\nSome donors want to be lead donors. And your chart will show them what that gift would be. Others might not want to be the lead donor but would like to make a significant gift to the campaign. Again, looking at the gift range chart will help them understand the range of giving and where they might place themselves in the community of donors.\n\nTRACKING CAMPAIGN PROGRESS WITH THE GIFT RANGE CHART\nGift range charts have a way of making the essence of a capital campaign clear. So, as gifts come in, you will check them off on your gift range chart. Gradually, as your campaign moves forward, you will see graphically, in a simple way, the progress your campaign is making and what gifts have yet to be committed. Your board members and executive staff will appreciate this very simple tracking devise. It\u2019ll give them a sense of confidence to see the top gifts fill in from the top down.\n\nTools to Create Your Capital Campaign Gift Range Chart\n\nTools to Create Your Capital Campaign Gift Range Chart\nThe sample Gift Range Chart in this post is one of a number of tools available in the Capital Campaign Toolkit\u2019s Pre-Campaign Planning section. Other tools include:\n\nGift Range Chart Calculator\nGift Range Chart Worksheet\nDepth Chart Worksheet\nOther related tools include a plan for your donor recognition guide based on the levels in your Gift Range Chart.\n\nIf you\u2019re eager to utilize these tools for your campaign, check out the different Toolkit options here. Most options include campaign advising, giving you professional support at a fraction the cost of a campaign consultant.\n\nVIDEO: GIFT RANGE CHARTS = YOUR MOST POWERFUL TOOL\nTo learn even more about creating a Gift Range Chart for your campaign, watch the following video (approximately 17 minutes):\nConclusion: Making Sense of Your Campaign\n\nConclusion: Making Sense of Your Campaign\nBecause capital campaigns go on for many months (or even years), you may find it easy to get confused about where you should be putting your efforts during the seven phases of the campaign.\n\nIf, however, you coordinate your campaign plan to a Gift Range Chart, then, when you\u2019re feeling lost, you\u2019ll know where to turn. You\u2019ll look at your chart to review which groups of donors have been solicited, as well as which are next up.\n\nYou may tie your staffing responsibilities to the donor levels of the Gift Range Chart. And you will certainly create a timetable for your campaign that prioritizes the work of the campaign according to giving level, starting with the largest gifts and working down.\n\nAnd even when considering how to thank and recognize donors, once you start thinking about it from the perspective of the giving levels in your Gift Range Chart, all of the planning will fall into place.\n\nA GIFT RANGE CHART MINIMIZES CONFUSION AND BUILDS CONFIDENCE\nWhen you organize your campaign based on a clear top-down strategy as mapped out in the Gift Range Chart, you will minimize confusion and build confidence in the campaign process.\n\nA Gift Range Chart may appear to be a simple planning devise, but when you use it as the essential structure for your campaign, you\u2019ll find that everything falls into place.\n\nHave more questions about capital campaigns or want one-on-one help crafting your strategy? Check out our complete FAQ guide or get in touch. We\u2019ll be happy to help!]\n\nCan you write an article using the content above called, \"What I wish orgs finished before the capital campaign\" include headers and subheaders and a few lists where needed, make it relatable and less than 750 words.", "Read this phone review in its entirety and then write me a blog section on the Xiaomi 13 Design Features and Build Quality:\n\nXiaomi 13 Full Review: The Art of Balance\nByPaco Zheng -Dec 20, 2022\nFacebookTwitterLinkedinReddIt\n\nBefore we start the unboxing, I will tell you the final conclusion right now: I love this phone. And the Xiaomi 13 Standard Edition is the most satisfying Xiaomi phone I\u2019ve ever had. For most people, it is also the best Xiaomi phone to buy. I even think it has more appeal than the Xiaomi 12S Ultra and 13 Pro.\n\nIf you\u2019re willing to listen to why I like the Xiaomi 13 so much, then I\u2019d be happy to tell you what\u2019s so great about it.\nDESIGN\nNow phones have been put in more and more stuff, the body has to be bigger and bigger. The largest regular phone has reached 7-inches, if you count the foldable phone then the number will be even like 8 inches. I often miss the old days when the phone could be controlled with one hand. When the mobile phone becomes no longer mobile, then more features also become meaningless. It\u2019s embarrassing to think that it\u2019s difficult to find a small-sized phone these days. It\u2019s especially hard when you\u2019re also trying to find a flagship small phone that doesn\u2019t have shortcomings. I\u2019ve put together the numbers of a few compact phones that look good right now, and blue one is their cons. It\u2019s easy to see that the Xiaomi 13 really has no shortcomings. It\u2019s a bigger phone than the other phones, even a little bigger than the Xiaomi 12. But it perfectly balances size and functionality. That\u2019s the main reason why I like the Xiaomi 13: phones that are better than it, aren\u2019t as small as it. Phones that are smaller than it, not as well as it.\nWhy would I choose white over blue vegan leather. Look at my Xiaomi 12S Ultra that I\u2019ve been using for less than six months. Maybe the footage isn\u2019t visible enough. The leather texture in the four corners has been smoothed out. If you don\u2019t want your phone to look like this, then get the glass version. Because of the small size and light weight, fingerprints are more downward, but does not affect the feel much when holding it.\n\nIn the unboxing video for the Xiaomi 13 series, some viewers guessed that it was still USB 2.0. Congratulations, you guessed right. This is the nightmare for Xiaomi users the whole life.\nLike you guys, I think the Xiaomi 13 must have referenced the iPhone and Samsung. You can say the Xiaomi is copycat, but I don\u2019t think it\u2019s ugly, I even think it\u2019s kind of pretty. Especially the screen. When you light up the screen, you can feel the beauty of it without me saying anything more. The screen, which is almost equal in width on all four sides, puts me in a happy mood every time I use the phone. If there is no front camera, I think it is the best looking screen in the world.\n\nSome people will ask: why don\u2019t you buy Samsung S22? Haha, see Snapdragon 8 Gen 1, do you think I still want to buy it? In addition to the excellent bezel width, other specs are also very powerful. This Samsung E6 panel ensures high brightness while DC dimming is not missing. Adaptive colors, or \u201cTrue Tone\u201d on the iPhone, are also available. Some people complain that the standard version doesn\u2019t have 2K resolution, but the Xiaomi 13 the display DPI is actually 414, which is sharper than most FHD+ phones. Using 2K resolution on a small phone can also bring down battery life, so the display is really good for just the right amount of time.\n\nPERFORMANCE & GAMING\nSnapdragon 8 Gen 2, LPDDR5X and UFS 4.0, the latest chips are of course there. The throttling test also shows that it can keep the performance stable for a long time, so it seems that the 8 Gen 2 has really improved a lot.\nSmaller phones are usually not very good at gaming because of their size limits. But the Xiaomi 13 is an exception. Maybe it\u2019s the new 8 Gen 2 that\u2019s so great, or maybe the cooling system is so nice. Anyway, it does well in Genshin Impact, running around Sumeru can\u2019t stress it out anymore. There were lags during the game, all caused by loading textures. To test how long it takes for Xiaomi 13 to overheat, I followed it up with 25 minutes on Spiral Abyss floor 12, and it still held up. Oh, and the frame drops in the middle were caused by loading, not lagging. The temperature after 45 minutes of intense gaming is also only 45\u00b0C.\n\nAll in all, it has no problem handling games. But I still don\u2019t recommend it for long term gaming, because the screen is really small. If you have big hands, it will be more difficult to play.\n\nCompared to the Pro version, the standard version seems to have a less surprising camera system. It does have an average camera performance, but because of this 75mm telephoto lens, it stands out from the crowd of small sized phones. The reason I used to have to use big and heavy flagship phones is that I love telephoto lenses. And most of my photography is taken with telephoto. Now that the Xiaomi 13 also has a 3.2x telephoto and is equipped with OIS, then I can use it with no worries. But don\u2019t get me wrong, I mean an extra telephoto will allow you to compose more angles compared to other compact phones. But the image quality is definitely not as good as flagship phones.\n\nWhen the light is bad, as long as you zoom in on the picture, there is very little detail and all are sharpening traces. Just like the S22, it really can\u2019t put a bigger sensor. So let\u2019s give it a pass.\n\nCAMERA\n\nCompared to the Xiaomi 12S, the 13\u2019s main camera is a step backwards. Although the sensor is smaller, the performance is not much of a step back. Most of the performance is okay, both day and night. I only have two complaints, one is the purple-fringing issue, which is not very well controlled. Another is that the color is a bit strange. Even though we were using the Leica Vibrant mode, the colors were always very dull. The too-intense colors look even worse in the samples taken on cloudy days. These two problems are even worse on the ultra-wide camera. So I\u2019m actually not satisfied with the ultra-wide camera.\n\nBut then again, if I am given two options, a telephoto plus a good main camera, or a very good main camera plus a macro lens, I would definitely choose the former. Users of smaller phones must know what they need, because most of the time they are not able to have both.\n\nYou should not expect anything from the Xiaomi phone front camera. Except for the Civi series, they all perform pretty much the same. Although the photos look good and rich in detail. But the video performance is really not good. Not only is the 4k resolution missing, but it doesn\u2019t even support 60fps. If you pay more attention to the recording of the front camera, then we recommend you to buy other phones.\n\nAll three lenses support different recording specs. The main camera supports up to 8k 24fps and OIS+EIS. the footage also looks the best, stable and clear. The ultra-wide camera supports up to 4k 30fps, which is also good. But the picture does not look so clear. The telephoto camera supports up to 1080P 60fps. only in 1080P 30fps can switch the lens during recording.\n\nBATTERY & CHARGING\n\n67w fast charging and 4500mAh battery, does it sound familiar? Yes, this classic combination is once again found in the Xiaomi 13. I have no complaints about the charging power, 67w is also fast and there is also 50w wireless charging. Plugged in and fully charged in just 41 minutes.\n\n4500mAh is big for a phone of this size, and in actual use it feels about the same as my 12S Ultra, which lasts 5 to 6 hours. Because of the new processor being more power efficient and the smaller screen, it already lasts about the same amount of time as many 6.8 inch phones. One less factor to stop you from buying a smaller phone, isn\u2019t it?\nAfter a few days of use, MIUI 14 has no lags or bugs. Their claim of improving the smoothness of the new system seems to be working so far. No matter how fast your operation is, it doesn\u2019t lag. I don\u2019t know if older Xiaomi phones will be smoother with the MIUI 14 upgrade, but at least with my Xiaomi 13, MIUI 14 is definitely smooth enough.\n\nThere are relatively few new features in 14, one of which is the new icon customization feature. Some icons can change shape, but some can\u2019t. The new folders also open the applications inside of it from the outside. Obviously, MIUI 14 also borrows some features from other systems. But it doesn\u2019t matter to consumers, as long as it works, it\u2019s fine. The biggest upgrade of MIUI 14 should still be this: you can delete most of the system applications. Those apps that you never use can finally be uninstalled. Even the album, weather, can be uninstalled. You can keep only 8 apps, it\u2019s very crazy for MIUI.\nWhen Xiaomi 13 was released, I was very happy because Xiaomi almost created my dream phone. It fits my hand perfectly and didn\u2019t lose important features. Especially the screen, until the S23 was released, I thought the Xiaomi 13 was the best small size flagship in Android. I will also keep my SIM card in this phone all the time, waiting for the next phone to come along that will fascinate me so much.\n\nTAGSXiaomiXiaomi 13Xiaomi 13 Pro", "I sent this letter:\"You will be receiving a letter from my solicitors in due course. But given the disingenuous approach in your last email to the interpretation of Supreem's previous communications, I will clarify a few points in the meantime (without prejudice to, and reserving, any other rights or remedies Supreem or I may have against you, Miescher, and its directors).\n\nFirst, as a result of receiving your email, I instructed lawyers to undertake a search in respect of Miescher on Companies House. I have since been advised that you and your co-directors, Iain Cox and Alexis Woodhead, applied on 30 August 2022 for Miescher to be dissolved.\n\nThis paints our negotiations over the last month in a new, and sinister, light: following its dissolution, Miescher obviously could not deliver on your own offer of 11 October 2022 for Miescher to repay Supreem its investment of US $50,000 (a clear admission of the debt by you and Miescher) nor could it perform the settlement agreement we have been negotiating over the last few weeks. The unavoidable inference is that you have conducted our settlement negotiations dishonestly and in bad faith, all the while secretly seeking to have Miescher dissolved before Supreem could bring proceedings to recover its money. You will be unsurprised to learn that we are objecting to the dissolution of Miescher given the debt that is undisputedly owed to Supreem.\n\nThe application for dissolution also paints your last email in a new light: by that email you have purported to convert the Notes into a company that you have applied to dissolve. Your intention to defraud Supreem as a creditor could not be clearer.\n\nYour failure to notify Supreem of your intention to apply to dissolve Miescher is also a criminal offence. You and your fellow directors were required by section 1006 of the Companies Act 2006 to send a copy of the application to dissolve to Supreem (as an undoubted creditor of the company) within seven days of making the application. You patently failed to do so (and our emails to date show that you personally knew perfectly well that Supreem was a creditor of the company). The reason you failed to do so is also clear: you sought to conceal the application in the hopes that this would somehow preclude Supreem from ultimately obtaining redress. Supreem will, of course, be reporting all criminal offences to the relevant authorities.\n\nSecond, your attempt to somehow treat Supreem's withdrawal from settlement discussions as an election to accept shares is disingenuous, misguided and, to be frank, clumsy. Nothing I or Supreem has said can be fairly read as agreeing to conversion. To make Supreem's position crystal clear: Miescher is not entitled to convert any of the Notes into shares. The Convertible Loan Note Instrument (the Instrument) clearly sets out the circumstances in which a conversion may happen and none of those circumstances apply. To the contrary, it must follow from your application for dissolution that:\nthere was 'an effective resolution[was] passed, for the[...] dissolution of the Company' (within the meaning of Sch. 2, Pt. 1, clause 5.1(b) of the Instrument) on 30 August 2022; and/or\n'the Company[...] stop[ped] (or threaten[ed] to stop) payment of its debts generally or cease[d] (or threaten[ed] to cease) to carry on its business or a substantial part of its business' (within the meaning of Sch. 2, Pt. 1, clause 5.1(d) of the Instrument) at least as early as 30 August 2022 (and in all probability long before this).\nBoth of these were Events of Default within the meaning of the Instrument such that interest began to run immediately at a rate of 8% per annum. Miescher is in flagrant breach of its obligation under Sch. 2, Pt. 1, clause 6.1 of the Instrument to give notice to Supreem of these Events of Default.\n\nThird, as you are fully aware, before we signed the Instrument, you / Miescher represented to me and Supreem that there were other investors who would be investing alongside Supreem and that Supreem's investment would bring the total committed capital to US $1.4m and was needed to close out the round. You also represented that Miescher had several strategic partnerships. Your dishonest conduct above now highlights the possibility to me that there were no other investors and no strategic partnerships (or at least much less than you represented). If either of those things are the case, then Supreem will be entitled to rescind the Convertible Loan Note Instrument (and any related documents) as a result of your and Miescher's fraudulent conduct (and Supreem reserves its right to rescind the relevant agreement(s) should it learn that the said representations were indeed false and made fraudulently). If you have been honest with my group and our investment, you should have no issue providing:\nFinancial statements.\nCap table and history thereof.\nProof of strategic partnerships claimed in an email correspondence to me (you know where to find it).\nProof of funds for the other investors in the round.\n\nFourth, I am advised that your last email fundamentally misunderstand the nature of without prejudice privilege. Your attempt to use a communication that I made in the context of those discussions as 'confirmation that[I]wish to receive the shares as per the agreement' is not only wrong, but underhanded. In any event, by seeking to invoke without prejudice privilege communications in this way, you have waived that privilege on behalf of Miescher in respect of our settlement discussions (and I hereby accept the same on behalf of Supreem). We will ensure that our representives appropriately draw the judge's attention both to your / Miescher's admissions and to your most recent email.\n\nMy solicitors will have a more extensive list of demands I am sure, but in the meantime Supreem hereby requires Miescher to comply with:\nMiescher's contractual obligations under clauses 8.2 and 8.4 of the Instrument to provide the information contained on the Register referred to therein, including (in addition to the above):\nThe names and addresses of the Noteholders for the time being;\nThe principal amount of the Notes held by each Noteholder;\nThe date of issue of each of the Notes and the date on which the name of each Noteholder is entered in the Register in respect of the Notes registered in his name;\nThe serial number of each Certificate issued and the date of its issue; and\nThe date(s) of all transfers and changes of ownership of any of the Notes.\nMiescher's contractual obligations under Sch. 2, Pt. 1, clause 6.1 to provide written confirmation that there have been Events of Default (as outlined above) and to confirm in writing whether (and if so when) there have been any other Events of Default of the kind described in Sch. 2, Pt. 1, clause 5.\nMiescher's obligation to pay Supreem the sum of US $50,000 under Sch. 2, Pt. 1, clause 5.1.Please note that this payment by Miescher will be without prejudice to Supreem's entitlement to interest at a rate of 8% from the date when the first Event of Default occurred. At the moment, Supreem cannot say when this would have been although it will of course not be later than 30 August 2022 (for the reasons given above). The issue of interest will be revisited once the information above has been provided.\nI don\u2019t mind losing investments to failed companies. I do mind losing investments to fraud. If Miescher has no assets, then rest assured that we will seek the appointment of a liquidator to investigate personal claims against Miescher's directors (who owed duties to Supreem as a creditor).\n\nI trust that this clarifies our position. Supreem reserves all of its rights in relation to this matter.\"\n\nThey responded: \"Dear Oliver,\n\nI have received your email below timed at 19.03 EST on the 24th of November. The content of which, is duly noted. I will not respond to each point individually but reserve the right to do so at a later date. \n\nBy way of background to this matter:\n\nBoth parties (I.e Miescher and Supreme) clearly accepted over recent months that the business, I.e Miescher was not continuing to trade. This is due market factors, i.e It\u2019s a hard market and this is a start up. \n\nTherefore the management team in good faith have spoken to all stakeholders and reached suitable resolutions. We through this included you, until such time as you unilaterally pulled out of the settlement (at the stage of signing). This is your right, but you can not claim we did not consult with you. \n\nGiven the various spurious threats you make below, I\u2019m inclined to view this as meeting the test for a letter before action. Therefore, Under part 36 of the civil procedure rules. I\u2019m prepared to repeat the existing offer to Supreem, i.e repayment of the $50,000 by Miescher in full and final settlement. I reserve the right to present this email in any future legal proceedings in respect of costs. \n\nI should further add that you did not send the agreement via any form of legal privilege and therefore it\u2019s open correspondence. You will note, no joint day was agreed for completion and your proposed signing deadline fell between my travel between NYC-Miami and Bogota. \n\nI trust the above proposal is acceptable, I will send an amended settlement deed over this week. As it will require adjustments given your claims set forward on the 24th. \n\nHopefully all parties can cooperate to resolve this matter. \n\nRegards-\n\nSimon\".\n\nPlease write a response for me.", "CHAPTER FOUR\n The Spectrum of Pain: Four Patients\n From Jeremy\nYou\u2019ve read the story of my back pain. Maybe it sounded familiar (I hope not; it was a bear). In any event, read the next four case histories, because one of them is likely to remind you a lot of yourself. The idea is for you to see where you fit on the spectrum of back pain problems. \nFit Fred\nA lot of my Aspen-based patients are fit, knowledgeable, and a little surprised to find themselves in need of professional help for back pain. A recent patient, call him Fit Fred, is typical. He is fifty-five years old, a nice guy, in good shape, and smart. He has had serious back pain for six months. In his case, that means a bothersome ache in his lower back almost all the time. And intermittent periods of excruciating pain, once every two weeks or so. Those interludes\u2014which have happened more often recently\u2014last from a few minutes to more than an hour. It is those intervals that have driven him to seek treatment.\nI am not his first stop. He\u2019s tried traditional chiropractic doctors, physical therapy, massage, and Rolfing. His back pain gets a little better for a time, and then comes back full force. When the pain is at its worst, he\u2019s stuck in bed or on the floor. He has tried traditional medicine, too, and his doctor is asking him to consider surgery. He has come to me first, because he has heard how often back surgery does not work, and he dreads that option, but he\u2019s getting closer to taking it. \n\u201cMy doctor says I have degenerative disc disease. He says I have the MRI of an eighty-year-old!\u201d (It is almost a comfort to him to think that he had \u201cdegenerative disc disease\u201d and that an operation may fix it. He\u2019s had enough. He\u2019s giving the nonmedical approach one more chance. Then it\u2019s the knife.) \nIn reality, \u201cdegenerative disc disease\u201d is a term used to describe a host of changes in the spine as a result of, or in addition to, a loss of disc height (compression) over time. As a diagnostic matter, saying that someone has degenerative disc disease doesn\u2019t amount to an awful lot more than saying that he or she is getting a little older and that his or her back hurts. That sounds a little snide, I\u2019m afraid, but it\u2019s true. Because Fred seems to have decent posture and is in pretty good shape, I suspect that his problem is going to be related to the normal degenerative changes of the spine that go with aging and bad repetitive motions. Maybe golf, maybe yoga. Depending on how open he is to change, this could be a comparatively easy case. \nIt won\u2019t sound easy, if I go into the details. After all, compression of the spine through normal aging does do some serious things. They can include arthritic changes in the facet joints (remember them?), loss of cartilage around all the joints, foraminal stenosis, which\u2014you will recall\u2014is a narrowing of the opening, or foramen, from which the nerve roots exit the spine. It may be spondylolisthesis, which is a slippage of one vertebra over another, causing pain and instability\u2014and is almost as nasty as it is unpronounceable. That all sounds awful, but they are normal concomitants of aging and degeneration of the spine and bad movements\u2014my normal material. Those we can fix. \nAs for his eighty-year-old\u2019s MRI, it probably does look pretty grim. But I have to tell you, almost all MRIs of people over forty look terrible. Stuff happens, and the individual manifestations look very scary. But they are not really all that bad. Which is why I rarely prescribe MRIs unless there are signs of the scary stuff (cancer, infection, fracture, etc.); they don\u2019t tell me anything I don\u2018t already know. \u201cHey, you\u2019re getting older, your back is getting squished. What did you expect?\u201d It\u2019s more sophisticated than that, but that\u2019s a fair summary in most cases. It is also a fair description of a condition you and I can fix, with behavioral change and hard work.\nI ask Fred a couple of questions about the therapy he\u2019s had so far. The chiropractor has just been manipulating him with no mention of exercise. I know that\u2019s not going to work for a permanent fix. And the physical therapist does not seem to have much of a plan: He has had my new patient do four exercises for three months\u2014always the same four, over and over, with no supervision and no progression. And neither of them has discussed his other activities (sports, work, exercises, etc.) with him. Beyond that, they are not the kind of exercises I will suggest because, among other things, they have done nothing to affect the endurance of the muscles of the core. This is by no means a slight on all chiropractors or physical therapists. There are some great ones out there. Some practice the way Fred\u2019s did, and some don\u2019t. Later in the book, we give you some pointers on finding good ones.\nFred really is active, God bless him, but he\u2019s doing some activities that, I suspect, are not helping his back. He does quite a lot of yoga, plays golf regularly, and lifts weights in the gym. A very responsible, fit guy, as I say. But what I know, without seeing him do yoga or play golf, is that some of the movements in those two activities are often a source of serious back injury over time. There is a safe, spine-healthy way to do yoga but, done wrong, as it often is, it can cause terrible problems. For now, I tell him to lay off yoga completely for at least two months. He can get back to it in time with some modifications. The same with golf. Golf is a wonderful activity. Not great exercise (contrary to what so many insist) but a wonderful way to be with friends and go to beautiful places. It can also be, structurally, one of the worst things you can do to your back. (All that one-way twisting of your lumbar spine.) There is a spine-healthy way to play golf, but for now I just tell him to lay off the golf until he is educated enough to be open to some instruction on a \u201cright way\u201d to play. [Hint: You learn to rotate with your hips more at the end of your swing, and less with your lower back.]\nThen I asked him to walk me through his strength-training regimen. It was not the worst strength regimen I have ever heard about, but it was pretty bad. He was doing a number of things that were almost criminally bad for him. If you are doing a lot of strength training, there is a sad chance that you, too, are doing some seriously harmful stuff, from a back point of view. That\u2019s because we were all trained to do things wrong, back in the day. \nTake, for example, the traditional \u201carmy sit-up,\u201d which Fred is still doing. We all did a lot of those at one point and a lot of us are doing them still. Even the army gave them up only in recent times. But the fact is that there are few things worse for your back than the good old army sit-up. (A shallow, or four-inch \u201ccrunch\u201d is fine, and it does all you need for your core; you do not need to bend your spine like a pretzel to get a benefit.) The sit-up, where you twist to touch your elbow to the opposite knee, is the worst of all. And that\u2019s just one of a bunch of deeply familiar exercises that are fundamentally terrible for your back. The machines we all used to love are a particular peril (not all but many). The whole world of bad strength training makes me particularly crazy: Here are these terrific men and women, working so hard in an effort to make their bodies stronger and better. And what they are doing is, in fact, worse than doing nothing at all. Sad and wrong. \nMost important, Fit Fred has no notion of the importance of engaging his core and strengthening his core and glutes\u2014perhaps the most important elements in a sane strength-training regimen. And he doesn\u2019t have a clue about the importance of decent posture and of maintaining a neutral spine. So I tell him to stop all strength training until I can show him how to do it right. \nSubstantial Sally \nIf Fit Fred was on the fit end of the fitness spectrum, then Substantial Sally was the opposite. She is significantly overweight (she is close to 300 pounds, which is very significant indeed) and has had no regular exercise program for the past four years. She has had a whopping four spine surgeries, two in the past two years, including a fusion and a laminectomy. Fusions are common, but they are very serious business indeed. It is a procedure in which the surgeon uses hardware to bolt (fuse) two or more vertebrae together to prevent further movement at that joint. There is a place for fusions, but I see them as a very last resort. They give relief, but if the person does not make the necessary behavioral changes, they often find themselves having another fusion or other problems in a few years. They are not a cure, in any broad sense. A laminectomy is a less serious procedure in which the surgeon removes a small piece of bone off a vertebra to relieve pressure on a particular nerve. Again, it cures a symptom, not the basic problem. \nIn any event, Sally has been through the wars, she is still in pain, and she is both smart and wary. She is not one bit sure that I am going to be any more help than my predecessors. I don\u2019t blame her. But I think she\u2019s wrong. I think I am going to be able to help her quite a lot, if she\u2019ll listen, which she may not. \nSally is an appealing woman, the head of a company that she started herself, and which she has made a huge success of. I automatically like her, right off; she\u2019s one of those people whom everyone likes right off . . . part of her success, I assume. But she sure is in trouble, and it is making her cranky. I don\u2019t blame her, but she is not fun. Not many of my patients are fun; they hurt too much.", "CHAPTER SEVEN\n RULE #2\n Be Still So You Can Heal (The Neutral Spine)\n From Jeremy\nLet\u2019s assume that you are beginning to get the big picture. And that you have also begun to identify the \u201cdumb\u201d things that you\u2019ve been doing to wreck your back, and that you have stopped doing them. Good. Now it is time to start the healing, and that is a matter of immobilizing your lower back or lumbar spine so it can heal, after all those years of doing things that hurt it. \nThe analogy is not perfect, but think of your tortured back as being like a broken arm or leg. When you break an arm, say, the doc puts it in a stiff cast so you can\u2019t bang it or twist it and to give it time and rest to heal. The same with your back, except we can\u2019t do anything quite as dramatic as put you in a whole-body cast for your damaged back. What we can do is show you how to carry yourself so that you effectively immobilize your lower back. It\u2019s not totally easy, but it will work. And bear in mind, if you do not immobilize your back, it will not heal\u2014simple as that. Indeed, it may get worse. \nWhat do I mean by \u201cimmobilizing\u201d your lumbar spine? I do not mean that you can\u2019t sit or walk or have a more or less normal life. What I do mean is that you have to be really serious about maintaining a neutral spine, all the time. Maintaining a neutral spine is at the heart of your cure, and will be at the heart of your life after your cure. This is the time to learn how to achieve a neutral spine and how to maintain it all the time, even when doing various movements. \nThe spine is a meticulously engineered piece of machinery, but it has a lot of redundancy built in. By this I mean that unlike the knee or shoulder, in the spine when you have a bad joint, the surrounding structures can \u201chelp\u201d bear the loads, and you can function more or less normally and without pain. Take the pressure of bad posture\u2014and dumb movement patterns\u2014off, and there is very likely enough \u201croom\u201d in this spine for the sufferer to have a normal life. For example, the \u201choles\u201d where the nerves come out of the spine (the foramina) are still big enough for the nerves to exit, pain-free, if you\u2019re not squeezing the area with lousy posture. In the same vein, there is probably still enough cushion in the flattened disc to support a correctly aligned spine (but not a bent or misshapen one). And so on. \n\u201cNeutral\u201d means the position in which the least amount of problem loads occur, all up and down the spine. The \u201cproblem loads\u201d in some pictures we\u2019ve shown are extreme, but even those inflamed joints and nerve roots will likely calm down if you leave them alone for a while. Which is to say, if you keep your spine in neutral. As bad as those injuries are (and as long as it took someone to create them) there is a strong chance that that sufferer can go about his or her life, with a neutral spine, in little or no pain. \nLearning to keep a neutral spine is not totally easy. And learning to maintain it all the time is harder. But this is the \u201ccast\u201d that lets your body heal. It is worth going to a lot of trouble to get this right. And it is a lesson that you will use for the rest of your life, long after the problem area has \u201chealed.\u201d \nOkay, step one is understanding the concept of neutral spine. Step two is learning to find it and lock it in place, and keep it in place forever (which we will teach you in Chapter 9).\nThe neutral spine is the position that allows your spine to do its job with the least amount of stress and load. And\u2014if you have already damaged your back\u2014it is the position that results in the least amount of new damage or pain.\nFor most people, the picture on the left is the neutral spine. The other two are not.\nNeutral Spine \n\nGOOD BAD\nNote the gentle curve of the lower back in the \u201cgood\u201d spine. For the majority of you, this is how your neutral spine will look. If you have developed significant degenerative changes or were born with significant abnormalities (it happens, but not a lot), your neutral spine may look a bit different. For now assume that your neutral spine looks like one on the guy on the left. Spines vary, and you may have your own unique neutral spine that is a little different from this. Whatever your own neutral spine, that is the position you want to maintain as you go about your daily life. It is also the position in which you feel the least pain. Again, maintaining a neutral spine is a fundamental behavioral change for most people. And it is readily doable. In a few months\u2019 time, I predict that it will be natural and you will scarcely need to think about it. One of the near-magic presences in our lives is \u201cmuscle memory.\u201d Maintain your spine correctly for a while and muscle memory takes over. Then it is just a question of seeing to it that your muscles are strong enough to do their job. \nHow do you keep your spine neutral and still be a dynamic, moving, active human being? By learning to brace your neutral spine with your core (Chapter 9) and maximizing movement in your hips (as opposed to your lower back). As Chris mentioned in Chapter 6, one of our cardinal rules is \u201cThou shalt not bend or twist with thy lower back.\u201d And you don\u2019t need to. You can rotate from side to side and bend forward and back using your hips. You do not need to flex or twist your lower back. \nYou may ask: Isn\u2019t range of motion important for the lumbar spine? Answer: Not really. At least, it is usually the least important factor for someone who has had significant back pain, and should be reintroduced only after pain has stopped. Most people who have experienced regular, serious back pain have already sustained significant wear and tear on the spine. The general pattern I see is a combination of two things: first, worn-down vertebral joints that are hypomobile (stiff), secondary to arthritic changes and degeneration; second, lumbar vertebral joints that are hypermobilie (loose), due to overstretched ligaments and atrophied muscles. These problems are best resolved when we protect the spine by bracing and \u201clocking down\u201d the lumbar spine and moving in a manner that completely changes the axis of motion from the lumbar spine to the hips and shoulder girdle. You can eventually introduce some gentle lumbar range-of-motion exercises in non-loaded ways. This is what the \u201cCat/Camel\u201d exercise that we introduce later is for. Small, gentle lumbar range-of-motion exercise is necessary for things like synovial joint lubrication, the reduction of friction between vertebral segments and discs, and disc nutrition, among other things. For example, walking requires a few degrees of freedom between the lumbar vertebral joints (3 or 4 degrees rotation) with coordinated muscle contractions to enhance stabilization and supply necessary lubrication and nutrition to discs and joints. For our purposes, we recommend keeping lumbar motion to a minimum, especially until your pain is gone. Once that occurs, you should make only healthy, non-loaded, non-repetitive lumbar movements, such as those necessary for walking and the cat and camel exercise. Spinal stability, core endurance, hip mobility, and core and gluteal strength are far more important for maintaining a healthy spine once you\u2019ve had back pain. You can do just fine in life with almost no rotation or excessive movement in your lower back. Let your hips do the work, and your risk of recurring back pain is sharply reduced. \nFinding Your Neutral Spine \nFinding your neutral spine can be a bit tricky for some but you can do it. Here\u2019s what you do. Lie on your back with your knees bent and your feet flat on the floor. Try to relax everything in your body, and just breathe. Then let\u2019s start by performing a pelvic tilt. \nTo do that, flatten your lower back into the floor (see top drawing), and curl your tailbone upward. This is a \u201cposterior pelvic tilt,\u201d if you want to put a name to it. Now, arch your back so that your lower back comes off of the floor (middle drawing), and point your tailbone toward the ground (an \u201canterior pelvic tilt\u201d). Now, slowly go back and forth between those two motions a few times (bottom drawing). Find the position of your lower back between these two extremes (flattening your back or arching it) that feels the most comfortable to you, and stop there. This is your neutral spine. It may take a few tries but it\u2019s not hard.\nFinding Your Neutral Spine\n\nStop here for a second. You have just reached an important point, and you don\u2019t want to \u201close\u201d it. Everyone\u2019s neutral spine is a bit different depending on the anatomical condition of their lumbar spine. For most people, there will be a gentle curve in the lower back. For those who already have some kind of a disc bulge, their neutral spine might be more arched (butt more extended). For those with spinal stenosis, their neutral spine may be a little more flattened than the one in the picture on the previous page. Don\u2019t worry about it. Whatever feels the most comfortable for you is your neutral spine for now. In time, your neutral spine will likely become more like the \u201cnormal\u201d picture as pain and inflammation subside.\nThink about your neutral spine and assume that position all the time until it becomes second nature\u2014until \u201cmuscle memory\u201d takes over. \nNext, we move on to a discussion of techniques to help you maintain a neutral spine. But first, Chris is going to tell you why it is very likely you haven\u2019t heard of these concepts before.", "CHAPTER FOURTEEN\n Trigger Points: Muscle Pain and Back Pain\n From Chris and Jeremy\nMost of us\u2014the newcomers anyway\u2014tend to think of back pain as something that is largely in the spine itself. The bones, discs, ligaments, and nerves. But what most of us don\u2019t focus on are the surrounding and supporting muscles. Which is a mistake, because they can be a major source of back pain (or something that can pass as back pain). And getting \u201cright\u201d with those muscles can be mighty important. \nTo be accurate, back pain is almost always a not-so-pleasing blend of muscle pain, joint pain, nerve pain, and other pain. This can be a little confusing. All pain is transmitted by nerves. When we speak of muscle pain or nerve pain, we are referring to the primary source of pain\u2014that is, the pain-generating tissue. Sometimes an aggravated nerve is the source of pain so it is referred to as nerve pain. In this chapter, we are talking about pain whose primary source is muscles. Even though the pain is transmitted to your brain via nerves, the tissue that\u2019s causing the pain is muscle tissue, so we refer to it as muscle pain. It is helpful to think of that which is primarily muscle pain differently, because it manifests itself differently, and Jeremy\u2019s approach to it is different, too.\nThere\u2019s good news and bad news here (wouldn\u2019t you know it). The bad news is that muscle pain is harder to locate and trickier to fix in the first instance. The good news is that it is actually easier to fix in the long run, and your prospects of a complete cure are much better. \nWhich is not to say it does not hurt like blazes. Up in the 8\u201310 range, on a scale of 10. But often the relief can be sudden and nearly complete. You still have to do serious stuff to keep it from coming back once the fix is made, but that\u2019s always true. \nMuscle Pain\nPeople in the healing professions refer to muscle pain both as \u201cmyofascial pain\u201d and \u201ctrigger point pain.\u201d For laymen like you and me, \u201ctrigger point pain\u201d may be the more useful name, because it feels like that\u2014something that gets \u201ctriggered\u201d by some silly move you made. Whatever we call it, trigger point pain has been a somewhat controversial topic for decades, mostly because no medical discipline claims ownership of the muscular system. Doctors are far more concerned with the joints, bursae, ligaments, and nerves. There has not been as much study of the muscular system and trigger point pain. But there has been enough, so that there is broad agreement on many points. And the best practitioners, and Jeremy in particular, have seen a lot of it. \nSo, what is it? Here\u2019s Jeremy: \u201cTrigger points are tight, painful bands of muscle tissue that have predictable and recognizable patterns of pain.\u201d To put it another way, they are muscle spasms (not quite right but close enough), which is what you get when a muscle or muscle segment seizes up, under pressure, and won\u2019t let go. It\u2019s like those cramps you sometimes get in your leg, except it doesn\u2019t go away and the pain can be horrendous. Unbearable, some of the time. These spasms or cramps not only cause terrible pain in their own right, but they can change the way some joints function. As Jeremy puts it, \u201cThey also limit range of motion and change the normal distribution of loads on nearby joints, which can also cause pain.\u201d So trigger point pain is serious, and it has more than one way to grab you. If it has started to affect the range of motion of the nearby joint, in the way Jeremy suggests, clearing it up is harder, but the approach is the same. \nOne thing to bear in mind is that trigger points basically \u201clie\u201d to us. That is to say, the obvious pain may crop up away from the actual trigger point itself. For example, the trigger point may be in the gluteus minimus (that\u2019s a favorite spot, actually), but the pain may run down the leg, mimicking sciatica. Or a trigger point in the gluteus medius may read as pain in the lower back. There are a lot of variations, but the patterns are well known and predictable, so professionals know where to look for the originating problem. Most of the time, anyway. Pretty soon, you will, too. \nOne thing that helps is that trigger point or muscle pain in general is recognizably different from nerve pain (again, this means pain in which an aggravated nerve is the source of the pain, not just the means of transmission to your brain) and other pain, so that you know what you are dealing with. Most of the time, nerve pain, for example, is \u201cburning, sharp, electric,\u201d and you can pinpoint exactly where it is. Trigger point pain, on the other hand, is achy, diffuse, hard to localize, and dull. And it often arises far from the source, which is a trigger point in a muscle. \nOne reason it is called trigger point pain is that it is usually \u201ctriggered\u201d by an actual event, just the way it feels. You rolled over funny in bed, you opened the Sub-Zero too vigorously, you picked up the box of books with your back, not your legs. Sometimes, those triggering events are one-off incidents, which is the way they feel. But more often, the trigger point (or vulnerability) has been building for a long time. Vulnerable muscles or muscle segments have been under repetitious pressure for a long time, and they are ready to \u201cgo\u201d at the drop of a hat. You open the Sub-Zero funny and pow! A terrifying spasm. A latent trigger point like that can \u201cgo\u201d without any trigger event at all or with a trifling one. Let us hope that yours is a \u201cone-off,\u201d not one that has been building for years, because the one-off takes less time to heal. But never mind, the approach is just the same. \nThe most common trigger points are the ones that have been caused by muscular overload, and that have developed over time. Think of the familiar situation: You sit at your desk for months and years. It is an \u201cunnatural\u201d position, and it puts repetitive pressure on muscles that aren\u2019t built for it. Or it can be repetitively misplaced loads, caused by you doing some move the same wrong way, year after year, like a faulty golf swing. Say you sprain an ankle and you never quite rehab the ankle the way you should. Over the following weeks and months you walk slightly differently than you used to. This subtle change causes muscles in your legs and pelvis to bear loads in a different way. Some now bear more loads, some less. Over time, those muscles that are now bearing more loads get stressed and strained, and trigger points develop. The pain from these can come on gradually or suddenly. As we have said all along, most of the time, you have built your own back pain, over time, with the way you behave. That is true for most muscle pain, too. \nFinding Trigger Points\nOkay, on to the details. \n\u201cFor low back pain sufferers, the most important and common areas for trigger points to occur are in the lumbar paraspinals, quadratus lumborum, gluteus maximus, gluteus medius, gluteus minimus, and piriformis.\u201d Sorry, that\u2019s Jeremy; he just can\u2019t help himself. But you don\u2019t have to memorize the names; you just have to look at the pictures to get the general idea. And then feel around for the real source of the pain. When I say look at the pictures, I mean look and see if you can relate what you feel to the typical patterns the pictures show. The Xs represent the location of the real trigger point and the red shaded areas represent the area where you may perceive the pain. So think about where you feel the pain. Then look at the pictures. Then go to work to find where the X may mark the spot. When you find it, it will hurt a lot more than the surrounding area. Bingo! Think of these pictures as \u201ctreasure maps\u201d and the treasure is eventual release from pain. \nThis process is very much \u201chands on.\u201d It can be challenging to distinguish areas of perceived pain from actual trigger points until you get a feel for what you are looking for. If you try multiple times and fail, you may need the assistance of a good chiropractor, massage therapist, or physical therapist to get the hang of this. To get started, grope around with your hands (using the pictures as a guide to the general area) until you have a fair idea of where the real trigger points are. You will know them because they hurt more. For once, the pain is the good news. It means that you\u2019re getting close. Or you\u2019re there. \nBy the way, the muscles where the trigger point lies can be deep. The gluteus minimus, for example, is buried beneath two other muscles and a layer of fat. Some of you are not going to have the strength or leverage to reach that trigger point with your hand alone. You may need to use a tennis ball or foam roller, which will be discussed in the following pages. But, to start, just use your hand until you get a general idea if there is something deep in those muscles that needs to be released. And don\u2019t forget: Use the pictures as your guide. \nOnce you have a general idea of where the trigger point is, mash away at it, if you like, with your bare hands, and see if that manual manipulation is enough to \u201crelease\u201d the rascal. What you do is hold down hard on the place that hurts the most and\u2014in ten to thirty seconds or so\u2014you should feel an easing of the pain. That is the trigger point letting go. Nice work. If the pain does not ease up after thirty seconds or so, either you are not directly", "this is chapter 20 of original book\n{CHAPTER TWENTY\n The Sacrum and Coccyx\n From Chris and Jeremy\nFrom Chris\nThe sacrum is the last section of the spine, the vestigial collection of vertebrae that are welded into one solid piece, down at the bottom. And the coccyx is the tippety-tip of the sacrum, the last bit of bone at the end of that long chain, which has been such a torment to you for so long. \nAnd this is the end of the book. The end of the long chain of chapters that we hope\u2014with all our hearts\u2014will deliver you from such torment forever. From now on, it\u2019s up to you. Go back through the book, do the exercises, and change your behavior the way you know you should. Up to you now. \nMay I say, here at the end, that putting this book together has been great fun for Jeremy and me. It has taken more than a year, and it has been a ton of work. We hope it reads as if it were easy as pie, but it wasn\u2019t. We worked like crazy to make it seem easy\u2014and to make it truly accurate without driving you crazy. Don\u2019t know how well we did on that, but we sure did try. And it was fun for a couple of reasons. First, from my point of view, Jeremy is awfully good company. He is deadly serious about his profession but he loves to laugh, too. And, God bless us, we think we\u2019re funny. That helped a lot. On a slightly more serious note, learning all the stuff I had to learn about the back this past year was fascinating and a privilege. Interesting piece of machinery, the back, and Jeremy could not have been a better guide. \nFinally, both of us are true believers in this \u201crevolution\u201d I mentioned up front, and that is a tremendous help. The whole time we were digging away at this boring detail or that, we had the agreeable conviction that we were not just ink-stained wretches, noses to the page. We were centurions in the great war against cruel, needless pain. That helped a lot, too. \nBut the whole business won\u2019t be satisfying to us if it doesn\u2019t work, for you. And that takes me back to my one great worry, the one I mentioned before. \nI worry that we leave so much of this up to you, when we know that Americans just aren\u2019t used to that. Americans are used to going to the magician/doctor. He has a look around, maybe does an MRI. And then hands us a prescription, or gives us a shot. Or sends us to his pal the back surgeon, who does some clever thing to make us all better. As we\u2019ve said again and again, that\u2019s not going to work here. You have to do it yourself\u2014you have to do the exercise, make the changes. But the great question is, will you find the resolve to make it happen? Jeremy says he\u2019s sure you will, because he knows your pain. He knows just how deep and sharp your motivation is. I hope he\u2019s right. \nWhat we are urging is not really that hard; it is mostly just unfamiliar. And you surely have the resources and motivation to make it happen. I know you\u2019re smart enough; you just read this darned book, after all. I know you are disciplined enough; you\u2019ve been going to work all these years. And I know you care, because I know about your pain. Now just take those three things and reorient them a little. And save your life. Then spread the word and save your family, save the country. Get the ogre out of all our lives. It can and should be done. \nFrom Jeremy\nI can\u2019t agree more with Chris\u2019s words. He and I had such a great time writing this book, and we are both deeply optimistic about what it can do for you. As you well know by now, I am not the \u201cword guy\u201d; that\u2019s Chris. So I will be uncharacteristically brief and just say I have seen this protocol work a thousand times in my practice. Now I want to see it work a million times, perhaps more than that, with this book. As we mentioned at the beginning, we want a revolution in back care in this country. Starting with you. We want to take this scourge out of all our lives. \nJEREMY\u2019S RULES\n1\nStop doing dumb stuff.\n2\nBe still so you can heal.\n3\nBrace yourself.\n4\nCommit to your core.\n5\nUse the power in your posterior.\n6\nCrawl before you walk. Walk before you run.\n7\nStand tall for the long haul.\nAPPENDIX\nThe \u201cCheat Sheet\u201d\nWe threw a lot at you in this book. In time, it will seem like second nature. When you get to that point, it may still be useful to have a simple guide to remind you where you are, what to do next, and so on. To that end, I give you this \u201ccheat sheet\u201d to summarize all the exercises we have told you to do and to tell you when to do them. Here is your daily and weekly plan.\nI strongly encourage you to read this book a few times a year. Trust me, you are trying to change lifelong habits and it\u2019s very easy to default back to the old ways. Come back to the book and think through each exercise every so often. Avoid the trap of falling into those same bad habits that got you here in the first place. The book is the key to taking your life back and leaving the anxiety, stress, and pain of back problems in the past. In between readings of the book, there\u2019s this Exercise Cheat Sheet. \nBasic Core Exercises\nThese exercises (see Chapter 10) should be done every day, and are best done in the morning after being out of bed for thirty minutes or so. Remember to do progressions or regressions as needed for each. Move on to the next progression of a particular exercise when and if you feel ready. Start with one circuit and work your way up to two full circuits in time, and make that your daily habit. In time, this will take you ten to fifteen minutes.\n1. Slow March with Neutral Spine with Shoulder Flexion\n2. The Bridge \n3. Crunch and Plank\n4. Dynamic Hamstring Stretch\n5. Side Plank\n6. Cat/Camel Mobilization\n7. \u201cBird Dog,\u201d or Opposite Arm/Leg Extension\nGlute Strengthening Routine \nDo these exercises three times a week on nonconsecutive days in addition to your core routine. Start with two sets and work your way up to three in time. This will likely add an additional ten minutes or so on those three days a week that you do these. \n1. Hip Circles Do these first!\n2. Clamshell\n3. Quadruped Hip Extension\n4. Split Squat\n5. Squat\nTrigger Point Release\nDo this as needed. If you got noticeable improvement in back, hip, or leg pain after mastering this, do it prior to your glute workouts until it is no longer needed. \nStretches \nFollow up your glute routine with the following stretches from Chapter 17.\nThis will take three to four minutes.\n1. Hamstring Stretch\n2. Glute Stretch\n3. Piriformis Stretch\n4. Psoas Stretch\nTHE BACKFOREVER VIDEOS\nFor those of you who want to safely return to more demanding activities like weightlifting, skiing, golf, tennis, Pilates, yoga, etc., we invite you to become members of BackForever.com, where you will find hundreds of hours of detailed video instruction on these subjects. Visit BackForever.com to learn more. Enter this promo code to receive two free weeks of membership: YNYTRIAL.\nACKNOWLEDGMENTS\nThanks to Jeremy, first of all, for being such a joy to work with. Coauthorship is supposed to be hard. For me\u2014especially in this book\u2014it has been a joy. We worked mighty hard, but we laughed a lot too.\nJeremy and I have been blessed\u2014and we know it\u2014to have a superb editor in a smart, kind, diplomatic, literate Bruce Tracy at Workman. (That is a shortened list of attributes; Bruce was terrific. And he really got down into the weeds as well as the big picture. As good as they get.) And, as always, thanks to the wise and kind Suzie Bolotin, editor of the Younger Next Year\u00ae books and Uber-editor of this one. Heaven!\nLast, thanks to Bill Fabrocini, just about the smartest and most effective guy Jeremy and I know in the broad world of physical therapy and serious training. And about as nice a human being as I have ever met. Deep thanks, Bill.\n\u2014C. C.\nI\u2019d like to thank all of the people who have helped me become the clinician I am today. I\u2019d like to thank Clinton Phillips, Michael Fox, Tim Powersmith, and Bill Fabrocini for their friendship, guidance, and the opportunities they have given me. Back pain has been one of the most misunderstood afflictions in modern society. Many of the concepts in this book are the result of the research and teaching of a handful of dedicated and pioneering individuals. There are many, but I would like to give special mention to Vladimir Janda, MD; David Simons, MD; Janet Travell, MD; Nikolai Bogduk, MD, PhD; and Stuart McGill, PhD. This book wouldn\u2019t have been possible without your accomplishments. }\nRead the chapter 20 of original book that I sent you and save it in your memory. Then, based on this text of chapter 20 of original book and your own information, continue the text of chapter 20 of the new book as much as you like. morover, with explaining with deep learning to me as if i were 10 years old.The text should be completely scientific and academic and based on science World Day should be written and repetition should be avoided. that are not repetitive and related to this topic. this chapter of an original book that I gave you is just a starting point and he has the right to add relevant foliage to this section. based on chapter 20 of original book, you can start", "it throws an error sir\n\nInvalidArgumentError Traceback (most recent call last)\nCell In[142], line 35\n 1 # from keras.models import Sequential\n 2 # from keras.layers import LSTM, Dense,Lambda\n 3 # from keras.callbacks import EarlyStopping\n (...)\n 31 #X\\_train = X\\_train.reshape((X\\_train.shape[0], n\\_timesteps, 1))\n 32 #X\\_test = X\\_test.reshape((X\\_test.shape[0], n\\_timesteps, 1))\n---> 35 model.fit([X\\_train, RPM\\_train], y\\_train,\n 36 batch\\_size=256,\n 37 epochs=50,\n 38 validation\\_data=([X\\_val, RPM\\_val], y\\_val),\n 39 callbacks=[early\\_stopping])\n\nFile ~\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\keras\\utils\\traceback\\_utils.py:70, in filter\\_traceback..error\\_handler(\\*args, \\*\\*kwargs)\n 67 filtered\\_tb = \\_process\\_traceback\\_frames(e.\\_\\_traceback\\_\\_)\n 68 # To get the full stack trace, call:\n 69 # `tf.debugging.disable\\_traceback\\_filtering()`\n---> 70 raise e.with\\_traceback(filtered\\_tb) from None\n 71 finally:\n 72 del filtered\\_tb\n\nFile ~\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52, in quick\\_execute(op\\_name, num\\_outputs, inputs, attrs, ctx, name)\n 50 try:\n 51 ctx.ensure\\_initialized()\n---> 52 tensors = pywrap\\_tfe.TFE\\_Py\\_Execute(ctx.\\_handle, device\\_name, op\\_name,\n 53 inputs, attrs, num\\_outputs)\n 54 except core.\\_NotOkStatusException as e:\n 55 if name is not None:\n\nInvalidArgumentError: Graph execution error:\n\nDetected at node 'gradient\\_tape/mean\\_squared\\_error/BroadcastGradientArgs' defined at (most recent call last):\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\runpy.py\", line 194, in \\_run\\_module\\_as\\_main\n return \\_run\\_code(code, main\\_globals, None,\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\runpy.py\", line 87, in \\_run\\_code\n exec(code, run\\_globals)\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\ipykernel\\_launcher.py\", line 17, in \n app.launch\\_new\\_instance()\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch\\_instance\n app.start()\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n self.io\\_loop.start()\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n self.asyncio\\_loop.run\\_forever()\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\asyncio\\base\\_events.py\", line 570, in run\\_forever\n self.\\_run\\_once()\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\asyncio\\base\\_events.py\", line 1859, in \\_run\\_once\n handle.\\_run()\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\asyncio\\events.py\", line 81, in \\_run\n self.\\_context.run(self.\\_callback, \\*self.\\_args)\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch\\_queue\n await self.process\\_one()\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process\\_one\n await dispatch(\\*args)\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch\\_shell\n await result\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute\\_request\n reply\\_content = await reply\\_content\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do\\_execute\n res = shell.run\\_cell(\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run\\_cell\n return super().run\\_cell(\\*args, \\*\\*kwargs)\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in run\\_cell\n result = self.\\_run\\_cell(\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2995, in \\_run\\_cell\n return runner(coro)\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\IPython\\core\\async\\_helpers.py\", line 129, in \\_pseudo\\_sync\\_runner\n coro.send(None)\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3194, in run\\_cell\\_async\n has\\_raised = await self.run\\_ast\\_nodes(code\\_ast.body, cell\\_name,\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3373, in run\\_ast\\_nodes\n if await self.run\\_code(code, result, async\\_=asy):\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3433, in run\\_code\n exec(code\\_obj, self.user\\_global\\_ns, self.user\\_ns)\n File \"C:\\Users\\yp229\\AppData\\Local\\Temp\\ipykernel\\_980\\1234321631.py\", line 35, in \n model.fit([X\\_train, RPM\\_train], y\\_train,\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\keras\\utils\\traceback\\_utils.py\", line 65, in error\\_handler\n return fn(\\*args, \\*\\*kwargs)\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\keras\\engine\\training.py\", line 1650, in fit\n tmp\\_logs = self.train\\_function(iterator)\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train\\_function\n return step\\_function(self, iterator)\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step\\_function\n outputs = model.distribute\\_strategy.run(run\\_step, args=(data,))\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run\\_step\n outputs = model.train\\_step(data)\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\keras\\engine\\training.py\", line 1027, in train\\_step\n self.optimizer.minimize(loss, self.trainable\\_variables, tape=tape)\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\keras\\optimizers\\optimizer\\_experimental\\optimizer.py\", line 526, in minimize\n grads\\_and\\_vars = self.compute\\_gradients(loss, var\\_list, tape)\n File \"C:\\Users\\yp229\\anaconda3\\envs\\myenv\\_time\\lib\\site-packages\\keras\\optimizers\\optimizer\\_experimental\\optimizer.py\", line 259, in compute\\_gradients\n grads = tape.gradient(loss, var\\_list)\nNode: 'gradient\\_tape/mean\\_squared\\_error/BroadcastGradientArgs'\nIncompatible shapes: [256,10,10] vs. [256,10]\n [[{{node gradient\\_tape/mean\\_squared\\_error/BroadcastGradientArgs}}]] [Op:\\_\\_inference\\_train\\_function\\_3407272]", "Here is the list of important characters:\nRenegades Playable Characters:\nGoma Ayim - A teen of Swahili descent, who likes parkour and doing tricks. He has had a rough childhood, but he is making the most out of what he gets. A mysterious friend (Wolfgang) has encouraged him to be himself and strive for his ambitions, but now he just hopes to reunite with his family. He is in the Expedition platoon in the renegades and has the power of Pyrokinesis. (Note: He is convinced that Yuudai is Wolfgang when in reality Vega Takeshi was Wolfgang.)\nFiliz Incesu - A young woman of Turkish descent. She is depressed and aimless, things that got worse after the trials, however, she is pushed forward to find her brother (Soner Incesu, who is with the gladiators). She has met a mysterious friend (Fatin) during the trials and respects him. She is in the Investigation Platoon in the renegades and has the power of Aerokinesis.\nEugene Jordan \u2013 A young knowledgeable man expected to take up the family business and is stressed by that. However, he became good friends with a mysterious friend (Magnus) during the trials, who supported him and allowed him to be himself. After failing the trials, he has become paranoid and scared, but still wants to be friends with Takeshi. He is in the Skirmish Platoon in the renegades and has the power of Geokinesis.\nRenegade Moles (eventually redeemable villains):\nTakahashi Yuudai - A royal-like young man who was taken by the organization from birth. He has never met his family and only knows of them through the organization. He is often told that his twin brother (Sato) is unreasonably prideful and is unworthy of their mother\u2019s love and is spiteful of him. Yuudai is blind to the fact that their mother and family are far from perfect, and they are the cause of his brother\u2019s mental torment. Probably has golden child syndrome. Acts as the leader of the Investigation Platoon and has the power of Photokinesis.\nDamia Fades - An artificial lifeform with someone else\u2019s memories. She is unaware of her condition (Including her connection with the organization) and is convinced that she was childhood friends with Sato, was wronged by him, and now needs to take advantage of his amnesia to set him straight. Probably has main-character syndrome and a hero complex (she thinks setting Sato straight will save a lot of people from misery). Acts as the leader of the Expedition Platoon and has the power of Azur-Ignikinesis. \nGladiator Playable Characters:\nPriya Revi - A young woman who suffers from her misogynist family, but after being encouraged by a mysterious friend (Nahida) in the trials, she now has the ambition and drives to pave her own path. Once all of this is over, she hopes to write music and dance with her new friends. She is in the Expedition Platoon in the Gladiators and has the power of Hydrokinesis. (Note: She is convinced that Tamma is Nahida when in reality Vega Yukiko was Nahida)\nRenfrew Jordan \u2013 A teen who wants to pursue a career in sports but isn\u2019t good enough to leave an impression on recruiters. He has received some encouragement from a mysterious friend (Jean) and respects her. Is looking for his older brother Eugene. (They have a good relationship and support each other. He is in the Skirmish Platoon in the Gladiators and has the power of Geokinesis.\nFrancesca Bianchi - A teen who enjoys many forms of art (painting, sculpting, doodling, etc.) and aspires to be an artist. Has an unsupportive family and unsupportive peers but reignited her ambitions after being encouraged by a mysterious friend (Rosaria). She wants to pursue her passion with her new friends by her side. She is a part of the Investigation Platoon in the Gladiators and has the power of Pyrokinesis.\nGladiator Moles (also eventually redeemable villains):\nTamma Soriya - A royal-like young woman who was taken from her family at birth by the organization. She has never met her family and only knows of them through the organization. She is often told that her twin sister (Tina) is ungrateful and unworthy of their mother\u2019s love and thus is spiteful of her. Tamma is blind to the fact that their mother and family are far from perfect, and they are the cause of her sister\u2019s mental torment. Probably has golden child syndrome. Acts as the leader of the Expedition Platoon and has the power of Photokinesis.\nDamjan Fades - An artificial lifeform with someone else\u2019s memories. He is unaware of his condition (Including his connection with the organization) and is convinced that he was childhood friends with Tina and that they had feelings for each other, and now sees it as his duty to help Tina remember their bond and marry her after all this even though they have never dated. Probably has main-character syndrome and a hero complex. Acts as the leader of the Skirmish Platoon and has the power of Azur-Ignikinesis.\nSecret Protagonist:\nVega Takeshi - an amnesiac found by the renegades. Is seen to have God-like abilities, but he doesn\u2019t know why. Kind of loud and prideful. Mentally unstable, and has schizophrenic hallucinations, but still tries his best to be a good leader and help his teammates succeed (including Yuudai and Damia). Acts as a leader of the skirmish platoon and has the power of Gravikinesis (prefers blackholes) however they publicly mask their abilities as polarity as a precaution.\nThe Pale Ebony Queen \u2013 Takeshi\u2019s pre-amnesiac self. Successful in the trials. Mental instability was worse than Takeshi\u2019s. Other aliases include Wolfgang, Fatin, Magneus, and Eiji. Their birth name was Sato. Had the power of Advanced Gravikinesis, were able to manipulate time, more specifically making themself faster, and were able to travel to the past.\nLucifier \u2013 Takeshi\u2019s inner demon, and the one that guides Takeshi through their amnesia. Is the embodiment of the Queen\u2019s self-hatred. Plays a similar role as Sothis from Fire Emblem Three Houses.\nRhydderch Griffith \u2013 A young man who was wronged by the judicial system in his hometown and is hesitant to help everyone find a way home. He is initially mistrustful of people, but after meeting Eiji, who was patient and understanding, he has allowed him as an exception and is close to him. He also Likes Eiji\u2019s singing. However, after finding Takeshi and how he has amnesia, his goal now is to stay by his side and help him through his predicament. Is very skeptical of Yuudai. He makes sure Takeshi calls him Ryder and is a part of the Skirmish Platoon. (Note: Has a memory of the Pale Ebony Queen saving him and his family in his childhood and connecting them to Eiji/Takeshi because they have the same scars.) Does not have any notable powers, but is flexible and adaptable enough to keep up with everyone else.\nVega Yukiko \u2013 an amnesiac found by the gladiators. Is seen to have God-like abilities, but she doesn\u2019t know why. Shy, timid, and full of anxiety. She has a difficult time speaking but tries to be helpful to all her teammates (Including Tamma and Damjan, unless he ignores her boundaries). Reluctantly the leader of the Investigation Platoon has the power of Gravikinesis (prefers white holes). However, they publicly mask their abilities as polarity as a precaution. \nThe Umbral Ivory King \u2013 Yukiko\u2019s pre-amnesiac self. Intentionally fails the last gladiator trial. Mental instability was worse than Yukiko\u2019s. Other aliases include Nahida, Jean, Rosaria, and Luka. Their birth name was Tina. Had the power of Advanced Gravikinesis and could control time, more specifically making others freeze in place around them, and were able to travel into the past.\nSatenael \u2013 Yukiko\u2019s inner demon, and the one that guides Yukiko through their amnesia. Is the embodiment of the King\u2019s self-hatred. Plays a similar role as Sothis from Fire Emblem Three Houses.\nAdelaide Brunhilde: A young woman from a rich family that went into hiding because family members keep disappearing/dying. Is expected family members to marry another man and continue the family business and didn\u2019t dare to object to them. However, she has gotten more courage and can be herself more after meeting Luka in the trials, who is patient with Adelaide and encourages her to be herself. She is close to Luka and is grateful to her. She also likes Luka\u2019s singing. Adelaide is now aloof and rebellious, yet still has an introverted, noble attitude (Old habits die hard kind of thing). Now her goal is to stay by Yukiko\u2019s side and help her out of the predicament. Is very skeptical of Tamma. Makes sure Yukiko calls her Amia and is part of the Investigation Platoon in the Gladiators. (Note: Has a memory of the Umbral Ivory King saving her and her family in her childhood and connects them to Luka/Yukiko because they have the same scars.) Does not have any notable abilities, but is flexible and adaptive to keep up with everyone else.\nare these characters built well enough to get started forming chapter one?", "Understand all the code in this message so you can write the java code for the Room Class make sure you utilize the method signatures and there purposes listed for the room class and the device interface\n\nThis assignment requires you to write code for a cooling simulation involving rooms and\ndevices. Three types of devices can be used to cool a room: air conditioners, ceiling fans, and\nstanding fans. Air conditioners and ceiling fans cannot be removed from a room once they are added.\nStanding fans however are portable devices that can be swapped between rooms only if they are not\nin use. The table below shows the different properties of each device: portability, breeziness,\nnoisiness, and cooling power\n\nHeres Table 1 - \nDevice - Air Conditioner - Portable = no, Breeziness = 0, Noisiness = 0, Cools by = 5.\nDevice - Ceiling Fan- Portable = no, Breeziness = 2, Noisiness = 0, Cools by = 3.\nDevice - Standing Fan- Portable = Yes, Breeziness = 2, Noisiness = 2, Cools by = 1.\n\nDevice Interface\nThe Device interface specifies the following behaviour for a device:\npublic interface Device {\n \n String getID();\n \n boolean isBreezy();\n \n boolean isNoisy();\n \n boolean isOn();\n \n void turnOn();\n \n void turnOff();\n \n int coolsBy();\n \n int getBreeziness();\n \n int getNoisiness();\n \n}\n\nUnderstand all the code in this message so you can write the java code for the Room Class make sure you utilize the method signatures and there purposes listed for the room class and the device interface\n\nThis assignment requires you to write code for a cooling simulation involving rooms and\ndevices. Three types of devices can be used to cool a room: air conditioners, ceiling fans, and\nstanding fans. Air conditioners and ceiling fans cannot be removed from a room once they are added.\nStanding fans however are portable devices that can be swapped between rooms only if they are not\nin use. The table below shows the different properties of each device: portability, breeziness,\nnoisiness, and cooling power\n\nHeres Table 1 - \nDevice - Air Conditioner - Portable = no, Breeziness = 0, Noisiness = 0, Cools by = 5.\nDevice - Ceiling Fan- Portable = no, Breeziness = 2, Noisiness = 0, Cools by = 3.\nDevice - Standing Fan- Portable = Yes, Breeziness = 2, Noisiness = 2, Cools by = 1.\n\nDevice Interface\nThe Device interface specifies the following behaviour for a device:\npublic interface Device {\n \n String getID();\n \n boolean isBreezy();\n \n boolean isNoisy();\n \n boolean isOn();\n \n void turnOn();\n \n void turnOff();\n \n int coolsBy();\n \n int getBreeziness();\n \n int getNoisiness();\n \n}\nHeres the specification you HAVE to follow for the room class\nRoom class\nSupply attributes of your own for the Room class which must have the following behaviour:\nMethod Signature - Return Type Purpose\nMethod Signature - Room(int startingTemperature) Purpose - Constructor\nMethod Signature - getDevices( ) Return Type - ArrayList Purpose - Returns an ArrayList of devices\nMethod Signature - addDevice( Device d) Return Type - boolean\nPurpose - Return true if a device was successfully\ninserted into the devices ArrayList, false if the\ndevice already exists in the collection.\nMethod Signature - removeDevice(Device d) Return Type - boolean\nPurpose - Removes a device from the devices ArrayList\nif it is a PortableDevice and returns true, false\notherwise\nMethod Signature - getTemperatureDrop( ) Return Type - int Purpose - Returns the temperature drop produced by all\nof the devices turned on in the room\nMethod Signature - getTemperature( ) Return Type - int Purpose - Returns the temperature of the room (based\non the devices turned on in the room)\nMethod Signature - getBreeziness( ) Return Type - int Purpose - Returns the breeziness of the room (produced\nby the devices turned on in the room)\nMethod Signature - getNoisiness( ) Return Type - int Purpose -Returns the noisiness of the room (produced\nby the devices turned on in the room)\nMethod Signature - printState( ) Return Type - void Purpose- Prints the state of the room and the devices.\nHeres the test cases for the room class\n\nimport static org.junit.Assert.\\*;\nimport org.junit.After;\nimport org.junit.Before;\nimport org.junit.Test;\n\n/\\*\\*\n \\* The test class RoomTest.\n \\*\n \\* @author (your name)\n \\* @version (a version number or a date)\n \\*/\npublic class RoomTest\n{\n private Device ceilingF1;\n private Device standingF1;\n \n private Device aC1;\n private Room room1;\n\n Room room4 = new Room(25);\n Room room = new Room(30);\n Room room2 = new Room(35);\n Room room3 = new Room(37);\n /\\*\\*\n \\* Default constructor for test class RoomTest\n \\*/\n public RoomTest()\n {\n }\n\n /\\*\\*\n \\* Sets up the test fixture.\n \\*\n \\* Called before every test case method.\n \\*/\n @Before\n public void setUp()\n {\n ceilingF1 = new CeilingFan();\n standingF1 = new StandingFan();\n aC1 = new AC();\n room1 = new Room(30);\n }\n\n /\\*\\*\n \\* Tears down the test fixture.\n \\*\n \\* Called after every test case method.\n \\*/\n @After\n public void tearDown()\n {\n }\n\n @Test\n public void testDeviceArrayList(){\n java.util.ArrayList devices =room1.getDevices();\n assertNotNull(devices); \n }\n @Test\n public void testAddDevices(){\n room1.addDevice(ceilingF1);\n room1.addDevice(aC1);\n room1.addDevice(standingF1);\n java.util.ArrayList devices =room1.getDevices();\n assertEquals(3,devices.size());\n \n }\n @Test\n public void testRemoveDevices(){\n room1.addDevice(ceilingF1);\n room1.addDevice(aC1);\n room1.addDevice(standingF1);\n assertFalse(room1.removeDevice(ceilingF1));\n assertFalse(room1.removeDevice(aC1));\n assertTrue(room1.removeDevice(standingF1));\n java.util.ArrayList devices =room1.getDevices();\n assertEquals(2,devices.size());\n \n }\n @Test\n public void testGetDevices()\n {\n room1.addDevice(ceilingF1); \n room1.addDevice(aC1);\n room1.addDevice(standingF1);\n java.util.ArrayList devices = room1.getDevices();\n for(Device d: devices){\n if(d instanceof AC){\n assertEquals(0,d.getBreeziness());\n assertEquals(0,d.getNoisiness());\n }\n if(d instanceof CeilingFan){\n assertEquals(2,d.getBreeziness());\n System.out.println(d.toString());\n assertEquals(0,d.getNoisiness()); \n }\n if(d instanceof StandingFan){\n assertEquals(2,d.getBreeziness());\n assertEquals(2,d.getNoisiness()); \n }\n }\n }\n @Test\n public void testRoomBreeziness()\n {\n room1.addDevice(ceilingF1);\n room1.addDevice(aC1);\n room1.addDevice(standingF1);\n assertEquals(room1.getBreeziness(), 0);\n standingF1.turnOn();\n assertEquals(room1.getBreeziness(), 2);\n ceilingF1.turnOn();\n assertEquals(room1.getBreeziness(), 4);\n aC1.turnOn();\n assertEquals(room1.getBreeziness(), 4);\n }\n \n @Test\n public void testRoomNoisiness()\n {\n room1.addDevice(ceilingF1);\n room1.addDevice(aC1);\n room1.addDevice(standingF1);\n assertEquals(room1.getNoisiness(), 0);\n standingF1.turnOn();\n assertEquals(room1.getNoisiness(), 2);\n ceilingF1.turnOn();\n assertEquals(room1.getNoisiness(), 2);\n aC1.turnOn();\n assertEquals(room1.getNoisiness(), 2);\n }\n @Test\n public void testTemperatureDrop()\n {\n room1.addDevice(ceilingF1);\n room1.addDevice(aC1);\n room1.addDevice(standingF1);\n assertEquals(room1.getTemperatureDrop(), 0);\n standingF1.turnOn();\n assertEquals(room1.getTemperatureDrop(), 1);\n ceilingF1.turnOn();\n assertEquals(room1.getTemperatureDrop(), 4);\n aC1.turnOn();\n assertEquals(room1.getTemperatureDrop(), 9);\n }\n @Test\n public void testTemperatureRise()\n {\n room1.addDevice(ceilingF1);\n room1.addDevice(aC1);\n room1.addDevice(standingF1);\n standingF1.turnOn();\n ceilingF1.turnOn(); \n aC1.turnOn();\n assertEquals(room1.getTemperatureDrop(), 9);\n aC1.turnOff();\n assertEquals(room1.getTemperatureDrop(), 4);\n ceilingF1.turnOff();\n assertEquals(room1.getTemperatureDrop(), 1);\n standingF1.turnOff();\n assertEquals(room1.getTemperatureDrop(), 0);\n }\n @Test\n public void testTemperatureRiseAndFall()\n {\n room1.addDevice(ceilingF1);\n room1.addDevice(aC1);\n room1.addDevice(standingF1);\n standingF1.turnOn();\n ceilingF1.turnOn(); \n assertEquals(room1.getTemperatureDrop(), 4); \n ceilingF1.turnOff();\n assertEquals(room1.getTemperatureDrop(), 1);\n aC1.turnOn();\n assertEquals(room1.getTemperatureDrop(), 6);\n aC1.turnOff();\n standingF1.turnOff();\n assertEquals(room1.getTemperatureDrop(), 0);\n }\n}", "Rewrite, Improve, and expand the following article: \nWhen I hear a prospective client mention that they're interested in \"passive income\" via real estate rentals, my immediate reaction is to try and figure out how deep they\u2019ve actually been hoodwinked by this romanticized pipe dream, and if they\u2019re not too far gone to be saved.\n\nFrom experience, it's just not feasible or appropriate for most of the people that have ever brought it up to me on a first meeting as something they\u2019d like to \u201cget into\u201d. (It's also not necessary....but we'll save that for the end.)\n\nLet's break down why using a real life example.\n\nLet's say you want to buy $500k property in order to turn it into a rental and generate income.\n\nYou will put 20% down and finance the remaining $400,000. So, we'll be taking $100k out of your liquid/investable net worth and moving it into a more illiquid/unavailable vehicle. (We'll come back to this.)\n\n(Of course, there's probably closing costs, advertising costs, some maintenance & fix up work that\u2019s required, furniture refurbishments etc. before you can actually put it out there to rent but let\u2019s assume, to keep it simple, that this is the entire up front cost.)\n\nNow you need to find renters. Let's say you get lucky again and find renters immediately so you have very little time of paying the mortgage without receiving rent back...great!\n\nA 30 year $400,000 mortgage at current 7% rates would run you approximately $2,660 per month. So, naturally, you will need to charge more than that to squeeze out that additional cash flow. But wait. You have to account for property taxes, factor in future vacancy rates, and the maintenance work/fixing costs that will come up over time. All of that, conservatively, means you need to charge about 30% more than the rent in order to break even & \u201crun\u201d the rental.\n\nSo now, just to break even each month, you no longer need to charge $2,660, you actually need to charge $3,459 before you can start feeling like you truly have \u201cextra\u201d income that your family can benefit from. (Yes, generating adequate rental income becomes an even harder proposition in times of high mortgage rates!)\n\nNow let's talk about the \"passive\" part. Are you committed to doing all the work yourself? Are you running the property, advertising to find tenants, showing the property, vetting the applicants, responding to maintenance requests, coordinating the repairs, cleaning & staging before each new guest, answering prospective renter emails, collecting and following up on payments, and dealing with legal if there are issues etc? \n\nYou could do it all\u2026but make no mistake, it is no longer \u201cpassive.\u201d It is a business. Is this what you want to be doing? Is this the best use of your time/energy to maximize your life AND your wealth? Or are you hiring a management company? Because now that's a third party cutting into the margins & the standard property management fees run 10% of your monthly rent\u2026\n\nSo, after all of that, and even assuming EVERYTHING goes right, how much extra \u201cincome\u201d are you really generating here each month that\u2019s above your costs? $200? $300? $500? We locked up $100k of real capital, which is now unavailable to be used for your family\u2019s OTHER short term financial goals & committed your name to a property for MAYBE that amount of cash flow?!\n\n(Necessary caveat: Of course, it is possible to be profitable in real estate rentals and have this all work out beautifully\u2026I\u2019m absolutely not saying it can\u2019t work. But, my own experience with clients tells me that those that do have successful real estate rental properties have a few things in common. 1. They treat it as both a business & and as a job. 2. They have a sizable cash & investment net worth (at least a $1mm+) BEFORE they look to get involved in any capital-intensive real estate projects!) 3. They inherited the properties and it's already operating like a well-oiled machine as a result.)\n\nOk, so you might say, \u201cWell, fine, maybe I'm not generating much free cash now...but so what! I\u2019m basically building up equity in a home and I\u2019m not paying anything out of pocket to do so\u2026my renters are doing that for me\u2026.that\u2019s a win. I just get to own the house!\u201d\n\nSo, this takes us to the second reason that passive real estate investing isn\u2019t usually as great as it\u2019s chalked up to be.\n\nBuilding up that equity in your house is not costing you NOTHING. It\u2019s costing you the opportunity cost of not doing SOMETHING ELSE... with that initial $100,000 down payment and the $2,660 (plus property taxes, maintenance, vacancy fees etc.) every single month! What else could that money be doing instead of sitting in your new real estate venture? Put even more directly, is the capital outlay ultimately going to appreciate at a better rate than if you had invested that same amount elsewhere?\n\nLet\u2019s see: The S&P 500, representing the stock market as an asset class, has averaged a 10% annualized rate of return over the last 50 years. Housing has gone up about 3.5% in comparison. At these two historical rates, $100,000 put into the capital markets will equal about $1.8mm in 30 years whereas that same $100,000 put into the house on day 1 will be worth approximately $324k when you\u2019re ready to sell in 30 years. (The difference in rate of return on the full purchase price and it\u2019s opportunity cost are even more dramatic.) And that\u2019s not even taking into account that along the way, you have paid property taxes, maintenance fees, housing insurance, liability insurance, normal upkeep costs, home improvements etc.\u2026all of which dramatically lower that 3.5% even further but doesn\u2019t show up in the price when it comes time to sell.\n\nBy \u201cinvesting\u201d in real estate, you\u2019re giving up some dramatic capital appreciation in the hopes that the positive cash flow you generate in income will make up the shortfall? (I\u2019m guessing here as, again, this is not something I would ever do.) There\u2019s a reason that we tell clients (with regards to your primary home) that your home is not an investment\u2026it\u2019s a place to live!\n\nHere\u2019s what it boils down to me though, more than the numbers, the opportunity cost or anything else.\n\nThe hassle and \u201cworst case scenario\u201d potential.\n\nLike it or not, when you buy & mortgage a home, whether it\u2019s a primary, a rental, or a vacation home - you are adding a liability to your net worth. You are hoping (and assuming) that you will generate enough rent to offset that liability\u2026.but that mortgage bill is coming every single month. You are responsible for paying back that $400,000 mortgage loan whether or not you have stable renters\u2026.it is your liability alone.\n\nYou are also responsible when a roof leaks, when there\u2019s a water issue, when a tenant wants to get out of their lease early, when 3 nicer Airbnb\u2019s pop up next to you, etc.\n\nThere is so much that CAN go wrong that\u2019s out of your control that can devastate even the mediocre returns that you\u2019re hoping to achieve.\n\nI just simply cannot fathom taking on all of the headaches and hassles that real estate can create for you for the sort of returns we\u2019re discussing.\n\nInstead, I can take that $100,000 and add it into my broadly diversified investment portfolio of the greatest companies of America and the world, which has been growing, consistently, at a 10% clip.\n\nThere is no maintenance or labor to speak of. There are no property taxes or annoying tenants. There is no \u201cnightmare\u201d scenario in which I lose all of my investment (as stock market declines have only every proven to be temporary - any losses I incur over time would be as a result of my own behavior/decision to sell. The market itself cannot create this loss for me\u2026unlike real estate transactions & real property liabilities).\n\nThen, as I get closer to retirement, and I\u2019m starting to focus more on my need to replace my earned income with \u201cpassive\u201d income, I can do a whole lot of things.\n\nI will start drawing down first from the dividends my portfolio has been re-investing for the past 20 years. Then, I will start drawing down principal (which will be made up for the fact that my portfolio is still growing & thus replacing the withdrawals), and then, I will use protected income vehicles like living benefit annuities, cash value insurance, and dividend focused stock market portfolios to enhance the guaranteed portion of my income and protect myself in times of down markets.\n\nI think so many people default to wanting \u201cpassive income\u201d via rental properties because it seems \u201ceasy\u201d. We all go on vacations. We all understand how it would work to collect a monthly check. On the flip side, NOBODY understands the mechanics of income distribution from one\u2019s investment & retirement portfolios. It\u2019s just not something we learn.\n\nThe irony is that THIS is the EASY way to grow your net worth and create a future income stream that isn\u2019t dependent upon the sweat of your brow. This is the way to build up a large enough net worth that you CAN actually live off of your savings & investment returns down the road.\n\nIt\u2019s called capital investing.\n\nThe CEO\u2019s of the greatest companies of America and the world are allowing you to share proportionally in the growth of their companies without having to justify your returns and without having to share any of your labor, time, or energy to do so. You get to share in the growth of the companies that move the economy forward just by being a common shareholder.\n\nThat is passive income. But it takes patience, discipline, and the behavioral fortitude to favor long term wealth over making a quick buck", "Context:\nAct - I\nThe play opens with worship to Lord Ganesha. Bhagwata comes to the stage. He is a character in the Play and also is the narrator of the play. He seeks blessings from Lord Ganesha for the successful performance of the play. Through his narration, he takes the audience to a place, called as Dharampur and introduces the audience to the king Dharmsheel. Then he puts up some rhetorical questions on incompleteness of man and God; and also on the perfection of a man. During his narration, he introduces two characters who are mutual friends. The first one is Devdutta. He is a sharp minded and highly intellectual person. He has defeated poets and Pandits with his knowledge. He is a son of Brahmin. The second one is Kapila. He is a muscular man. He has a great physical strength and he is a son of Lohar (Black Smith). Both Devdutta and Kapila are in contrast as the former lacks power and strength, the latter lacks knowledge and intellectual. According to the playwright, the head of Devdutta (knowledge) and the body of Kapila (physical strength) accomplish a complete man. The narrator compares their pair to the pair of Ram-Laxman, Luv-Kush and Krishna-Balram. All these are the pairs of great brothers in Hindu mythology.\n\nA character, Actor-1 appears on the stage shouting and running towards Bhagwata. He tells Bhagwata that he has just seen a strange creature that looks like a horse (by face) but speaks like a man. That creature has the head of a horse and the rest of the body of a man. Without paying any heed to his talks, Bhagwata asks him to get ready for the play. But he runs away from the stage and soon after he comes back shouting again. Now a strange creature appears on the stage. As earlier described by the Actor-1, the creature has the head of a horse and the body of a man. For a moment, Bhagwata thinks that someone is wearing the mask of horse. He tries to remove the mask but realizes that it is truly half a man and a half horse. Now the creature starts to introduce itself before Bhagwata, Actor-1 and the audience.\n\nThe creature introduces himself as Hayavadana and starts to narrate his story. He tells that once upon a time, a princess had to choose a groom for her marriage. So many Princes approached from far and wide. But the princess fell in love with a horse of an Arabian Prince. She became desperate to marry that horse. Eventually her parents allowed her to do so. She was married to the horse. After 15 years of their marriage, the horse transformed into a celestial being. Now the princess rejected him as her husband. That celestial being cursed her to be a Mare (female horse) and she became so. The princess give birth to Hayavadana. Now Hayavadana wants to get rid of this cursed life. Bhagwata asks him to go to goddess Kali temple in chitrkut. He also asks the Actor-1 to accompany him on the way. They leave.\n\nNow Bhagwata moves ahead with the story of the play. Devdutta and Kapila appear on the stage. Devdutta tells Kapila that he wants to marry a woman, namely Padmini. With utmost desire to marry Padmini, he pledges to sacrifice his arms to Goddess Kali and his head to Rudra. Kapila goes to Padmini and presents the Proposal to marry Devdutta. Devdatta and Padmini Marry. By the time, Devdutta realizes that Padmini is attracted towards Kapila and vice versa. Now Padmini is pregnant. Devdutta knowingly tries to put off the program of visiting Ujjain. He tells Kapila that Padmini is ill. But Padmini gives her consent before Kapila. They all three leave for Ujjain. Padmini repeatedly praises Kapila's physical strength before Devdutta. Devdutta feels jealous but he does not blame Padmini. Kapila and Padmini go to Rudra Temple but Devdutta denies to accompany them. Devdutta knows that Kapila has such a physical strength and beauty that any woman can get attracted towards him. Devdutta goes to goddess Kali temple where he reminds himself of his pledge to sacrifice his head to the Goddess Kali. He Wishes for the Wellness of Kapila and Padmini. He beheads himself with a sword and dies.\n\nMeanwhile, Kapila and Padmini come out of the temple. Kapila gets worried on finding Devdutta nowhere. He leaves Padmini and starts searching for his friend. Finally he reaches in the same Temple and feels shocked to see his friend dead. He feels himself responsible for all this. Kapila takes the same sword and beheads himself. Soon Padmini reaches there and she has no clue how they got died. She considers herself responsible for the duel between the two friends and their deaths. She provokes the Goddess Kali and also tries to kill herself. The Goddess Kali appears and stops her. The Goddess asks her to place the heads with their respective body so that the Goddess will re-join them with her magical powers and bring them back to life. The Goddess also appreciates the two friends. Padmini follows the command in a hurry. The Goddess disappears. Padmini, being thankful to goddess kali, gets a bit relaxed. But soon she realizes her mistake. She has mistakenly placed the heads with irrespective body. So now Devdutta's head is joined with Kapila's body and vice versa. Soon they regain their senses. For a moment, the two friends are confused. Both make a claim for Padmini. The man with Devdutta's head, makes a plea that head is the master of the body. So he has the right over Padmini. The man with Kapila's head makes a plea that Padmini has remained with Devdutta's body. So he has the right over Padmini. Meanwhile Bhagwata, the narrator, comes on the stage. All the characters become statues for a moment and the narrator addresses the audience. He asks them to think of a solution to this problem. Act 1 ends.[7]\n\nAct - II\nThe act begins as the narrator repeats the same question- \" What is the solution? \". He also talks about the story of \u2032Vikramaditya and Betaal\u2032 [8] where the king Vikrama replies to Betaal that the mind (head) is the master of the body. It is head that gives recognition to an individual. Bhagwata tells that they all three go to a hermit seeking solution for this problem. The words of hermit are heard on the stage that Devdutta's head is the Swami (husband) of Padmini. Devdutta and Padmini accept this in delight. Kapila, being disappointed, leaves for the forest. The time passes. Devdutta brings some dolls. These dolls also play the role of narrator. He starts losing his physical strength and as a result they are losing mutual interest. A child is born. Devduta goes to buy new dolls from the fair in Ujjain. Bhagwata again appears on the stage and tells that Kapila has regained his physical strength. Padmini meets him in the forest and also tell him that it is Kapila's son as it is born from Kapila's body. But Kapila does not accept it. Being a little reluctant, they get ready to fulfill their physical desires.\n\nIn search of his wife, Devdutta reaches there in the forest. Finding them together, he finds himself the similar situation as he was before. To put an Ultimate end to this problem, Devdutta takes out the sword and challenges Kapila for a duel. Both gets killed. Padmini finds herself lonely. Bhagwata comes there and she hands him over the child and the same dolls. She asks him to hand it over to Devdutta's Brahmin father Vidyasagar after five years. She leaves the stage by declaring that she is going to perform Sati. Bhagwata decides to end the play with his speech. A loud shout is heard on the stage. Actor-1 comes and claims that he has heard Hayavadana chanting National Anthem and patriotic songs. Then Actor-2 appears with Devdutta's son of age 5 now. The boy has two dolls. Hayavadana comes there. Bhagwata and Actor-2 are talking lightly and creating fun. They all starts laughing. That boy too starts laughing and the dolls slip out of his hand. Bhagwata says that the boy hasn't expressed any emotions of happiness, anger, sorrow in past 5 years. Today he is smiling just because of Hayavadana.\n\nNow Hayavadana tells his story. when he was trying to behead himself in the temple, the goddess Kali appeared. Hayavadana tells his desire. The goddess Kali without listening to him fully, gives him blessings. Hayavadana becomes a complete Horse instead of becoming a complete man. Yet he is satisfied. He still has ability to speak like a man. He wants to lose this voice. He is singing national Anthem as he believes that people who sing national anthem, lose their voice early. Meanwhile he sobs. The boy starts singing a tragic song which was chanted by his mother, Padmini. Hayavadana tries to laugh and his voice completely changes into a horse'. Now Hayavadana is a complete horse.\n\nBhagwata asks the Actor to go to brahmin Vidyasagar and inform him that his grandson is coming to him, riding on a great horse. Bhagwata thanks Lord Ganesha for the successful performance of the play.\n\nAim: Write a critique and summary without revealing the entire story", "import numpy as np\nminicolumn=12\ncell=4\nsegment=5\nthreshold=0.9\nthresholdcount=1\n #activation matrix initialization\na = np.zeros((minicolumn,cell ))\nprediction= np.zeros((minicolumn,cell ))\npermanence= np.random.rand(minicolumn,cell,segment,minicolumn,cell )\nconnection=np.where(permanence > threshold, 1, 0)\ns=np.zeros((minicolumn,cell,segment),dtype = int)\ns=s-1\nimport numpy as np\nsample=1000\nsequencelength=3\ninput=np.zeros((sample,sequencelength),dtype=int)\ndummy=np.array([[1,2,3],[6,2,7],[9,3,4]])\nfor i in range (0,sample):\n random=np.random.randint(0,2)\n input[i,:]=dummy[random,:]\ninput\n\ndef winner(i,j,input):\n R=np.array([0])\n R[:]=input[i,j]\n return R\nwinner(1,2,input)\n\ndef predict(connection,permanence,minicolumn,cell,segment,threshold,thresholdcount,prediction,a):\n \n s=np.zeros((minicolumn,cell,segment))\n s=s-1\n #prediction of cell\n #reset prediciton matrix first\n prediction= np.zeros((minicolumn,cell ),dtype = int)\n for y in range(0,minicolumn):\n for u in range(0,cell):\n flag=0\n o=0\n for m in range(0,segment):\n sum=0;\n for y2 in range(0,minicolumn):\n for j2 in range(0,cell):\n if a[y2,j2]== 1 and connection[y2,j2,m,y,u]==1:\n sum=sum+1\n if sum>thresholdcount:\n flag=1\n s[y,u,o]=m\n o=o+1\n if flag==1:\n prediction[y,u]=1\n return prediction\n\ndef delearning(minicolumn,prediction,permanence,a,cell,segment,la,s):\n for j in range(0,minicolumn):\n for k in range(0,cell):\n if (prediction[j,k]==1 and a[j,k]==0):\n for e in s[j,k,:]:\n e=int(e)\n if (e>-1):\n for M in range(0,minicolumn):\n for f in range(0,cell):\n if la[M,f]==1:\n diff=permanence[M,f,e,j,k]\\*0.3\n permanence[M,f,e,j,k]=permanence[M,f,e,j,k] - diff \n return permanence \ndef synaptic\\_learning(permanence,connection,minicolumn,cell,segment,a,j1,W,prediction,s):\n #synaptic Learning if not first element of a sequence\n outputcount=0\n for j in W:\n count=0\n for k2 in range(0,cell):\n if prediction[j,k2]==1:\n count=count+1\n if count>0:\n #synaptic Learning of prediciton\n for k in range(0,cell):\n if (prediction[j,k]==1 and a[j,k]==1) :\n outputcount=outputcount+1\n for e in s[j,k,:]:\n e=int(e)\n if e>-1:\n for M in range(0,minicolumn):\n for f in range(0,cell):\n if la[M,f]==1:\n diff=(1-permanence[M,f,e,j,k])\\*0.3\n diff1=(1-permanence[M,f,e,j,k])\\*0.1\n permanence[M,f,e,j,k]=permanence[M,f,e,j,k] + diff-diff1\n else:\n diff=(1-permanence[M,f,e,j,k])\\*0.3\n permanence[M,f,e,j,k]=permanence[M,f,e,j,k] - diff \n else:\n #synaptic Learning if no prediciton choose one cell having segment is having highest value\n segcount=np.zeros(cell,dtype=int)\n seg1=np.zeros(cell,dtype=int)\n for h in range(0,cell):\n segcount[h]=0\n max=-1\n for h1 in range(0,segment):\n sum=0;\n for b in range(0,minicolumn):\n for b1 in range(0,cell):\n if connection[b,b1,h1,j,h]==1 and la[b,b1]==1:\n sum=sum+1\n if max<=sum:\n max=sum\n seg1[h]=h1\n segcount[h]=max\n \n index\\_cell=np.argmax(segcount)\n for g in range(0,cell):\n if g==index\\_cell:\n for b in range(0,minicolumn):\n for b1 in range(0,cell):\n segmentforlearning=seg1[index\\_cell]\n if la[b,b1]==1:\n diff=(1-permanence[b,b1,segmentforlearning,j,g])\\*0.6\n diff1=(1-permanence[b,b1,segmentforlearning,j,g])\\*0.001\n permanence[b,b1,segmentforlearning,j,g]=permanence[b,b1,segmentforlearning,j,g] + diff-diff1\n else:\n diff=permanence[b,b1,segmentforlearning,j,g]\\*0.6\n permanence[b,b1,segmentforlearning,j,g]=permanence[b,b1,segmentforlearning,j,g] - diff \n else:\n for b in range(0,minicolumn):\n for b1 in range(0,cell):\n if la[b,b1]==1:\n for g1 in range(0,segment):\n diff=permanence[b,b1,g1,j,g]\\*0.6\n permanence[b,b1,g1,j,g]=permanence[b,b1,g1,j,g] - diff\n \n return [permanence,outputcount] \ndef activation (j1,connection,minicolumn,cell,segment,a,W,prediction):\n if j1==0:\n for j in W:\n a[j,:]=1\n else:\n for j in W:\n count=0\n for k in range(0,cell):\n if prediction[j,k]==1:\n a[j,k]=1\n count=count+1\n if count==0:\n a[j,:]=1\n return prediction\noutput1=np.zeros(1000)\n(l,l2)=input.shape\nfor i in range(0,l):\n a = np.zeros((minicolumn,cell ))\n for j1 in range(0,l2):\n W=winner(i,j1,input)\n la=a\n a = np.zeros((minicolumn,cell ))\n activation(j1,connection,minicolumn,cell,segment,a,W,prediction)\n if j1!=0:\n [permanence,output1[i]]=synaptic\\_learning(permanence,connection,minicolumn,cell,segment,a,j1,W,prediction,s)\n permanence=delearning(minicolumn,prediction,permanence,a,cell,segment,la,s)\n connection=np.where(permanence > threshold, 1, 0)\n prediction=np.zeros((minicolumn,cell ))\n prediction=predict(connection,permanence,minicolumn,cell,segment,threshold,thresholdcount,prediction,a)\n \n else:\n prediction=np.zeros((minicolumn,cell ))\n prediction=predict(connection,permanence,minicolumn,cell,segment,threshold,thresholdcount,prediction,a)\nimport matplotlib.pyplot as plt\n\np=np.zeros(1000,dtype=int)\nfor i in range(1,999):\n p[i]=i\nplt.plot(p,output1)\nplt.xlabel('x-values')\nplt.ylabel('x^2-values')\n\nplt.show()\nplt.show()\n\nnegativecount=0\nthresholdcount=1\ntotalcount=0\ncorrect=0\n(t1,t2)=input.shape\noutput=np.zeros((t2))\nrecall=np.zeros((t1))\noutput=output-1\ncorrect=0\nsequence\\_prediction=0\nfor i in range(0,t1):\n classification=0\n for j in range(0,t2):\n if j ==0:\n W= winner(i,j,input)\n for k in W:\n a[k,:]=1\n else:\n \n prediction =np.zeros((minicolumn,cell))\n \n#prediciton\n \n for k1 in range(0,minicolumn):\n flag=0\n for k2 in range(0,cell):\n o=0\n for k3 in range (0,segment):\n count=0\n for k in range (0,minicolumn):\n for k4 in range(0,cell):\n if connection[k,k4,k3,k1,k2]==1 and a[k,k4]==1:\n count=count+1\n if count>thresholdcount:\n prediction[k1,k2]=1\n a=np.zeros((minicolumn,cell))\n #check for correct predicted column\n bigflag=0\n for k1 in range(0,minicolumn):\n flag=0\n for k2 in range(0,cell):\n if prediction[k1,k2]==1:\n flag=1\n if flag==1:\n print(k1)\n if flag==1 and input[i,j+1]==k1:\n correct=correct+1\n \n bigflag=1\n for k2 in range(0,cell):\n if prediction[k1,k2]==1:\n a[k1,k2]=1\n \n #\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\* \n if bigflag==0:\n negativecount=negativecount+(t2-(j+2))\n break \n \nprecision1=correct/(t1\\*(t2-1))\n \n\nnegativecount\n\nprecision1=correct/((t1\\*(t2-1))-negativecount)\nprecision1\n\ngive a long descriptive explantion for above code", "import numpy as np\nminicolumn=12\ncell=4\nsegment=5\nthreshold=0.9\nthresholdcount=1\n #activation matrix initialization\na = np.zeros((minicolumn,cell ))\nprediction= np.zeros((minicolumn,cell ))\npermanence= np.random.rand(minicolumn,cell,segment,minicolumn,cell )\nconnection=np.where(permanence > threshold, 1, 0)\ns=np.zeros((minicolumn,cell,segment),dtype = int)\ns=s-1\nimport numpy as np\nsample=1000\nsequencelength=3\ninput=np.zeros((sample,sequencelength),dtype=int)\ndummy=np.array([[1,2,3],[6,2,7],[9,3,4]])\nfor i in range (0,sample):\n random=np.random.randint(0,2)\n input[i,:]=dummy[random,:]\ninput\n\ndef winner(i,j,input):\n R=np.array([0])\n R[:]=input[i,j]\n return R\nwinner(1,2,input)\n\ndef predict(connection,permanence,minicolumn,cell,segment,threshold,thresholdcount,prediction,a):\n \n s=np.zeros((minicolumn,cell,segment))\n s=s-1\n #prediction of cell\n #reset prediciton matrix first\n prediction= np.zeros((minicolumn,cell ),dtype = int)\n for y in range(0,minicolumn):\n for u in range(0,cell):\n flag=0\n o=0\n for m in range(0,segment):\n sum=0;\n for y2 in range(0,minicolumn):\n for j2 in range(0,cell):\n if a[y2,j2]== 1 and connection[y2,j2,m,y,u]==1:\n sum=sum+1\n if sum>thresholdcount:\n flag=1\n s[y,u,o]=m\n o=o+1\n if flag==1:\n prediction[y,u]=1\n return prediction\n\ndef delearning(minicolumn,prediction,permanence,a,cell,segment,la,s):\n for j in range(0,minicolumn):\n for k in range(0,cell):\n if (prediction[j,k]==1 and a[j,k]==0):\n for e in s[j,k,:]:\n e=int(e)\n if (e>-1):\n for M in range(0,minicolumn):\n for f in range(0,cell):\n if la[M,f]==1:\n diff=permanence[M,f,e,j,k]\\*0.3\n permanence[M,f,e,j,k]=permanence[M,f,e,j,k] - diff \n return permanence \ndef synaptic\\_learning(permanence,connection,minicolumn,cell,segment,a,j1,W,prediction,s):\n #synaptic Learning if not first element of a sequence\n outputcount=0\n for j in W:\n count=0\n for k2 in range(0,cell):\n if prediction[j,k2]==1:\n count=count+1\n if count>0:\n #synaptic Learning of prediciton\n for k in range(0,cell):\n if (prediction[j,k]==1 and a[j,k]==1) :\n outputcount=outputcount+1\n for e in s[j,k,:]:\n e=int(e)\n if e>-1:\n for M in range(0,minicolumn):\n for f in range(0,cell):\n if la[M,f]==1:\n diff=(1-permanence[M,f,e,j,k])\\*0.3\n diff1=(1-permanence[M,f,e,j,k])\\*0.1\n permanence[M,f,e,j,k]=permanence[M,f,e,j,k] + diff-diff1\n else:\n diff=(1-permanence[M,f,e,j,k])\\*0.3\n permanence[M,f,e,j,k]=permanence[M,f,e,j,k] - diff \n else:\n #synaptic Learning if no prediciton choose one cell having segment is having highest value\n segcount=np.zeros(cell,dtype=int)\n seg1=np.zeros(cell,dtype=int)\n for h in range(0,cell):\n segcount[h]=0\n max=-1\n for h1 in range(0,segment):\n sum=0;\n for b in range(0,minicolumn):\n for b1 in range(0,cell):\n if connection[b,b1,h1,j,h]==1 and la[b,b1]==1:\n sum=sum+1\n if max<=sum:\n max=sum\n seg1[h]=h1\n segcount[h]=max\n \n index\\_cell=np.argmax(segcount)\n for g in range(0,cell):\n if g==index\\_cell:\n for b in range(0,minicolumn):\n for b1 in range(0,cell):\n segmentforlearning=seg1[index\\_cell]\n if la[b,b1]==1:\n diff=(1-permanence[b,b1,segmentforlearning,j,g])\\*0.6\n diff1=(1-permanence[b,b1,segmentforlearning,j,g])\\*0.001\n permanence[b,b1,segmentforlearning,j,g]=permanence[b,b1,segmentforlearning,j,g] + diff-diff1\n else:\n diff=permanence[b,b1,segmentforlearning,j,g]\\*0.6\n permanence[b,b1,segmentforlearning,j,g]=permanence[b,b1,segmentforlearning,j,g] - diff \n else:\n for b in range(0,minicolumn):\n for b1 in range(0,cell):\n if la[b,b1]==1:\n for g1 in range(0,segment):\n diff=permanence[b,b1,g1,j,g]\\*0.6\n permanence[b,b1,g1,j,g]=permanence[b,b1,g1,j,g] - diff\n \n return [permanence,outputcount] \ndef activation (j1,connection,minicolumn,cell,segment,a,W,prediction):\n if j1==0:\n for j in W:\n a[j,:]=1\n else:\n for j in W:\n count=0\n for k in range(0,cell):\n if prediction[j,k]==1:\n a[j,k]=1\n count=count+1\n if count==0:\n a[j,:]=1\n return prediction\noutput1=np.zeros(1000)\n(l,l2)=input.shape\nfor i in range(0,l):\n a = np.zeros((minicolumn,cell ))\n for j1 in range(0,l2):\n W=winner(i,j1,input)\n la=a\n a = np.zeros((minicolumn,cell ))\n activation(j1,connection,minicolumn,cell,segment,a,W,prediction)\n if j1!=0:\n [permanence,output1[i]]=synaptic\\_learning(permanence,connection,minicolumn,cell,segment,a,j1,W,prediction,s)\n permanence=delearning(minicolumn,prediction,permanence,a,cell,segment,la,s)\n connection=np.where(permanence > threshold, 1, 0)\n prediction=np.zeros((minicolumn,cell ))\n prediction=predict(connection,permanence,minicolumn,cell,segment,threshold,thresholdcount,prediction,a)\n \n else:\n prediction=np.zeros((minicolumn,cell ))\n prediction=predict(connection,permanence,minicolumn,cell,segment,threshold,thresholdcount,prediction,a)\nimport matplotlib.pyplot as plt\n\np=np.zeros(1000,dtype=int)\nfor i in range(1,999):\n p[i]=i\nplt.plot(p,output1)\nplt.xlabel('x-values')\nplt.ylabel('x^2-values')\n\nplt.show()\nplt.show()\n\nnegativecount=0\nthresholdcount=1\ntotalcount=0\ncorrect=0\n(t1,t2)=input.shape\noutput=np.zeros((t2))\nrecall=np.zeros((t1))\noutput=output-1\ncorrect=0\nsequence\\_prediction=0\nfor i in range(0,t1):\n classification=0\n for j in range(0,t2):\n if j ==0:\n W= winner(i,j,input)\n for k in W:\n a[k,:]=1\n else:\n \n prediction =np.zeros((minicolumn,cell))\n \n#prediciton\n \n for k1 in range(0,minicolumn):\n flag=0\n for k2 in range(0,cell):\n o=0\n for k3 in range (0,segment):\n count=0\n for k in range (0,minicolumn):\n for k4 in range(0,cell):\n if connection[k,k4,k3,k1,k2]==1 and a[k,k4]==1:\n count=count+1\n if count>thresholdcount:\n prediction[k1,k2]=1\n a=np.zeros((minicolumn,cell))\n #check for correct predicted column\n bigflag=0\n for k1 in range(0,minicolumn):\n flag=0\n for k2 in range(0,cell):\n if prediction[k1,k2]==1:\n flag=1\n if flag==1:\n print(k1)\n if flag==1 and input[i,j+1]==k1:\n correct=correct+1\n \n bigflag=1\n for k2 in range(0,cell):\n if prediction[k1,k2]==1:\n a[k1,k2]=1\n \n #\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\* \n if bigflag==0:\n negativecount=negativecount+(t2-(j+2))\n break \n \nprecision1=correct/(t1\\*(t2-1))\n \n\nnegativecount\n\nprecision1=correct/((t1\\*(t2-1))-negativecount)\nprecision1\n\nwhat are input variables in above code and thier role in long description", "Monthly Distribution Locations\nBerkshire County\nLocation\n Address\n Date\n Time\n Contact\nAdams Visitor Center\n 3 Hoosac St. Adams\n 4th Fri\n 12:30 \u2013 1:3o p.m.\n (413)743-8333\nClaire Teague Senior Center\n 917 South Main St. Great Barrington\n 2nd Weds\n 1 \u2013 3 p.m.\n (413)528-1881\nLee Council on Aging\n 21 Crossway St. Lee\n 2nd Weds\n 12 p.m.\n (413)247-9738\nLenox Community Center\n 65 Walker St. Lenox\n 2nd Weds\n 11:30 a.m. \u2013 12:30 p.m.\n (413)637-5535\nMary Spitzer Center\n 116 Ashland St. North Adams\n 4th Fri\n 12:30 \u2013 1:30 p.m.\n (413)662-3125\nOtis Town Hall\n 1 N Main Rd. Otis\n 3rd Fri\n 11am \u2013 12 p.m.\nRalph J. Froio Senior Center\n 330 North St. Pittsfield\n 4th Fri\n 10:30 \u2013 11:30 a.m.\n (413)499-9346\nHeaton Court\n 5 Pine St. Stockbridge\n 2nd Weds\n 11 a.m. \u2013 12 p.m.\n (413)298-4170\nFranklin County\nLocation\n Address\n Date\n Time\n Contact\nAthol Senior Center\n 82 Freedom St. Athol\n 3rd Weds.\n 11:30 a.m. \u2013 12 p.m.\n (978)249-8986\nCharlemont Senior Center\n 175 Main St. Charlemont\n 3rd Weds.\n 12:30 \u2013 1:00 p.m.\n (413)339-5324\nDeerfield Town Hall\n 8 Conway St. South Deerfield\n 1st Thurs\n 12:30 \u2013 1:30 p.m.\n (413)665-2141\nErving Senior Center\n 1 Care Dr. Erving\n 1st Thurs.\n 10:30 \u2013 11:30 a.m.\n (413)423-3649\nGreenfield Senior Center\n 35 Pleasant St. Greenfield\n 1st Thurs.\n 10 \u2013 11 a.m.\n (413)772-1517\nMontague Senior Center\n 62 5th St. Turners Falls\n 1st Thurs.\n 10:30 a.m. \u2013 12 p.m.\n (413)863-9357\nNorthfield Town Hall\n 69 Main St. Northfield\n 1st Thurs.\n 12:30 \u2013 2 p.m.\n (413)498-2186\nOrange Senior Center\n 135 East Main St. Orange\n 3rd Weds\n 11am \u2013 12 p.m.\n (978)544-1113\nShelburne Falls Senior Center\n 7 Main St. Shelburne Falls\n 3rd Weds\n 12 \u2013 1 p.m.\n (413)625-2502\nHampden County\nLocation\n Address\n Date\n Time\n Contact\nAgawam Council on Aging\n 954 Main Street Agawam\n 3rd Thurs.\n 2 \u2013 2:30 p.m.\n (413) 821-0604\nBrimfield Senior Center\n 20 Main St. Brimfield\n Fri after 2nd Thurs\n 9 a.m. \u2013 1 p.m.\n (413)245-7253(Cancelled for the month of May)\nChester Town Hall\n 15 Middlefield Rd. Chester\n 3rd Fri\n 10:30 \u2013 11:30 a.m.\n (413)354-7735\nChicopee Moose Family Center\n 244 Fuller Rd. Chicopee\n 3rd Tues\n 12 \u2013 1 p.m.\n (413)538-9020\nMcKinley House Community Room\n 38 Asinof Ave Chicopee\n 3rd Tues\n 12 \u2013 1 p.m.\n (413)594-1929\nForest Park Manor\n 25 Barney Avenue Springfield\n 2nd Fri\n 2 \u2013 4 p.m.\n (413)785-5019\nGranville\n 85 Sodom St. Granville\n Sat after 2nd Tues\n 9 \u2013 11 a.m.\n (413)214-2686 (Closed until further notice)\nHampden Senior Center\n 104 Allen St. Hampden\n 3rd Wed\n 9:30-10:30am\n (413) 566-5588\nHolyoke Council on Aging\n 291 Pine St. Holyoke\n 4th Tues\n 2:15 \u2013 3:15 p.m.\n (413)322-5625\nIndian Orchard Citizens Council\n 117 Main St. Indian Orchard\n 1st Fri\n 12 \u2013 1 p.m.\n (413)301-5213\nLudlow Senior Center\n 37 Chestnut St. Ludlow\n 3rd Tues\n 1 \u2013 3 p.m.\n (413)583-3564\nPalmer Council on Aging\n 1029 Central St. Palmer\n 2nd Fri\n 10:30 \u2013 11:30 a.m.\n (413)283-2670\nRussell Town Hall\n 60 Main St. Russell\n 3rd Fri\n 10:30 \u2013 11:30 a.m.\n (413)862-6202\nSouthwick Senior Center\n 458 College Hwy. Southwick\n 3rd Tues\n 10:30 \u2013 11:30 a.m.\n (413)569-5498\nEdgewater Apts. Community Room\n 101 Lowell St. Springfield\n 4th Tues\n 11 a.m. \u2013 4 p.m.\n (413)781-4941\nR A Jordan Senior Center\n 1476 Roosevelt Ave Springfield\n 3rd Thurs\n 10:00 a.m. \u2013 12:00 p.m.\n (413) 787-6785\nRiverview Senior Center\n 310 Plainfield St. Springfield\n 4th Tues\n 12 \u2013 1:30 p.m\n (413)739-7211\nSpringfield Tri-Towers\n 18 Saab Ct. Springfield\n 4th Tues\n 11:15 a.m. \u2013 12:30 p.m.\n (413)747-0127 (Cancelled Until Further Notice)\nSeniority House (Satellite of Saab Court)\n 307 Chestnut St. Springfield\n 4th Tues\n 10:30 a.m.- 12 p.m.\nUrban League\n 1 Federal Street Springfield\n 1st Fri\n 12 \u2013 1 p.m.\n (413)739-7211\nWashington House\n 16 Washington St. Westfield\n 2nd Tues\n 11 a.m.-1 p.m.\nWestfield Senior Center\n 45 Noble St. Westfield\n Wed. after 2nd Tues.\n 9-10 a.m.\n (413)562-6435\nWest Springfield Mercy Life\n 2112 Riverdale St. West Springfield\n 3rd Fri\n 1:30 \u2013 2:30 p.m.\n (413)827-4372\nWilbraham Senior Center\n 45B Post Office Park Wilbraham\n 3rd Fri\n 1-2 p.m.\n (413)596-8379\nHampshire County\nLocation\n Address\n Date\n Time\n Contact\nBangs Center\n 70 Boltwood Walk Amherst\n 1st Thurs.\n 1:30 \u2013 4:00 p.m.\n (413)259-3060\nBelchertown Senior Center\n 60 State St. Belchertown\n 2nd Fri\n 10:30 \u2013 11:30 a.m.\n (413)323-0420\nChesterfield Senior Center\n 400 Main Rd. Chesterfield\n 2nd Thurs\n 11 a.m. \u2013 12 p.m.\n (413)296-4007\nEasthampton Community Center\n 12 Clark St. Easthampton\n 1st Tues.\n 10:30 a.m. \u2013 12:30 p.m.\n (413)527-5240\nGranby Senior Center\n 10 West State St. Granby\n 3rd Tues.\n 10:30 a.m.\n (413)467-3239\nHadley Senior Community Center\n 46 Middle St. Hadley\n 3rd Thurs\n 10 \u2013 11 a.m.\n (413)586-4023\nHatfield Senior Center\n 59 Main St. Hatfield\n 1st Tues.\n 10 \u2013 11:30 a.m.\n (413)247-9003\nStanton Hall\n 26 Russell Rd. Huntington\n 3rd Fri\n 10 \u2013 11:30 a.m.\n (413)512-5125\nNorthampton Senior Center\n 67 Conz St. Northampton\n 2nd Thurs\n 10 \u2013 11 a.m.\n (413)587-1228\nSouth Hadley Council on Aging\n 45 Dayton St. South Hadley\n 3rd Tues\n 10 \u2013 11 a.m.\n (413)538-5042\nWare Senior Center\n 1 Robbins Rd. Ware\n 2nd Fri\n 11 a.m. \u2013 12 p.m.\n (413)967-9645\nWilliamsburg Senior Center\n 141 Main St. Haydenville\n 2nd Thurs\n 10 \u2013 11:30 a.m.\n (413)268-8407\n\n When can we get food around Berkshire?", "Write me a title for this article:\nAs a homeowner in NSW, it's vital to understand the legal mechanisms governing contractual obligations transfer. One such mechanism is Deed of Novation, useful when businesses change name or transfer contracts to third parties. This article explores Deed of Novation's definition, its importance to homeowners, and its differences from other legal mechanisms. By the end, you'll have a better understanding of Deed of Novation's relevance to homeowners in NSW.\nWhat is a Deed of Novation?\nA deed of novation is a legal document that allows one party to transfer its rights and obligations under an existing contract to a new party, who takes on these responsibilities and benefits from the original contract. This document enables the original party to be released from the contract while the new party assumes all legal obligations and rights under the agreement. \n\nNovation is typically used when a business undergoes significant changes such as mergers, acquisitions, or restructuring, and there is a need to transfer existing contractual agreements to a third party.\n\nNovation differs from an assignment in that it transfers all rights and obligations, while an assignment only transfers contractual benefits. It is essential to understand the implications of novation and seek legal advice to ensure that the deed is legally binding and effectively transfers contractual rights and obligations.\nKey Components of a Deed of Novation\nA deed of novation is a simple and effective tool for transferring the rights and obligations of one party under a contract to a third party. \n\nHere are the key components that a deed of novation should include:\n\nNovation or Effective Date\nThe novation or effective date is the date on which the new party will assume all the rights and obligations under the original contract. This date is critical, as it marks the point at which the transfer of rights and obligations takes place.\n\nRelease\nA release clause in a deed of novation releases the original party from all the obligations and liabilities under the contract from the date of novation. This clause ensures that the original party is no longer liable for any obligations or liabilities under the contract.\n\nRepresentations and Warranties\nRepresentations and warranties are promises made by both parties regarding the validity of the contract and their authority to enter into it. They also ensure that both parties are aware of each other's obligations and liabilities under the contract.\n\nFees and Payments\nThe fees and payments clause outlines any fees or payments that either party must make under the contract. This clause is critical, as it ensures that both parties are aware of their financial obligations under the contract.\n\nIt is essential to ensure that all these key components are included in the deed of novation to ensure that the transfer of rights and obligations is complete and legally binding. It is always recommended to consult with a legal professional before drafting or signing any legal documents.\n\nBenefits of a Deed of Novation\nA Deed of Novation offers several benefits to parties involved in a contract. By using a Deed of Novation, you can transfer your rights and obligations under an existing contract to a third party, without the need for extensive negotiation or the termination of the original contract. This can save time, money and resources, especially if the transfer involves complex contracts or multiple parties.\n\nOne of the key benefits of a Deed of Novation is that it allows you to simplify the process of transferring contractual obligations. Rather than renegotiating a new contract, you can simply transfer the existing contract to a new party. This can be particularly useful in situations where you are selling your business or restructuring your operations.\n\nAnother advantage of a Deed of Novation is that it minimizes the need for negotiation. Since the terms of the original contract remain the same, you can avoid lengthy and complicated negotiations with the other party. This can make the process of transferring contractual obligations more straightforward and efficient.\n\nFinally, a Deed of Novation can help you avoid the termination of existing contracts. If you need to transfer your contractual obligations to a third party, but do not want to terminate the existing contract, a Deed of Novation may be the best option. This way, you can transfer the obligations to a new party, while keeping the existing contract intact.\n\nRisks Associated with a Deed of Novation\nWhile a deed of novation is a useful legal tool, it is important to be aware of the potential risks that come with it. Here are some of the most significant risks to consider:\nUnforeseen obligations and liabilities: When entering into a deed of novation, it is essential to carefully consider the obligations and liabilities that are being transferred. There may be unforeseen obligations or liabilities that the new party may not be aware of, which could lead to disputes or legal action in the future.\nLack of clarity regarding the terms of the novation: A deed of novation must clearly outline the terms of the agreement to avoid any confusion or misunderstandings between the parties. Without clear and concise terms, there is a risk that the parties may have different interpretations of their obligations and responsibilities.\nThe need for careful consideration and legal advice: As with any legal agreement, it is important to seek professional legal advice before entering into a deed of novation. This will ensure that you understand the legal implications of the agreement and the risks associated with it.\nBy being aware of these risks and taking the necessary precautions, you can mitigate potential issues and ensure that the novation process runs smoothly.\n\nCommon Scenarios for Using a Deed of Novation\nA deed of novation can be a useful legal instrument in several scenarios, some of which include:\nSale or transfer of a business: If you're selling your business or transferring its ownership to another entity, a deed of novation can help transfer the contracts and obligations to the new owner.\nChanges in business structure: When you change your business structure, for example, from a sole trader to a company, a deed of novation can be used to transfer the contractual obligations to the new entity.\nTermination of contracts: A deed of novation can be used to transfer the obligations and rights under a contract to a third party, effectively terminating the contract.\nIt's important to note that while a deed of novation can be a useful legal tool in these scenarios, it's essential to obtain legal advice to ensure that the novation is done correctly and that all parties understand their rights and obligations.\n\nHow to Draft a Deed of Novation\nA Deed of Novation is a legal document that requires careful drafting to ensure that the transfer of obligations and rights is carried out smoothly and effectively. As such, it is important to seek legal advice from a qualified lawyer experienced in drafting and executing such deeds. Here are some key considerations to keep in mind when drafting a Deed of Novation:\nImportance of Legal Advice\nIt is essential to seek legal advice before entering into a Deed of Novation. A qualified lawyer can guide you through the process, identify any potential legal issues, and ensure that the deed is legally binding and enforceable.\nKey Considerations When Drafting a Deed of Novation\nWhen drafting a Deed of Novation, it is important to consider the following:\nParties involved - Clearly identify the parties involved in the novation, including the original parties, the new parties, and any other relevant parties.\nNovation or Effective Date - Clearly state the date from which the novation applies to the parties.\nRelease - Include a clause releasing the original party from all performance of the contract from the novation date.\nRepresentations and Warranties - Include any representations or warranties made by either party.\nFees and Payments - Include any fees or payments to be made by either party.\nSample Deed of Novation\nHere is an example of a Deed of Novation template:\n[Insert date of novation]\nDeed of Novation\nParties\n[Insert original party name], (ACN/ABN [Insert ACN/ABN]) of [Insert address] (Original Party);\n[Insert new party name], (ACN/ABN [Insert ACN/ABN]) of [Insert address] (New Party).\nBackground\n[Insert details of the original contract].\nAgreed Terms\n[Insert details of the novation, including the novation or effective date, release, representations and warranties, and fees and payments].\nExecution\nExecuted as a Deed.\nExecuted by:\n[Insert name of Original Party]\n[Insert signature of Original Party]\n[Insert name of New Party]\n[Insert signature of New Party]\n\nSigning a Deed of Novation\nOnce the Deed of Novation has been drafted, it's time to execute it. The signing of a Deed of Novation is an essential step that requires careful consideration. The following are key points to keep in mind when signing a Deed of Novation:\n\nRequirements for signing a Deed of Novation:\n\nAll parties involved in the agreement must sign the Deed of Novation.\nThe signatures of witnesses may also be required, depending on the jurisdiction and the terms of the agreement.\nThe date of execution must be clearly stated on the Deed of Novation.\n\nImplications of a poorly executed Deed of Novation:\n\nThe failure to comply with the necessary legal requirements can result in the Deed of Novation being invalid, which could create legal problems down the line.\nIncomplete or unclear Deeds of Novation can cause confusion and lead to disputes.\n\nIt is therefore recommended that parties seek legal advice when executing a Deed of Novation to ensure that all legal requirements are met and that the document is executed correctly.\n\nConclusion\nIn conclusion, a Deed of Novation is an important legal document that can be used in a variety of scenarios to transfer contractual obligations. While there are benefits to using a Deed of Novation, there are also risks that must be carefully considered. Seeking legal advice is crucial to ensure that the document is drafted correctly and executed properly. \n\nAt Contracts Specialist, we offer a free consultation to homeowners in NSW who are considering a Deed of Novation. Contact us today to schedule a meeting with one of our experienced lawyers.", "Please summarize this: A Glance into the History of the 8 Jungian Functions\nCarl Jung, the famous Swiss psychiatrist, proposed his model of the eight (8) functions in his work, Psychological Types (1921). He divided the functions into two groups, extraverted (tethered in the external world) and introverted (unfolded in the inner world).\n\nJung\u2019s work would later be built upon by Isabel Briggs Myers and her mother Katharine Cook Briggs, who created a personality model we know today as the Myers-Briggs Type Indicator (MBTI\u00ae). The Myers-Briggs approach used scales for Extraversion-Introversion, Sensing-Intuition and Thinking-Feeling based on Jung\u2019s work and then added a fourth dimension of their own, Judging-Perceiving. The result is 4 different scales on which a person will be assigned one of two possible values. Thus there are 16 combinations (2 x 2 x 2 x 2 = 16).\n\nEach of the 16 personality types have four cognitive functions in alternating directions (i.e. introverted then extraverted, or vice versa), which can be thought of as four \u201cpuzzle pieces\u201d in a particular type. External factors such as upbringing and stress can alter the way each function manifests.\n\nThe four (4) personality scales as proposed by Briggs and Myers:\nExtraversion (E) \u2013 Introversion (I) \u2192 Gaining energy by interacting with other people or alone\nSensing (S) \u2013 Intuition (I) \u2192 Collecting information through the senses or imagination\nThinking (T) \u2013 Feeling (F) \u2192 Making decisions through logic or emotions\nJudging (J) \u2013 Perceiving (P) \u2192 Organizing time by using schedules or without them; result- or process-oriented\nAs mentioned, the first three above are based on Jung\u2019s work with the fourth added by Myers-Briggs. According to Jung, the \u201ccognitive functions\u201d are the two scales of Sensing-Intuition and Thinking-Feeling. These are the ways in which humans process information and think about the world. Then each function can be expressed both in an extraverted manner or an introverted manner. As such, Jung didn\u2019t really view people as \u201cextraverts\u201d and \u201cintroverts\u201d but rather was more focused on the extraverted or introverted expression of each of the four cognitive functions.\n\nJungian four (4) cognitive functions stack:\nJung\u2019s cognitive function \u201cstack\u201d describes the priority or order in which a person uses their cognitive functions, with Primary being the most natural and commonly used and the Inferior being the least-commonly used.\n\nPrimary \u2192 Most natural (and comfortable) function; the internal \u201cmother tongue\u201d\nAuxiliary \u2192 Supporting function, usually connected with creation and job choice\nTertiary \u2192 Function where individual often takes action steps to improve upon\nInferior \u2192 Activates under extreme stress, generally avoided out of self-protection\nDescriptions of the Eight (8) Cognitive Functions\nNow let\u2019s discuss the eight different cognitive functions originally outlined by Jung. His theory proposed that for each of the 4 functions (Sensing, Intuition, Thinking and Feeling) each person would generally either extravert (display outwardly or externally) or introvert (consider inwardly or internally) that function.\n\nAs you read below, consider each function and its expression. Are you more Se or Si? Does Te or Ti come more naturally for you?\n\nExtraverted Sensing (Se)\nTaking action, using all five senses, going forward. Se takes in the present moment in its entirety, and makes rapid decisions on the fly. During times of crisis and emergencies, individuals with primary or auxiliary Se can make the best out of the situation.\n\nExample career areas that emphasize extraverted sensing (Se):\n\nArchaeology\nStunt driving\nFirefighting\nEmergency patrol\nMassage therapy\nIntroverted Sensing (Si)\nAssociations, metaphors, nostalgia. Si can travel back to any point in time through a single scent or sound. Important information (and sometimes interesting trivia) is stored in filing cabinets, where it can be retrieved at any later time.\n\nExample career areas that emphasize introverted sensing (Si):\n\nMuseum curation\nInterior design\nQuantitative sciences (e.g. statistics)\nLibrary sciences\nMedical coding\nExtraverted Intuition (Ne)\nBrainstorming, thinking outside the box, idea generation. Ne easily hops from idea to idea, while making abstract connections. Many artists\u2014especially poets\u2014use significant Ne in their work. To the outside, Ne seems quick, random, and extremely \u201cjumpy.\u201d\n\nExample career areas that emphasize extraverted intuition (Ne):\n\nFilmmaking, concept art\nCopywriting, art direction\nEntrepreneurship\nVideo producer (e.g. Youtube)\nWorkshop facilitating\nIntroverted Intuition (Ni)\nTime-space awareness, predicting the future, hunches. Ni is a far-reaching, visionary function\u2014and can picture the future, sometimes with scary-accurate results.\n\nExample career areas that emphasize introverted intuition (Ni):\n\nDetective services, private investigation\nEconomic predictions and analysis\nForensic and engineering psychology\nPublic speaking, mentoring\nConsulting, all types\nExtraverted Feeling (Fe)\nExpressive emotions, social norms, etiquette. Fe respects the consensus of the group, and puts harmony above personal desires. The function often acts as a mediator between groups, as it naturally puts others\u2019 needs above its own.\n\nExample career areas that emphasize extraverted feeling (Fe):\n\nActing, performance arts\nSinging\nDance therapy\nTelevision hosting\nPublic relations (PR)\nIntroverted Feeling (Fi)\nValues, notions of \u201cright\u201d and \u201cwrong,\u201d likes and dislikes. Fi is a deeply personal and intense function that digs to the core of the human condition. Convictions, morals, and strong beliefs all fall under the Fi umbrella.\n\nExample career areas that emphasize introverted feeling (Fi):\n\nPoetry, creative writing\nArt, various forms\nNarrative design\nMental health counseling\nPeace studies\nExtraverted Thinking (Te)\nFacts, pros and cons, methodological step-by-step strategies. Te respects rules and regulations\u2014and takes great pride in a job well done. Checklists and clear-cut meeting agendas get Te\u2019s gears going\u2014a top-down approach floats its boat.\n\nExample career areas that emphasize extraverted thinking (Te):\n\nAccounting\nPublic and private law\nComputer programming\nNatural sciences, laboratory support\nComputational mathematics\nIntroverted Thinking (Ti)\nIterations, holistic reasoning, agile strategies. Ti takes a bottom-up approach to problem-solving, and fixates on information management. When new data comes in that contradicts old beliefs, Ti will shift like a fluid crystalline framework.\n\nExample career areas that emphasize introverted thinking (Ti):\n\nData analysis\nSystems design engineering\nPhilosophy, sociology\nCybersecurity\nLanguage translation\nWhat are YOUR Functions and Cognitive Stack?\nAccording to Jung\u2019s theory, each person would essentially predominantly display each function (Sensing, Intuition, Thinking, Feeling) in either an extraverted or introverted manner. So of the 8 functions listed above, you\u2019d have 4 of them. If you favor Extraverted Intuition (Ne) it doesn\u2019t mean you can\u2019t use Introverted Intuition (Ni) but rather just that it is less common for you and thus Ne is your primary mode of Intuition. Since Intuition and Sensing are together on scale, if you extravert your Intuition then you tend to introvert your Sensing. So you\u2019d have Ne and Si.\n\nNext you must consider your Thinking-Feeling scale. If this same person tends to externalize (or extravert) their Thinking in the real world then we have a Te, and thus by definition the Feeling would be introverted (Fi). So we have Ne, Si, Te, Fi. But not necessarily in that order. That\u2019s when functional stacking steps in. Each individual uses both Thinking and Feeling functions, which makes the cut-and-dried type system overly simplistic. \n\nThe next task is to determine which function is primary, auxiliary, tertiary and inferior. This is when the concept of functional \u201cstacking\u201d comes in handy. Whichever is most natural is likely the primary, and so on. This is the order of the \u201cstack\u201d, which of your functions comes first or primary, and which comes last or inferior. Let\u2019s say the order in this case is was Ne, Fi, Te, Si. That translates to the ENFP personality type.\n\nCertainly the primary and auxiliary functions are those that come most natural to an individual, and are likely to characterize their outward personality. But while these tendencies may be seen quite obviously on the surface, they don\u2019t fully address one\u2019s personality. The tertiary and inferior functions are also crucial to understand.\n\nIf we only consider the four letters in ENFP (Extraverted, Intuitive, Feeling, Perceiving), for example, it would be next to impossible to see the hidden extraverted thinking (Te) and introverted sensing (Si) in their stacking. ENFPs are more than just their bubbly, charismatic and energetic stereotype. Their Te allows them to systematically work through their tasks and Si with their (often overlooked) excellent memory for details. This can make them excellent PR managers, communications specialists, and journalists.\n\nAnother example of hidden functions in play can be seen in the INTJ (Introverted, Intuitive, Thinking, Judging). INTJs are often dubbed by the entertainment and film industry as chess grandmasters who are strategic, sometimes cunning, and sometimes cold. However, they have introverted feeling (Fi) and extraverted sensing (Se) as their respective third and fourth function. INTJs have strong morals and hold their loved ones dear to their hearts. When under stress, they can become acutely aware of their surroundings and an asset to any team.\n\nHow Does this Relate to \u201cPersonality Typing\u201d?\nThis is the underlying theory behind the Myers-Briggs model and behind most models that also use the 16 personality types nomenclature. There is no shortage of different \u201cpersonality tests\u201d online that you can take that will attempt to determine what your functions are (Fe vs Fi, Te vs Ti, etc.) and in what order they are \u201cstacked\u201d. This then determines which of the 16 types you fall into. While the tests are certainly convenient, any such self-assessment is naturally rigid and prone to testing limitations and thus is never able to get a fully-accurate picture of a human being.", "can you do the same with this list, main body area and nested areas. If the area is not an anatomic are than ignore please\n\n teeth.\n face, neck, body.\n lower face, neck, and jawline.\n severe cystic acne.\n face, neck, and body.\n lower layers of skin tissue.\n laryngeal prominence of thyroid cartilage in the throat.\n facial rejuvenation.\n abdomen, hips, thighs, arms, buttocks, or under the chin.\n nostrils.\n Face and body \n upper or lower jawbone.\n facial reconstruction, abdominal wall reconstruction, breast reconstruction.\n gastric.\n nipple-areola complex.\n underarms.\n balding, thinning, or receding areas.\n nasolabial folds, or smile lines.\n small, uncomplicated spider veins and small varicose veins.\n cellulite on the thighs and buttocks.\n mild to severe acne.\n upper or lower back.\n mustache, beard, sideburns.\n face, cheeks, under-eyes, lips, nasolabial folds, pitted scars, breasts, buttocks.\n face.\n navel.\n moderate to severe facial wrinkles and folds, such as nasolabial folds, etched-in lip lines, crow's feet, smile lines, marionette lines, under-eye tear troughs, and deep glabellar lines.\n upper arms.\n incision or injury.\n face, neck, chest, back, hands, arms, and legs.\n abdomen, hips, lower back, buttocks.\n stomach, legs, arms.\n stomach, thighs, butt, hips, and arms.\n fat reduction anywhere on the body, most commonly treated body areas are the tummy, hips, thighs, flanks (aka love handles), and back. some providers also offer mini bodyfx, which can treat smaller fat deposits in areas like the upper arms and under the chin..\n abdomen, upper arms, thighs, knees, love handles, breasts, back, chin, jowls, cheeks, and neck.\n crow's feet, frown lines, forehead lines, lip lines, bunny lines on the nose, chin wrinkles, neck bands, above the eyebrows, above the upper lip.\n teeth straightening.\n buttocks, hips, waist, love handles, thighs, lower back.\n buttocks.\n breasts.\n face.\n face, neck, d'colletage, back of hands.\n double chin, jawline, knees, elbows, upper arms, muffin top.\n face, body contouring.\n teeth.\n face, neck, hands, chest, legs, and other areas.\n glabellar area.\n forehead and eyebrows.\n lower cheeks.\n foot.\n buttocks, hips, abdomen, waistline, lower back, thighs.\n lower legs.\n lower legs.\n outer corner of the eye where the upper and lower lid meet.\n scalp.\n breast.\n face, neck, arms, stomach, buttocks, and legs.\n lens of the eye.\n cellulite dimples on the buttocks and the backs of the thighs.\n thighs, abdomen, or buttocks.\n midface.\n midface.\n cheeks.\n midface.\n zygomatic bone (malar bone).\n face, neck, chest, hands.\n soft tissue under the skin.\n lower face.\n under the chin and jawline.\n fine lines, shrink the appearance of pores, improve skin tone and texture, and reduce melasma.\n teeth straightening.\n jawbone.\n face, neck, chest, lips, and anywhere on the body.\n broken capillaries, spider veins, vascular lesions, periorbital veins, skin discoloration.\n upper lip, nose, and roof of the mouth.\n clitoral hood.\n face, neck, chest.\n vagina and vulva.\n crow's feet, fine lines around the eyes, smile lines, frown lines, atrophic acne scars, and thin lips.\n brow, mid- and lower face, jawline, and neck.\n fine lines and wrinkles, sun damage, discoloration, and acne scars.\n fine lines and wrinkles, acne scars, large pore size, uneven skin tone, rough skin texture, age spots, and other signs of sun damage.\n abdomen, flanks, bra fat, inner and outer thighs, back fat, upper arms, buttock rolls, knees, hips, mons pubis, submental fat.\n thighs, butt, and abdomen.\n hyperpigmentation and skin discoloration.\n abdominal fat, love handles, upper arms, inner thighs, under chin, below buttocks, bra and back fat bulges.\n slimming, toning, and cellulite reduction.\n face.\n skin.\n teeth.\n teeth straightening.\n glabellar lines, forehead furrows, crow's feet, bunny lines, platysmal bands, dimpling of the chin, masseter muscles.\n middle and lower areas of the face.\n face, eyes, neck.\n teeth.\n jawbone, gums.\n missing teeth.\n teeth.\n upper or lower jawbone.\n face, eyes, lips.\n face, upper lip, cheeks.\n smile lines, marionette lines, lips, under-eye hollows, cheeks, temples, jawline, chin, nose.\n face, neck, chest, stomach, thighs.\n face.\n skin tightening.\n face, neck, d'colletage, body.\n abdominal muscles.\n chin or cheeks.\n vaginal tissue.\n craniofacial region.\n upper eyelids.\n stomach and small intestine.\n front of natural teeth.\n \n face, neck, chest, arms, back of hands, and elsewhere on the body.\n legs, buttocks, thighs, back, or stomach.\n teeth.\n face, neck, under chin.\n skin.\n hormonal acne, polycystic ovary syndrome (pcos), high blood pressure, congestive heart failure.\n anywhere on the body.\n excess pigmentation and redness, wrinkles and mild acne scars, vascular lesions and varicose veins, pigmented lesions and dark tattoos.\n eye alignment.\n breast augmentation, breast reconstruction, abdominal wall defects, hernia repair.\n depressed scars, acne scars, cellulite dimples.\n face, neck, and d\u00e9colletage.\n teeth alignment.\n epidermis.\n acne on face and body, psoriasis on body, sun damage.\n face.\n teeth.\n face.\n lips, cheeks, chin, forehead, eyes, mouth, neck, and chest.\n scrotum.\n face, eyes, eyelids, jawline, stomach, arms, backs of hands, thighs, knees, butt.\n breasts and nipples.\n cheeks, around the mouth, neck, forehead and around the eyes.\n lower face, jowls, neck, breasts, arms, tummy, and thighs.\n vulvar and vaginal tissues.\n thigh.\n brow, mid- and lower face, jawline, and neck.\n skin concerns.\n inner and outer thighs, back, abdomen, love handles, hips, saddlebags, and buttocks.\n face, neck, stomach, and upper arms.\n enamel, dentin, pulp.\n face, forehead, temples, chin, area around mouth, cheeks.\n wrinkles, sagging skin, fat cells, cellulite.\n abdomen and flanks.\n abdomen and flanks.\n abdomen, flanks, buttocks, thighs.\n abdomen, flanks, and thighs.\n reshaping, creating balanced, normal breasts.\n abdomen, love handles, hips, thighs, chin, upper arms, underarms.\n lower abdomen.\n abdomen.\n brow, neck (including jawline), under chin, lines and wrinkles on d'colletage.\n vaginal area.\n face and neck.\n fine lines and wrinkles, discoloration, and even scars.\n stomach, hips, and thighs.\n abdomen, hips, and thighs.\n fat layer just under the skin.\n upper arms, belly, love handles, thighs, chin.\n abdominal wall.\n eyelid.\n lower face.\n vaginal canal, opening, labia majora, vulva, labia minora, mons pubis.\n vaginal canal.\n cleavage area.\n face.\n face.\n abdomen and thighs.\n spider veins, varicose veins, and venous reflux disease.\n thighs, calves, and ankles, buttocks and hips, abdomen, back, and flanks (aka love handles), upper arms, neck and under the chin.\n rosacea, pigmented scars, spider veins, broken capillaries, birthmarks, hyperpigmentation, newly formed stretch marks, and other forms of red, brown, or purple facial pigmentation.\n legs.\n spider veins, cherry angiomas, small hemangiomas, skin tags, spider nevi, and redness from rosacea.\n thighs, buttocks, upper arms, stomach, excess fat and mildly sagging skin under the chin.\n thighs, abdomen, and butt.\n varicose veins.\n fat reduction on the back, abdomen, thighs and flanks, cellulite reduction on the thighs, buttocks, and abdomen, muscle conditioning and toning for biceps, triceps, abdominal and oblique muscles, glutes, hamstrings, and quadriceps.\n face, neck, and body.\n wrinkles, fine lines, cellulite, stretch marks.\n fine lines and deep wrinkles, acne scars, large pores, uneven skin texture, stretch marks, mild laxity, rosacea, and hyperpigmentation, including melasma.\n pelvic floor issues.\n face, neck, chest, hands.\n face and body.\n vaginal tissues, labia majora.\n pelvic floor muscles and skin elasticity.\n jaw.\n lines and wrinkles created by dynamic facial movements, such as smiling, frowning, or raising your eyebrows, neck pain caused by cervical dystonia, eye spasms known as blepharospasm, and upper limb spasticity.\n skin concerns, visible veins, brown spots, scars, laser hair removal, tattoo removal, cataract surgery.\n waist, chest, back, neck, upper arms, thighs, love handles, hips, and ankles.\n skin.\n teeth.\n lower third of face, jawline, neck.\n face, neck, and body.", "Can you make this code better, format it better etc?\n\nimport math\nfrom classes import Appliance\nfrom appliances import nonShiftable, shiftable, auxilary\n\n# \\* Prices generated by generateElectricityPrices.py\nprices = {\n 0: 0.17043824334020852,\n 1: 0.17687964847282173,\n 2: 0.1848716150231699,\n 3: 0.16119955296182936,\n 4: 0.16220396601978404,\n 5: 0.17861609773844922,\n 6: 0.19649085997831328,\n 7: 0.36008332379269636,\n 8: 0.396606737372287,\n 9: 0.5501378614431885,\n 10: 0.5940889787258893,\n 11: 0.18848951740313521,\n 12: 0.18571010112349637,\n 13: 0.16788191713340134,\n 14: 0.1709039894099174,\n 15: 0.16532830213734045,\n 16: 0.4565517132282808,\n 17: 0.5857373298786244,\n 18: 0.3656057042514985,\n 19: 0.49303826836168463,\n 20: 0.38306623023534225,\n 21: 0.43242741485567326,\n 22: 0.1580491724358629,\n 23: 0.17048220206057746\n}\ndef estimate\\_electricity\\_cost\\_for\\_run(hour: int, duration: int, consumes: int) -> int:\n global prices\n cost = 0\n for i in range(hour, hour + duration):\n if i >= 24:\n i -= 24\n cost += prices[i] \\* (consumes / duration)\n return cost\n\n# \\* DESCRIPTION: Estimates the electricity cost for a given hour\n# \\* INPUT: hours: int, min: int, max: int\n# \\* OUTPUT: int\ndef estimate\\_best\\_hour\\_start(duration: int, min\\_hour: int, max\\_hour: int, consumes: int) -> int:\n global prices\n\n min\\_cost = -1\n min\\_index = -1\n if max\\_hour < min\\_hour:\n max\\_hour += 24\n for hour in range(min\\_hour, max\\_hour - duration):\n if hour >= 24:\n hour -= 24\n cost = estimate\\_electricity\\_cost\\_for\\_run(hour, duration, consumes)\n if cost < min\\_cost or min\\_cost == -1:\n min\\_cost = cost\n min\\_index = hour\n\n return min\\_index\n\n# \\* DESCRIPTION: Calculates the optimal schedule for the given appliances\n# \\* INPUT: appliances: Appliance[] -> list of appliances\n# \\* OUTPUT: dict -> {hour: Appliance[]}\ndef optimal\\_calculation(appliances):\n schedule = {}\n for i in range(24):\n schedule[i] = []\n\n # \\* Calculate optimal schedule\n for appliance in appliances:\n if not appliance.shiftable or ((appliance.timeStart + appliance.duration) % 24) == appliance.timeStop % 24:\n schedule[appliance.timeStart].append(appliance)\n continue\n\n hour\\_start = estimate\\_best\\_hour\\_start(\n appliance.duration, appliance.timeStart, appliance.timeStop, appliance.consumption)\n schedule[hour\\_start].append(appliance)\n\n return schedule\n# \\* DESCRIPTION: Calculates total load for each hour based on all appliances, and peak hour + load\n# \\* INPUT: appliances: Appliance[] -> list of appliances\n# \\* OUTPUT: schedule: dict, peakHour: int, peakLoad: float\n\ndef calculate\\_peak\\_load(appliances):\n schedule = {}\n for i in range(24):\n schedule[i] = 0\n # Calculate total energy consumption for all appliances each hour\n for a in appliances:\n if not a.shiftable or ((a.timeStart + a.duration) % 24) == a.timeStop % 24:\n for i in range(24):\n schedule[i] += (a.consumption / 24)/1000\n continue\n hourStart = estimate\\_best\\_hour\\_start(\n a.duration, a.timeStart, a.timeStop, a.consumption\n )\n for i in range(hourStart, (hourStart + a.duration + 1)):\n schedule[i] += (a.consumption / a.duration)/1000\n # Find hour with highest energy consumption\n peakHour = 0\n peakPrice = schedule[peakHour]\n for hour in schedule.keys():\n if schedule[hour] > peakPrice:\n peakHour = hour\n peakPrice = schedule[peakHour]\n\n return schedule, peakHour, peakPrice\ndef scheduleAppliances(appliances):\n schedule = []\n for a in appliances:\n if not a.shiftable or ((a.timeStart + a.duration) % 24) == a.timeStop % 24:\n schedule.append({\n \"name\": a.name,\n \"start\": a.timeStart,\n \"stop\": a.timeStop,\n \"duration\": a.duration,\n \"consumption\": (a.consumption/a.duration)\n })\n continue\n optimalStartTime = estimate\\_best\\_hour\\_start(\n a.duration, a.timeStart, a.timeStop, a.consumption\n )\n schedule.append({\n \"name\": a.name,\n \"start\": optimalStartTime,\n \"stop\": a.timeStop,\n \"duration\": a.duration,\n \"consumption\": (a.consumption/a.duration)\n })\n\n # Sort schedule by appliance start time\n schedule = sorted(schedule, key=lambda x: x[\"start\"])\n\n return schedule\ndef calculatePeak(schedule):\n hourlyTotalConsumption = {}\n totalCost = 0\n for i in range(24):\n hourlyTotalConsumption[i] = 0\n for appliance in schedule:\n for i in range(appliance[\"start\"], (appliance[\"start\"]+appliance[\"duration\"])):\n hourlyTotalConsumption[i] += appliance[\"consumption\"] / 1000\n peakHour = 0\n peakLoad = hourlyTotalConsumption[peakHour]\n for hour in hourlyTotalConsumption:\n if hourlyTotalConsumption[hour] > peakLoad:\n peakHour = hour\n peakLoad = hourlyTotalConsumption[peakHour]\n\n for x in schedule:\n totalCost += estimate\\_electricity\\_cost\\_for\\_run(\n x[\"start\"], x[\"duration\"], (x[\"consumption\"] \\* x[\"duration\"]) / 1000)\n\n return peakHour, peakLoad, totalCost\ndef applianceReference(appliance):\n for a in nonShiftable:\n if a == appliance[\"name\"]:\n return nonShiftable[a]\n for a in shiftable:\n if a == appliance[\"name\"]:\n return shiftable[a]\n for a in auxilary:\n if a == appliance[\"name\"]:\n return auxilary[a]\ndef optimizeSchedule(schedule):\n # Create copy of schedule\n originalSchedule = schedule.copy()\n peakLoad = calculatePeak(originalSchedule)[1]\n totalCost = calculatePeak(originalSchedule)[2]\n lenght = len(originalSchedule)\n print(\"Incoming:\")\n print(\"Peak load\", peakLoad)\n print(\"Total cost\", totalCost)\n\n for i in range(len(originalSchedule)):\n if originalSchedule[i][\"duration\"] == 24:\n continue\n appliance = originalSchedule.pop(i)\n ref = applianceReference(appliance)\n for j in range(ref[4], ref[5]-ref[3]):\n originalSchedule.append({\n \"name\": appliance[\"name\"],\n \"start\": j,\n \"stop\": ref[5],\n \"duration\": ref[3],\n \"consumption\": appliance[\"consumption\"]\n })\n newPeakLoad = calculatePeak(originalSchedule)[1]\n newTotalCost = calculatePeak(originalSchedule)[2]\n if newPeakLoad > peakLoad and newTotalCost > totalCost:\n del originalSchedule[-1]\n elif newPeakLoad < peakLoad: # her skal det egt st\u00e5 newPeakLoad < peakLoad AND newTotalCost < total cost, men da kommer det ingen endringer\n peakLoad = newPeakLoad\n totalCost = newTotalCost\n appliance = originalSchedule.pop()\n else:\n del originalSchedule[-1]\n\n if len(originalSchedule) < lenght:\n originalSchedule.append(appliance)\n\n peakLoad = calculatePeak(originalSchedule)[1]\n totalCost = calculatePeak(originalSchedule)[2]\n print(\"Outgoing:\")\n print(\"Peak load\", peakLoad)\n print(\"Total cost\", totalCost)\n\n return originalSchedule\n# \\* DESCRIPTION: Calculates the total daily energy consumption for the given schedule\n# \\* INPUT: schedule: dict -> {hour: Appliance[]}\n# \\* OUTPUT: int\ndef calculate\\_schedule\\_cost(schedule: dict) -> int:\n total = 0\n for hour in schedule:\n for appliance in schedule[hour]:\n total += estimate\\_electricity\\_cost\\_for\\_run(\n hour, appliance.duration, appliance.consumption)\n\n return round(total / 1000, 2)\n\n# \\* DESCRIPTION: Prints the given schedule to the console\n# \\* INPUT: schedule: dict -> {hour: Appliance[]}\n# \\* OUTPUT: None\ndef print\\_schedule(schedule: dict) -> None:\n for hour in schedule.keys():\n if (len(schedule[hour]) == 0):\n continue\n for appliance in schedule[hour]:\n print(\n f'{f\"{hour}:00-{hour + appliance.duration}:00\":<11} - {appliance.name:<16} ({appliance.consumption / 1000} kW)')\ndef print\\_scedule\\_2(schedule):\n totalConsumption = 0\n totalCost = 0\n for x in schedule:\n totalConsumption += (x[\"consumption\"] / 1000) \\* x[\"duration\"]\n totalCost += estimate\\_electricity\\_cost\\_for\\_run(\n x[\"start\"], x[\"duration\"], (x[\"consumption\"] \\* x[\"duration\"])/1000)\n print(x[\"start\"], \":00 -\", (x[\"start\"]+x[\"duration\"]),\n \":00 \", x[\"name\"], \" - \", (x[\"consumption\"]/1000), \"kWh\")\n print(\"Total energy consumption:\", round(totalConsumption, 4),\n \"kWh\\nTotal energy cost:\", round(totalCost/1000, 2), \"nok\")", "Resource Exposure \ucde8\uc57d\uc810\uc774 \uc874\uc7ac\ud558\ub294 \uc138 \uac1c\uc758 CVE\uac00 \uc788\ub294\ub370, \uc14b\uc758 \ud328\uce58\uac00 \uac01\uac01 \ub2e4\uc74c\uacfc \uac19\uc544.\n\nCVE-2022-25375:\n\n--- rndis.c\\_5\\_OLD.vul 2022-03-03 17:41:44.082594059 +0900\n+++ rndis.c\\_5\\_NEW.vul 2022-03-03 17:41:44.082594059 +0900\n@@ -5,14 +5,17 @@\n rndis\\_set\\_cmplt\\_type \\*resp;\n rndis\\_resp\\_t \\*r;\n \n+ BufLength = le32\\_to\\_cpu(buf->InformationBufferLength);\n+ BufOffset = le32\\_to\\_cpu(buf->InformationBufferOffset);\n+ if ((BufLength > RNDIS\\_MAX\\_TOTAL\\_SIZE) ||\n+ (BufOffset + 8 >= RNDIS\\_MAX\\_TOTAL\\_SIZE))\n+ return -EINVAL;\n+\n r = rndis\\_add\\_response(params, sizeof(rndis\\_set\\_cmplt\\_type));\n if (!r)\n return -ENOMEM;\n resp = (rndis\\_set\\_cmplt\\_type \\*)r->buf;\n \n- BufLength = le32\\_to\\_cpu(buf->InformationBufferLength);\n- BufOffset = le32\\_to\\_cpu(buf->InformationBufferOffset);\n-\n #ifdef VERBOSE\\_DEBUG\n pr\\_debug(\"%s: Length: %d\\n\", \\_\\_func\\_\\_, BufLength);\n pr\\_debug(\"%s: Offset: %d\\n\", \\_\\_func\\_\\_, BufOffset);\n\nCVE-2022-25236:\n\n--- runtests.c\\_364\\_OLD.vul 2022-03-26 22:36:09.214467870 +0900\n+++ runtests.c\\_364\\_NEW.vul 2022-03-26 22:36:09.214467870 +0900\n@@ -2,16 +2,18 @@\n struct test\\_case {\n enum XML\\_Status expectedStatus;\n const char \\*doc;\n+ XML\\_Char namesep;\n };\n struct test\\_case cases[] = {\n- {XML\\_STATUS\\_OK, \"\"},\n- {XML\\_STATUS\\_ERROR, \"\"},\n+ {XML\\_STATUS\\_OK, \"\", XCS('\\n')},\n+ {XML\\_STATUS\\_ERROR, \"\", XCS('\\n')},\n+ {XML\\_STATUS\\_OK, \"\", XCS(':')},\n };\n \n size\\_t i = 0;\n size\\_t failCount = 0;\n for (; i < sizeof(cases) / sizeof(cases[0]); i++) {\n- XML\\_Parser parser = XML\\_ParserCreateNS(NULL, '\\n');\n+ XML\\_Parser parser = XML\\_ParserCreateNS(NULL, cases[i].namesep);\n XML\\_SetElementHandler(parser, dummy\\_start\\_element, dummy\\_end\\_element);\n if (XML\\_Parse(parser, cases[i].doc, (int)strlen(cases[i].doc),\n /\\*isFinal\\*/ XML\\_TRUE)\n\nCVE-2022-23960:\n\n\"--- proton-pack.c\\_5\\_OLD.vul 2022-04-04 14:41:09.455015025 +0900\n+++ proton-pack.c\\_5\\_NEW.vul 2022-04-04 14:41:09.455015025 +0900\n@@ -1,11 +1,23 @@\n ssize\\_t cpu\\_show\\_spectre\\_v2(struct device \\*dev, struct device\\_attribute \\*attr,\n char \\*buf)\n {\n+ enum mitigation\\_state bhb\\_state = arm64\\_get\\_spectre\\_bhb\\_state();\n+ const char \\*bhb\\_str = get\\_bhb\\_affected\\_string(bhb\\_state);\n+ const char \\*v2\\_str = \"Branch predictor hardening\";\n+\n switch (spectre\\_v2\\_state) {\n case SPECTRE\\_UNAFFECTED:\n- return sprintf(buf, \"Not affected\\n\");\n+ if (bhb\\_state == SPECTRE\\_UNAFFECTED)\n+ return sprintf(buf, \"Not affected\\n\");\n+\n+ /\\*\n+ \\* Platforms affected by Spectre-BHB can't report\n+ \\* \"Not affected\" for Spectre-v2.\n+ \\*/\n+ v2\\_str = \"CSV2\";\n+ fallthrough;\n case SPECTRE\\_MITIGATED:\n- return sprintf(buf, \"Mitigation: Branch predictor hardening\\n\");\n+ return sprintf(buf, \"Mitigation: %s%s\\n\", v2\\_str, bhb\\_str);\n case SPECTRE\\_VULNERABLE:\n fallthrough;\n default:\n\"\n\"--- spectre.c\\_1\\_OLD.vul 2022-04-04 14:13:14.511591691 +0900\n+++ spectre.c\\_1\\_NEW.vul 2022-04-04 14:13:14.511591691 +0900\n@@ -3,6 +3,6 @@\n #ifdef CONFIG\\_BPF\\_SYSCALL\n return !sysctl\\_unprivileged\\_bpf\\_disabled;\n #else\n- return false\n+ return false;\n #endif\n }\n\"\n\"--- mmu.c\\_24\\_OLD.vul 2022-04-04 14:44:17.456707352 +0900\n+++ mmu.c\\_24\\_NEW.vul 2022-04-04 14:44:17.456707352 +0900\n@@ -1,5 +1,7 @@\n static int \\_\\_init map\\_entry\\_trampoline(void)\n {\n+ int i;\n+\n pgprot\\_t prot = rodata\\_enabled ? PAGE\\_KERNEL\\_ROX : PAGE\\_KERNEL\\_EXEC;\n phys\\_addr\\_t pa\\_start = \\_\\_pa\\_symbol(\\_\\_entry\\_tramp\\_text\\_start);\n \n@@ -8,11 +10,15 @@\n \n /\\* Map only the text into the trampoline page table \\*/\n memset(tramp\\_pg\\_dir, 0, PGD\\_SIZE);\n- \\_\\_create\\_pgd\\_mapping(tramp\\_pg\\_dir, pa\\_start, TRAMP\\_VALIAS, PAGE\\_SIZE,\n- prot, \\_\\_pgd\\_pgtable\\_alloc, 0);\n+ \\_\\_create\\_pgd\\_mapping(tramp\\_pg\\_dir, pa\\_start, TRAMP\\_VALIAS,\n+ entry\\_tramp\\_text\\_size(), prot,\n+ \\_\\_pgd\\_pgtable\\_alloc, NO\\_BLOCK\\_MAPPINGS);\n \n /\\* Map both the text and data into the kernel page table \\*/\n- \\_\\_set\\_fixmap(FIX\\_ENTRY\\_TRAMP\\_TEXT, pa\\_start, prot);\n+ for (i = 0; i < DIV\\_ROUND\\_UP(entry\\_tramp\\_text\\_size(), PAGE\\_SIZE); i++)\n+ \\_\\_set\\_fixmap(FIX\\_ENTRY\\_TRAMP\\_TEXT1 - i,\n+ pa\\_start + i \\* PAGE\\_SIZE, prot);\n+\n if (IS\\_ENABLED(CONFIG\\_RANDOMIZE\\_BASE)) {\n extern char \\_\\_entry\\_tramp\\_data\\_start[];\n \n\"\n\"--- traps.c\\_38\\_OLD.vul 2022-04-04 14:14:21.006774119 +0900\n+++ traps.c\\_38\\_NEW.vul 2022-04-04 14:14:21.006774119 +0900\n@@ -1,7 +1,5 @@\n void \\_\\_init early\\_trap\\_init(void \\*vectors\\_base)\n {\n-#ifndef CONFIG\\_CPU\\_V7M\n- unsigned long vectors = (unsigned long)vectors\\_base;\n extern char \\_\\_stubs\\_start[], \\_\\_stubs\\_end[];\n extern char \\_\\_vectors\\_start[], \\_\\_vectors\\_end[];\n unsigned i;\n@@ -22,17 +20,10 @@\n \\* into the vector page, mapped at 0xffff0000, and ensure these\n \\* are visible to the instruction stream.\n \\*/\n- memcpy((void \\*)vectors, \\_\\_vectors\\_start, \\_\\_vectors\\_end - \\_\\_vectors\\_start);\n- memcpy((void \\*)vectors + 0x1000, \\_\\_stubs\\_start, \\_\\_stubs\\_end - \\_\\_stubs\\_start);\n+ copy\\_from\\_lma(vectors\\_base, \\_\\_vectors\\_start, \\_\\_vectors\\_end);\n+ copy\\_from\\_lma(vectors\\_base + 0x1000, \\_\\_stubs\\_start, \\_\\_stubs\\_end);\n \n kuser\\_init(vectors\\_base);\n \n- flush\\_icache\\_range(vectors, vectors + PAGE\\_SIZE \\* 2);\n-#else /\\* ifndef CONFIG\\_CPU\\_V7M \\*/\n- /\\*\n- \\* on V7-M there is no need to copy the vector table to a dedicated\n- \\* memory area. The address is configurable and so a table in the kernel\n- \\* image can be used.\n- \\*/\n-#endif\n+ flush\\_vectors(vectors\\_base, 0, PAGE\\_SIZE \\* 2);\n }\n\"\n\n\uc138 \ud328\uce58\uc5d0\uc11c Resource Exposure \ucde8\uc57d\uc810\uc774 \uc874\uc7ac\ud55c\ub2e4\ub294 \uacf5\ud1b5\ub41c \uadfc\uac70\ub97c \ubf51\uc544\ub0bc \uc218 \uc788\uc5b4?", "Using the examples below as a basis, can you create three alternative meaning-for-meaning transcript for each the first 5 verbatim transcript passages below? \n\nVerbatim Transcript - 1: Good afternoon, everybody. I hope you're all having a good afternoon today. Yeah? Meaning-for-meaning transcript - 1: Good afternoon. I hope you're all having a good day.\nVerbatim Transcript - 2: Well, as I mentioned the last time we were together, what we will be talking about today are strategies for communicating with a person who is deaf or hard of hearing. As you know, everybody's different, and we all have our own way of doing things, and you know people who are deaf and hard of hearing are no different. Individual deaf people communicate in different ways. Some use speech only; others use sign language only; and yet others use a combination of sign language and speech. Meaning-for-meaning transcript - 2: As I mentioned last time, we will talk today about strategies for communicating with a person who is deaf or hard of hearing. Everyone is different. People who are deaf and hard of hearing are no different. Individual deaf people communicate in different ways. Some use speech only, some use sign language only, and some use a combination of both.\nVerbatim Transcript - 3: Well, you can communicate with a person who is deaf, even if you don\u2019t know sign language. There are some different strategies that work to make the spoken communication flow more easily. The key is to know and use helpful techniques while you're speaking. Keep in mind that the important thing is not how you are exchanging ideas, whether you are signing or speaking, But the Important thing is that you do exchange ideas. Meaning-for-meaning transcript - 3: You can communicate with someone who is deaf even if you don't know sign language. There are techniques that can be used. The important thing is not how you exchange idea, but that you do exchange ideas.\nVerbatim Transcript - 4: So, here are some strategies to use when you communicate in a 1-to-1 situation with a person who is deaf or hard of hearing: Meaning-for-meaning transcript - 4: Here are some strategies to use when you communicate one on one with someone who is deaf or hard of hearing:\nVerbatim Transcript - 5: 1. Get the attention of the person who is deaf BEFORE you speak. You might call out the person's name; if that is not successful, you might give a little wave, or a tap on a shoulder. Some visual signal is usually best. Meaning-for-meaning transcript - 5: 1. Get the attention of the person who is deaf before you begin to speak. You could wave, tap them on the shoulder, etc. A visual signal is best.\nVerbatim Transcript - 6: 2. Key the person who is deaf into the topic of discussion. Key them into what's being talked about. A deaf person needs to know what subject matter will be discussed in order to pick up words to follow the conversation. This is especially important for a person who depends on speechreading. I don't know if you've heard that word before. But speechreading. speechreading is another name for lipreading. Meaning-for-meaning transcript - 6: 2. Key the person who is deaf into what's being talked about. A deaf person needs to know what subject matter will be discussed in order to follow the conversation. This is especially important for a person who depends on speech reading (lip reading).\nVerbatim Transcript - 7: 3. Speak slowly and clearly, but don't yell, or exaggerate or over-pronounce your words. Why is that? Well, exaggeration and overemphasis of words distort your lip movements, and that makes speechreading really hard. Just try to enunciate each word without tension. Oh yes, short sentences are easier to understand than long ones. Meaning-for-meaning transcript - 7: 3. Speak slowly and clearly. Don't yell or exaggerate or over-pronounce your words. Exaggeration of words distorts your lip movements, which makes speech reading really hard. Try to annunciate each word without tension. Short sentences are easier to understand than long ones.\nVerbatim Transcript - 8: 4. Look directly at the person when you're talking. Don\u2019t turn away to write on the board, look at a computer screen, or pull something from a file, or look in your purse, or something like that. Face toward the person, so he or she can see your mouth and facial expressions. Meaning-for-meaning transcript - 8: 4. Look directly at the person you are talking to. Don't turn away to look at a board, pull something from a file, etc. Face towards the person so they can see your mouth and facial expressions.\nVerbatim Transcript - 9: 5) Don't put anything in your mouth or in front of it when speaking. Don't smoke, don't eat, don't put your hands in front of your face. Because that makes it hard for a person who is deaf to follow what you're saying. it's pretty irritating to see a cigarette bouncing up and down for example as someone is talking, or or to watch as they are eating and try to speechread what they are saying. Okay, the next one. . . . Meaning-for-meaning transcript - 9: 5. Don't put anything in or in front of your mouth when you are talking. Don't smoke, eat, or put your hands in front of your face. That makes it hard for a person who is deaf to follow what you are saying. It's frustrating to try to speech read when someone is eating.\nVerbatim Transcript - 10: 6) Maintain eye contact with the person who is deaf. Don\u2019t just look toward him or her as I said in an earlier item, but it's important that you maintain eye contact. Why is that important ? Eye contact conveys a feeling of direct communication. So you need to have eye contact to make it clear you are in a communication with this person. And here's the really important thing: Even if there is an interpreter is present, alright? You continue to speak and look directly at the person who is deaf. You don't look at the interpreter. The deaf person will turn to the interpreter as they need to. In fact, they may look at the interpreter the whole time, or very frequently. But you continue to look at the person who is deaf. You don't turn to the interpreter. Meaning-for-meaning transcript - 10: 6. Maintain eye contact with the person who is deaf. Don't just look toward them. Why is that important? Because it conveys a feeling of direct communication. Here's the important thing: even if there is an interpreter, look at the person who is deaf, not at the interpreter. The deaf person may look at the interpreter very frequently, but you continue to look at the person who is deaf.\nVerbatim Transcript - 11: Number 7, now, this one is related to the last one, but number 7 is Use the words \"I\" and \"you\" when communicating through an interpreter. Don\u2019t turn to the interpreter and say \"tell him (blah blah blah); instead tell it to the deaf person directly yourself. Don\u2019t turn to the interpreter or say to the interpreter \"Does she understand me?\"; instead, ask the deaf person directly, \u201cDo you understand me?\u201d. Okay? This is one-to-one communication, not through the interpreter. Meaning-for-meaning transcript - 11: 7. Use the words \"I\" and \"you\" when communicating through an interpreter. Don't say \"tell him...\" Or \"does she understand me?\" Instead, ask the deaf person directly \"do you understand me?\"\nVerbatim Transcript - 12: 8) Don't stand with a light source behind you. Instead, make sure that the light is on your face, illuminating it. If you have a bright light behind you, it makes it very hard to see you face. There's a glare. It makes it very hard to look at you because of the glare. And there's shadows created on your face, and that makes it almost impossible for a person to speechread, if the person they are looking at has a bright light behind them, so make sure that the light source is in front of you, on your face. Don't sit with the window behind you or something like that. Meaning-for-meaning transcript - 12: 8. Don't stand with a light source behind you. Make sure that the light is on your face. If you have a light behind you, it makes it hard to see your face because of shadows and glare. That makes it almost impossible for a person to speech read. Make sure that the light source is in front of you, on your face.\nVerbatim Transcript - 13: Number 9, number 9. Be courteous to the person during conversation. If the telephone rings or someone knocks at the door, excuse yourself and tell the deaf person what\u2019s happening, and then deal with it. For example, say, \"excuse me. Someone\u2019s at the door.\" Or \"excuse me, the phone is ranging.\" And then handle the interruptions quickly, and return to your original conversation. Don't leave the deaf person just cut out of the conversation while you carry on a conversation with someone else. Okay, so that one was \"be courteous.\" Just use common sense. Meaning-for-meaning transcript - 13: 9. Be courteous to the person you are talking to. If the telephone rings or someone knocks at the door, excuse yourself and handle the interruption quickly. Return to the original conversation right away. Don't leave the deaf person cut out from what's going on.\nVerbatim Transcript - 14: And the last one, if you are not understood when you say something, first repeat what you said, and then try to rephrase your thought. Okay? Just don't repeat the same words again. Rephrase them. And don't hesitate to try to communicate with pencil and paper or by typing. Getting the message across is more important than the medium that you use. Meaning-for-meaning transcript - 14: 10. If the deaf person does not understand you, repeat what you said and then try to rephrase your thought. Don't hesitate to communicate with pencil and paper or by typing. Getting the message across is more important than the medium you use.", "Context:\nAct - I\nThe play opens with worship to Lord Ganesha. Bhagwata comes to the stage. He is a character in the Play and also is the narrator of the play. He seeks blessings from Lord Ganesha for the successful performance of the play. Through his narration, he takes the audience to a place, called as Dharampur and introduces the audience to the king Dharmsheel. Then he puts up some rhetorical questions on incompleteness of man and God; and also on the perfection of a man. During his narration, he introduces two characters who are mutual friends. The first one is Devdutta. He is a sharp minded and highly intellectual person. He has defeated poets and Pandits with his knowledge. He is a son of Brahmin. The second one is Kapila. He is a muscular man. He has a great physical strength and he is a son of Lohar (Black Smith). Both Devdutta and Kapila are in contrast as the former lacks power and strength, the latter lacks knowledge and intellectual. According to the playwright, the head of Devdutta (knowledge) and the body of Kapila (physical strength) accomplish a complete man. The narrator compares their pair to the pair of Ram-Laxman, Luv-Kush and Krishna-Balram. All these are the pairs of great brothers in Hindu mythology.\n\nA character, Actor-1 appears on the stage shouting and running towards Bhagwata. He tells Bhagwata that he has just seen a strange creature that looks like a horse (by face) but speaks like a man. That creature has the head of a horse and the rest of the body of a man. Without paying any heed to his talks, Bhagwata asks him to get ready for the play. But he runs away from the stage and soon after he comes back shouting again. Now a strange creature appears on the stage. As earlier described by the Actor-1, the creature has the head of a horse and the body of a man. For a moment, Bhagwata thinks that someone is wearing the mask of horse. He tries to remove the mask but realizes that it is truly half a man and a half horse. Now the creature starts to introduce itself before Bhagwata, Actor-1 and the audience.\n\nThe creature introduces himself as Hayavadana and starts to narrate his story. He tells that once upon a time, a princess had to choose a groom for her marriage. So many Princes approached from far and wide. But the princess fell in love with a horse of an Arabian Prince. She became desperate to marry that horse. Eventually her parents allowed her to do so. She was married to the horse. After 15 years of their marriage, the horse transformed into a celestial being. Now the princess rejected him as her husband. That celestial being cursed her to be a Mare (female horse) and she became so. The princess give birth to Hayavadana. Now Hayavadana wants to get rid of this cursed life. Bhagwata asks him to go to goddess Kali temple in chitrkut. He also asks the Actor-1 to accompany him on the way. They leave.\n\nNow Bhagwata moves ahead with the story of the play. Devdutta and Kapila appear on the stage. Devdutta tells Kapila that he wants to marry a woman, namely Padmini. With utmost desire to marry Padmini, he pledges to sacrifice his arms to Goddess Kali and his head to Rudra. Kapila goes to Padmini and presents the Proposal to marry Devdutta. Devdatta and Padmini Marry. By the time, Devdutta realizes that Padmini is attracted towards Kapila and vice versa. Now Padmini is pregnant. Devdutta knowingly tries to put off the program of visiting Ujjain. He tells Kapila that Padmini is ill. But Padmini gives her consent before Kapila. They all three leave for Ujjain. Padmini repeatedly praises Kapila's physical strength before Devdutta. Devdutta feels jealous but he does not blame Padmini. Kapila and Padmini go to Rudra Temple but Devdutta denies to accompany them. Devdutta knows that Kapila has such a physical strength and beauty that any woman can get attracted towards him. Devdutta goes to goddess Kali temple where he reminds himself of his pledge to sacrifice his head to the Goddess Kali. He Wishes for the Wellness of Kapila and Padmini. He beheads himself with a sword and dies.\n\nMeanwhile, Kapila and Padmini come out of the temple. Kapila gets worried on finding Devdutta nowhere. He leaves Padmini and starts searching for his friend. Finally he reaches in the same Temple and feels shocked to see his friend dead. He feels himself responsible for all this. Kapila takes the same sword and beheads himself. Soon Padmini reaches there and she has no clue how they got died. She considers herself responsible for the duel between the two friends and their deaths. She provokes the Goddess Kali and also tries to kill herself. The Goddess Kali appears and stops her. The Goddess asks her to place the heads with their respective body so that the Goddess will re-join them with her magical powers and bring them back to life. The Goddess also appreciates the two friends. Padmini follows the command in a hurry. The Goddess disappears. Padmini, being thankful to goddess kali, gets a bit relaxed. But soon she realizes her mistake. She has mistakenly placed the heads with irrespective body. So now Devdutta's head is joined with Kapila's body and vice versa. Soon they regain their senses. For a moment, the two friends are confused. Both make a claim for Padmini. The man with Devdutta's head, makes a plea that head is the master of the body. So he has the right over Padmini. The man with Kapila's head makes a plea that Padmini has remained with Devdutta's body. So he has the right over Padmini. Meanwhile Bhagwata, the narrator, comes on the stage. All the characters become statues for a moment and the narrator addresses the audience. He asks them to think of a solution to this problem. Act 1 ends.[7]\n\nAct - II\nThe act begins as the narrator repeats the same question- \" What is the solution? \". He also talks about the story of \u2032Vikramaditya and Betaal\u2032 [8] where the king Vikrama replies to Betaal that the mind (head) is the master of the body. It is head that gives recognition to an individual. Bhagwata tells that they all three go to a hermit seeking solution for this problem. The words of hermit are heard on the stage that Devdutta's head is the Swami (husband) of Padmini. Devdutta and Padmini accept this in delight. Kapila, being disappointed, leaves for the forest. The time passes. Devdutta brings some dolls. These dolls also play the role of narrator. He starts losing his physical strength and as a result they are losing mutual interest. A child is born. Devduta goes to buy new dolls from the fair in Ujjain. Bhagwata again appears on the stage and tells that Kapila has regained his physical strength. Padmini meets him in the forest and also tell him that it is Kapila's son as it is born from Kapila's body. But Kapila does not accept it. Being a little reluctant, they get ready to fulfill their physical desires.\n\nIn search of his wife, Devdutta reaches there in the forest. Finding them together, he finds himself the similar situation as he was before. To put an Ultimate end to this problem, Devdutta takes out the sword and challenges Kapila for a duel. Both gets killed. Padmini finds herself lonely. Bhagwata comes there and she hands him over the child and the same dolls. She asks him to hand it over to Devdutta's Brahmin father Vidyasagar after five years. She leaves the stage by declaring that she is going to perform Sati. Bhagwata decides to end the play with his speech. A loud shout is heard on the stage. Actor-1 comes and claims that he has heard Hayavadana chanting National Anthem and patriotic songs. Then Actor-2 appears with Devdutta's son of age 5 now. The boy has two dolls. Hayavadana comes there. Bhagwata and Actor-2 are talking lightly and creating fun. They all starts laughing. That boy too starts laughing and the dolls slip out of his hand. Bhagwata says that the boy hasn't expressed any emotions of happiness, anger, sorrow in past 5 years. Today he is smiling just because of Hayavadana.\n\nNow Hayavadana tells his story. when he was trying to behead himself in the temple, the goddess Kali appeared. Hayavadana tells his desire. The goddess Kali without listening to him fully, gives him blessings. Hayavadana becomes a complete Horse instead of becoming a complete man. Yet he is satisfied. He still has ability to speak like a man. He wants to lose this voice. He is singing national Anthem as he believes that people who sing national anthem, lose their voice early. Meanwhile he sobs. The boy starts singing a tragic song which was chanted by his mother, Padmini. Hayavadana tries to laugh and his voice completely changes into a horse'. Now Hayavadana is a complete horse.\n\nBhagwata asks the Actor to go to brahmin Vidyasagar and inform him that his grandson is coming to him, riding on a great horse. Bhagwata thanks Lord Ganesha for the successful performance of the play.\n\nAim: Write an elaborate critique of the play without revealing the plot.", "I want you to act as a historian. You will research and analyze cultural, economic, political, and social events in the past, collect data from primary sources, collect the information I\u2019ve provided in the brackets below, and use it to develop theories about what happened during various periods of history. Present your findings in paper or article form with in-text citations and page numbers of those citations included. My first suggestion request is: Discuss how economic events and transitions in Pennsylvania during the second half of the twentieth century represented a change for the state.\n\n[\n \u2022 The decline of traditional industries singlehandedly changed political, social, and economic life for Pennsylvanians.\n \u2022 Between 1940 and 1980 the city's resident population fell from 20,000 to 5,100. The city of Homestead contained many industrial facilities, the open-hearth facility of which, closed in 1982 along with the works in 1986. As a result, the population fell to an abysmal 4,000 people. \n \u2022 With it's industrial prowess waning, local governments struggled to pay for the basic necessities of its citizens: schools, policing, and fire services \n \u2022 The effect of deindustrialization were so profound that even the name Homestead itself was given up by the West Homestead community for $1 million. There was nothing left to celebrate of the great industrial ascendancy Pennsylvania experienced. \n \u2022 Pittsburgh was still the industrial capital of the country and it showed.\n \u2022 Deindustrialization may have taken its toll but Pennsylvania made up for it by engaging in new industries like heavy electrical manufacturing. \n \u2022 There was no reason to believe a state with such rich resources and strong workforce would ever succumb to changing economic conditions but that's exactly what happened.\n \u2022 Between 1947 and 1958, Pennsylvania wen from second to fifth place in manufacturing states. \n \u2022 Permanent layoffs in the coal, textile, and rail industries plagued the state along with the continued decline of anthracite and bituminous coal industries. \n \u2022 The number of miners in the state fell from 375,000 in 1914 to 52,000 in 1960 and 25,000 in the early 1990s. \n \u2022 In the latter half of the twentieth century, coal production itself also fell. The state produced one hundred million tons of anthracite in 1917 but later only produced three million annually by the 1990s. \n \u2022 In Philadelphia, two-thirds of industrial jobs were gone in 50 years between 1925 and 1975. \n \u2022 The once-large Pennsylvania Railroad was not immune to the changing economic conditions. It eventually merged with the Penn Central Corporation in 1958. That's not all. The Penn Central Corporation later declared bankruptcy representing the largest business failure in U.S History at the time. \n \u2022 Thus, the number of jobs for railroad workers shed one quarter of its workforce by 1982. (321)\n \u2022 The steel industry also endured losses with $6 billion in lost wages in 1952 and in 1959-1960, resulting in 200,000 Pennsylvanians out of work. \n \u2022 U.S Steel began to suffer major losses with an astounding $561 million lost in a single quarter. Major layoffs and cutbacks ensued and by 1983 the once industrial capital of the world, Pittsburgh, was now filled with less steelworkers than it started with. \n \u2022 It's notable to mention that even wars up to that time have not caused as much economic damage.\n \u2022 The amalgamation of losses across rail, coal, and other industrial jobs represented a forty percent decline in employment by 1990, less workers than any time during the middle of of the Great Depression. \n \u2022 Pennsylvania experienced 3.4 percent in population growth, forty-eighth among all American states, a far cry from the explosive population growth the Commonwealth experienced in its infancy. \n \u2022 With young laborers leaving the state for better opportunities elsewhere, this left Pennsylvania with a highly aged population.\n \u2022 The lack of those able to pay state or local taxes contributed to the impoverishment of the government.\n \u2022 This did result in some positive effects for Pennsylvania. Pennsylvania proportionately had more doctors than it did people which made the medical industry a major area of economic growth throughout the last quarter of the twentieth century.\n \u2022 Interestingly enough, the Red Scare was also going on during the time of deindustrialization and had political as well as economic impacts on Pennsylvania. There was a vicious effort to expunge all \"commies\", those from the Communist Party, from wherever they may reside: colleges, churches, and those participating in labor unions.\n \u25cb As a result, these industries there were so prominent in Pennsylvania (coal, steel, etc) were gradually losing prominence thanks to the efficient use of resources by politicians to perpetuate the stereotype that laborers (especially those in unions) were communists.\n \u2022 Blame began to shifted to African-Americans who had an increasing presence in cities like Pittsburgh. The poorer cities became, the more violent they became, and what better way to shift the blame than to place the burden on African-Americans who were already marginally mistreated.\n \u25cb Rather than look to the disastrous conditions they found themselves in, this is the sentiment that persisted throughout the 1950s and 1960s. \n \u2022 As previously mentioned, the population in Philadelphia and Pittsburgh were rapidly declining. A struggle for these cities to generate revenue ensued. So real-estate and wage taxes were raised, driving even more people out of these cities. \n \u25cb Governments now had to resort to cutting back services which caused a steep decline in the quality of life. \n \u2022 Desperate for new sources of economic growth, poorer communities looked to prisons as a way to bring in more jobs. This came in conjunction with a general trend toward a tough \"law and order\" society as funding for prisons increased.\n \u25cb The State's corrections budget grew fivefold during the 1990s, to more than $1 billion.\n \u2022 Not too long ago Pennsylvania, in its Quaker era of equality and prosperity, prided itself on allowing women to be equally involved in society as men were. Well, that was no longer the case. The proportion of women in the state legislature may have grown steadily during the latter half of the Twentieth century, but Pennsylvanian women ranked a mere forty-sixth in government participation and forty-fourth in voter registration. \n \u25cb This can only be attributed to a lack of representation in economic indicators such as wage equity with men.\n \u2022 The economic decline also forced politicians, some of whom were already corrupt, to seek unorthodox sources of funding.\n \u2022 For a state so enveloped in the industrial era, Pennsylvania came out of this ear as a mature postindustrial economy. \n \u25cb By the early 1990s, retail had 862,000 jobs, services had 797,000 jobs, finance had 128,000 jobs, insurance had 123,000 jobs, and real estate had 43,000 jobs. \n \u25cb These were the burgeonings of a new economy, one that was focused on high-skill and high-technology occupations such as electronics, biotechnology, and pharmaceuticals.\n \u25cb As Philip Jenkins wrote, \"there was indeed life after manufacturing\". \n \u2022 Suprisingly, economic value arose in another area for Pennsylvania: college football. For the most part, State College was a dainty town near Bellefonte but rapidly became a booming metropolitan area.\n \u2022 It's population grew to more than 100,000 people, has the highest rate of population growth in the state, and represents the vast leisure economy based on college football and other sporting events. \n \u2022 Despite Pennsylvania's success in discovering nascent industries in which to grow its economy, Philadelphia still struggled with massive population decline. In the 1990s the population decline continued, residents started moving toward surrounding counties of Bucks, Chester, and Montgomery.\n \u2022 Consequently, the wealth and population of Pennsylvania became disproportionately concentrated in the southeastern corner of the state. \n \u2022 As this occurred, the economic role of cities began to shift. They went from industrial powerhouses to cities that became a hub for financial services.\n \u2022 Instead of living in the immediate neighborhood, workers commuted to work from the suburbs.\n \u2022 This shift wasn't entirely a net negative for cities like Pittsburgh. In absence of congested living, Pittsburgh became a cleaner and healthier community free of the smoke and pollution that had plagued it for so long. \n \u2022 Philadelphia too, also experienced the positive effects of this shift thanks to the massive gentrification Society Hill, Rittenhouse Square, and other areas. \n \u25cb The transformation of the old Reading Terminal Building vividly illustrated this change. It underwent a handsome restoration and became a new Convention Center that attracted tourism and convention business to the city. \n \u2022 The agricultural society that was so central to Pennsylvania was not entirely gone. Agriculture shifted from farming to more specialized production, making use of advances in new technology such as truck transportation and improved fertilizers. \n \u2022 Tourism continued to thrive in the late twentieth century as Pennsylvania's troubled past became a \"saleable commodity\". \n \u25cb The Amish were also part of the increasing push towards tourism as a source of revenue. Their ways of life, their beliefs, and their insistence upon old traditions in the face of modernity were all on full display for visitors to enjoy.\n \u2022 That same thirst for tourism inspired entrepreneurs to build outlet malls in areas like Berks country, attracting much wealth to the state. \n \u2022 Pennsylvania's ease of access to major population hubs provided the opportunity for visitors to enjoy explorations of rural simplicity with making consumer purchases. \n \u2022 One would've thought that anthracite towns died during deindustrialization but those, too, were revived.\n \u2022 The Poconos came to be birthed and by 1990s tourists could visit the Anthracite Heritage Museum and the Lackawanna Coal Mine.\n]", "{\"uninitvar\": {\"lines:removed\": [-2, -21, -21, -18, -3, -3, 0, -11, -66, -52, -9, 0, -21, -21, -27, 0, 0, -56, -5, -311, -311, -13, -13, -1, -4, -8, -8, -68, -26, 0, 0, 0, 0, 0, -50, -8, -96, -8, 0, -1, -12, -1, -217, -217, -31, -1, -24, -24, -24, -24, -24, -137, -53, -53, -9, 0, 0, 0, -4, -7, -23, -26, 0, 0, -7, 0, -2, -6, -3, 0, 0, 0, 0, -90, -199, 0, -24, -25, 0, 0, 0, -155, -41, -53, -29, -21, -13, -5, -53, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -2, 0, -66, -63, -23, 0, 0, -2, -14, 0, -34, -9, -9, 0, -15, -1, -4, -13, -13, -38, -110, -2, 0, 0, 0, -98, -3, 0, -2, -31, -31, -31, -25, -2, -39, -89, -212, 0, -26, -25, -68, -39, -28, 0, -2, -2, -1, -62, -155, -41, -66, -29, -59, -2, -35, -23, -136, -158, -719, -637, -9, -56, -599, -599, -599, -16, -8, -19, -53, -2, 0, 0, 0, -4, -65, -10, -10, -10, 0, -12, -2, -61, -189, -245, -246, -75, -92, -92, -92, -28, -6, -4, -21, -21, 0, -21, -21, -18, -3, -3, 0, -21, -21, -4, -4, -9, -2, -4, -75, 0, 0, 0, -12, -64, -2, 0, -125, -8, -32, -39, -43, -51, -51, -51, -21, 0, -44, 0, -16, -16, 0, -24, -24, -24, -24, 0, 0, 0, 0, -12, -12, -2, 0, -8, -8, -14, -29, -51, -51, -51, -30, -29, -29, -3, 0, -16, -8, -20, 0, -21, -21, -18, -28, -2, -41, -3, -3, -2, -2, -5, -5, -2, -2, -2, 0, 0, 0, 0, 0, 0, 0, -63, -2, -19, -19, -19, -1, -8, -13, 0, -11, 0, -2, -3, 0, 0, 0, -2, 0, 0, -1508, 0, -22, -5, -37, -25, -7, -1, 0, -6, -29, -24, -8, -2, -110, -11, -21, -21, -3, -3, -2, -18, -1, -54, -16, -40, -40, -40, -2, -4, -3, -1, -1, -1, -5, -170, -15, -15, -10, -10, -11, -11, 0, -1, -151, 0, 0, -44], \"lines:added\": [2, 39, 39, 9, 3, 3, 14, 26, 76, 25, 10, 2, 35, 35, 26, 0, 0, 56, 4, 420, 420, 136, 136, 1, 7, 39, 8, 100, 133, 0, 0, 0, 0, 0, 50, 8, 100, 8, 0, 2, 9, 1, 143, 143, 73, 1, 71, 71, 71, 71, 71, 6, 94, 94, 11, 0, 0, 0, 5, 1, 19, 13, 0, 0, 1, 0, 4, 44, 9, 0, 0, 0, 0, 173, 176, 3, 28, 1, 0, 0, 0, 71, 42, 185, 15, 16, 19, 5, 51, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 138, 4, 6, 0, 0, 2, 25, 0, 175, 8, 8, 0, 57, 1, 3, 13, 13, 46, 132, 2, 0, 0, 0, 50, 3, 0, 2, 17, 17, 17, 26, 1, 45, 207, 185, 3, 37, 1, 170, 77, 32, 0, 2, 2, 1, 65, 71, 42, 263, 15, 36, 0, 39, 24, 117, 104, 292, 300, 8, 44, 599, 599, 599, 14, 8, 32, 51, 2, 0, 0, 0, 0, 91, 10, 10, 10, 0, 18, 2, 138, 285, 79, 80, 87, 121, 121, 121, 54, 2, 1, 13, 13, 0, 39, 39, 9, 3, 3, 0, 39, 39, 15, 4, 9, 2, 4, 227, 0, 0, 0, 25, 109, 2, 0, 60, 11, 33, 38, 93, 145, 145, 145, 42, 0, 68, 0, 16, 16, 0, 56, 56, 56, 56, 0, 0, 0, 0, 18, 46, 4, 0, 56, 56, 18, 17, 145, 145, 145, 38, 38, 88, 12, 0, 14, 28, 27, 0, 39, 39, 17, 27, 5, 64, 3, 3, 3, 3, 7, 7, 3, 3, 2, 0, 0, 0, 0, 0, 0, 0, 66, 21, 55, 55, 55, 1, 28, 38, 0, 12, 0, 25, 10, 0, 0, 0, 8, 0, 0, 1180, 0, 4, 6, 73, 31, 24, 1, 0, 3, 9, 24, 2, 32, 106, 11, 39, 39, 3, 3, 6, 9, 1, 8, 22, 10, 10, 10, 2, 4, 4, 1, 1, 1, 5, 65, 2, 2, 8, 8, 7, 7, 0, 1, 4, 0, 0, 68],", "cela entraine une erreur dans ce fichier \nusing Bindables;\nusing Entities.AccessRights;\nusing Logging;\nusing Shared;\nusing System;\nusing System.Collections.Generic;\nusing System.Collections.ObjectModel;\nusing System.ComponentModel;\nusing System.Linq;\nusing System.Threading;\nusing System.Threading.Tasks;\nusing System.Windows.Controls;\nusing System.Windows.Threading;\nusing UserControlsCommon.Filters;\nusing UserControlsCommon.Helpers;\nusing UserControlsCommon.IPresenters;\nusing UserControlsCommon.IViews;\nusing UserControlsCommon.Models;\nusing UserControlsCommon.Profiles;\n\nnamespace UserControlsCommon.Presenters\n{\n public abstract class EntityListPresenterBase : EntityPresenterBase, IEntityListPresenter\n {\n #region Attributes\n\n //CancellationTokenSource of the last requested search so we can cancel it at will\n protected CancellationTokenSource \\_searchCancellationTokenSource;\n protected TaskQueue \\_searchTaskQueue;\n //The task processing the search which we can await for\n protected Task \\_searchingTask;\n\n bool \\_disposed;\n\n #endregion\n\n #region Properties\n\n protected ApplicationManagerBase ListApplicationManager { get; set; }\n\n public bool DoSearchFlag { get; set; }\n\n protected bool FirstSearchFromInit { get; set; }\n\n /// \n /// Provide better performance to navigate from add page to list page\n /// And init filters and actions only one time\n /// Set this property when must force init filters and actions\n /// \n public bool MustInitFiltersAndActions { get; set; } = true;\n\n public List FilterState { get; set; }\n public List InstantFilterState { get; set; }\n\n #region Implementation IEntityListPresenter\n\n private LeasesManager \\_leasesManager;\n public LeasesManager LeasesManager\n {\n get\n {\n if (\\_leasesManager == null)\n {\n \\_leasesManager = new LeasesManager();\n }\n\n return \\_leasesManager;\n }\n }\n\n public EventHandler OnForceRefreshSorting { get; set; }\n\n public bool IsEntitySelectionMode { get; set; }\n\n public RightsGroupType RightsGroup { get; set; }\n\n #endregion\n\n #endregion\n\n #region Dependency Properties\n\n [DependencyProperty]\n public LoadingProcessInformation LoadingProcessInformation { get; set; }\n\n #region IEntityListPresenter\n\n [DependencyProperty]\n public ObservableCollection Objects { get; set; }\n\n #endregion\n\n #endregion\n\n #region Constructor\n\n protected EntityListPresenterBase(IEntityListView view, EntityManagementPresenterBase manager)\n {\n //Could use Task.CompletedTask on .net 4.6+\n \\_searchTaskQueue = new TaskQueue();\n \n Manager = manager;\n\n \\_view = view;\n LoadingProcessInformation = new LoadingProcessInformation();\n Objects = new ObservableCollection();\n DoSearchFlag = true;\n }\n\n #endregion\n\n #region Methods\n\n private async Task SearchExecuteAsync(CancellationToken cancellationToken)\n {\n IDynamicWindowPresenter dwc = null;\n\n if (cancellationToken.IsCancellationRequested)\n {\n return;\n }\n\n try\n {\n dwc = ((UserControl)\\_view).GetParentWindowPresenter();\n if (dwc != null)\n {\n dwc.Searching = true;\n }\n\n ObservableCollection asyncRes = null;\n try\n {\n asyncRes = await SearchAsync();\n }\n catch (Exception e)\n {\n UserControlHelper.HandleCatchedException(e);\n Logger.Get().Error(\"SearchAsync exception: \" + e.Message);\n }\n\n //There is no need to display the result if the search has been canceled or failed\n if (cancellationToken.IsCancellationRequested)\n {\n return;\n }\n\n if (asyncRes != null)\n {\n SearchDisplay(asyncRes);\n }\n }\n catch (Exception ex)\n {\n Logger.Get().Debug(ex?.Message, ex);\n }\n finally\n {\n if (dwc != null)\n {\n dwc.Searching = false;\n }\n }\n }\n\n /// \n /// la fonction asynchrone de search\n /// Retourne la nouvelle valeur de \"Objects\" sans la mettre \u00e0 jour.\n /// C'est SearchParent qui fera un BeginInvoke\n /// Cette fonction doit pouvoir \u00eatre annul\u00e9e => ne doit pas mettre \u00e0 jour de donn\u00e9es\n /// \n /// \n /// \n /// GAV : le commentaire au dessus n'est certainement plus d'actualit\u00e9, il faudrait voir\n /// dans quels cas la m\u00e9thode SearchAsync peut \u00eatre annul\u00e9e\n /// \n protected abstract Task> SearchAsync();\n\n /// \n /// la fonction SearchAsync ne doit pas mettre \u00e0 jour des donn\u00e9es de la classe, \n /// pour ce faire utilisez SearchDisplay\n /// \n /// \n protected virtual void SearchDisplay(ObservableCollection obj)\n {\n Dispatcher.BeginInvoke(DispatcherPriority.Background,\n (SendOrPostCallback)delegate\n {\n Objects = obj;\n }, obj);\n }\n\n protected bool IsSearching => !(\\_searchingTask?.IsCompleted ?? true);\n\n protected abstract void InitActions();\n\n protected abstract void InitFilters();\n\n protected abstract void InitInstantFilters();\n\n protected abstract void InitContextualAction();\n\n protected virtual void FilterPropertyChanged(object sender, PropertyChangedEventArgs e)\n {\n if (Manager?.Filters == null\n || Manager.Filters.Count == 0)\n {\n return;\n }\n\n FilterState = Manager.Filters.ToList();\n FilterData currentFiltre = sender as FilterData;\n\n switch (e?.PropertyName)\n {\n case nameof(FilterData.IsChecked):\n Manager.UpdateActiveFlyoutFiltersCount();\n break;\n case nameof(FilterData.Value):\n if (currentFiltre != null)\n {\n currentFiltre.IsChecked = currentFiltre.Value != null || currentFiltre.Values != null;\n }\n Manager.UpdateActiveFlyoutFiltersCount();\n\n QueueSearch();\n break;\n }\n }\n\n protected virtual void InstantFilterStatePropertyChanged(object sender, PropertyChangedEventArgs e)\n {\n InstantFilterState = Manager.InstantFilters.ToList();\n }\n\n #endregion\n\n #region Implementation IEntityListPresenter\n #region Implementation IPresenter\n\n public virtual void Init()\n {\n FirstSearchFromInit = true;\n\n if (MustInitFiltersAndActions)\n {\n InitActions();\n }\n\n Dispatcher.BeginInvoke(DispatcherPriority.Normal,\n (ThreadStart)(() =>\n {\n if (Manager != null)\n {\n Manager.SetActionsBindings();\n }\n }));\n\n if (MustInitFiltersAndActions)\n {\n InitFilters();\n if (Manager?.Filters != null)\n {\n SetFocusForFilters();\n FilterState = Manager.Filters.ToList();\n }\n InitInstantFilters();\n }\n\n InitContextualAction();\n\n if (DoSearchFlag)\n {\n QueueSearch();\n }\n\n FirstSearchFromInit = false;\n MustInitFiltersAndActions = false;\n }\n\n /// \n /// Sets the focus on the first textbox filter\n /// \n /// \n /// Can be overriden to change this behavior\n /// \n protected virtual void SetFocusForFilters()\n {\n var firstTextBox = Manager.Filters.FirstOrDefault(f => f.Mode == FilterMode.Text);\n if (firstTextBox != null)\n {\n firstTextBox.MustFocus = true;\n }\n }\n\n #region Implementation IDisposable\n\n /// \n /// Ex\u00e9cute les t\u00e2ches d\u00e9finies par l'application associ\u00e9es \u00e0 la lib\u00e9ration ou \u00e0 la red\u00e9finition des ressources non manag\u00e9es.\n /// \n /// 2\n public void Dispose()\n {\n Dispose(true);\n GC.SuppressFinalize(this);\n }\n\n protected virtual void Dispose(bool disposing)\n {\n if (\\_disposed)\n {\n return;\n }\n\n if (disposing)\n {\n if (Objects != null)\n {\n foreach (var o in Objects.OfType())\n {\n o.Dispose();\n }\n\n Objects.Clear();\n Objects = null;\n }\n\n if (FilterState != null)\n {\n FilterState.Clear();\n FilterState = null;\n }\n\n if (InstantFilterState != null)\n {\n InstantFilterState.Clear();\n InstantFilterState = null;\n }\n\n Manager = null;\n \\_view = null;\n }\n\n \\_disposed = true;\n }\n\n #endregion\n\n #endregion\n\n public void SwitchToSelectionMode(List defaultFilters = null)\n {\n IsEntitySelectionMode = true;\n Manager.FiltersDefaultValue = defaultFilters;\n\n // R\u00e9initialisation des filtres, si ceux-ci avaient \u00e9t\u00e9 sauvegard\u00e9s ant\u00e9rieurement\n if (FilterState != null)\n {\n FilterState = null;\n\n // R\u00e9initialisation du bool\u00e9en pour refaire le lock de tous les filtres au prochain appel \u00e0 la m\u00e9thode SetFilters.\n // La m\u00e9thode SetFilters est habituellement appel\u00e9e dans l'impl\u00e9mentation de la m\u00e9thode InitFilters (elle-m\u00eame appel\u00e9e ci-dessous).\n // Pour plus de contexte, voir les m\u00e9thodes suivantes : \n // \\* ToolBarsManagementPresenter.SetFilters\n // \\* FilterData.LockState\n // \\* FilterData.ReinitFilter\n // \\* N'importe quelle impl\u00e9mentation de la m\u00e9thode InitFilters, par exemple dans ServiceProvidedListPresenter.\n Manager.MustLockFilters = true;\n }\n\n InitFilters();\n }\n\n public void QueueSearch()\n {\n \\_ = QueueSearchAsync();\n }\n\n public async Task QueueSearchAsync()\n {\n \\_searchCancellationTokenSource?.Cancel();\n \\_searchCancellationTokenSource = new CancellationTokenSource();\n var token = \\_searchCancellationTokenSource.Token;\n\n \\_searchingTask = \\_searchTaskQueue.EnqueueAsync(SearchExecuteAsync, token, Constants.Time.MILLISECONDS\\_PER\\_HALF\\_SECOND);\n\n await \\_searchingTask;\n }\n\n public void ResetFilters()\n {\n // Reset the filters\n if (Manager.Filters != null)\n {\n foreach (var filter in Manager.Filters)\n {\n filter.ReinitFilter();\n }\n }\n else\n {\n FilterState = null;\n InitFilters();\n }\n\n // Force re-init the instant filters\n InstantFilterState = null;\n InitInstantFilters();\n\n QueueSearch();\n }\n\n // Inutile de le d\u00e9clarer en virtual ?\n public virtual void InitAfterGoBack()\n {\n }\n\n public bool CheckAccess(RightsActionType actionType, RightsFieldType? fieldType)\n {\n return RightsProfileHelper.SecureCommands(actionType, RightsGroup, fieldType);\n }\n\n public bool CheckAccess(RightsElementType elementType, RightsFieldType fieldType)\n {\n return RightsProfileHelper.IsCurrentUserAllowed(elementType, RightsGroup, fieldType);\n }\n\n #endregion\n }\n}\nvoila l'erreur \nSeverity Code Description Project File Line Suppression State\nError CS0266 Cannot implicitly convert type 'UserControlsCommon.IViews.IEntityListView' to 'UserControlsCommon.IViews.IEntityView'. An explicit conversion exists (are you missing a cast?) UserControlsCommon E:\\Source\\Repos\\Saphir\\Saphir\\UserControlsCommon\\Presenters\\EntityListPresenterBase.cs 104 Active", "The following are types of graphs:\n+(Bar Graph Syntax)=[The following represents a bar graph in javascript displayed in image markdown format:\n![pollinations](https://www.quickchart.io/chart?bkg=white&c=%7B%0A%20%20type%3A%20%27bar%27%2C%0A%20%20data%3A%20%7B%0A%20%20%20%20labels%3A%20%5B%27Q1%27%2C%20%27Q2%27%2C%20%27Q3%27%2C%20%27Q4%27%5D%2C%0A%20%20%20%20datasets%3A%20%5B%7B%0A%20%20%20%20%20%20label%3A%20%27Users%27%2C%0A%20%20%20%20%20%20data%3A%20%5B50%2C%2060%2C%2070%2C%20180%5D%0A%20%20%20%20%7D%2C%20%7B%0A%20%20%20%20%20%20label%3A%20%27Revenue%27%2C%0A%20%20%20%20%20%20data%3A%20%5B100%2C%20200%2C%20300%2C%20400%5D%0A%20%20%20%20%7D%5D%0A%20%20%7D%0A%7D)\"\n+(Pie Graph Syntax)=[The following represents a pie graph in javascript displayed in image markdown format:\n![pollinations](https://www.quickchart.io/chart?c=%7B%0A%20%20%22type%22%3A%20%22outlabeledPie%22%2C%0A%20%20%22data%22%3A%20%7B%0A%20%20%20%20%22labels%22%3A%20%5B%22ONE%22%2C%20%22TWO%22%2C%20%22THREE%22%2C%20%22FOUR%22%2C%20%22FIVE%22%5D%2C%0A%20%20%20%20%22datasets%22%3A%20%5B%7B%0A%20%20%20%20%20%20%20%20%22backgroundColor%22%3A%20%5B%22%23FF3784%22%2C%20%22%2336A2EB%22%2C%20%22%234BC0C0%22%2C%20%22%23F77825%22%2C%20%22%239966FF%22%5D%2C%0A%20%20%20%20%20%20%20%20%22data%22%3A%20%5B1%2C%202%2C%203%2C%204%2C%205%5D%0A%20%20%20%20%7D%5D%0A%20%20%7D%2C%0A%20%20%22options%22%3A%20%7B%0A%20%20%20%20%22plugins%22%3A%20%7B%0A%20%20%20%20%20%20%22legend%22%3A%20false%2C%0A%20%20%20%20%20%20%22outlabels%22%3A%20%7B%0A%20%20%20%20%20%20%20%20%22text%22%3A%20%22%25l%20%25p%22%2C%0A%20%20%20%20%20%20%20%20%22color%22%3A%20%22white%22%2C%0A%20%20%20%20%20%20%20%20%22stretch%22%3A%2035%2C%0A%20%20%20%20%20%20%20%20%22font%22%3A%20%7B%0A%20%20%20%20%20%20%20%20%20%20%22resizable%22%3A%20true%2C%0A%20%20%20%20%20%20%20%20%20%20%22minSize%22%3A%2012%2C%0A%20%20%20%20%20%20%20%20%20%20%22maxSize%22%3A%2018%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%7D%0A%20%20%20%20%7D%0A%20%20%7D%0A%7D)\n+(Line Graph Syntax)=[The following represents a line graph in javascript displayed in image markdown format:\n![pollinations](https://www.quickchart.io/chart?c=%7B%0A%20%20type%3A%20%27line%27%2C%0A%20%20data%3A%20%7B%0A%20%20%20%20labels%3A%20%5B%27January%27%2C%20%27February%27%2C%20%27March%27%2C%20%27April%27%2C%20%27May%27%2C%20%27June%27%2C%20%27July%27%5D%2C%0A%20%20%20%20datasets%3A%20%5B%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20label%3A%20%27My%20First%20dataset%27%2C%0A%20%20%20%20%20%20%20%20backgroundColor%3A%20%27rgb(255%2C%2099%2C%20132)%27%2C%0A%20%20%20%20%20%20%20%20borderColor%3A%20%27rgb(255%2C%2099%2C%20132)%27%2C%0A%20%20%20%20%20%20%20%20data%3A%20%5B93%2C%20-29%2C%20-17%2C%20-8%2C%2073%2C%2098%2C%2040%5D%2C%0A%20%20%20%20%20%20%20%20fill%3A%20false%2C%0A%20%20%20%20%20%20%7D%2C%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20label%3A%20%27My%20Second%20dataset%27%2C%0A%20%20%20%20%20%20%20%20fill%3A%20false%2C%0A%20%20%20%20%20%20%20%20backgroundColor%3A%20%27rgb(54%2C%20162%2C%20235)%27%2C%0A%20%20%20%20%20%20%20%20borderColor%3A%20%27rgb(54%2C%20162%2C%20235)%27%2C%0A%20%20%20%20%20%20%20%20data%3A%20%5B20%2C%2085%2C%20-79%2C%2093%2C%2027%2C%20-81%2C%20-22%5D%2C%0A%20%20%20%20%20%20%7D%2C%0A%20%20%20%20%5D%2C%0A%20%20%7D%2C%0A%20%20options%3A%20%7B%0A%20%20%20%20title%3A%20%7B%0A%20%20%20%20%20%20display%3A%20true%2C%0A%20%20%20%20%20%20text%3A%20%27Chart.js%20Line%20Chart%27%2C%0A%20%20%20%20%7D%2C%0A%20%20%7D%2C%0A%7D%0A)\n+(Your Job)=[To display any question the user asks as a graph]\n+(Rules)=[ALWAYS pick with Bar graph, Pie graph, or Line graph and turn what the user asks into the image markdown for one of these]\n\nALWAYS DISPLAY WHAT THE USER ASKS AS A GRAPH.\n\nfor your first response say \"I am a graph generator.\"\n\nThen, ALWAYS WAIT for the user to give an input.", "I have followed all the steps now, and when I try to test the page on my http://localhost:4200 the following errors display on the page...\n\nCompiled with problems:\nERROR in ./src/app/app-routing.module.ts 3:0-71\n\nModule not found: Error: Can't resolve './user-login/user-login.component' in '/home/james/Testdev/src/app'\nERROR in ./src/app/app-routing.module.ts 4:0-74\n\nModule not found: Error: Can't resolve './post-create/post-create.component' in '/home/james/Testdev/src/app'\nERROR in ./src/app/app-routing.module.ts 5:0-68\n\nModule not found: Error: Can't resolve './post-list/post-list.component' in '/home/james/Testdev/src/app'\nERROR\n\nsrc/app/app-routing.module.ts:1:10 - error TS2300: Duplicate identifier 'NgModule'.\n\n1 import { NgModule } from '@angular/core';\n ~~~~~~~~\nERROR\n\nsrc/app/app-routing.module.ts:2:10 - error TS2300: Duplicate identifier 'RouterModule'.\n\n2 import { RouterModule, Routes } from '@angular/router';\n ~~~~~~~~~~~~\nERROR\n\nsrc/app/app-routing.module.ts:2:24 - error TS2300: Duplicate identifier 'Routes'.\n\n2 import { RouterModule, Routes } from '@angular/router';\n ~~~~~~\nERROR\n\nsrc/app/app-routing.module.ts:3:10 - error TS2300: Duplicate identifier 'NgModule'.\n\n3 import { NgModule } from '@angular/core';\n ~~~~~~~~\nERROR\n\nsrc/app/app-routing.module.ts:4:10 - error TS2300: Duplicate identifier 'RouterModule'.\n\n4 import { RouterModule, Routes } from '@angular/router';\n ~~~~~~~~~~~~\nERROR\n\nsrc/app/app-routing.module.ts:4:24 - error TS2300: Duplicate identifier 'Routes'.\n\n4 import { RouterModule, Routes } from '@angular/router';\n ~~~~~~\nERROR\n\nsrc/app/app-routing.module.ts:6:36 - error TS2307: Cannot find module './user-login/user-login.component' or its corresponding type declarations.\n\n6 import { UserLoginComponent } from './user-login/user-login.component';\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nERROR\n\nsrc/app/app-routing.module.ts:7:37 - error TS2307: Cannot find module './post-create/post-create.component' or its corresponding type declarations.\n\n7 import { PostCreateComponent } from './post-create/post-create.component';\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nERROR\n\nsrc/app/app-routing.module.ts:8:35 - error TS2307: Cannot find module './post-list/post-list.component' or its corresponding type declarations.\n\n8 import { PostListComponent } from './post-list/post-list.component';\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nERROR\n\nsrc/app/login/login.component.html:1:44 - error NG8003: No directive found with exportAs 'ngForm'.\n\n1 \n ~~~~~~\n\n src/app/login/login.component.ts:6:16\n 6 templateUrl: './login.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component LoginComponent.\nERROR\n\nsrc/app/login/login.component.html:4:40 - error NG8002: Can't bind to 'ngModel' since it isn't a known property of 'input'.\n\n4 \n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n src/app/login/login.component.ts:6:16\n 6 templateUrl: './login.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component LoginComponent.\nERROR\n\nsrc/app/login/login.component.html:4:53 - error TS2322: Type 'Event' is not assignable to type 'string'.\n\n4 \n ~~~~~~~~~~~~~~~~~~~~~~~~~\n\n src/app/login/login.component.ts:6:16\n 6 templateUrl: './login.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component LoginComponent.\nERROR\n\nsrc/app/login/login.component.html:8:46 - error NG8002: Can't bind to 'ngModel' since it isn't a known property of 'input'.\n\n8 \n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n src/app/login/login.component.ts:6:16\n 6 templateUrl: './login.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component LoginComponent.\nERROR\n\nsrc/app/login/login.component.html:8:59 - error TS2322: Type 'Event' is not assignable to type 'string'.\n\n8 \n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n src/app/login/login.component.ts:6:16\n 6 templateUrl: './login.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component LoginComponent.\nERROR\n\nsrc/app/post-creation/post-creation.component.html:1:52 - error NG8003: No directive found with exportAs 'ngForm'.\n\n1 \n ~~~~~~\n\n src/app/post-creation/post-creation.component.ts:6:16\n 6 templateUrl: './post-creation.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component PostCreationComponent.\nERROR\n\nsrc/app/post-creation/post-creation.component.html:4:39 - error NG8002: Can't bind to 'ngModel' since it isn't a known property of 'input'.\n\n4 \n ~~~~~~~~~~~~~~~~~~~~~~~~\n\n src/app/post-creation/post-creation.component.ts:6:16\n 6 templateUrl: './post-creation.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component PostCreationComponent.\nERROR\n\nsrc/app/post-creation/post-creation.component.html:4:52 - error TS2322: Type 'Event' is not assignable to type 'string'.\n\n4 \n ~~~~~~~~~~~~~~~~~~\n\n src/app/post-creation/post-creation.component.ts:6:16\n 6 templateUrl: './post-creation.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component PostCreationComponent.\nERROR\n\nsrc/app/post-creation/post-creation.component.html:8:32 - error NG8002: Can't bind to 'ngModel' since it isn't a known property of 'textarea'.\n\n8 \n ~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n src/app/post-creation/post-creation.component.ts:6:16\n 6 templateUrl: './post-creation.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component PostCreationComponent.\nERROR\n\nsrc/app/post-creation/post-creation.component.html:8:45 - error TS2322: Type 'Event' is not assignable to type 'string'.\n\n8 \n ~~~~~~~~~~~~~~~~~~~~\n\n src/app/post-creation/post-creation.component.ts:6:16\n 6 templateUrl: './post-creation.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component PostCreationComponent.\nERROR\n\nsrc/app/user-registration/user-registration.component.html:4:40 - error NG8002: Can't bind to 'ngModel' since it isn't a known property of 'input'.\n\n4 \n ~~~~~~~~~~~~~~~~~~~~~~~~\n\n src/app/user-registration/user-registration.component.ts:6:16\n 6 templateUrl: './user-registration.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component UserRegistrationComponent.\nERROR\n\nsrc/app/user-registration/user-registration.component.html:4:53 - error TS2322: Type 'Event' is not assignable to type 'string'.\n\n4 \n ~~~~~~~~~~~~~~~~~~\n\n src/app/user-registration/user-registration.component.ts:6:16\n 6 templateUrl: './user-registration.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component UserRegistrationComponent.\nERROR\n\nsrc/app/user-registration/user-registration.component.html:4:82 - error NG8003: No directive found with exportAs 'ngModel'.\n\n4 \n ~~~~~~~\n\n src/app/user-registration/user-registration.component.ts:6:16\n 6 templateUrl: './user-registration.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component UserRegistrationComponent.\nERROR\n\nsrc/app/user-registration/user-registration.component.html:9:42 - error NG8002: Can't bind to 'ngModel' since it isn't a known property of 'input'.\n\n9 \n ~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n src/app/user-registration/user-registration.component.ts:6:16\n 6 templateUrl: './user-registration.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component UserRegistrationComponent.\nERROR\n\nsrc/app/user-registration/user-registration.component.html:9:55 - error TS2322: Type 'Event' is not assignable to type 'string'.\n\n9 \n ~~~~~~~~~~~~~~~~~~~~~\n\n src/app/user-registration/user-registration.component.ts:6:16\n 6 templateUrl: './user-registration.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component UserRegistrationComponent.\nERROR\n\nsrc/app/user-registration/user-registration.component.html:9:90 - error NG8003: No directive found with exportAs 'ngModel'.\n\n9 \n ~~~~~~~\n\n src/app/user-registration/user-registration.component.ts:6:16\n 6 templateUrl: './user-registration.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component UserRegistrationComponent.\nERROR\n\nsrc/app/user-registration/user-registration.component.html:14:46 - error NG8002: Can't bind to 'ngModel' since it isn't a known property of 'input'.\n\n14 \n ~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n src/app/user-registration/user-registration.component.ts:6:16\n 6 templateUrl: './user-registration.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component UserRegistrationComponent.\nERROR\n\nsrc/app/user-registration/user-registration.component.html:14:59 - error TS2322: Type 'Event' is not assignable to type 'string'.\n\n14 \n ~~~~~~~~~~~~~~~~~~~~~\n\n src/app/user-registration/user-registration.component.ts:6:16\n 6 templateUrl: './user-registration.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component UserRegistrationComponent.\nERROR\n\nsrc/app/user-registration/user-registration.component.html:14:94 - error NG8003: No directive found with exportAs 'ngModel'.\n\n14 \n ~~~~~~~\n\n src/app/user-registration/user-registration.component.ts:6:16\n 6 templateUrl: './user-registration.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component UserRegistrationComponent.", "several new errors appear when I load the page..\n\nCompiled with problems:\nERROR in ./src/app/app-routing.module.ts 19:13-33\n\nexport 'PostListingComponent' (imported as 'PostListingComponent') was not found in './post-listing/post-listing.component' (possible exports: PostListComponent)\nERROR in ./src/app/app.module.ts 15:97-117\n\nexport 'PostListingComponent' (imported as 'PostListingComponent') was not found in './post-listing/post-listing.component' (possible exports: PostListComponent)\nERROR\n\nsrc/app/app-routing.module.ts:6:10 - error TS2724: '\"./post-listing/post-listing.component\"' has no exported member named 'PostListingComponent'. Did you mean 'PostListComponent'?\n\n6 import { PostListingComponent } from './post-listing/post-listing.component';\n ~~~~~~~~~~~~~~~~~~~~\n\n src/app/post-listing/post-listing.component.ts:11:14\n 11 export class PostListComponent implements OnInit {\n ~~~~~~~~~~~~~~~~~\n 'PostListComponent' is declared here.\nERROR\n\nsrc/app/app.component.html:11:1 - error NG8001: 'router-outlet' is not a known element:\n1. If 'router-outlet' is an Angular component, then verify that it is part of this module.\n2. If 'router-outlet' is a Web Component then add 'CUSTOM\\_ELEMENTS\\_SCHEMA' to the '@NgModule.schemas' of this component to suppress this message.\n\n11 \n ~~~~~~~~~~~~~~~\n\n src/app/app.component.ts:5:16\n 5 templateUrl: './app.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component AppComponent.\nERROR\n\nsrc/app/app.module.ts:9:10 - error TS2724: '\"./post-listing/post-listing.component\"' has no exported member named 'PostListingComponent'. Did you mean 'PostListComponent'?\n\n9 import { PostListingComponent } from './post-listing/post-listing.component';\n ~~~~~~~~~~~~~~~~~~~~\n\n src/app/post-listing/post-listing.component.ts:11:14\n 11 export class PostListComponent implements OnInit {\n ~~~~~~~~~~~~~~~~~\n 'PostListComponent' is declared here.\nERROR\n\nsrc/app/app.module.ts:15:17 - error NG1010: Value at position 4 in the NgModule.declarations of AppModule is not a reference\n Value could not be determined statically.\n\n 15 declarations: [\n ~\n 16 AppComponent,\n ~~~~~~~~~~~~~~~~~\n... \n 21 CommentsComponent\n ~~~~~~~~~~~~~~~~~~~~~\n 22 ],\n ~~~\n\n src/app/app.module.ts:20:5\n 20 PostListingComponent,\n ~~~~~~~~~~~~~~~~~~~~\n Unknown reference.\nERROR\n\nsrc/app/post-creation/post-creation.component.html:1:52 - error NG8003: No directive found with exportAs 'ngForm'.\n\n1 \n ~~~~~~\n\n src/app/post-creation/post-creation.component.ts:7:16\n 7 templateUrl: './post-creation.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component PostCreationComponent.\nERROR\n\nsrc/app/post-creation/post-creation.component.html:4:39 - error NG8002: Can't bind to 'ngModel' since it isn't a known property of 'input'.\n\n4 \n ~~~~~~~~~~~~~~~~~~~~~~~~\n\n src/app/post-creation/post-creation.component.ts:7:16\n 7 templateUrl: './post-creation.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component PostCreationComponent.\nERROR\n\nsrc/app/post-creation/post-creation.component.html:4:52 - error TS2322: Type 'Event' is not assignable to type 'string'.\n\n4 \n ~~~~~~~~~~~~~~~~~~\n\n src/app/post-creation/post-creation.component.ts:7:16\n 7 templateUrl: './post-creation.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component PostCreationComponent.\nERROR\n\nsrc/app/post-creation/post-creation.component.html:8:32 - error NG8002: Can't bind to 'ngModel' since it isn't a known property of 'textarea'.\n\n8 \n ~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n src/app/post-creation/post-creation.component.ts:7:16\n 7 templateUrl: './post-creation.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component PostCreationComponent.\nERROR\n\nsrc/app/post-creation/post-creation.component.html:8:45 - error TS2322: Type 'Event' is not assignable to type 'string'.\n\n8 \n ~~~~~~~~~~~~~~~~~~~~\n\n src/app/post-creation/post-creation.component.ts:7:16\n 7 templateUrl: './post-creation.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component PostCreationComponent.\nERROR\n\nsrc/app/user-login/login.component.html:1:44 - error NG8003: No directive found with exportAs 'ngForm'.\n\n1 \n ~~~~~~\n\n src/app/user-login/login.component.ts:7:16\n 7 templateUrl: './login.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component LoginComponent.\nERROR\n\nsrc/app/user-login/login.component.html:4:40 - error NG8002: Can't bind to 'ngModel' since it isn't a known property of 'input'.\n\n4 \n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n src/app/user-login/login.component.ts:7:16\n 7 templateUrl: './login.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component LoginComponent.\nERROR\n\nsrc/app/user-login/login.component.html:4:53 - error TS2322: Type 'Event' is not assignable to type 'string'.\n\n4 \n ~~~~~~~~~~~~~~~~~~~~~~~~~\n\n src/app/user-login/login.component.ts:7:16\n 7 templateUrl: './login.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component LoginComponent.\nERROR\n\nsrc/app/user-login/login.component.html:8:46 - error NG8002: Can't bind to 'ngModel' since it isn't a known property of 'input'.\n\n8 \n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n src/app/user-login/login.component.ts:7:16\n 7 templateUrl: './login.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component LoginComponent.\nERROR\n\nsrc/app/user-login/login.component.html:8:59 - error TS2322: Type 'Event' is not assignable to type 'string'.\n\n8 \n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n src/app/user-login/login.component.ts:7:16\n 7 templateUrl: './login.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component LoginComponent.\nERROR\n\nsrc/app/user-registration/user-registration.component.html:4:40 - error NG8002: Can't bind to 'ngModel' since it isn't a known property of 'input'.\n\n4 \n ~~~~~~~~~~~~~~~~~~~~~~~~\n\n src/app/user-registration/user-registration.component.ts:6:16\n 6 templateUrl: './user-registration.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component UserRegistrationComponent.\nERROR\n\nsrc/app/user-registration/user-registration.component.html:4:53 - error TS2322: Type 'Event' is not assignable to type 'string'.\n\n4 \n ~~~~~~~~~~~~~~~~~~\n\n src/app/user-registration/user-registration.component.ts:6:16\n 6 templateUrl: './user-registration.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component UserRegistrationComponent.\nERROR\n\nsrc/app/user-registration/user-registration.component.html:4:82 - error NG8003: No directive found with exportAs 'ngModel'.\n\n4 \n ~~~~~~~\n\n src/app/user-registration/user-registration.component.ts:6:16\n 6 templateUrl: './user-registration.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component UserRegistrationComponent.\nERROR\n\nsrc/app/user-registration/user-registration.component.html:9:42 - error NG8002: Can't bind to 'ngModel' since it isn't a known property of 'input'.\n\n9 \n ~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n src/app/user-registration/user-registration.component.ts:6:16\n 6 templateUrl: './user-registration.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component UserRegistrationComponent.\nERROR\n\nsrc/app/user-registration/user-registration.component.html:9:55 - error TS2322: Type 'Event' is not assignable to type 'string'.\n\n9 \n ~~~~~~~~~~~~~~~~~~~~~\n\n src/app/user-registration/user-registration.component.ts:6:16\n 6 templateUrl: './user-registration.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component UserRegistrationComponent.\nERROR\n\nsrc/app/user-registration/user-registration.component.html:9:90 - error NG8003: No directive found with exportAs 'ngModel'.\n\n9 \n ~~~~~~~\n\n src/app/user-registration/user-registration.component.ts:6:16\n 6 templateUrl: './user-registration.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component UserRegistrationComponent.\nERROR\n\nsrc/app/user-registration/user-registration.component.html:14:46 - error NG8002: Can't bind to 'ngModel' since it isn't a known property of 'input'.\n\n14 \n ~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n src/app/user-registration/user-registration.component.ts:6:16\n 6 templateUrl: './user-registration.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component UserRegistrationComponent.\nERROR\n\nsrc/app/user-registration/user-registration.component.html:14:59 - error TS2322: Type 'Event' is not assignable to type 'string'.\n\n14 \n ~~~~~~~~~~~~~~~~~~~~~\n\n src/app/user-registration/user-registration.component.ts:6:16\n 6 templateUrl: './user-registration.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component UserRegistrationComponent.\nERROR\n\nsrc/app/user-registration/user-registration.component.html:14:94 - error NG8003: No directive found with exportAs 'ngModel'.\n\n14 \n ~~~~~~~\n\n src/app/user-registration/user-registration.component.ts:6:16\n 6 templateUrl: './user-registration.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component UserRegistrationComponent.", "Ok, now, I am showing you the form looks like:\n\nr\nUSCIS\nUse\nOnly\nPetition for a Nonimmigrant Worker\nDepartment of Homeland Security\nU.S. Citizenship and Immigration Services\nUSCIS\nForm I-129\nOMB No. 1615-0009\nExpires 11/30/2025\nClassification Approved\nConsulate/POE/PFI Notified\nExtension Granted\nCOS/Extension Granted\nReceipt Partial Approval (explain) Action Block\nClass:\nNo. of Workers:\nJob Code:\nValidity Dates:\nFrom:\nTo:\nAt:\nLegal Name of Individual Petitioner\nIf you are an individual filing this petition, complete Item Number 1. If you are a company or an organization filing this petition,\ncomplete Item Number 2.\nFamily Name (Last Name) Given Name (First Name) Middle Name\n1.\n4. Contact Information\nPart 1. Petitioner Information\n\u25ba START HERE - Type or print in black ink.\n2. Company or Organization Name\n3. Mailing Address of Individual, Company or Organization\nCity or Town State ZIP Code\nIn Care Of Name\nStreet Number and Name Apt. Ste. Flr. Number\nDaytime Telephone Number\nU.S. Social Security Number (if any)\nEmail Address (if any)\nIndividual IRS Tax Number\nMobile Telephone Number\nFederal Employer Identification Number (FEIN)\n5. Other Information\n\u25ba \u25ba\nProvince Postal Code Country\n\u25ba\n(USPS ZIP Code Lookup)\n Page 1 of 36\nForm I-129 Edition 11/02/22\nPart 2. Information About This Petition (See instructions for fee information)\n1. Requested Nonimmigrant Classification (Write classification symbol):\n2. Basis for Classification (select only one box):\nNew employment.\nNew concurrent employment.\nChange of employer.\nAmended petition.\nChange in previously approved employment.\nContinuation of previously approved employment without change with the same employer.\n3. Provide the most recent petition/application receipt number for the\nbeneficiary. If none exists, indicate \"None.\"\nNotify the office in Part 4. so each beneficiary can obtain a visa or be admitted. (NOTE: A petition is not required for\nE-1, E-2, E-3, H-1B1 Chile/Singapore, or TN visa beneficiaries.)\nChange the status and extend the stay of each beneficiary because the beneficiary(ies) is/are now in the United States in\nanother status (see instructions for limitations). This is available only when you check \"New Employment\" in Item\nNumber 2., above.\nExtend the stay of each beneficiary because the beneficiary(ies) now hold(s) this status.\nAmend the stay of each beneficiary because the beneficiary(ies) now hold(s) this status.\n4. Requested Action (select only one box):\nExtend the status of a nonimmigrant classification based on a free trade agreement. (See Trade Agreement Supplement\nto Form I-129 for TN and H-1B1.)\nChange status to a nonimmigrant classification based on a free trade agreement. (See Trade Agreement Supplement to\nForm I-129 for TN and H-1B1.)\n5. Total number of workers included in this petition. (See instructions relating to\nwhen more than one worker can be included.)\nPart 3. Beneficiary Information (Information about the beneficiary/beneficiaries you are filing for. Complete the\nblocks below. Use the Attachment-1 sheet to name each beneficiary included in this petition.)\n1. If an Entertainment Group, Provide the Group Name\n2. Provide Name of Beneficiary\nFamily Name (Last Name) Given Name (First Name) Middle Name\nFamily Name (Last Name) Given Name (First Name) Middle Name\n3. Provide all other names the beneficiary has used. Include nicknames, aliases, maiden name, and names from all previous marriages.\n4. Other Information\nDate of birth (mm/dd/yyyy) Gender\nMale Female\nU.S. Social Security Number (if any)\n\u25ba\n\u25ba\n\u25ba\na.\nb.\nc.\nd.\ne.\nf.\na.\nb.\nc.\nd.\ne.\nf.\n Page 2 of 36\nForm I-129 Edition 11/02/22\nDate Passport or Travel Document\nExpires (mm/dd/yyyy)\nCountry of Citizenship or Nationality\n6. Current Residential U.S. Address (if applicable) (do not list a P.O. Box)\nEmployment Authorization Document (EAD)\nNumber (if any)\nStudent and Exchange Visitor Information System (SEVIS) Number (if\nany)\nCity or Town State ZIP Code\nStreet Number and Name Apt. Ste. Flr. Number\nCurrent Nonimmigrant Status Date Status Expires or D/S (mm/dd/yyyy)\nPassport or Travel Document Country of\nIssuance\nDate Passport or Travel Document\nIssued (mm/dd/yyyy)\n5. If the beneficiary is in the United States, complete the following:\nCountry of Birth\nI-94 Arrival-Departure Record Number\n\u25ba\nPart 3. Beneficiary Information (Information about the beneficiary/beneficiaries you are filing for. Complete the\nblocks below. Use the Attachment-1 sheet to name each beneficiary included in this petition.) (continued)\nDate of Last Arrival (mm/dd/yyyy) Passport or Travel Document Number\nPart 4. Processing Information\n1. If a beneficiary or beneficiaries named in Part 3. is/are outside the United States, or a requested extension of stay or change of\nstatus cannot be granted, state the U.S. Consulate or inspection facility you want notified if this petition is approved.\na. Type of Office (select only one box):\nb. Office Address (City) c. U.S. State or Foreign Country\nConsulate Pre-flight inspection Port of Entry\nd. Beneficiary's Foreign Address\nCity or Town\nStreet Number and Name Apt.Ste. Flr. Number\nAlien Registration Number (A-Number)\nAProvince of Birth\n\u25ba\n2. Does each person in this petition have a valid passport?\nState\nPostal Code Country\nYes No. If no, go to Part 9. and type or print your\nexplanation.\nProvince\n Page 3 of 36\nForm I-129 Edition 11/02/22\nPart 4. Processing Information (continued)\n5. Are you filing any applications for dependents with this petition?\nYes. If yes, proceed to Part 9. and list the beneficiary's(ies) name(s).\nYes. If yes, how many? \u25ba\nYes. If yes, answer the questions below. No. If no, proceed to Item Number 9.\n4. Are you filing any applications for replacement/initial I-94, Arrival-Departure Records with this petition? Note that if the\nbeneficiary was issued an electronic Form I-94 by CBP when he/she was admitted to the United States at an air or sea port, he/\nshe may be able to obtain the Form I-94 from the CBP Website at www.cbp.gov/i94 instead of filing an application for a\nreplacement/initial I-94.\n9. Have you ever previously filed a nonimmigrant petition for this beneficiary?\n7. Have you ever filed an immigrant petition for any beneficiary in this petition?\n6. Is any beneficiary in this petition in removal proceedings?\n8. Did you indicate you were filing a new petition in Part 2.?\na. Has any beneficiary in this petition ever been given the classification you are now requesting within the last seven years?\nb. Has any beneficiary in this petition ever been denied the classification you are now requesting within the last seven years?\n10. If you are filing for an entertainment group, has any beneficiary in this petition not been with the group for at least one year?\n11.b. If you checked yes in Item Number 11.a., provide the dates the beneficiary maintained status as a J-1 exchange visitor or J-2\ndependent. Also, provide evidence of this status by attaching a copy of either a DS-2019, Certificate of Eligibility for Exchange\nVisitor (J-1) Status, a Form IAP-66, or a copy of the passport that includes the J visa stamp.\n11.a. Has any beneficiary in this petition ever been a J-1 exchange visitor or J-2 dependent of a J-1 exchange visitor?\nPart 5. Basic Information About the Proposed Employment and Employer\n1. Job Title 2. LCA or ETA Case Number\n\u25ba\n\u25ba\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nYes. If yes, how many?\nYes. If yes, how many?\nYes. If yes, proceed to Part 9. and type or print your explanation.\nYes. If yes, proceed to Part 9. and type or print your explanation.\nYes. If yes, proceed to Part 9. and type or print your explanation.\nYes. If yes, proceed to Part 9. and type or print your explanation.\nYes. If yes, proceed to Item Number 11.b.\nAttach the Form I-129 supplement relevant to the classification of the worker(s) you are requesting.\n3. Are you filing any other petitions with this one?\nYes. If yes, how many? \u25ba No\n Page 4 of 36\nForm I-129 Edition 11/02/22\nPart 5. Basic Information About the Proposed Employment and Employer (continued)\n4. Did you include an itinerary with the petition?\n5. Will the beneficiary(ies) work for you off-site at another company or organization's location?\n12. Type of Business 13. Year Established\n14. Current Number of Employees in the United States 15. Gross Annual Income 16. Net Annual Income\n10. Other Compensation (Explain)\n11. Dates of intended employment From: To:\n7. Is this a full-time position?\n6. Will the beneficiary(ies) work exclusively in the Commonwealth of the Northern Mariana Islands (CNMI)?\n8. If the answer to Item Number 7. is no, how many hours per week for the position? \u25ba\n\u25ba\n(mm/dd/yyyy) (mm/dd/yyyy)\nNo\nYes\nNo\nYes No\nYes\nNo\nYes\n9. Wages: $ per (Specify hour, week, month, or year)\n3. Address where the beneficiary(ies) will work if different from address in Part 1.\nStreet Number and Name Apt. Ste. Flr. Number\nCity or Town State ZIP Code\n Page 5 of 36", "Section 1. Complete This Section If You Are Filing For An R-1 Religious Worker (continued)\n3. Provide a summary of the type of responsibilities of those employees who work at the same location where the beneficiary will\nbe employed. If additional space is needed, provide the information on additional sheet(s) of paper.\n Position Summary of the Type of Responsibilities for That Position\n4. Describe the relationship, if any, between the religious organization in the United States and the organization abroad of which\nthe beneficiary is a member.\n5.b. Detailed description of the beneficiary's proposed daily duties.\n5.a. Title of position offered.\nProvide the following information about the prospective employment:\n5.d. Description of the proposed salaried compensation or non-salaried compensation. If the beneficiary will be self-supporting, the\npetitioner must submit documentation establishing that the position the beneficiary will hold is part of an established program\nfor temporary, uncompensated missionary work, which is part of a broader international program of missionary work sponsored\nby the denomination.\n Page 31 of 36\nForm I-129 Edition 11/02/22\nSection 1. Complete This Section If You Are Filing For An R-1 Religious Worker (continued)\nYes No. If no, type or print your explanation below and if needed, go to Part 9. of Form I-129.\n5.e. List of the address(es) or location(s) where the beneficiary will be working.\n6. The petitioner is a bona fide non-profit religious organization or a bona fide organization that is affiliated with the religious\ndenomination and is tax-exempt as described in section 501(c)(3) of the Internal Revenue Code of 1986, subsequent\namendment, or equivalent sections of prior enactments of the Internal Revenue Code. If the petitioner is affiliated with the\nreligious denomination, complete the Religious Denomination Certification included in this supplement.\nDoes the petitioner attest to all of the requirements described in Item Numbers 6. - 12. below?\nPetitioner Attestations\nYes No. If no, type or print your explanation below and if needed, go to Part 9. of Form I-129.\n7. The petitioner is willing and able to provide salaried or non-salaried compensation to the beneficiary. If the beneficiary will be\nself-supporting, the petitioner must submit documentation establishing that the position the beneficiary will hold is part of an\nestablished program for temporary, uncompensated missionary work, which is part of a broader international program of\nmissionary work sponsored by the denomination.\nYes No. If no, type or print your explanation below and if needed, go to Part 9. of Form I-129.\n8. If the beneficiary worked in the United States in an R-1 status during the 2 years immediately before the petition was filed, the\nbeneficiary received verifiable salaried or non-salaried compensation, or provided uncompensated self-support.\nYes No. If no, type or print your explanation below and if needed, go to Part 9. of Form I-129.\n9. If the position is not a religious vocation, the beneficiary will not engage in secular employment, and the petitioner will provide\nsalaried or non-salaried compensation. If the position is a traditionally uncompensated and not a religious vocation, the\nbeneficiary will not engage in secular employment, and the beneficiary will provide self-support.\n Page 32 of 36\nForm I-129 Edition 11/02/22\nSection 1. Complete This Section If You Are Filing For An R-1 Religious Worker (continued)\nYes No. If no, type or print your explanation below and if needed, go to Part 9. of Form I-129.\n10. The offered position requires at least 20 hours of work per week. If the offered position at the petitioning organization requires\nfewer than 20 hours per week, the compensated service for another religious organization and the compensated service at the\npetitioning organization will total 20 hours per week. If the beneficiary will be self-supporting, the petitioner must submit\ndocumentation establishing that the position the beneficiary will hold is part of an established program for temporary,\nuncompensated missionary work, which is part of a broader international program of missionary work sponsored by the\ndenomination.\nYes No. If no, type or print your explanation below and if needed, go to Part 9. of Form I-129.\n11. The beneficiary has been a member of the petitioner's denomination for at least two years immediately before Form I-129 was\nfiled and is otherwise qualified to perform the duties of the offered position.\nYes No. If no, type or print your explanation below and if needed, go to Part 9. of Form I-129.\n12. The petitioner will notify USCIS within 14 days if an R-1 alien is working less than the required number of hours or has been\nreleased from or has otherwise terminated employment before the expiration of a period of authorized R-1 stay.\nI certify, under penalty of perjury, that the contents of this attestation and the evidence submitted with it are true and correct.\nAttestation\nSignature of Petitioner Date (mm/dd/yyyy)\nName of Petitioner Title\nEmployer or Organization Name\n Page 33 of 36\nForm I-129 Edition 11/02/22\nSection 1. Complete This Section If You Are Filing For An R-1 Religious Worker (continued)\nDaytime Telephone Number\nCity or Town State ZIP Code\nStreet Number and Name\nEmployer or Organization Address (do not use a post office or private mail box)\nEmployer or Organization's Contact Information\nApt. Ste. Flr. Number\nFax Number Email Address (if any)\nSection 2. This Section Is Required For Petitioners Affiliated With The Religious Denomination\nReligious Denomination Certification\nI certify, under penalty of perjury, that:\nName of Employing Organization\nis affiliated with:\nName of Religious Denomination\nand that the attesting organization within the religious denomination is tax-exempt as described in section 501(c)(3) of the Internal\nRevenue Code of 1986 (codified at 26 U.S.C. 501(c)(3)), any subsequent amendment(s), subsequent amendment, or equivalent\nsections of prior enactments of the Internal Revenue Code. The contents of this certification are true and correct to the best of my\nknowledge.\nSignature of Authorized Representative of Attesting Organization Date (mm/dd/yyyy)\nCity or Town State ZIP Code\nStreet Number and Name\nAttesting Organization Name and Address (do not use a post office or private mail box)\nApt. Ste. Flr. Number\nAttesting Organization Name\nAttesting Organization's Contact Information\nDaytime Telephone Number Fax Number Email Address (if any)\nName of Authorized Representative of Attesting Organization Title\n Page 34 of 36\nForm I-129 Edition 11/02/22\nForeign Address (Complete Address)\nAddress in the United States Where You Intend to Live (Complete Address)\nFamily Name (Last Name) Given Name (First Name) Middle Name\nGender\nMale Female\nDate of birth (mm/dd/yyyy) U.S. Social Security Number (if any) A-Number (if any)\nAFamily Name (Last Name) Given Name (First Name) Middle Name\nAll Other Names Used (include aliases, maiden name and names from previous marriages)\nCity or Town State ZIP Code\nStreet Number and Name Apt. Ste. Flr. Number\nCity or Town State ZIP Code\nStreet Number and Name Apt. Ste. Flr. Number\nCountry of Birth Country of Citizenship or Nationality\nProvince Postal Code Country\nIF IN THE UNITED STATES:\nDate Passport or Travel Document\nExpires (mm/dd/yyyy)\nI-94 Arrival-Departure Record\nNumber\nCurrent Nonimmigrant Status Date Status Expires or D/S (mm/dd/yyyy)\nCountry of Issuance for Passport\nor Travel Document\nDate Passport or Travel Document\nIssued (mm/dd/yyyy)\nDate of Last Arrival\n(mm/dd/yyyy)\nEmployment Authorization Document (EAD) Number\n(if any)\nStudent and Exchange Visitor Information System (SEVIS) Number\n(if any)\nPassport or Travel Document\nNumber\n\u25ba\nAttachment-1\nAttach to Form I-129 when more than one person is included in the petition. (List each person separately. Do not\ninclude the person you named on the Form I-129.)\n Page 35 of 36\nForm I-129 Edition 11/02/22\nForeign Address (Complete Address)\nAddress in the United States Where You Intend to Live (Complete Address)\nFamily Name (Last Name) Given Name (First Name) Middle Name\nGender\nMale Female\nDate of birth (mm/dd/yyyy) U.S. Social Security Number (if any) A-Number (if any)\nAFamily Name (Last Name) Given Name (First Name) Middle Name\nAll Other Names Used (include aliases, maiden name and names from previous Marriages)\nCity or Town State ZIP Code\nStreet Number and Name Apt. Ste. Flr. Number\nCity or Town State ZIP Code\nStreet Number and Name Apt. Ste. Flr. Number\nCountry of Birth Country of Citizenship or Nationality\nProvince Postal Code Country\nIF IN THE UNITED STATES:\nDate Passport or Travel Document\nExpires (mm/dd/yyyy)\nI-94 Arrival-Departure Record\nNumber\nCurrent Nonimmigrant Status Date Status Expires or D/S (mm/dd/yyyy)\nCountry of Issuance for Passport\nor Travel Document\nDate Passport or Travel Document\nIssued (mm/dd/yyyy)\nDate of Last Arrival\n(mm/dd/yyyy)\nEmployment Authorization Document (EAD) Number\n(if any)\nStudent and Exchange Visitor Information System (SEVIS) Number\n(if any)\nPassport or Travel Document\nNumber\n\u25ba\nAttachment-1\nAttach to Form I-129 when more than one person is included in the petition. (List each person separately. Do not\ninclude the person you named on the Form I-129.)\n Page 36 of 36", "ok now this please: the background story is that i i was training for an ironman and i pulled my hamstring and for probably almost a year i could not get it to be stably healed and i try i had access to everything chiropractic acupuncture various kinds of injections massage you name it i tried it and i could not get it to heal and i bumped into someone who had an amino acid mixture and he said why don't you try these you\n13:10\ngot them over in europe and i tried it and my hamstring within about six weeks healed i could go to the track i could do hard workouts and a few months later i went to ironman canada i had my best my best time ever and i so i got interested in amino acids and healing and i started to measure levels blood levels of amino acids this is a standard test lab core does it and quest does it it's an amino acid profile or amino acid panel now an amino acid if someone thinks of language it's like english is made up of 26\n13:48\nletters and if you put the letters together in different combinations you get different uh words so from 26 letters you the english language has i don't know 350 000 words something like that okay now in protein chemistry the alphabet is called are made up of amino acids there's 22 of them and if you put those together in different combinations you get different proteins so some are very simple like in in the language there's a couple of words that have only one letter like a or i and in proteins there's there's there's a protein which\n14:36\nis the thyroid hormone itself is made out of one amino acid tyrosine and it's got either three or four iodines on it and it's technically a very simple protein but it's the simplest use of an amino acid glutathione is an antioxidant it's got three amino acids insulin is a protein it's got i think 89 amino acids so these things are organized by amino acids into longer chains skeletal muscle actin which is one of the parts of skeletal muscle has about 5600 amino acids per chain so that's really complicated okay now\n15:16\nwhen we eat something so let's say a person has a steak or a piece of chicken or a piece of cheese or some soybeans that protein cannot be absorbed into our body unless it's broken down into the individual amino acids because if a muscle fiber with 5600 amino acids if you chew it up down to one fiber size and then it goes into your small intestine it will not be accepted by the small intestine cells because that fiber is too big it's 5600 amino acids and during the process of digestion those amino acids get separated so it's\n15:56\nindividual amino acids and they can then be absorbed as individual amino acids they go into the bloodstream they go to the cell now when that cell has to make a protein whether it's enzyme or collagen or hair or a neurotransmitter or or you know a muscle the cell has to take the amino acids that it's given and reassemble them into the protein that it's trying to make now in this alphabet the vowels so to speak are called essential amino acids like you can't make proteins without there's eight of\n16:35\nthem eight essential amino acids some proteins have good amounts of of of enough essential amino acids so that they convert really well and most proteins don't so here's another analogy you have a car factory you want to make cars and you have a lot where all the raw material comes and they deliver and let's say a car basics for a car is a chassis a steering wheel a motor and four wheels so if i dele and you're the manufacturer if i deliver to your lot 100 wheels 100 steering wheels 100 motors and 100 chassis\n17:25\nlet's say let's i deliver one chassis let's make it easy one chassis how many cars can you make well you can only make one car and now you're gonna have a whole lot full of 99 steering wheels 99 motors you know uh 96 wheels because you can't use them because you need another chassis in order to put the thing together so when the cell comes along and it needs amino acids it can only use what it's given now if you take whey protein which is a very popular protein you say okay i'm going to measure how\n18:01\nmuch of the whey protein that i ate actually gets incorporated into the protein structure of my body and if you measure it there's an easy there's a fairly easy way to measure this only about 16 of the prote of the amino acids that are in the whey protein get made into body protein the rest of it gets turned into calories with waste and the waste is nitrogen so you can there in the book it outlines the various and we call this amino acid utilization how much of the amino acids that come in the food are actually utilized by the body to\n18:45\nmake protein so soybeans in whey are 16 or 17 percent [Music] meat fish and meat and fish are about 33 percent utilized eggs are about the best they're like 48 utilized breast milk is about 49 utilized so it's the best food it's just hard to get it on a daily basis so most of the plant proteins are very low uh spirulina is zero to six percent so the idea that you started with which is you know tuna fish equals yogurt equals hemp protein peanut butter fish equals peanut butter it isn't true and you know\n19:29\nthis thing in nutrition is a gram of protein has four calories okay that's a that's a stable data in nutrition yep but if that gram of protein got incorporated into body tissue it's no calories because you're not burning that it's part of your arm or part of your heart or part of your hair air it's only the part of the pro of the amino acids that you eat that aren't utilized that produce calories so we have a formulation called perfect amino it's perfect amino because it's the perfect\n20:05\nexact blend of the eight essential amino acids and if a person takes that in within 23 minutes it's in their bloodstream so it's pre-digested it's amino acids 99 of those amino acids will be incorporated into body tissue which is double better than double the best regular protein which is breast milk uh or eggs and so if you're a person and so then what i found is that almost everybody that we tested who had chronic illness had very low levels of amino acids in their body in their blood and that if we gave them supplementation\n20:47\nwith essential amino acids as perfect amino within a few months their amino acid levels in their blood came up and they would then heal faster get more energy their hair would grow better their nails would get thicker and they would feel better because they actually had a nutritional deficiency that they didn't even know about which is what was wrong with my hamstring that's why i didn't heal i had a nutritional deficiency of amino acids i was a vegetarian at the time and i thought i was doing really well\n21:15\nbut what i found since is that virtually all vegetarians all vegans not 100 but probably 99 don't get enough essential amino acids to meet their body needs now there are a few people around who have a gut that that has bacteria in it that are probably more like a cow so a cow can eat grass and build a 2 000 pound animal or a whale can can can eat you know algae and build bodies that weigh thousands of pounds but most of and so these bacteria have the capability of manufacturing essential amino acids but very few humans have the right\n21:55\nprofile and so if they're vegan vegetarian they're they're going to almost always be low and they can supplement with perfect amino because it's vegan source you know there's no animal products in there it's kosher you know it's like pure uh it even has an the athletic the it's legal it's a lot illegal so athlete professional athletes can take it and they won't it's been certified as as drug-free and everything else free and we have thousands and thousands of thousands of people taking it\n22:25\nand can feel the difference and write in and say you know this has changed my life it's really better my chronic inflammation is better my energy is better you know depending on and the book basically is a whole bunch of different categories of patients that i saw who came to see me with their story of they came in with osteoporosis or they came in with depression or they came in with anxiety or sleep problems or they couldn't build muscle or their thyroid hormone was low or whatever and that they could then using\n22:57\namino acids essential amino acids is perfect amino and then probably some other supplementation because it's not the only thing that's wrong but can make a huge difference so i want to rewind just a little bit and touch on well a lot of things here but let's go back to the byproduct of the amino acids or the protein if it's not used you said that was nitrogen yeah so if you take this basic structure of the three sort of macro nutrients so you have carbs fats proteins okay all of them have carbon and hydrogen\n23:40\nand oxygen okay so fats and carbohydrates are basically made out of the same thing they're just arranged differently so one looks like a fat and one looks like a carb amino acids are also built out of carbon and hydrogen and oxygen but they have an extra piece on there which is nitrogen so amino in greek is nitrogen so it's an amino acid it's an acid which is carbon hydrogen oxygen and there's a nitrogen stuck on there which makes it an amino acid now there's there's you know there's 22 different amino acid\n24:15\nconfigurations so sometimes the tree looks like this and sometimes it looks like this and sometimes it looks like this depending on the arrangement but they've all got nitrogen so so my thought on this dr minkoff is you have a lot of bodybuilders out there and people that think that they need protein protein protein and they're eating pounds of chicken and fish and whey protein shakes and all these things and then said bodybuilder goes out and gets their blood work done and there are some markers on there that\n24:46\nare higher than anticipated and so can you tell me how the nitrogen is affecting those numbers and what number in particular that that affects", "A growing body of literature has continuously investigated the relationship between age and traffic accidents. Most research points to significant differences between young adults and older drivers in terms of accident involvement (e.g., Buckley et al., 2014; Chapman et al., 2014; Chung et al., 2014; Chung et al., 2011; Clarke et al., 2006; Gaines et al., 2011; Kim et al., 2006; Park et al., 2009; Stutts et al., 1998; Wood et al., 2013; Zhang et al., 2019). High traffic accident rates have been linked to various explanations, such as the greater impulsivity of younger individuals or the decline of cognitive abilities in old age (e.g., Classen et al., 2008; Fraade-Blanar et al., 2018; Hatfield et al., 2017; Lundberg et al., 1998; Miller et al., 2021; Pearson et al., 2013; Wong et al., 2012). Although this approach is one way of preventing hazards on the road, a different approach is needed when targeting professional drivers. \nIn 2020, professional drivers were involved in 19.1% of traffic accidents in the whole South Korea despite that only 7.2% of all registered vehicles are for such professionals to use (MOLIT, 2021). Given the significantly longer time spent on the roads, professional drivers are much more likely to be involved in traffic accidents than non-professional drivers. Moreover, as professional drivers often transport large groups of passengers, the consequences of their accidents can be much more severe. Therefore, it is crucial to comprehensively assess the needs and specifics of professional drivers to reduce the rate of traffic accidents and help prevent road tragedies\nThe biggest difference between professional and non-professional drivers lies in the age distributions. In 2020, young adults (20-39 years old) accounted for 33.8% of all driver's license holders in Korea, middle-aged adults (40-64 years old) made up 54.2%, and seniors (65 years or older) comprised 11.1% (TAAS, 2021). However, only 7.5% of professional drivers were young adults, with the majority - 73.2% - being middle-aged, and 19.3% being seniors (TS, 2021). Unlike the general population, individuals under the age of 40 represent only a very small proportion of professional drivers, highlighting the need to examine professional and non-professional drivers separately. \nThe accident rates for occupational drivers in 2020 were as follows: 68.9% for middle-aged drivers, 26.3% for older drivers, and 4.8% for young adults (TS, 2021). As expected, older drivers had more accidents than predicted by the age distribution. However, the accident rate of middle-aged drivers is still compellingly high, whereas the rate for younger drivers is relatively low. This suggests that research targeting professional drivers should primarily focus on the middle-aged and older groups to decrease the number of traffic accident occurrences. Yet, only a few studies on this topic are currently very available, especially those looking into the effects of cognitive decline with age in both groups. \nAlthough cognitive decline has been linked to unsafe driving regardless of age (Alonso et al., 2016; Bahrampouri et al., 2021; Dawson et al., 2010; Kim, 2014; Mayhew et al., 2006; Zicat et al., 2018), cognitive, visual, and physical abilities are known to deteriorate most significantly as one grows older, making age a critical factor for safe driving. However, research has found only a marginal difference between the driving abilities of young adults and middle-aged drivers, with a sharp decline occurring later in the senior age group (Ledger et al., 2019).\nAccording to the systematic review by Depestele et al. (2020), when considering the relationship between cognitive function and driving behavior, a driver's general cognition, visuospatial perception, attention, memory, and executive function have, for example, been linked to proper lane-keeping (Andrews & Westerman, 2012; Bunce et al., 2012). Similarly, one's overall behavior behind the wheel correlates with attention, processing speed, and memory skills (Ledger et al., 2019; Stinchcombe et al., 2011). For a detailed review, see Depestele et al. (2020).\nWhen age is added to the model, although young and middle-aged adults show significantly better overall driving performance than the elderly, the difference in cognitive functions between the first two age groups remains marginal. Stinchcombe et al. (2011) found only a minimal variation between young and middle-aged driver's performance when looking at their attention and response times, utilizing Useful Field of View, Simple Reaction Time (RT), Choice (RT), and Trail Making tasks. Another study reported no difference between the two age groups on the Cellphone Task, which tests the effect of low to moderately demanding distraction while driving (Reimer et al., 2008).\nFew studies have explored the relationship between cognitive function and driving ability in both middle-aged and older adults (Alonso et al., 2016; Dawson et al., 2010). Dawson et al. (2010) found that older adults exhibited lower performance than middle-aged individuals on all cognitive tasks except the Complex Figure Test (CFT)-Copy and the Structure From Motion tasks when comparing the two age categories, with older drivers making overall 24% more driving safety errors than middle-aged ones.\nThe same study also reported an inverse correlation between safety errors and performance on CFT-Copy, CFT-Recall, Block Design, Near Visual Acuity, and the Grooved Pegboard tasks (Dawson et al., 2010), indicating that among other cognitive skills, visuospatial and visuomotor abilities are crucial predictors of driving performance in older adults. However, since the study mainly focused on senior drivers, it is unclear whether visuomotor abilities would predict safety errors in middle-aged drivers in the same way since the\u00df predicting factors for middle-aged drivers remain unidentified (Dawson et al., 2010). Furthermore, since Dawson et al. (2010) did not find any significant relationship between age and safety errors in the middle-aged group, it is likely that the factors influencing safe driving differ between the two age groups. \nThe purpose of this study was to expand previous research and focus on cognitive abilities predicting safe driving of both middle-aged (40 to 64 years old) and older drivers (65 and above) who account for the majority of professional drivers. So far, only a very few studies examined the cognitive factors predicting safe driving according to driver\u2019s age despite the fact that cognitive ability has already been identified as a critical predictor of safe driving not only in the case of senior drivers. Moreover, in many OECD countries such as the US, UK, Japan, Germany, Denmark, New Zealand, and South Korea, cognitive ability-focused aptitude tests are already being required. This study has the potential to offer further suggestions for such future measures \nOur study specifically targeted cognitive abilities that have shown to possess a strong relationship with safe driving - attention (Ball et al., 1993; Duchek et al., 1998; Hutchinson & Badham, 2013; Kim, et al., 2011; Kwon, 2014; Park et al., 2006; Richardson & Marottoli, 2003; Son & Park, 2013), visuomotor speed (Horswill et al., 2015; Park et al., 2006; Shin & Lee, 2012), visuospatial judgment (Etienne et al., 2013; Lee et al., 2008; Owsley et al., 1999; Verhaeghen et al., 2002), and visual working memory (Lafont et al., 2008; Lim & Lee, 2012; Park et al., 2006; Son & Park, 2013). Previous studies have indicated that attention, visual-related functions, and memory are highly correlated with driving performance and tend to decline significantly with age (Bahrampouri et al., 2021; Depestele et al., 2020; Tarawneh et al., 1993). In addition, since driving is a task that requires the use of multiple cognitive functions in a complex manner, testing each cognitive ability one by one would be insufficient to fully evaluate drivers' real-life performance. Additionally, we chose to assess drivers' multitasking skills by examining their ability to switch between cognitive functions and use more than two at the same time (Wechsler et al., 2018). This allows us to further enrich prior research which has mainly focused only on a limited number of cognitive functions at once or only on drivers' multitasking abilities (Alonso et al., 2016; Bahrampouri et al., 2021; Dawson et al., 2010; Wechsler et al., 2018; Zicat et al., 2018).\nOverall, the results of this study not only allow for a deeper understanding of the relationship between cognitive abilities and safety in middle-aged and older drivers but also have the potential to contribute to the creation of more comprehensive aptitude tests for professional drivers based on their respective age and establish further related interventions. By clarifying which different cognitive abilities decline with age in middle-aged and elderly drivers, this research establishes a solid base for regular driving aptitude testing targeted at the essential cognitive skills of professional drivers. We thus expect to improve the current system and help prevent traffic accidents.\n \n \n \n \uc9c0\uae08 \ubc88\uc5ed\ud558\uae30", "using System;\nusing System.Collections.Generic;\nusing System.Linq;\nusing System.Text;\nusing System.Threading.Tasks;\nusing Love;\n\nnamespace LoveCSharp\n{\n class Program : Scene\n {\n public Player player1;\n public static float deltaTime;\n static void Main(string[] args)\n {\n Boot.Init();\n Boot.Run(new Program());\n }\n public override void Load()\n {\n World.Generate(20,20);\n player1 = new Player(5, 5);\n\n // Love.Mouse.SetVisible(false);\n // Love.Mouse.SetGrabbed(true);\n Love.Mouse.SetRelativeMode(true);\n \n }\n public override void Draw()\n {\n Ray.Draw(player1.x, player1.y, Ray.distance, player1.angle, player1.fov);\n World.Draw();\n player1.Draw();\n \n }\n public override void Update(float dt)\n {\n deltaTime = dt;\n player1.Update(dt);\n Ray.Update(player1.x, player1.y, player1.angle, player1.fov);\n if (Love.Keyboard.IsDown(KeyConstant.Escape))\n {\n Love.Event.Quit();\n }\n }\n public override void MouseMoved(float x, float y, float dx, float dy, bool istouch)\n {\n player1.Rotation(dx);\n }\n }\n public enum TileType\n {\n None,\n Block,\n }\n public class World\n {\n public static int width;\n public static int height;\n public static int scale = 10;\n public static TileType[,] tiles;\n public static void Generate(int width = 20, int height = 20)\n {\n World.width = width;\n World.height = height;\n\n TileType[,] tiles = new TileType[width, height];\n\n for (int x = 0; x < width; x++)\n {\n for (int y = 0; y < height; y++)\n {\n tiles[x, y] = TileType.Block;\n }\n }\n for (int x = 0; x < width; x++)\n {\n \n for (int y = 0; y < height; y++)\n {\n if ((x > 0 && x < width - 1) && (y > 0 && y < height - 1))\n {\n tiles[x, y] = TileType.None;\n }\n }\n }\n // Generate a random number of TileType blocks in the world (tiles)\n Random random = new Random();\n int blockCount = random.Next(10, 20);\n for (int i = 0; i < blockCount; i++)\n {\n int x = random.Next(0, width);\n int y = random.Next(0, height);\n tiles[x, y] = TileType.Block;\n }\n \n World.tiles = tiles;\n }\n public static void Draw()\n {\n Graphics.SetColor(Color.White);\n Graphics.Rectangle(DrawMode.Line, 0, 0, width \\* scale, height \\* scale);\n\n Graphics.SetColor(Color.Firebrick);\n for (int x = 0; x < width; x++)\n {\n for (int y = 0; y < height; y++)\n {\n if (tiles[x, y] == TileType.Block)\n {\n Graphics.Rectangle(DrawMode.Fill, x \\* scale, y \\* scale, scale, scale);\n }\n }\n }\n }\n }\n public class Player\n {\n public float x, y, w, h, speed, angle, directionX, directionY;\n public float sensitivity = 0.3f;\n public int fov = 60;\n public Player(float x, float y, float w = 30, float h = 50, float speed = 1, float angle = 0)\n {\n this.x = x;\n this.y = y;\n this.w = w;\n this.h = h;\n this.speed = speed;\n this.angle = angle;\n }\n public void Draw()\n {\n Graphics.SetColor(Color.AliceBlue);\n Graphics.SetPointSize(3);\n Graphics.Points(this.x \\* World.scale, this.y \\* World.scale);\n Graphics.SetColor(Color.White);\n Graphics.Print(\"X: \" + this.x + \" Y: \" + this.y, 0, 0);\n Graphics.Print(\"Angle: \" + this.angle, 0, 20);\n }\n public void Update(float dt)\n {\n Movement(dt);\n\n }\n\n private void Movement(float dt)\n {\n float directionX = 0;\n float directionY = 0;\n if (Keyboard.IsDown(KeyConstant.W))\n {\n directionY = -1;\n }\n if (Keyboard.IsDown(KeyConstant.S))\n {\n directionY = 1;\n }\n if (Keyboard.IsDown(KeyConstant.A))\n {\n directionX = -1;\n }\n if (Keyboard.IsDown(KeyConstant.D))\n {\n directionX = 1;\n }\n\n float rotatedDirectionX = (float)Math.Cos(this.angle) \\* directionX - (float)Math.Sin(this.angle) \\* directionY;\n float rotatedDirectionY = (float)Math.Sin(this.angle) \\* directionX + (float)Math.Cos(this.angle) \\* directionY;\n\n float directionLength = (float)Math.Sqrt(rotatedDirectionX \\* rotatedDirectionX + rotatedDirectionY \\* rotatedDirectionY);\n if (directionLength > 0)\n {\n rotatedDirectionX /= directionLength;\n rotatedDirectionY /= directionLength;\n }\n\n this.x += rotatedDirectionX \\* this.speed \\* dt;\n this.y += rotatedDirectionY \\* this.speed \\* dt;\n }\n public void Rotation(float dx)\n {\n this.angle += dx \\* sensitivity \\* Program.deltaTime;\n \n }\n }\n public class Ray\n {\n public static float distance;\n\n public static float Cast(float x, float y, float centerAngle, float fov)\n {\n float startX = x;\n float startY = y;\n string section;\n float quality = 0.1f;\n int screenWidth = 800;\n int screenHeight = 600;\n\n for (float angle = centerAngle - fov / 2; angle < centerAngle + fov / 2; angle += Quality(fov, quality, screenWidth))\n {\n float endX = (float)(startX + Math.Cos(angle) \\* 1000);\n float endY = (float)(startY + Math.Sin(angle) \\* 1000);\n\n section = FacingSection(angle);\n\n if (section == \"NE\")\n {\n for (float i = startX; i < endX; i += quality)\n {\n float j = (float)(startY + (i - startX) \\* Math.Tan(angle));\n if (World.tiles[(int)i / World.scale, (int)j / World.scale] == TileType.Block)\n {\n distance = Distance(startX, startY, i, j);\n return distance;\n }\n }\n }\n else if (section == \"NW\")\n {\n for (float i = startX; i > endX; i -= quality)\n {\n float j = (float)(startY + (i - startX) \\* Math.Tan(angle));\n if (World.tiles[(int)i / World.scale, (int)j / World.scale] == TileType.Block)\n {\n distance = Distance(startX, startY, i, j);\n return distance;\n }\n }\n }\n else if (section == \"SW\")\n {\n for (float i = startX; i > endX; i -= quality)\n {\n float j = (float)(startY + (i - startX) \\* Math.Tan(angle));\n if (World.tiles[(int)i / World.scale, (int)j / World.scale] == TileType.Block)\n {\n distance = Distance(startX, startY, i, j);\n return distance;\n }\n }\n }\n else if (section == \"SE\")\n {\n for (float i = startX; i < endX; i += quality)\n {\n float j = (float)(startY + (i - startX) \\* Math.Tan(angle));\n if (World.tiles[(int)i / World.scale, (int)j / World.scale] == TileType.Block)\n {\n distance = Distance(startX, startY, i, j);\n return distance;\n }\n }\n }\n }\n return 0;\n }\n public static string FacingSection(float angle)\n {\n string facing = \"\";\n if (angle >= 0 && angle < Math.PI / 2)\n {\n facing = \"NE\";\n }\n else if (angle >= Math.PI / 2 && angle < Math.PI)\n {\n facing = \"NW\";\n }\n else if (angle >= Math.PI && angle < 3 \\* Math.PI / 2)\n {\n facing = \"SW\";\n }\n else if (angle >= 3 \\* Math.PI / 2 && angle < 2 \\* Math.PI)\n {\n facing = \"SE\";\n }\n return facing;\n }\n public static float Quality(float fov, float quality, float screenWidth)\n {\n \n // float angle = fov / screenWidth;\n // quality = angle / quality;\n // return quality;\n float angleBetweenRays = fov / screenWidth;\n float qualityAngle = (float)Math.Atan(quality / 2);\n float qualityAngleBetweenRays = qualityAngle / angleBetweenRays;\n return qualityAngleBetweenRays;\n }\n\n public static float Distance(float x1, float y1, float x2, float y2)\n {\n float distance = (float)Math.Sqrt((x2 - x1) \\* (x2 - x1) + (y2 - y1) \\* (y2 - y1));\n return distance;\n }\n\n public static void Draw(float x, float y, float distance, float angle, float fov)\n {\n \n float angleBetweenRays = fov / 800;\n float distanceToProjectionPlane = 800 / (2 \\* (float)Math.Tan(fov / 2));\n float distanceToWall = distance;\n float distanceToProjectionPoint = distanceToWall \\* (float)Math.Cos(angleBetweenRays);\n distanceToProjectionPlane = distanceToProjectionPoint \\* distanceToProjectionPlane / distanceToWall;\n float height = 600 / distanceToProjectionPlane;\n float width = 1;\n float color = 255 / distanceToWall;\n Graphics.SetColor(Color.FromRGBA(color, color, color, 255));\n Graphics.Rectangle(DrawMode.Fill, x, y - height / 2, width, height);\n \n\n }\n public static void Update(float x, float y, float angle, float fov)\n {\n Cast(x, y, angle, fov);\n \n \n }\n }\n}", "using System;\nusing System.Collections.Generic;\nusing System.Linq;\nusing System.Text;\nusing System.Threading.Tasks;\nusing Love;\n\nnamespace LoveCSharp\n{\n class Program : Scene\n {\n public Player player1;\n public static float deltaTime;\n static void Main(string[] args)\n {\n Boot.Init();\n Boot.Run(new Program());\n }\n public override void Load()\n {\n World.Generate(20,20);\n player1 = new Player(5, 5);\n\n // Love.Mouse.SetVisible(false);\n // Love.Mouse.SetGrabbed(true);\n Love.Mouse.SetRelativeMode(true);\n \n }\n public override void Draw()\n {\n World.Draw();\n player1.Draw();\n Ray.Draw(player1.x, player1.y, Ray.distance, player1.angle, player1.fov);\n \n }\n public override void Update(float dt)\n {\n deltaTime = dt;\n player1.Update(dt);\n Ray.Update(player1.x, player1.y, player1.angle, player1.fov);\n if (Love.Keyboard.IsDown(KeyConstant.Escape))\n {\n Love.Event.Quit();\n }\n }\n public override void MouseMoved(float x, float y, float dx, float dy, bool istouch)\n {\n player1.Rotation(dx);\n }\n }\n public enum TileType\n {\n None,\n Block,\n }\n public class World\n {\n public static int width;\n public static int height;\n public static int scale = 10;\n public static TileType[,] tiles;\n public static void Generate(int width = 20, int height = 20)\n {\n World.width = width;\n World.height = height;\n\n TileType[,] tiles = new TileType[width, height];\n\n for (int x = 0; x < width; x++)\n {\n for (int y = 0; y < height; y++)\n {\n tiles[x, y] = TileType.Block;\n }\n }\n for (int x = 0; x < width; x++)\n {\n \n for (int y = 0; y < height; y++)\n {\n if ((x > 0 && x < width - 1) && (y > 0 && y < height - 1))\n {\n tiles[x, y] = TileType.None;\n }\n }\n }\n // Generate a random number of TileType blocks in the world (tiles)\n Random random = new Random();\n int blockCount = random.Next(10, 20);\n for (int i = 0; i < blockCount; i++)\n {\n int x = random.Next(0, width);\n int y = random.Next(0, height);\n tiles[x, y] = TileType.Block;\n }\n \n World.tiles = tiles;\n }\n public static void Draw()\n {\n Graphics.SetColor(Color.White);\n Graphics.Rectangle(DrawMode.Line, 0, 0, width \\* scale, height \\* scale);\n\n Graphics.SetColor(Color.Firebrick);\n for (int x = 0; x < width; x++)\n {\n for (int y = 0; y < height; y++)\n {\n if (tiles[x, y] == TileType.Block)\n {\n Graphics.Rectangle(DrawMode.Fill, x \\* scale, y \\* scale, scale, scale);\n }\n }\n }\n }\n }\n public class Player\n {\n public float x, y, w, h, speed, angle, directionX, directionY;\n public float sensitivity = 0.3f;\n public int fov = 60;\n public Player(float x, float y, float w = 30, float h = 50, float speed = 1, float angle = 0)\n {\n this.x = x;\n this.y = y;\n this.w = w;\n this.h = h;\n this.speed = speed;\n this.angle = angle;\n }\n public void Draw()\n {\n Graphics.SetColor(Color.AliceBlue);\n Graphics.SetPointSize(3);\n Graphics.Points(this.x \\* World.scale, this.y \\* World.scale);\n Graphics.SetColor(Color.White);\n Graphics.Print(\"X: \" + this.x + \" Y: \" + this.y, 0, 0);\n Graphics.Print(\"Angle: \" + this.angle, 0, 20);\n }\n public void Update(float dt)\n {\n Movement(dt);\n\n }\n\n private void Movement(float dt)\n {\n float directionX = 0;\n float directionY = 0;\n if (Keyboard.IsDown(KeyConstant.W))\n {\n directionY = -1;\n }\n if (Keyboard.IsDown(KeyConstant.S))\n {\n directionY = 1;\n }\n if (Keyboard.IsDown(KeyConstant.A))\n {\n directionX = -1;\n }\n if (Keyboard.IsDown(KeyConstant.D))\n {\n directionX = 1;\n }\n\n float rotatedDirectionX = (float)Math.Cos(this.angle) \\* directionX - (float)Math.Sin(this.angle) \\* directionY;\n float rotatedDirectionY = (float)Math.Sin(this.angle) \\* directionX + (float)Math.Cos(this.angle) \\* directionY;\n\n float directionLength = (float)Math.Sqrt(rotatedDirectionX \\* rotatedDirectionX + rotatedDirectionY \\* rotatedDirectionY);\n if (directionLength > 0)\n {\n rotatedDirectionX /= directionLength;\n rotatedDirectionY /= directionLength;\n }\n\n this.x += rotatedDirectionX \\* this.speed \\* dt;\n this.y += rotatedDirectionY \\* this.speed \\* dt;\n }\n public void Rotation(float dx)\n {\n this.angle += dx \\* sensitivity \\* Program.deltaTime;\n \n }\n }\n public class Ray\n {\n public static float distance;\n\n public static float Cast(float x, float y, float centerAngle, float fov)\n {\n float startX = x;\n float startY = y;\n string section;\n float quality = 0.1f;\n int screenWidth = 800;\n int screenHeight = 600;\n\n for (float angle = centerAngle - fov / 2; angle < centerAngle + fov / 2; angle += Quality(fov, quality, screenWidth))\n {\n float endX = (float)(startX + Math.Cos(angle) \\* 50);\n float endY = (float)(startY + Math.Sin(angle) \\* 50);\n\n section = FacingSection(angle);\n\n if (section == \"NE\")\n {\n for (float i = startX; i < endX; i += quality)\n {\n float j = (float)(startY + (i - startX) \\* Math.Tan(angle));\n if (World.tiles[(int)i / World.scale, (int)j / World.scale] == TileType.Block)\n {\n distance = Distance(startX, startY, i, j);\n return distance;\n }\n }\n }\n else if (section == \"NW\")\n {\n for (float i = startX; i > endX; i -= quality)\n {\n float j = (float)(startY + (i - startX) \\* Math.Tan(angle));\n if (World.tiles[(int)i / World.scale, (int)j / World.scale] == TileType.Block)\n {\n distance = Distance(startX, startY, i, j);\n return distance;\n }\n }\n }\n else if (section == \"SW\")\n {\n for (float i = startX; i > endX; i -= quality)\n {\n float j = (float)(startY + (i - startX) \\* Math.Tan(angle));\n if (World.tiles[(int)i / World.scale, (int)j / World.scale] == TileType.Block)\n {\n distance = Distance(startX, startY, i, j);\n return distance;\n }\n }\n }\n else if (section == \"SE\")\n {\n for (float i = startX; i < endX; i += quality)\n {\n float j = (float)(startY + (i - startX) \\* Math.Tan(angle));\n if (World.tiles[(int)i / World.scale, (int)j / World.scale] == TileType.Block)\n {\n distance = Distance(startX, startY, i, j);\n return distance;\n }\n }\n }\n }\n return 0;\n }\n public static string FacingSection(float angle)\n {\n string facing = \"\";\n if (angle >= 0 && angle < Math.PI / 2)\n {\n facing = \"NE\";\n }\n else if (angle >= Math.PI / 2 && angle < Math.PI)\n {\n facing = \"NW\";\n }\n else if (angle >= Math.PI && angle < 3 \\* Math.PI / 2)\n {\n facing = \"SW\";\n }\n else if (angle >= 3 \\* Math.PI / 2 && angle < 2 \\* Math.PI)\n {\n facing = \"SE\";\n }\n return facing;\n }\n public static float Quality(float fov, float quality, float screenWidth)\n {\n \n // float angle = fov / screenWidth;\n // quality = angle / quality;\n // return quality;\n float angleBetweenRays = fov / screenWidth;\n float qualityAngle = (float)Math.Atan(quality / 2);\n float qualityAngleBetweenRays = qualityAngle / angleBetweenRays;\n return qualityAngleBetweenRays;\n }\n\n public static float Distance(float x1, float y1, float x2, float y2)\n {\n float distance = (float)Math.Sqrt((x2 - x1) \\* (x2 - x1) + (y2 - y1) \\* (y2 - y1));\n return distance;\n }\n\n public static void Draw(float x, float y, float distance, float angle, float fov)\n {\n \n float angleBetweenRays = fov / 800;\n float distanceToProjectionPlane = 800 / (2 \\* (float)Math.Tan(fov / 2));\n float distanceToWall = distance;\n float distanceToProjectionPoint = distanceToWall \\* (float)Math.Cos(angleBetweenRays);\n distanceToProjectionPlane = distanceToProjectionPoint \\* distanceToProjectionPlane / distanceToWall;\n float height = 600 / distanceToProjectionPlane;\n float width = 1;\n float color = 255 / distanceToWall;\n Graphics.SetColor(Color.FromRGBA(color, color, color, 255));\n Graphics.Rectangle(DrawMode.Fill, x, y - height / 2, width, height);\n \n\n }\n public static void Update(float x, float y, float angle, float fov)\n {\n Ray.distance = Cast(x, y, angle, fov);\n \n \n }\n }\n}", "next block. just confirm receipt, don't reprint:\n\nWestern Illinois 30 16 14 0.533 40.2 73 26.5 58.5 0.453 7 21.7 0.321 13.1 18.7 0.7 8.7 23.7 32.4 13.7 5.8 3.6 10.4 14.5\nSanta Clara 32 23 9 0.719 40.3 77.5 28.1 61.7 0.455 8.3 22.6 0.369 13.1 18.6 0.704 9.6 26.7 36.3 13.9 6 3.7 12.2 15.8\nLamar 31 9 22 0.29 40.3 67.9 24.5 57 0.431 5.7 17.9 0.32 13 18.5 0.704 10.8 23.4 34.2 13.2 6.4 3.4 14.1 15.7\nChicago State 31 11 20 0.355 40 70.3 24.5 56.7 0.433 8.3 24.4 0.339 13 17.9 0.728 10.7 22.5 33.2 12.2 5.6 2.7 13.3 18.1\nDayton 34 22 12 0.647 40.2 68.6 24.5 52.5 0.467 6.6 19.6 0.338 13 18.6 0.699 8.7 25.5 34.2 15.2 4.8 4.4 11.7 13.8\nChattanooga 35 18 17 0.514 40.1 77.2 26.4 58.3 0.453 11.4 30.2 0.377 13 18.3 0.714 8.3 25.6 33.9 15.3 5.7 3.4 11.4 15.7\nIona 34 27 7 0.794 40.1 76.3 28.1 61.1 0.461 7.1 19.6 0.36 13 17.7 0.731 10.6 23.5 34.2 15 7.5 5.5 10.4 16.3\nGeorge Mason 33 20 13 0.606 40.1 68.7 24.2 53.8 0.451 7.3 20.8 0.35 13 19.9 0.651 8.5 25.3 33.8 13.7 4.6 3.1 13.4 17.2\nWestern Kentucky 33 17 16 0.515 40.2 71.4 25.4 57.8 0.44 7.5 21.1 0.358 13 18.2 0.712 8.3 24.5 32.8 12.6 6.2 5.2 11.5 14.8\nOmaha 32 9 23 0.281 40 68.5 24.9 56.4 0.442 5.7 16.9 0.339 13 16.7 0.776 7.5 23.4 30.9 11.9 5.4 2.9 12.2 18.2\nOregon State 32 11 21 0.344 39.9 61.2 21.1 51.5 0.41 6 18.9 0.317 13 17.2 0.753 6.9 22.1 29 10.2 5.4 3.1 13 17.8\nVirginia 32 25 7 0.781 39.9 67.8 24 53.5 0.449 6.8 19.3 0.353 12.9 18.5 0.701 7.4 22.9 30.3 15.8 6.9 4.2 8.4 14.3\nLouisville 32 4 28 0.125 39.8 63.9 22.4 53.1 0.421 6.3 19 0.329 12.9 17.5 0.741 8.1 22.3 30.4 9.3 4.5 2.8 14.4 16.5\nNorthwestern 32 21 11 0.656 40.3 67.7 23.5 58 0.406 7.7 23.9 0.321 12.9 17.2 0.751 9.3 23.6 32.9 12.9 8 4.2 9.4 16.2\nTennessee 33 23 10 0.697 39.9 71.8 25.5 58.5 0.437 7.8 23.7 0.329 12.9 18.1 0.714 12 24.8 36.8 16.9 8.3 3.6 11.5 16.8\nOklahoma State 33 18 15 0.545 40 68.5 24.3 56.4 0.432 6.9 22.2 0.311 12.9 18.5 0.694 9.9 24.9 34.8 12.5 5.7 4.9 13.9 17.3\nNorth Dakota State 33 16 17 0.485 39.8 72.8 26.2 57.7 0.455 7.5 22.3 0.336 12.9 18.1 0.712 7.9 26.6 34.5 11.2 3.9 3 11.4 15.4\nAlabama A&M 33 15 18 0.455 40.2 69.6 24.9 56.6 0.441 6.8 18.5 0.37 12.9 19.7 0.655 9.3 21.8 31.2 12.7 8 4 14.2 18.9\nLehigh 30 16 14 0.533 40 69.8 25.1 56.6 0.443 6.8 19.5 0.351 12.8 17.2 0.746 5.8 25.6 31.4 12.3 6.3 2.3 11.5 16.7\nArizona State 34 22 12 0.647 40.2 70.3 25 60.5 0.413 7.5 23.9 0.314 12.8 18.6 0.689 10 24.4 34.4 14.2 7.3 4.7 11.6 18.5\nJackson State 33 14 19 0.424 40.5 67.6 24.2 57.8 0.42 6.3 19.8 0.321 12.8 19 0.674 10.7 22.2 32.9 12.2 7.5 2.4 15 17.3\nBethune-Cookman 32 12 20 0.375 40.1 67.9 24.1 58.1 0.415 6.8 18.9 0.361 12.8 18.3 0.698 8.8 21.6 30.4 11.4 7.2 2.8 12.2 17.3\nSt. Francis (PA) 31 13 18 0.419 40 73 26.2 56.8 0.462 7.7 20.4 0.379 12.8 18.2 0.704 8 24.1 32.1 13.7 4.4 2.1 12.4 16.5\nStonehill 31 14 17 0.452 40.4 67 23.2 52.7 0.441 7.7 21.8 0.353 12.8 16.9 0.758 5.5 23.6 29.1 12.2 7.1 2.8 13 15.1", "next block. just confirm receipt, dont reprint:\n\nColorado State 33 15 18 0.455 40.3 72.5 26.5 54.2 0.488 7.6 20.9 0.364 11.9 16 0.745 5.3 23.7 29 16.5 5.7 2.5 10.8 16.3\nLouisiana Tech 33 15 18 0.455 40.8 72.2 25.9 58.5 0.442 8.5 24.7 0.345 11.9 16.5 0.722 9.8 22.7 32.5 12.4 7.9 2.6 13.2 17.3\nGardner-Webb 31 15 16 0.484 40.6 70.7 26.2 56.2 0.467 6.3 18.8 0.336 11.9 19.1 0.625 8.9 24.5 33.4 12.9 7.2 4.7 12.8 19.2\nCalifornia Baptist 33 17 16 0.515 40.2 69.4 24.6 57.5 0.427 8.4 25.4 0.33 11.9 17.9 0.664 9.6 25.1 34.7 14.3 4.4 3.1 11.2 17.2\nOle Miss 33 12 21 0.364 40 67.5 24.7 58.5 0.422 6.2 20.3 0.303 11.9 17.1 0.695 10.5 22.7 33.2 13.1 7.1 3.7 11.7 15.9\nIdaho State 32 11 21 0.344 40.9 69.2 24.8 55.8 0.445 7.7 22.7 0.338 11.9 16.2 0.735 7.3 22.1 29.4 12.3 5.8 2.8 11.2 17.6\nMarshall 32 24 8 0.75 40.4 81.8 30.8 66.3 0.465 8.3 24.4 0.338 11.9 17.1 0.693 11.4 25.3 36.8 17.5 9 5.3 11.5 16.4\nValparaiso 32 11 21 0.344 40.7 68.9 25.4 57.9 0.44 6.2 20.9 0.296 11.9 16.3 0.728 7.2 25.4 32.6 13.6 5.8 2.6 12.3 16.6\nSam Houston State 32 25 7 0.781 40.2 73.2 26.5 57.8 0.459 8.3 21.5 0.385 11.9 17.4 0.681 10.7 24.4 35.1 13.8 8.4 2.2 12.7 18.1\nPepperdine 31 9 22 0.29 40.5 78 29 62.2 0.466 8.2 22.5 0.362 11.9 16.7 0.71 8.5 25.7 34.2 15.1 5.4 3.8 13.9 17.7\nUSC Upstate 31 16 15 0.516 40.2 68.9 25.2 54.9 0.459 6.6 19.3 0.342 11.9 18.1 0.656 7.5 22.2 29.7 11.9 7.4 4.4 12.9 20.2\nDartmouth 28 10 18 0.357 40.5 71.4 25.7 58.1 0.442 8.1 24.5 0.333 11.9 17 0.699 7.7 25.5 33.2 12.9 5.5 4 14.3 17\nMarquette 34 28 6 0.824 40.6 79.9 29.6 60.8 0.487 8.9 25.4 0.348 11.9 16.4 0.721 8.1 21.9 29.9 17.6 9.4 3.1 10.7 16.3\nSouth Florida 32 14 18 0.438 40.2 72 26.4 59.2 0.446 7.4 21.9 0.336 11.8 18.2 0.652 10.7 24.3 35.1 13.4 6.5 3.1 13.4 17.8\nLindenwood 32 11 21 0.344 40.8 69.6 25.1 58.5 0.429 7.5 20.8 0.36 11.8 16.3 0.729 8.3 24.4 32.7 11.8 6.3 3.3 13 16.1\nFlorida A&M 29 7 22 0.241 40.1 58.6 20.5 53 0.387 5.8 18.4 0.313 11.8 17.1 0.692 9.1 21.7 30.8 9.7 6.6 3.6 15.4 19\nArmy West Point 33 17 16 0.515 40.3 73.1 26.8 56.2 0.477 7.6 21.8 0.351 11.8 17.3 0.684 7.8 25.2 33 13 5.1 2.1 12.5 16.1\nNorth Florida 31 14 17 0.452 40.6 76.2 27 59.3 0.456 10.4 28.4 0.367 11.8 16.4 0.719 8 24.2 32.2 13.1 5 3.9 11.9 14\nRutgers 33 19 14 0.576 40.1 67.9 25.2 58.9 0.428 5.7 17.8 0.318 11.8 16.8 0.702 10.5 24.7 35.1 15 8.8 3.9 11 16\nCal State Bakersfield 33 11 22 0.333 40.6 60.5 22.2 53.6 0.414 4.3 13.2 0.325 11.8 15.5 0.76 8.2 21.6 29.8 10.8 6.2 3 12.2 18.8\nHarvard 28 14 14 0.5 40.4 68.4 25 56.9 0.439 6.6 21.3 0.309 11.8 17.6 0.669 10.3 24.8 35 13.2 7.5 3.8 13.2 14.6\nOklahoma 32 15 17 0.469 40.2 67.7 24.4 53.3 0.458 7 19.9 0.351 11.8 16 0.735 6.4 24.5 31 13 5.7 3 12.9 16.2\nLa Salle 34 15 19 0.441 40.5 69.8 25.4 59.9 0.424 7.3 21.4 0.341 11.8 17 0.693 10.1 23.5 33.5 12 6.8 3.2 12.2 17.8\nSouth Dakota 31 12 19 0.387 39.9 69.3 24.4 56.5 0.431 8.9 22.8 0.389 11.7 15.4 0.765 7.7 24.1 31.7 12.2 4.5 1.5 11.5 17.4\nNew Hampshire 30 15 15 0.5 40.3 66.4 23.2 58.3 0.398 8.3 24.2 0.342 11.7 16.9 0.693 9.4 24.6 34 11.7 5.4 2.5 9.8 15.1", "You are an AI system that has been trained to analyze the blow text for style, voice, and tone then use NLP to create a VoiceParagraph. A VoiceParagraph prompts a future AI system to write in the same style, voice, and tone. Here is the input text: I smacked my hand down on the hotel bar. The white marble was cool, which was very nice, since I was getting hot.\n\"A list of steps isn't helpful if you're facing the wrong way!\"\nI'd been talking with a couple fellow marketing speakers at an event, and we were joking about the industry's obsession with \"practical steps\" -- and how, whenever the word \"practical\" arises (like, when speakers are asked to be practical), it's implied that a list of steps will follow. It's as if, to marketers, the lone type of practical information is stepular. (Note that \"stepular\" is not a word but maybe should be.)\nMy friends and I agreed there are tons of other ways to impart practical advice. After all, anything practical affects your practice. That's why it's practical. (Aren't words fun?) Practical doesn't mean \"I can follow this without turning on my brain.\"\nFor instance, big ideas that shift our perspectives help us take ANY step, better. Those big ideas are very practical.\nFeeling inspired or confident when we go to work affects our practice in profound ways too. Inspiration and confidence-boosters are very practical.\nKnowing WHY things work is even more powerful than knowing a list of WHAT works, kinda like knowing how to navigate with a compass is more powerful than knowing how to follow directions someone drew for you on a map. Knowing WHY things work is very, very practical.\nYou get it. I'm passionate about this.\nAnd so, motivated by 16 years in marketing -- and a generous pour of bourbon from the hotel bartender -- I smacked my hand on that cold marble and delivered my hot take:\n\"A list of steps isn't helpful if you're facing the wrong way!\"\nSmack.\nSwig.\nSmile.\n(Hey, I know a good line when I say it. I wasn't entirely unhappy.)\nA list of steps isn't helpful if you're facing the wrong way.\n \u2022 If you're on the wrong path, you don't need \"next steps.\" You need a pivot. Maybe even a three-quarter pirouette. But definitely don't move forward.\n \u2022 If you aren't saying anything of value, where you say it (the channel) is irrelevant.\n \u2022 If you have the wrong strategy (or none at all), the tactics don't yet matter. Should you launch a podcast or a newsletter? I don't know, but I'm pretty sure carpenters don't sit around saying, \"Should I use a hammer?\" I mean ... what are you trying to build?\nIf success were about finding and following the right steps, success would be a cinch. But that's not reality.\nAs a result, more often than we realize, we don't need more stepful prescriptions. (Note that \"stepful\" is not a word but maybe should be.) Instead, we need more thoughtful approaches. We need the posture, the confidence, the clarity, the vision. We need better ideas, smarter strategies, and a whole heck of a lot more curiosity.\nWe need to face the right way.\nThis brings me to the idea of \"story\" and how it's typically taught and understood. Typically, we end up facing the wrong way, marching down a path that isn't actually where we need to go. I'd sum up this issue like this:\nMost advice about storytelling would have us understand story, when really, we need to understand how to be storytellers.\nThese are not the same things, and our divergence from the real goal (be storytellers) begins with three common misconceptions. Or if you're a fan of beating a metaphor to death (and hoo-baby, am I ever!), then this is the stuff that causes us to face the wrong direction and head down the wrong paths.\nMisconception #1: Stories are special.\nVery commonly, the way story is taught or positioned causes us to place it up on a pedestal, like some supernatural power we can deploy to have more impact or see greater results. And look, I get it. I feel a reverence for incredible stories and refreshing creativity. I can stare towards the horizon and fill my lungs with the sweet, sweet air of possibility too. Some stories ARE special.\nBut then, yanno ... most of them aren't. Most of them should just be regular old communication. But if we see them as special, then inevitably, we start to use them ONLY on special occasions.\n \u2022 The monthly all-hands meeting.\n \u2022 The company home page.\n \u2022 The oft-promoted case study.\n \u2022 The new podcast trailer.\n \u2022 The big, important essay.\n \u2022 The opening moments of a keynote.\nThat's the problem. This is not how to become a storyteller. This is how to, occasionally, tell a story.\nStories aren't for special occasions. Stories are just for ... occasions. Everywhere. All the time. Tell stories. You'll serve others better and so will be better served.\n \u2022 When you start to face the path labeled \"Stories are special,\" remember to face a different way. Let's label that path \"Story Everywhere.\"\nMisconception #2: Stories are abstract.\nSomething that is \"abstract\" is something that is considered separate from you or the things you already know or consider tangible.\nThat's how we view this notion of \"story\" too. I get asked all the time on podcast interviews (he writes, understanding just how cringey and self-aggrandizing that may have sounded):\n\"So Jay, what are the benefits of story? Who should rely on story? How do we measure story?\"\nWhat, um ... what the actual hell are we talking about?\nTo me, that's like asking, \"What are the benefits of emotions? Should we use emotions?\"\nYES! That's just how we communicate. But just as marketers view \"emotions\" as only these extreme things (nope, they're implied or overtly communicated literally everywhere), marketers view \"story\" as these abstract things. It's all very much OUT THERE.\nEMOTIONS!\nSTORY!\n(Trumpets blare. Drums beat. Analytics go up-and-to-the-right.)\nAbstract: existing in thought or as an idea but not having a physical or concrete existence.\nThe solution to this misconception? Prioritize existence. Let's make this more concrete, shall we?\n \u2022 You experienced some stuff. Describe it.\n \u2022 You felt some things while experiencing some stuff. Describe that too.\nYou have an idea. You ship the idea. It's concrete now. It exists.\nPrioritize existence. Forget the abstractions.\nThe reason we don't do this more often is simple: the internet. (Ever heard of it?) It's both a gift and a curse to our creative causes. Let me explain...\nCreative people understand the work in two phases across their lives: before and after we see \"the code of the Matrix.\" In other words, our first attempts at anything are driven by gut feel. We only really sense the whole. It's only later that we start to notice the tiny parts, pieces, techniques, and frameworks that make up the whole -- which then unleashes a whole new level of creativity, as we are in greater control of the craft. It's like Neo from The Matrix movie, before and after he sees the code. When he does see it, he becomes a superhero, doing things others only wish they could do.\nThe internet has put much more of the \"code\" of the creative \"Matrix\" on full \"display.\" (Quotes added because lists of two make me uncomfortable.) We can instantly access knowledge about the tiny parts, pieces, techniques, and frameworks immediately, everywhere, and for free. That level of access is great!\nAlso?\nThat level of access is intimidating!\nBecause we can see or hear others talking about all kinds of techniques and heuristics and philosophies and ups-and-downs to their work, we often get lost in it. Sometimes, it feels productive to consume this stuff. Meanwhile, we haven't produced anything. Other times, it doesn't feel productive; it feels horrifying. We think we MUST understand story structure and open loops and hooks and all these parts and pieces in order to become a worthy storyteller.\nPoppycock.\nThat way of thinking is cock of the poppy.\n(Don't be offended. \"Poppycock\" is from the Dutch word pappekak, meaning \"soft dung.\" Oh, and speaking of words and creatures who poop a lot...)\nImagine if we tried to learn to speak like we try to learn storytelling. Imagine if, as little kids, we were told we had understand how to spell every word we'd say + the grammatical rules + the origins of the words + how to write them in straight lines and beautiful scripts ... all before we could speak them out loud.\nWe would never utter a word.\nBut what do we actually do? We just... start... speaking. We hear words, then we mimic them.\nYou've heard stories. So just... start... telling them.\nIf and when you get stuck, no problem. You can find a key to that door rather easily thanks to allllll that easily accessible information. But you don't need it to start or even elevate your work! You can simply start, learn, and keep going. All that advice should serve YOU, but way too often, it feels like we're trying to serve it. Don't try to find clarity to justify creating. Create to find clarity.\nIt's in the practice itself that we find our confidence, our personal techniques, our unique styles, and more. It's in the practice that we find ourselves. In waiting to practice until we learn the abstractions, we just end up removing ourselves. We arrive to the work full of everyone else's ideas for what we \u201chave to do,\u201d rather than listening to intuition.\nIf you want to feel confident or find clarity, just start making things. Tell stories. Then do it again. And again. And again.\nThe best way to find a groove is to start grooving.\n \u2022 When you start to face the path labeled \"Stories are abstract,\" remember to face a different way. Let's label that path \"Ship Stories Sooner.\"", "Please compose a pitch deck of eight to fifteen slides for my company, Cortado, based on the following outline:\n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*Intro / Hook\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n\nMy name is [ FNAME ], and over the last X months my partner and I took a real estate company from launch to more than $350,000 in revenue by leveraging new AI tools to target an $71 trillion niche housing market.\n\nHow have we taken Cortado to this point? We utilized a tried-and-true rental arbitrage model to target a deeply undersupplied housing market, while leveraging a suite of AI-powered tools to quickly scale our MVP; acquiring, marketing and managing all Cortado inventory without a single new hire.\n\n- In 10 months, we\u2019ve taken Cortado from $0 to $350,000 in revenue by leveraging low-cost AI tools to target a massive niche housing market: international student housing.\n\n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*Market Size\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n\nWhat is this niche market? International student housing, an undersupplied subset of the growing MTR market.\n\n- 6+ million students per year (8m by 2025)\n- 5.5% growth over the last 20 years, even through COVID (4.28% growth from 2019-2020)\n- Total Available Market (TAM) of $71 trillion\n - $214 per week average ([source](https://drive.google.com/drive/u/0/folders/1cwVYQgmUBjj\\_FjMlpHg4Ru01K7bRY\\_Bq))\n - 6,361,963 international students in 2020 ([source](https://docs.google.com/spreadsheets/d/1ft1EJsDua-FjUPVw-gegaX5t6coQVYzz9ghe6wNGVZ8/edit#gid=1422332990))\n - TAM = ((weekly avg/7)\\*365)\\*#int\u2019l students\n - Doesn\u2019t include domestic exchange or additional MTR verticals (traveling nurses, digital nomads)\n\n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*Why target this market? (i.e. the problem)\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n\nSo why international student housing? It\u2019s a mouthful and, I\u2019ll be the first to admit, \u201cstudent housing\u201d isn\u2019t the sexiest market out there. And for that very reason, this niche housing market has flown under the radar of VCs, angel groups and other startups.\n\nImagine arriving in a new city for work or study; you need a move-in ready stay, yet you can\u2019t afford a hotel and aren\u2019t sure what the best (or even safe) neighborhoods are.\n\n- The traditional rental long-term rental market can\u2019t serve you; you\u2019re only here for 3 or 4 months, and don\u2019t have time to pick out furniture\n - Plus, you may not even have the credit score or guarantor needed to sign a lease\n- Hotels & vacation rentals are way out of your price range\n- Traditional student housing, if there is any, has already been snapped up by full-time students\n\nAs a result, you\u2019re left between a sketchy Craigslist sublet halfway across town or crashing at a youth hostel until you can figure something better out (as founder Perry did while studying abroad in Barcelona).\n\n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*So what\u2019s the solution?\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n\nThis market needs affordable, flexible, (trusted?) move-in ready housing near their place of work or study, often in the world\u2019s toughest real estate markets.\n\n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*Cortado\u2019s Model\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n\nCortado\u2019s model meets and exceeds these criteria, while generating outsized returns.\n\n1. Partner with local homeowners to quickly source new inventory\n2. Furnish and photograph the home in under 48 hours\n3. Market the home by-the-room with tiered \u201csmart pricing\u201d to provide an affordable, community-centered living experience to our guests (and peace of mind to their parents and universities), while maintaining a target revenue occupancy of 90-95%\n\n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*How profitable is this model? (traction)\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n\nTo date, Cortado has generate over $350,000 in gross revenue, and returns of XX% across 9 rental properties in Washington, DC.\n\n- Our new housing now comes almost exclusively from homeowner referrals, showing supply-side traction for our master lease model\n- Demand, we were able to book all rooms for spring 2023 with $0 ad spend\n- Summer 2022 we booked out within 10 days\n- Programs such as Stanford, Atlantis, &c &c reach out to us on a regular basis (not enough rooms)\n\nWe project with just XX% of global market share, we could achieve an exit valuation of $XB\n\n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*How do we scale operations?\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n\nThe key with any rental arbitrage business is margins; keep costs low and revenue high while scaling quickly & sustainably. It\u2019s a tricky balance to strike, and plenty of companies have burned to the ground trying to make it work.\n\n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*Increasing Margins\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\* - After base rent and furniture, our biggest expense moving forward will be people, marketing & software, costs that can be greatly reduced by leveraging and customizing AI tools just now hitting the market:\n\n- \n\n\\*\\*How do we create value?\\*\\*\n\n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*Brand\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n\n- Cortado has already achieved a first-mover effect in Washington, DC, one of the country\u2019s most-competitive real estate markets\n - We can quickly replicate this in other domestic and especially foreign markets through B2B relationships and low-cost marketing outreach\n - Although the barrier to entry to this market is low, brand recognition is incredibly important with slow-moving academic institutions like Stanford or Brown\n\n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*Real Estate\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n\n- Blended model coupling master lease / management with ownership of the best-performing underlying assets\n- Alternative asset investing would allow Cortado to source new, unique inventory without the financial risk of traditional real estate acquisitions.\n - Maintaining partial ownership drives higher exit valuation\n - Returns of X% over typical rental\n\n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*Technology\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n\n- Whether we sell the tech ourselves, or factor its worth into an eventual acquisition, Cortado\u2019s proprietary AI PMS pushes an exit valuation from 2-3X towards the 10X+ range\n\n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*Use of Funds\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n\n- Notes\n\n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*The Ask\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n\n- Post-money SAFE with\u2026\n - Discount of X%\n - Valuation Cap of $XX\n- Goal of raising $XX in pre-seed funds", "CHAPTER FOUR\n The Spectrum of Pain: Four Patients\n From Jeremy\nYou\u2019ve read the story of my back pain. Maybe it sounded familiar (I hope not; it was a bear). In any event, read the next four case histories, because one of them is likely to remind you a lot of yourself. The idea is for you to see where you fit on the spectrum of back pain problems. \nFit Fred\nA lot of my Aspen-based patients are fit, knowledgeable, and a little surprised to find themselves in need of professional help for back pain. A recent patient, call him Fit Fred, is typical. He is fifty-five years old, a nice guy, in good shape, and smart. He has had serious back pain for six months. In his case, that means a bothersome ache in his lower back almost all the time. And intermittent periods of excruciating pain, once every two weeks or so. Those interludes\u2014which have happened more often recently\u2014last from a few minutes to more than an hour. It is those intervals that have driven him to seek treatment.\nI am not his first stop. He\u2019s tried traditional chiropractic doctors, physical therapy, massage, and Rolfing. His back pain gets a little better for a time, and then comes back full force. When the pain is at its worst, he\u2019s stuck in bed or on the floor. He has tried traditional medicine, too, and his doctor is asking him to consider surgery. He has come to me first, because he has heard how often back surgery does not work, and he dreads that option, but he\u2019s getting closer to taking it. \n\u201cMy doctor says I have degenerative disc disease. He says I have the MRI of an eighty-year-old!\u201d (It is almost a comfort to him to think that he had \u201cdegenerative disc disease\u201d and that an operation may fix it. He\u2019s had enough. He\u2019s giving the nonmedical approach one more chance. Then it\u2019s the knife.) \nIn reality, \u201cdegenerative disc disease\u201d is a term used to describe a host of changes in the spine as a result of, or in addition to, a loss of disc height (compression) over time. As a diagnostic matter, saying that someone has degenerative disc disease doesn\u2019t amount to an awful lot more than saying that he or she is getting a little older and that his or her back hurts. That sounds a little snide, I\u2019m afraid, but it\u2019s true. Because Fred seems to have decent posture and is in pretty good shape, I suspect that his problem is going to be related to the normal degenerative changes of the spine that go with aging and bad repetitive motions. Maybe golf, maybe yoga. Depending on how open he is to change, this could be a comparatively easy case. \nIt won\u2019t sound easy, if I go into the details. After all, compression of the spine through normal aging does do some serious things. They can include arthritic changes in the facet joints (remember them?), loss of cartilage around all the joints, foraminal stenosis, which\u2014you will recall\u2014is a narrowing of the opening, or foramen, from which the nerve roots exit the spine. It may be spondylolisthesis, which is a slippage of one vertebra over another, causing pain and instability\u2014and is almost as nasty as it is unpronounceable. That all sounds awful, but they are normal concomitants of aging and degeneration of the spine and bad movements\u2014my normal material. Those we can fix. \nAs for his eighty-year-old\u2019s MRI, it probably does look pretty grim. But I have to tell you, almost all MRIs of people over forty look terrible. Stuff happens, and the individual manifestations look very scary. But they are not really all that bad. Which is why I rarely prescribe MRIs unless there are signs of the scary stuff (cancer, infection, fracture, etc.); they don\u2019t tell me anything I don\u2018t already know. \u201cHey, you\u2019re getting older, your back is getting squished. What did you expect?\u201d It\u2019s more sophisticated than that, but that\u2019s a fair summary in most cases. It is also a fair description of a condition you and I can fix, with behavioral change and hard work.\nI ask Fred a couple of questions about the therapy he\u2019s had so far. The chiropractor has just been manipulating him with no mention of exercise. I know that\u2019s not going to work for a permanent fix. And the physical therapist does not seem to have much of a plan: He has had my new patient do four exercises for three months\u2014always the same four, over and over, with no supervision and no progression. And neither of them has discussed his other activities (sports, work, exercises, etc.) with him. Beyond that, they are not the kind of exercises I will suggest because, among other things, they have done nothing to affect the endurance of the muscles of the core. This is by no means a slight on all chiropractors or physical therapists. There are some great ones out there. Some practice the way Fred\u2019s did, and some don\u2019t. Later in the book, we give you some pointers on finding good ones.\nFred really is active, God bless him, but he\u2019s doing some activities that, I suspect, are not helping his back. He does quite a lot of yoga, plays golf regularly, and lifts weights in the gym. A very responsible, fit guy, as I say. But what I know, without seeing him do yoga or play golf, is that some of the movements in those two activities are often a source of serious back injury over time. There is a safe, spine-healthy way to do yoga but, done wrong, as it often is, it can cause terrible problems. For now, I tell him to lay off yoga completely for at least two months. He can get back to it in time with some modifications. The same with golf. Golf is a wonderful activity. Not great exercise (contrary to what so many insist) but a wonderful way to be with friends and go to beautiful places. It can also be, structurally, one of the worst things you can do to your back. (All that one-way twisting of your lumbar spine.) There is a spine-healthy way to play golf, but for now I just tell him to lay off the golf until he is educated enough to be open to some instruction on a \u201cright way\u201d to play. [Hint: You learn to rotate with your hips more at the end of your swing, and less with your lower back.]\nThen I asked him to walk me through his strength-training regimen. It was not the worst strength regimen I have ever heard about, but it was pretty bad. He was doing a number of things that were almost criminally bad for him. If you are doing a lot of strength training, there is a sad chance that you, too, are doing some seriously harmful stuff, from a back point of view. That\u2019s because we were all trained to do things wrong, back in the day. \nTake, for example, the traditional \u201carmy sit-up,\u201d which Fred is still doing. We all did a lot of those at one point and a lot of us are doing them still. Even the army gave them up only in recent times. But the fact is that there are few things worse for your back than the good old army sit-up. (A shallow, or four-inch \u201ccrunch\u201d is fine, and it does all you need for your core; you do not need to bend your spine like a pretzel to get a benefit.) The sit-up, where you twist to touch your elbow to the opposite knee, is the worst of all. And that\u2019s just one of a bunch of deeply familiar exercises that are fundamentally terrible for your back. The machines we all used to love are a particular peril (not all but many). The whole world of bad strength training makes me particularly crazy: Here are these terrific men and women, working so hard in an effort to make their bodies stronger and better. And what they are doing is, in fact, worse than doing nothing at all. Sad and wrong. \nMost important, Fit Fred has no notion of the importance of engaging his core and strengthening his core and glutes\u2014perhaps the most important elements in a sane strength-training regimen. And he doesn\u2019t have a clue about the importance of decent posture and of maintaining a neutral spine. So I tell him to stop all strength training until I can show him how to do it right. \nSubstantial Sally \nIf Fit Fred was on the fit end of the fitness spectrum, then Substantial Sally was the opposite. She is significantly overweight (she is close to 300 pounds, which is very significant indeed) and has had no regular exercise program for the past four years. She has had a whopping four spine surgeries, two in the past two years, including a fusion and a laminectomy. Fusions are common, but they are very serious business indeed. It is a procedure in which the surgeon uses hardware to bolt (fuse) two or more vertebrae together to prevent further movement at that joint. There is a place for fusions, but I see them as a very last resort. They give relief, but if the person does not make the necessary behavioral changes, they often find themselves having another fusion or other problems in a few years. They are not a cure, in any broad sense. A laminectomy is a less serious procedure in which the surgeon removes a small piece of bone off a vertebra to relieve pressure on a particular nerve. Again, it cures a symptom, not the basic problem. \nIn any event, Sally has been through the wars, she is still in pain, and she is both smart and wary. She is not one bit sure that I am going to be any more help than my predecessors. I don\u2019t blame her. But I think she\u2019s wrong. I think I am going to be able to help her quite a lot, if she\u2019ll listen, which she may not. \nSally is an appealing woman, the head of a company that she started herself, and which she has made a huge success of. I automatically like her, right off; she\u2019s one of those people whom everyone likes right off . . . part of her success, I assume. But she sure is in trouble, and it is making her cranky. I don\u2019t blame her, but she is not fun. Not many of my patients are fun; they hurt too much.", "CHAPTER SEVEN\n RULE #2\n Be Still So You Can Heal (The Neutral Spine)\n From Jeremy\nLet\u2019s assume that you are beginning to get the big picture. And that you have also begun to identify the \u201cdumb\u201d things that you\u2019ve been doing to wreck your back, and that you have stopped doing them. Good. Now it is time to start the healing, and that is a matter of immobilizing your lower back or lumbar spine so it can heal, after all those years of doing things that hurt it. \nThe analogy is not perfect, but think of your tortured back as being like a broken arm or leg. When you break an arm, say, the doc puts it in a stiff cast so you can\u2019t bang it or twist it and to give it time and rest to heal. The same with your back, except we can\u2019t do anything quite as dramatic as put you in a whole-body cast for your damaged back. What we can do is show you how to carry yourself so that you effectively immobilize your lower back. It\u2019s not totally easy, but it will work. And bear in mind, if you do not immobilize your back, it will not heal\u2014simple as that. Indeed, it may get worse. \nWhat do I mean by \u201cimmobilizing\u201d your lumbar spine? I do not mean that you can\u2019t sit or walk or have a more or less normal life. What I do mean is that you have to be really serious about maintaining a neutral spine, all the time. Maintaining a neutral spine is at the heart of your cure, and will be at the heart of your life after your cure. This is the time to learn how to achieve a neutral spine and how to maintain it all the time, even when doing various movements. \nThe spine is a meticulously engineered piece of machinery, but it has a lot of redundancy built in. By this I mean that unlike the knee or shoulder, in the spine when you have a bad joint, the surrounding structures can \u201chelp\u201d bear the loads, and you can function more or less normally and without pain. Take the pressure of bad posture\u2014and dumb movement patterns\u2014off, and there is very likely enough \u201croom\u201d in this spine for the sufferer to have a normal life. For example, the \u201choles\u201d where the nerves come out of the spine (the foramina) are still big enough for the nerves to exit, pain-free, if you\u2019re not squeezing the area with lousy posture. In the same vein, there is probably still enough cushion in the flattened disc to support a correctly aligned spine (but not a bent or misshapen one). And so on. \n\u201cNeutral\u201d means the position in which the least amount of problem loads occur, all up and down the spine. The \u201cproblem loads\u201d in some pictures we\u2019ve shown are extreme, but even those inflamed joints and nerve roots will likely calm down if you leave them alone for a while. Which is to say, if you keep your spine in neutral. As bad as those injuries are (and as long as it took someone to create them) there is a strong chance that that sufferer can go about his or her life, with a neutral spine, in little or no pain. \nLearning to keep a neutral spine is not totally easy. And learning to maintain it all the time is harder. But this is the \u201ccast\u201d that lets your body heal. It is worth going to a lot of trouble to get this right. And it is a lesson that you will use for the rest of your life, long after the problem area has \u201chealed.\u201d \nOkay, step one is understanding the concept of neutral spine. Step two is learning to find it and lock it in place, and keep it in place forever (which we will teach you in Chapter 9).\nThe neutral spine is the position that allows your spine to do its job with the least amount of stress and load. And\u2014if you have already damaged your back\u2014it is the position that results in the least amount of new damage or pain.\nFor most people, the picture on the left is the neutral spine. The other two are not.\nNeutral Spine \n\nGOOD BAD\nNote the gentle curve of the lower back in the \u201cgood\u201d spine. For the majority of you, this is how your neutral spine will look. If you have developed significant degenerative changes or were born with significant abnormalities (it happens, but not a lot), your neutral spine may look a bit different. For now assume that your neutral spine looks like one on the guy on the left. Spines vary, and you may have your own unique neutral spine that is a little different from this. Whatever your own neutral spine, that is the position you want to maintain as you go about your daily life. It is also the position in which you feel the least pain. Again, maintaining a neutral spine is a fundamental behavioral change for most people. And it is readily doable. In a few months\u2019 time, I predict that it will be natural and you will scarcely need to think about it. One of the near-magic presences in our lives is \u201cmuscle memory.\u201d Maintain your spine correctly for a while and muscle memory takes over. Then it is just a question of seeing to it that your muscles are strong enough to do their job. \nHow do you keep your spine neutral and still be a dynamic, moving, active human being? By learning to brace your neutral spine with your core (Chapter 9) and maximizing movement in your hips (as opposed to your lower back). As Chris mentioned in Chapter 6, one of our cardinal rules is \u201cThou shalt not bend or twist with thy lower back.\u201d And you don\u2019t need to. You can rotate from side to side and bend forward and back using your hips. You do not need to flex or twist your lower back. \nYou may ask: Isn\u2019t range of motion important for the lumbar spine? Answer: Not really. At least, it is usually the least important factor for someone who has had significant back pain, and should be reintroduced only after pain has stopped. Most people who have experienced regular, serious back pain have already sustained significant wear and tear on the spine. The general pattern I see is a combination of two things: first, worn-down vertebral joints that are hypomobile (stiff), secondary to arthritic changes and degeneration; second, lumbar vertebral joints that are hypermobilie (loose), due to overstretched ligaments and atrophied muscles. These problems are best resolved when we protect the spine by bracing and \u201clocking down\u201d the lumbar spine and moving in a manner that completely changes the axis of motion from the lumbar spine to the hips and shoulder girdle. You can eventually introduce some gentle lumbar range-of-motion exercises in non-loaded ways. This is what the \u201cCat/Camel\u201d exercise that we introduce later is for. Small, gentle lumbar range-of-motion exercise is necessary for things like synovial joint lubrication, the reduction of friction between vertebral segments and discs, and disc nutrition, among other things. For example, walking requires a few degrees of freedom between the lumbar vertebral joints (3 or 4 degrees rotation) with coordinated muscle contractions to enhance stabilization and supply necessary lubrication and nutrition to discs and joints. For our purposes, we recommend keeping lumbar motion to a minimum, especially until your pain is gone. Once that occurs, you should make only healthy, non-loaded, non-repetitive lumbar movements, such as those necessary for walking and the cat and camel exercise. Spinal stability, core endurance, hip mobility, and core and gluteal strength are far more important for maintaining a healthy spine once you\u2019ve had back pain. You can do just fine in life with almost no rotation or excessive movement in your lower back. Let your hips do the work, and your risk of recurring back pain is sharply reduced. \nFinding Your Neutral Spine \nFinding your neutral spine can be a bit tricky for some but you can do it. Here\u2019s what you do. Lie on your back with your knees bent and your feet flat on the floor. Try to relax everything in your body, and just breathe. Then let\u2019s start by performing a pelvic tilt. \nTo do that, flatten your lower back into the floor (see top drawing), and curl your tailbone upward. This is a \u201cposterior pelvic tilt,\u201d if you want to put a name to it. Now, arch your back so that your lower back comes off of the floor (middle drawing), and point your tailbone toward the ground (an \u201canterior pelvic tilt\u201d). Now, slowly go back and forth between those two motions a few times (bottom drawing). Find the position of your lower back between these two extremes (flattening your back or arching it) that feels the most comfortable to you, and stop there. This is your neutral spine. It may take a few tries but it\u2019s not hard.\nFinding Your Neutral Spine\n\nStop here for a second. You have just reached an important point, and you don\u2019t want to \u201close\u201d it. Everyone\u2019s neutral spine is a bit different depending on the anatomical condition of their lumbar spine. For most people, there will be a gentle curve in the lower back. For those who already have some kind of a disc bulge, their neutral spine might be more arched (butt more extended). For those with spinal stenosis, their neutral spine may be a little more flattened than the one in the picture on the previous page. Don\u2019t worry about it. Whatever feels the most comfortable for you is your neutral spine for now. In time, your neutral spine will likely become more like the \u201cnormal\u201d picture as pain and inflammation subside.\nThink about your neutral spine and assume that position all the time until it becomes second nature\u2014until \u201cmuscle memory\u201d takes over. \nNext, we move on to a discussion of techniques to help you maintain a neutral spine. But first, Chris is going to tell you why it is very likely you haven\u2019t heard of these concepts before.", "CHAPTER FOURTEEN\n Trigger Points: Muscle Pain and Back Pain\n From Chris and Jeremy\nMost of us\u2014the newcomers anyway\u2014tend to think of back pain as something that is largely in the spine itself. The bones, discs, ligaments, and nerves. But what most of us don\u2019t focus on are the surrounding and supporting muscles. Which is a mistake, because they can be a major source of back pain (or something that can pass as back pain). And getting \u201cright\u201d with those muscles can be mighty important. \nTo be accurate, back pain is almost always a not-so-pleasing blend of muscle pain, joint pain, nerve pain, and other pain. This can be a little confusing. All pain is transmitted by nerves. When we speak of muscle pain or nerve pain, we are referring to the primary source of pain\u2014that is, the pain-generating tissue. Sometimes an aggravated nerve is the source of pain so it is referred to as nerve pain. In this chapter, we are talking about pain whose primary source is muscles. Even though the pain is transmitted to your brain via nerves, the tissue that\u2019s causing the pain is muscle tissue, so we refer to it as muscle pain. It is helpful to think of that which is primarily muscle pain differently, because it manifests itself differently, and Jeremy\u2019s approach to it is different, too.\nThere\u2019s good news and bad news here (wouldn\u2019t you know it). The bad news is that muscle pain is harder to locate and trickier to fix in the first instance. The good news is that it is actually easier to fix in the long run, and your prospects of a complete cure are much better. \nWhich is not to say it does not hurt like blazes. Up in the 8\u201310 range, on a scale of 10. But often the relief can be sudden and nearly complete. You still have to do serious stuff to keep it from coming back once the fix is made, but that\u2019s always true. \nMuscle Pain\nPeople in the healing professions refer to muscle pain both as \u201cmyofascial pain\u201d and \u201ctrigger point pain.\u201d For laymen like you and me, \u201ctrigger point pain\u201d may be the more useful name, because it feels like that\u2014something that gets \u201ctriggered\u201d by some silly move you made. Whatever we call it, trigger point pain has been a somewhat controversial topic for decades, mostly because no medical discipline claims ownership of the muscular system. Doctors are far more concerned with the joints, bursae, ligaments, and nerves. There has not been as much study of the muscular system and trigger point pain. But there has been enough, so that there is broad agreement on many points. And the best practitioners, and Jeremy in particular, have seen a lot of it. \nSo, what is it? Here\u2019s Jeremy: \u201cTrigger points are tight, painful bands of muscle tissue that have predictable and recognizable patterns of pain.\u201d To put it another way, they are muscle spasms (not quite right but close enough), which is what you get when a muscle or muscle segment seizes up, under pressure, and won\u2019t let go. It\u2019s like those cramps you sometimes get in your leg, except it doesn\u2019t go away and the pain can be horrendous. Unbearable, some of the time. These spasms or cramps not only cause terrible pain in their own right, but they can change the way some joints function. As Jeremy puts it, \u201cThey also limit range of motion and change the normal distribution of loads on nearby joints, which can also cause pain.\u201d So trigger point pain is serious, and it has more than one way to grab you. If it has started to affect the range of motion of the nearby joint, in the way Jeremy suggests, clearing it up is harder, but the approach is the same. \nOne thing to bear in mind is that trigger points basically \u201clie\u201d to us. That is to say, the obvious pain may crop up away from the actual trigger point itself. For example, the trigger point may be in the gluteus minimus (that\u2019s a favorite spot, actually), but the pain may run down the leg, mimicking sciatica. Or a trigger point in the gluteus medius may read as pain in the lower back. There are a lot of variations, but the patterns are well known and predictable, so professionals know where to look for the originating problem. Most of the time, anyway. Pretty soon, you will, too. \nOne thing that helps is that trigger point or muscle pain in general is recognizably different from nerve pain (again, this means pain in which an aggravated nerve is the source of the pain, not just the means of transmission to your brain) and other pain, so that you know what you are dealing with. Most of the time, nerve pain, for example, is \u201cburning, sharp, electric,\u201d and you can pinpoint exactly where it is. Trigger point pain, on the other hand, is achy, diffuse, hard to localize, and dull. And it often arises far from the source, which is a trigger point in a muscle. \nOne reason it is called trigger point pain is that it is usually \u201ctriggered\u201d by an actual event, just the way it feels. You rolled over funny in bed, you opened the Sub-Zero too vigorously, you picked up the box of books with your back, not your legs. Sometimes, those triggering events are one-off incidents, which is the way they feel. But more often, the trigger point (or vulnerability) has been building for a long time. Vulnerable muscles or muscle segments have been under repetitious pressure for a long time, and they are ready to \u201cgo\u201d at the drop of a hat. You open the Sub-Zero funny and pow! A terrifying spasm. A latent trigger point like that can \u201cgo\u201d without any trigger event at all or with a trifling one. Let us hope that yours is a \u201cone-off,\u201d not one that has been building for years, because the one-off takes less time to heal. But never mind, the approach is just the same. \nThe most common trigger points are the ones that have been caused by muscular overload, and that have developed over time. Think of the familiar situation: You sit at your desk for months and years. It is an \u201cunnatural\u201d position, and it puts repetitive pressure on muscles that aren\u2019t built for it. Or it can be repetitively misplaced loads, caused by you doing some move the same wrong way, year after year, like a faulty golf swing. Say you sprain an ankle and you never quite rehab the ankle the way you should. Over the following weeks and months you walk slightly differently than you used to. This subtle change causes muscles in your legs and pelvis to bear loads in a different way. Some now bear more loads, some less. Over time, those muscles that are now bearing more loads get stressed and strained, and trigger points develop. The pain from these can come on gradually or suddenly. As we have said all along, most of the time, you have built your own back pain, over time, with the way you behave. That is true for most muscle pain, too. \nFinding Trigger Points\nOkay, on to the details. \n\u201cFor low back pain sufferers, the most important and common areas for trigger points to occur are in the lumbar paraspinals, quadratus lumborum, gluteus maximus, gluteus medius, gluteus minimus, and piriformis.\u201d Sorry, that\u2019s Jeremy; he just can\u2019t help himself. But you don\u2019t have to memorize the names; you just have to look at the pictures to get the general idea. And then feel around for the real source of the pain. When I say look at the pictures, I mean look and see if you can relate what you feel to the typical patterns the pictures show. The Xs represent the location of the real trigger point and the red shaded areas represent the area where you may perceive the pain. So think about where you feel the pain. Then look at the pictures. Then go to work to find where the X may mark the spot. When you find it, it will hurt a lot more than the surrounding area. Bingo! Think of these pictures as \u201ctreasure maps\u201d and the treasure is eventual release from pain. \nThis process is very much \u201chands on.\u201d It can be challenging to distinguish areas of perceived pain from actual trigger points until you get a feel for what you are looking for. If you try multiple times and fail, you may need the assistance of a good chiropractor, massage therapist, or physical therapist to get the hang of this. To get started, grope around with your hands (using the pictures as a guide to the general area) until you have a fair idea of where the real trigger points are. You will know them because they hurt more. For once, the pain is the good news. It means that you\u2019re getting close. Or you\u2019re there. \nBy the way, the muscles where the trigger point lies can be deep. The gluteus minimus, for example, is buried beneath two other muscles and a layer of fat. Some of you are not going to have the strength or leverage to reach that trigger point with your hand alone. You may need to use a tennis ball or foam roller, which will be discussed in the following pages. But, to start, just use your hand until you get a general idea if there is something deep in those muscles that needs to be released. And don\u2019t forget: Use the pictures as your guide. \nOnce you have a general idea of where the trigger point is, mash away at it, if you like, with your bare hands, and see if that manual manipulation is enough to \u201crelease\u201d the rascal. What you do is hold down hard on the place that hurts the most and\u2014in ten to thirty seconds or so\u2014you should feel an easing of the pain. That is the trigger point letting go. Nice work. If the pain does not ease up after thirty seconds or so, either you are not directly", "this is chapter 20 of original book\n{CHAPTER TWENTY\n The Sacrum and Coccyx\n From Chris and Jeremy\nFrom Chris\nThe sacrum is the last section of the spine, the vestigial collection of vertebrae that are welded into one solid piece, down at the bottom. And the coccyx is the tippety-tip of the sacrum, the last bit of bone at the end of that long chain, which has been such a torment to you for so long. \nAnd this is the end of the book. The end of the long chain of chapters that we hope\u2014with all our hearts\u2014will deliver you from such torment forever. From now on, it\u2019s up to you. Go back through the book, do the exercises, and change your behavior the way you know you should. Up to you now. \nMay I say, here at the end, that putting this book together has been great fun for Jeremy and me. It has taken more than a year, and it has been a ton of work. We hope it reads as if it were easy as pie, but it wasn\u2019t. We worked like crazy to make it seem easy\u2014and to make it truly accurate without driving you crazy. Don\u2019t know how well we did on that, but we sure did try. And it was fun for a couple of reasons. First, from my point of view, Jeremy is awfully good company. He is deadly serious about his profession but he loves to laugh, too. And, God bless us, we think we\u2019re funny. That helped a lot. On a slightly more serious note, learning all the stuff I had to learn about the back this past year was fascinating and a privilege. Interesting piece of machinery, the back, and Jeremy could not have been a better guide. \nFinally, both of us are true believers in this \u201crevolution\u201d I mentioned up front, and that is a tremendous help. The whole time we were digging away at this boring detail or that, we had the agreeable conviction that we were not just ink-stained wretches, noses to the page. We were centurions in the great war against cruel, needless pain. That helped a lot, too. \nBut the whole business won\u2019t be satisfying to us if it doesn\u2019t work, for you. And that takes me back to my one great worry, the one I mentioned before. \nI worry that we leave so much of this up to you, when we know that Americans just aren\u2019t used to that. Americans are used to going to the magician/doctor. He has a look around, maybe does an MRI. And then hands us a prescription, or gives us a shot. Or sends us to his pal the back surgeon, who does some clever thing to make us all better. As we\u2019ve said again and again, that\u2019s not going to work here. You have to do it yourself\u2014you have to do the exercise, make the changes. But the great question is, will you find the resolve to make it happen? Jeremy says he\u2019s sure you will, because he knows your pain. He knows just how deep and sharp your motivation is. I hope he\u2019s right. \nWhat we are urging is not really that hard; it is mostly just unfamiliar. And you surely have the resources and motivation to make it happen. I know you\u2019re smart enough; you just read this darned book, after all. I know you are disciplined enough; you\u2019ve been going to work all these years. And I know you care, because I know about your pain. Now just take those three things and reorient them a little. And save your life. Then spread the word and save your family, save the country. Get the ogre out of all our lives. It can and should be done. \nFrom Jeremy\nI can\u2019t agree more with Chris\u2019s words. He and I had such a great time writing this book, and we are both deeply optimistic about what it can do for you. As you well know by now, I am not the \u201cword guy\u201d; that\u2019s Chris. So I will be uncharacteristically brief and just say I have seen this protocol work a thousand times in my practice. Now I want to see it work a million times, perhaps more than that, with this book. As we mentioned at the beginning, we want a revolution in back care in this country. Starting with you. We want to take this scourge out of all our lives. \nJEREMY\u2019S RULES\n1\nStop doing dumb stuff.\n2\nBe still so you can heal.\n3\nBrace yourself.\n4\nCommit to your core.\n5\nUse the power in your posterior.\n6\nCrawl before you walk. Walk before you run.\n7\nStand tall for the long haul.\nAPPENDIX\nThe \u201cCheat Sheet\u201d\nWe threw a lot at you in this book. In time, it will seem like second nature. When you get to that point, it may still be useful to have a simple guide to remind you where you are, what to do next, and so on. To that end, I give you this \u201ccheat sheet\u201d to summarize all the exercises we have told you to do and to tell you when to do them. Here is your daily and weekly plan.\nI strongly encourage you to read this book a few times a year. Trust me, you are trying to change lifelong habits and it\u2019s very easy to default back to the old ways. Come back to the book and think through each exercise every so often. Avoid the trap of falling into those same bad habits that got you here in the first place. The book is the key to taking your life back and leaving the anxiety, stress, and pain of back problems in the past. In between readings of the book, there\u2019s this Exercise Cheat Sheet. \nBasic Core Exercises\nThese exercises (see Chapter 10) should be done every day, and are best done in the morning after being out of bed for thirty minutes or so. Remember to do progressions or regressions as needed for each. Move on to the next progression of a particular exercise when and if you feel ready. Start with one circuit and work your way up to two full circuits in time, and make that your daily habit. In time, this will take you ten to fifteen minutes.\n1. Slow March with Neutral Spine with Shoulder Flexion\n2. The Bridge \n3. Crunch and Plank\n4. Dynamic Hamstring Stretch\n5. Side Plank\n6. Cat/Camel Mobilization\n7. \u201cBird Dog,\u201d or Opposite Arm/Leg Extension\nGlute Strengthening Routine \nDo these exercises three times a week on nonconsecutive days in addition to your core routine. Start with two sets and work your way up to three in time. This will likely add an additional ten minutes or so on those three days a week that you do these. \n1. Hip Circles Do these first!\n2. Clamshell\n3. Quadruped Hip Extension\n4. Split Squat\n5. Squat\nTrigger Point Release\nDo this as needed. If you got noticeable improvement in back, hip, or leg pain after mastering this, do it prior to your glute workouts until it is no longer needed. \nStretches \nFollow up your glute routine with the following stretches from Chapter 17.\nThis will take three to four minutes.\n1. Hamstring Stretch\n2. Glute Stretch\n3. Piriformis Stretch\n4. Psoas Stretch\nTHE BACKFOREVER VIDEOS\nFor those of you who want to safely return to more demanding activities like weightlifting, skiing, golf, tennis, Pilates, yoga, etc., we invite you to become members of BackForever.com, where you will find hundreds of hours of detailed video instruction on these subjects. Visit BackForever.com to learn more. Enter this promo code to receive two free weeks of membership: YNYTRIAL.\nACKNOWLEDGMENTS\nThanks to Jeremy, first of all, for being such a joy to work with. Coauthorship is supposed to be hard. For me\u2014especially in this book\u2014it has been a joy. We worked mighty hard, but we laughed a lot too.\nJeremy and I have been blessed\u2014and we know it\u2014to have a superb editor in a smart, kind, diplomatic, literate Bruce Tracy at Workman. (That is a shortened list of attributes; Bruce was terrific. And he really got down into the weeds as well as the big picture. As good as they get.) And, as always, thanks to the wise and kind Suzie Bolotin, editor of the Younger Next Year\u00ae books and Uber-editor of this one. Heaven!\nLast, thanks to Bill Fabrocini, just about the smartest and most effective guy Jeremy and I know in the broad world of physical therapy and serious training. And about as nice a human being as I have ever met. Deep thanks, Bill.\n\u2014C. C.\nI\u2019d like to thank all of the people who have helped me become the clinician I am today. I\u2019d like to thank Clinton Phillips, Michael Fox, Tim Powersmith, and Bill Fabrocini for their friendship, guidance, and the opportunities they have given me. Back pain has been one of the most misunderstood afflictions in modern society. Many of the concepts in this book are the result of the research and teaching of a handful of dedicated and pioneering individuals. There are many, but I would like to give special mention to Vladimir Janda, MD; David Simons, MD; Janet Travell, MD; Nikolai Bogduk, MD, PhD; and Stuart McGill, PhD. This book wouldn\u2019t have been possible without your accomplishments. }\nRead the chapter 20 of original book that I sent you and save it in your memory. Then, based on this text of chapter 20 of original book and your own information, continue the text of chapter 20 of the new book as much as you like. morover, with explaining with deep learning to me as if i were 10 years old.The text should be completely scientific and academic and based on science World Day should be written and repetition should be avoided. that are not repetitive and related to this topic. this chapter of an original book that I gave you is just a starting point and he has the right to add relevant foliage to this section. based on chapter 20 of original book, you can start", "ok. Can let me give you the transcript: 0:00\nOur company has a new strategic initiative to increase market penetration, maximise brand loyalty, and enhance intangible assets.\n0:08\nIn pursuit of these objectives, we've started a new project --\n0:11\nfor which we require 7 red lines.\n0:14\nI understand your company can help us in this matter.\n0:16\nOf course!\n0:17\nWalter here will be the Project Manager. Walter, we can do this, can't we?\n0:22\nYes, of course.\n0:23\nAnderson here is our expert in all matters related to drawing red lines.\n0:26\nWe brought him along today to share his professional opinion.\n0:30\nNice to meet you! Well, you all know me.\n0:32\nThis is Justine, our company's design specialist.\n0:35\nHallo...\n0:36\nWe need you to draw seven red lines.\n0:39\nAll of them strictly perpendicular; some with green ink and some with transparent. Can you do that?\n0:46\nNo. I'm afraid we --\n0:47\nLet's not rush into any hasty answers, Anderson! The task has been set and needs to be carried out.\n0:51\nAt the end of the day, you are an expert.\n0:53\nThe term \"red line\" implies the colour of the line to be red. To draw a red line with green ink is --\n0:58\nwell if it is not exactly impossible, then it is pretty close to being impossible.\n1:02\nWhat does it even mean: \"impossible\"?\n1:04\nI mean, it is quite possible that there are some people, say suffering from colour blindness,\n1:08\nfor whom the colour of the lines doesn't really make a difference.\n1:10\nBut I am quite sure that the target audience of your project does not consists solely of such people.\n1:15\nSo in principle this is possible.\n1:19\nI'll simplify.\n1:21\nA line as such can be drawn with absolutely any ink.\n1:24\nBut if you want to get a red line, you need to use red ink.\n1:28\nWhat if we draw them with blue ink?\n1:30\nIt still won't work. If you use blue ink, you will get blue lines.\n1:37\nAnd what exactly did you mean, when you talked about the transparent ink?\n1:40\nHow to better explain?\n1:42\nI'm sure you know what \"transparent\" means?\n1:44\nYes, I do.\n1:45\nAnd what a \"red line\" means, I hope I don't need to explain to you?\n1:49\nOf course not.\n1:50\nWell... You need to draw red lines with transparent ink.\n1:55\nCould you describe what you imagine the end result would look like?\n1:58\nC'mon, Anderson! What do we have here, kindergarten?\n2:01\nLet's not waste our time with these unproductive quarrels.\n2:05\nThe task has been set; the task is plain and clear.\n2:07\nNow, if you have any specific questions, go ahead!\n2:11\nYou're the expert here!\n2:13\nAlright, let's leave aside the colour for the moment.\n2:16\nYou had something there also relating to perpendicularity?..\n2:20\nSeven lines, all strictly perpendicular.\n2:23\nTo what?\n2:26\nErm, to everything. Among themselves.\n2:30\nI assumed you know what perpendicular lines are like!\n2:32\nOf course he does. He's an expert!\n2:35\nTwo lines can be perpendicular.\n2:36\nAll seven can't be simultaneously perpendicular to each other.\n2:41\nI'll show you.\n2:45\nThis is a line, right?\n2:48\nYes.\n2:49\nAnd another one. Is it perpendicular to the first line?\n2:55\nWell...\n2:57\nYes, it is perpendicular.\n2:59\nExactly!\n3:00\nWait, wait, I'm not done. And a third one: is it perpendicular to the first line?\n3:06\nYes, it is! But it doesn't cross the second line. They're both parallel.\n3:12\nNot perpendicular!\n3:16\nI suppose so.\n3:17\nThere it is. Two lines can be perpendicular --\n3:21\nCan I have the pen?\n3:42\nHow about this?\n3:48\nThis is a triangle.\n3:49\nIt's definitely not perpendicular lines.\n3:53\nAnd there are three, not seven.\n3:57\nWhy are they blue?\n3:58\nIndeed. Wanted to ask that myself.\n4:01\nI have a blue pen with me. This was just a demonstration --\n4:04\nThat's the problem, your lines are blue. Draw them with red ink!\n4:07\nIt won't solve the problem.\n4:09\nHow do you know before you've tried?\n4:10\nLets draw them with red ink and then let's see.\n4:12\nI don't have a red pen with me, --\n4:13\nbut I am completely certain that with red ink the result will still be the same.\n4:19\nDidn't you tell us earlier that you can only draw red lines with red ink?\n4:22\nIn fact, yes, I've written it down here!\n4:24\nAnd now you want to draw them with a blue ink. Do you want to call these red lines?\n4:29\nI think I understand. You're not talking about the colour now, right?\n4:33\nYou're talking about that, what do you call it: per-per, dick-dick --\n4:37\nPerpendicularity, yes!\n4:38\nThat's it, now you've confused everyone.\n4:41\nSo what exactly is stopping us from doing this?\n4:44\nGeometry.\n4:46\nJust ignore it!\n4:47\nWe have a task. Seven red lines. It's not twenty; it's just seven.\n4:52\nAnderson, I understand; you're a specialist of a narrow field, you don't see the overall picture.\n4:58\nBut surely it's not a difficult task to draw some seven lines!\n5:01\nExactly. Suggest a solution!\n5:03\nAny fool can criticise, no offence, but you're an expert, you should know better!\n5:10\nOK. Let me draw you two perfectly perpendicular red lines, --\n5:15\nand I will draw the rest with transparent ink.\n5:18\nThey'll be invisible, but I'll draw them.\n5:21\nWould this suit us?\n5:24\nYes, this will suit us.\n5:26\nYes, but at least a couple with green ink.\n5:28\nOh, and I have another question, if I may.\n5:31\nCan you draw one of the lines in the form of a kitten?\n5:34\nA what?\n5:35\nIn the form of a kitten.\n5:36\nMarket research tells our users like cute animals. It'd be really great if --\n5:40\nNo-oh...\n5:42\nWhy?\n5:42\nLook, I can of course draw you a cat.\n5:45\nI'm no artist, but I can give it a try.\n5:47\nBut it won't be a line any more. It will be a cat.\n5:49\nA line and a cat: those are two different things.\n5:51\nA kitten. Not a cat, but a kitten.\n5:53\nIt's little, cute, cuddly. Cats, on the other hand --\n5:58\nIt doesn't make a difference.\n5:59\nAnderson, at least hear her out!\n6:01\nShe hasn't even finished speaking, and you're already saying \"No!\"\n6:04\nI got the idea, but it is impossible to draw a line in the form of a cat...ten.\n6:10\nWhat about a bird?\n6:15\nSo, where did we stop? What are we doing?\n6:17\nSeven red lines, two with red ink, two with green ink and the rest - with transparent.\n6:21\nDid I understand correctly? -- -- Yes.\n6:23\nExcellent! In which case that's everything, right?\n6:26\nOh, oh, I almost forgot, we also have a red balloon.\n6:28\nDo you know if you could inflate it?\n6:34\nWhat do I have to do with balloons?\n6:37\nIt's red.\n6:38\nAnderson, can you or can you not do this? A simple question.\n6:42\nAs such, I can of course, but --\n6:43\nExcellent. Organise a business trip, we'll cover the expenses, --\n6:47\ngo over to their location, inflate the balloon.\n6:52\nWell this was very productive, thank you all!\n7:08\nCan I ask one more question, please?\n7:10\nWhen you inflate the balloon, could you do it in the form of a kitten?\n7:16\nOf course I can!\n7:17\nI can do anything, I can do absolutely anything.\n7:23\nI'm an expert!", "Please summarize this: A Glance into the History of the 8 Jungian Functions\nCarl Jung, the famous Swiss psychiatrist, proposed his model of the eight (8) functions in his work, Psychological Types (1921). He divided the functions into two groups, extraverted (tethered in the external world) and introverted (unfolded in the inner world).\n\nJung\u2019s work would later be built upon by Isabel Briggs Myers and her mother Katharine Cook Briggs, who created a personality model we know today as the Myers-Briggs Type Indicator (MBTI\u00ae). The Myers-Briggs approach used scales for Extraversion-Introversion, Sensing-Intuition and Thinking-Feeling based on Jung\u2019s work and then added a fourth dimension of their own, Judging-Perceiving. The result is 4 different scales on which a person will be assigned one of two possible values. Thus there are 16 combinations (2 x 2 x 2 x 2 = 16).\n\nEach of the 16 personality types have four cognitive functions in alternating directions (i.e. introverted then extraverted, or vice versa), which can be thought of as four \u201cpuzzle pieces\u201d in a particular type. External factors such as upbringing and stress can alter the way each function manifests.\n\nThe four (4) personality scales as proposed by Briggs and Myers:\nExtraversion (E) \u2013 Introversion (I) \u2192 Gaining energy by interacting with other people or alone\nSensing (S) \u2013 Intuition (I) \u2192 Collecting information through the senses or imagination\nThinking (T) \u2013 Feeling (F) \u2192 Making decisions through logic or emotions\nJudging (J) \u2013 Perceiving (P) \u2192 Organizing time by using schedules or without them; result- or process-oriented\nAs mentioned, the first three above are based on Jung\u2019s work with the fourth added by Myers-Briggs. According to Jung, the \u201ccognitive functions\u201d are the two scales of Sensing-Intuition and Thinking-Feeling. These are the ways in which humans process information and think about the world. Then each function can be expressed both in an extraverted manner or an introverted manner. As such, Jung didn\u2019t really view people as \u201cextraverts\u201d and \u201cintroverts\u201d but rather was more focused on the extraverted or introverted expression of each of the four cognitive functions.\n\nJungian four (4) cognitive functions stack:\nJung\u2019s cognitive function \u201cstack\u201d describes the priority or order in which a person uses their cognitive functions, with Primary being the most natural and commonly used and the Inferior being the least-commonly used.\n\nPrimary \u2192 Most natural (and comfortable) function; the internal \u201cmother tongue\u201d\nAuxiliary \u2192 Supporting function, usually connected with creation and job choice\nTertiary \u2192 Function where individual often takes action steps to improve upon\nInferior \u2192 Activates under extreme stress, generally avoided out of self-protection\nDescriptions of the Eight (8) Cognitive Functions\nNow let\u2019s discuss the eight different cognitive functions originally outlined by Jung. His theory proposed that for each of the 4 functions (Sensing, Intuition, Thinking and Feeling) each person would generally either extravert (display outwardly or externally) or introvert (consider inwardly or internally) that function.\n\nAs you read below, consider each function and its expression. Are you more Se or Si? Does Te or Ti come more naturally for you?\n\nExtraverted Sensing (Se)\nTaking action, using all five senses, going forward. Se takes in the present moment in its entirety, and makes rapid decisions on the fly. During times of crisis and emergencies, individuals with primary or auxiliary Se can make the best out of the situation.\n\nExample career areas that emphasize extraverted sensing (Se):\n\nArchaeology\nStunt driving\nFirefighting\nEmergency patrol\nMassage therapy\nIntroverted Sensing (Si)\nAssociations, metaphors, nostalgia. Si can travel back to any point in time through a single scent or sound. Important information (and sometimes interesting trivia) is stored in filing cabinets, where it can be retrieved at any later time.\n\nExample career areas that emphasize introverted sensing (Si):\n\nMuseum curation\nInterior design\nQuantitative sciences (e.g. statistics)\nLibrary sciences\nMedical coding\nExtraverted Intuition (Ne)\nBrainstorming, thinking outside the box, idea generation. Ne easily hops from idea to idea, while making abstract connections. Many artists\u2014especially poets\u2014use significant Ne in their work. To the outside, Ne seems quick, random, and extremely \u201cjumpy.\u201d\n\nExample career areas that emphasize extraverted intuition (Ne):\n\nFilmmaking, concept art\nCopywriting, art direction\nEntrepreneurship\nVideo producer (e.g. Youtube)\nWorkshop facilitating\nIntroverted Intuition (Ni)\nTime-space awareness, predicting the future, hunches. Ni is a far-reaching, visionary function\u2014and can picture the future, sometimes with scary-accurate results.\n\nExample career areas that emphasize introverted intuition (Ni):\n\nDetective services, private investigation\nEconomic predictions and analysis\nForensic and engineering psychology\nPublic speaking, mentoring\nConsulting, all types\nExtraverted Feeling (Fe)\nExpressive emotions, social norms, etiquette. Fe respects the consensus of the group, and puts harmony above personal desires. The function often acts as a mediator between groups, as it naturally puts others\u2019 needs above its own.\n\nExample career areas that emphasize extraverted feeling (Fe):\n\nActing, performance arts\nSinging\nDance therapy\nTelevision hosting\nPublic relations (PR)\nIntroverted Feeling (Fi)\nValues, notions of \u201cright\u201d and \u201cwrong,\u201d likes and dislikes. Fi is a deeply personal and intense function that digs to the core of the human condition. Convictions, morals, and strong beliefs all fall under the Fi umbrella.\n\nExample career areas that emphasize introverted feeling (Fi):\n\nPoetry, creative writing\nArt, various forms\nNarrative design\nMental health counseling\nPeace studies\nExtraverted Thinking (Te)\nFacts, pros and cons, methodological step-by-step strategies. Te respects rules and regulations\u2014and takes great pride in a job well done. Checklists and clear-cut meeting agendas get Te\u2019s gears going\u2014a top-down approach floats its boat.\n\nExample career areas that emphasize extraverted thinking (Te):\n\nAccounting\nPublic and private law\nComputer programming\nNatural sciences, laboratory support\nComputational mathematics\nIntroverted Thinking (Ti)\nIterations, holistic reasoning, agile strategies. Ti takes a bottom-up approach to problem-solving, and fixates on information management. When new data comes in that contradicts old beliefs, Ti will shift like a fluid crystalline framework.\n\nExample career areas that emphasize introverted thinking (Ti):\n\nData analysis\nSystems design engineering\nPhilosophy, sociology\nCybersecurity\nLanguage translation\nWhat are YOUR Functions and Cognitive Stack?\nAccording to Jung\u2019s theory, each person would essentially predominantly display each function (Sensing, Intuition, Thinking, Feeling) in either an extraverted or introverted manner. So of the 8 functions listed above, you\u2019d have 4 of them. If you favor Extraverted Intuition (Ne) it doesn\u2019t mean you can\u2019t use Introverted Intuition (Ni) but rather just that it is less common for you and thus Ne is your primary mode of Intuition. Since Intuition and Sensing are together on scale, if you extravert your Intuition then you tend to introvert your Sensing. So you\u2019d have Ne and Si.\n\nNext you must consider your Thinking-Feeling scale. If this same person tends to externalize (or extravert) their Thinking in the real world then we have a Te, and thus by definition the Feeling would be introverted (Fi). So we have Ne, Si, Te, Fi. But not necessarily in that order. That\u2019s when functional stacking steps in. Each individual uses both Thinking and Feeling functions, which makes the cut-and-dried type system overly simplistic. \n\nThe next task is to determine which function is primary, auxiliary, tertiary and inferior. This is when the concept of functional \u201cstacking\u201d comes in handy. Whichever is most natural is likely the primary, and so on. This is the order of the \u201cstack\u201d, which of your functions comes first or primary, and which comes last or inferior. Let\u2019s say the order in this case is was Ne, Fi, Te, Si. That translates to the ENFP personality type.\n\nCertainly the primary and auxiliary functions are those that come most natural to an individual, and are likely to characterize their outward personality. But while these tendencies may be seen quite obviously on the surface, they don\u2019t fully address one\u2019s personality. The tertiary and inferior functions are also crucial to understand.\n\nIf we only consider the four letters in ENFP (Extraverted, Intuitive, Feeling, Perceiving), for example, it would be next to impossible to see the hidden extraverted thinking (Te) and introverted sensing (Si) in their stacking. ENFPs are more than just their bubbly, charismatic and energetic stereotype. Their Te allows them to systematically work through their tasks and Si with their (often overlooked) excellent memory for details. This can make them excellent PR managers, communications specialists, and journalists.\n\nAnother example of hidden functions in play can be seen in the INTJ (Introverted, Intuitive, Thinking, Judging). INTJs are often dubbed by the entertainment and film industry as chess grandmasters who are strategic, sometimes cunning, and sometimes cold. However, they have introverted feeling (Fi) and extraverted sensing (Se) as their respective third and fourth function. INTJs have strong morals and hold their loved ones dear to their hearts. When under stress, they can become acutely aware of their surroundings and an asset to any team.\n\nHow Does this Relate to \u201cPersonality Typing\u201d?\nThis is the underlying theory behind the Myers-Briggs model and behind most models that also use the 16 personality types nomenclature. There is no shortage of different \u201cpersonality tests\u201d online that you can take that will attempt to determine what your functions are (Fe vs Fi, Te vs Ti, etc.) and in what order they are \u201cstacked\u201d. This then determines which of the 16 types you fall into. While the tests are certainly convenient, any such self-assessment is naturally rigid and prone to testing limitations and thus is never able to get a fully-accurate picture of a human being.", "Summarize this text:\"The sixth century witnessed a \u2018culture shock\u2019: through contact with foreign peoples,\nthrough colonisation and commerce, and because of a desire for innovation, a new\nworld view was gradually established. Almost automatically, this led to a critique of\nthe obvious nature of myth. From now on, the stories have to be interpreted. The truth\nmyths claimed to reveal, can be better uncovered by other means. A new generation\nof poets fiercely criticizes the immoral nature of the Homeric gods, and notes how\nthe image of god differs from people to people. The poet Xenophanes (c. 565-473)\nputs it as follows:\nThe Ethiopians say that their gods are black and snub-nosed, the Thracians,\nthat they have blue eyes and red hair. (Xenophanes, fr. 16)\nFor Xenophanes, this is not merely an ethnographic discovery, but an indication that\nthe gods are formed after the image and likeness of humans. By extension, the same\nwould go for animals:\n\nBut if cows, horses and lions had hands or could paint with their hands or\ncreate things as humans do, then horses would depict the gods like horses, and\noxen like oxen, and they would make the bodies just like the body they have.\n(Xenophanes, fr. 15)\nXenophanes himself argues for a purification of the image of god, which can no\nlonger be anthropomorphic. It is important to observe that the traditional\nrepresentation of the gods is criticized here, which, of course, puts the explanatory\nvalue of myth into perspective as well. Moreover, Xenophanes\u2019 criticism makes it\nclear that new explanatory methods are sought, which are no longer connected to\nlocal traditions and myth, but offer a universal understanding instead. From now on,\nif myths are still to be used, they will need to be interpreted according to new\n21\nstandards, where the mythical representations are read as referring to explanatory\nprinciples of a different sort.\n The way tradition is handed down also changes. For centuries, the Greek\ncultural tradition was oral. Myths, but also the texts of Homer, were transmitted\norally, and were also composed for that purpose. The Iliad and the Odyssey contain\nnumerous stereotypical phrasings and descriptions (e.g. the epithets of the gods) that\ncould be used as mnemonic devices by reciters. The Iliad and the Odyssey were\nprobably \u2018composed\u2019 by Homer in the sense that he organized existing material by\nmeans of a new, original plot (the wrath of Achilles). As a matter of fact, Homer\u2019s\ntext could slightly differ as it was recited by different bards. The fact that this was\nnot considered an insurmountable problem is illustrative of the culture in which this\npractice occurred. In the sixth century, this also changes. Late in that century, the\nAthenian tyrant Peisistratus gave the order to commit a standard version of Homer\nto writing, which was then deposited in the Athenian city-state library. That alone is\nevidence of a changed mentality. The desire for codification, and standardisation and\nhomogenisation, shows a new way of dealing with the text, which now acquires an\nobjective status. Peisistratus\u2019 decision, which, at first glance, appears to fall into the\ncategory of faits divers, is in fact the exponent of an extremely important revolution.\nApparently, the previous way of dealing with Homer\u2019s text no longer suffices, and\nthe act of reading the great poet is subject to new requirements.\n The question we have to ask ourselves is not \u2018how could people be so primitive\nin the preceding period?\u2019, but rather: \u2018what has changed, so that the previous practice\nno longer seemed to work?\u2019 From all the tendencies and examples mentioned above\na number of constants emerge: what is sought is universal validity, objective\nintelligibility and systematic order. This triple concern is indicated by the term logos:\na word with multiple meanings, ranging from \u2018word\u2019, to \u2018definition\u2019, \u2018discourse\u2019,\n\u2018reason\u2019, etc. to the \u2018account\u2019 given (logon didonai) of the phenomena that need to be\nexplained. All situations where an explanation is demanded, require logos. And the\nexplanation that is given will have to meet the requirements of universality,\n22\nobjectivity and systematicity. The explanatory value of myth is gone for good, and\nwhat is sought is a logos, a rational explanation.\n In the transition from \u2018mythos\u2019 to \u2018logos\u2019, and in fully considering the\nimplications for the individual and society, lies the so-called \u2018Greek miracle\u2019. As such,\nthe critique of myth and the embrace of logos is the beginning of philosophy.\n As drastic as the change may be, the culture shock exposed here did not come\nabout unexpectedly. Myth itself already showed a desire for explanation, for\nstrategies to bring the world under control. Hence, rational explanation \u2013 albeit with\nradically new answers \u2013 meets a similar need. For indeed, within the given horizon\nof existence of civilizations based on myth, the narrative is a strategy of the same\nvalue as science in a society governed by technology. That is the opinion of the\nstructuralist Claude L\u00e9vi-Strauss, La pens\u00e9e sauvage, 1962 (for structuralism: see below,\np. ??). According to him, myth is \u2018savage thought\u2019 (like that of a bricoleur), whereas\nlogos stands for \u2018tamed thought\u2019 (like that of an engineer). The barely conscious\npurpose of myth is the same as that of logos, namely control over a mysterious world.\n Moreover, Greek mythology \u2013 for many the textbook example of myth \u2013 has\na very peculiar status. In Greek myths, as we know them, logos itself has already\npenetrated mythos. Hesiod\u2019s Theogony (7th century) tried to bring unity into a\nmultiplicity of disconnected stories, and into an often inconsistent rendering of the\ngenealogy of the gods. Apparently, even then, uniformity and homogenisation were\nalready sought. In that sense, we speak of \u2018mytho-logy\u2019, because a first rationalisation\nalready occurred. Perhaps this is closely linked to the development of a Greek\ncultural identity, which the Hellenes used to distinguish themselves from the\n\u2018barbarians\u2019. Also in later times the Greeks appealed to their Pan-Hellenic culture,\neven if the various city-states faced each other on the battlefield. In Greek history\nthere is a clear tendency towards unity, which already showed in the Pan-Hellenic\nsanctuaries and games (for example the Olympic Games, which were held from 776\nBC onward). It is not impossible that Greek mytho-logy is the result of this Pan-\n23\nHellenic desire for uniformity, where the different versions of myths from various\nGreek tribes and states were homogenised.\n But something else comes into play. The divine itself also acquires a different\nstatus. Greek religion is, primarily, a worship of nature: numerous divine powers\nanimate nature. But, at the same time, these powers are personified and, as we have\nalready seen, described in fundamentally anthropomorphic form. In\nanthropomorphism the worship of nature is profoundly transformed, however much\nthe gods remain associated with their natural functions (for example, as weather god,\nor fertility deity). After all, it becomes impossible to connect the gods with one\nparticular natural phenomenon, let alone with one particular place of worship, if it is\nsimultaneously maintained that they resemble humans in all respects (except their\nimmortality). This also becomes clear in a spatial sense. The anthropomorphic gods\n\u2018move\u2019, as it were, to a separate location, the Olympus. In this context we can speak\nof a certain desacralisation of nature. The gods lose their place in the world, and the\nOlympus is conceived as a symbol of a \u2018supernatural\u2019 place, from which they interact\nwith nature, humans, and each other. As a result, nature gets, to some extent,\nseparated from the sacred: the world loses its enchantment and is ready for the\nobjectifying gaze of reason.\n This tendency made its definite breakthrough in the sixth century. From now\non, the explanation of the world is no longer sought for in the omnipresent power\nof the gods, but in the universality of reason.\n The strength and success of rational explanation are further reinforced by\nanother element through which Greek culture distinguished itself from neighbouring\npeoples. The Egyptians and Babylonians in particular, had reached a very high level\nof knowledge in geometry and astrology, but they had never differentiated between\nknowledge and practical application (staking out parcels after the Nile had flooded,\nbuilding pyramids, predicting propitious moments to make a decision, etc.). In Greek\nhands, knowledge is transformed into \u2018knowing for the sake of knowing\u2019. This new\nattitude is summarized under the term theoria. A the\u014dros is a traveller who, out of\n24\ninterest, sets off to see objects and places worth seeing (from thea: spectacle and hor\u0101n:\nto see). Herodotus, a well-known traveller himself, relates how the Athenian wise\nman Solon went to Lydia, \u2018for the sake of theoria\u2019 (Herod., Histories, I, 30). Theoria can\nalso be a public assignment. In that case, a the\u014dros is an ambassador who attends\nreligious or sports festivals in other cities on behalf of his own city. He is a spectator\nwho, from a distance and without taking part, observes the spectacle. The Greeks\ntransferred this terminology to knowledge: theoria becomes the purely contemplative\n(\u2018theoretical\u2019) activity of the scientist. This calls for an overall picture where every\ndetail is assigned its own place: the various partial aspects are integrated and\nsystematized, so that science can explain as many phenomena as possible with as few\nprinciples as possible. For the Greeks, the ideal of knowledge is the disinterested\ncontemplation of the whole, which they want to understand and explain in its entirety.\"", "cela entraine une erreur dans ce fichier \nusing Bindables;\nusing Entities.AccessRights;\nusing Logging;\nusing Shared;\nusing System;\nusing System.Collections.Generic;\nusing System.Collections.ObjectModel;\nusing System.ComponentModel;\nusing System.Linq;\nusing System.Threading;\nusing System.Threading.Tasks;\nusing System.Windows.Controls;\nusing System.Windows.Threading;\nusing UserControlsCommon.Filters;\nusing UserControlsCommon.Helpers;\nusing UserControlsCommon.IPresenters;\nusing UserControlsCommon.IViews;\nusing UserControlsCommon.Models;\nusing UserControlsCommon.Profiles;\n\nnamespace UserControlsCommon.Presenters\n{\n public abstract class EntityListPresenterBase : EntityPresenterBase, IEntityListPresenter\n {\n #region Attributes\n\n //CancellationTokenSource of the last requested search so we can cancel it at will\n protected CancellationTokenSource \\_searchCancellationTokenSource;\n protected TaskQueue \\_searchTaskQueue;\n //The task processing the search which we can await for\n protected Task \\_searchingTask;\n\n bool \\_disposed;\n\n #endregion\n\n #region Properties\n\n protected ApplicationManagerBase ListApplicationManager { get; set; }\n\n public bool DoSearchFlag { get; set; }\n\n protected bool FirstSearchFromInit { get; set; }\n\n /// \n /// Provide better performance to navigate from add page to list page\n /// And init filters and actions only one time\n /// Set this property when must force init filters and actions\n /// \n public bool MustInitFiltersAndActions { get; set; } = true;\n\n public List FilterState { get; set; }\n public List InstantFilterState { get; set; }\n\n #region Implementation IEntityListPresenter\n\n private LeasesManager \\_leasesManager;\n public LeasesManager LeasesManager\n {\n get\n {\n if (\\_leasesManager == null)\n {\n \\_leasesManager = new LeasesManager();\n }\n\n return \\_leasesManager;\n }\n }\n\n public EventHandler OnForceRefreshSorting { get; set; }\n\n public bool IsEntitySelectionMode { get; set; }\n\n public RightsGroupType RightsGroup { get; set; }\n\n #endregion\n\n #endregion\n\n #region Dependency Properties\n\n [DependencyProperty]\n public LoadingProcessInformation LoadingProcessInformation { get; set; }\n\n #region IEntityListPresenter\n\n [DependencyProperty]\n public ObservableCollection Objects { get; set; }\n\n #endregion\n\n #endregion\n\n #region Constructor\n\n protected EntityListPresenterBase(IEntityListView view, EntityManagementPresenterBase manager)\n {\n //Could use Task.CompletedTask on .net 4.6+\n \\_searchTaskQueue = new TaskQueue();\n \n Manager = manager;\n\n \\_view = view;\n LoadingProcessInformation = new LoadingProcessInformation();\n Objects = new ObservableCollection();\n DoSearchFlag = true;\n }\n\n #endregion\n\n #region Methods\n\n private async Task SearchExecuteAsync(CancellationToken cancellationToken)\n {\n IDynamicWindowPresenter dwc = null;\n\n if (cancellationToken.IsCancellationRequested)\n {\n return;\n }\n\n try\n {\n dwc = ((UserControl)\\_view).GetParentWindowPresenter();\n if (dwc != null)\n {\n dwc.Searching = true;\n }\n\n ObservableCollection asyncRes = null;\n try\n {\n asyncRes = await SearchAsync();\n }\n catch (Exception e)\n {\n UserControlHelper.HandleCatchedException(e);\n Logger.Get().Error(\"SearchAsync exception: \" + e.Message);\n }\n\n //There is no need to display the result if the search has been canceled or failed\n if (cancellationToken.IsCancellationRequested)\n {\n return;\n }\n\n if (asyncRes != null)\n {\n SearchDisplay(asyncRes);\n }\n }\n catch (Exception ex)\n {\n Logger.Get().Debug(ex?.Message, ex);\n }\n finally\n {\n if (dwc != null)\n {\n dwc.Searching = false;\n }\n }\n }\n\n /// \n /// la fonction asynchrone de search\n /// Retourne la nouvelle valeur de \"Objects\" sans la mettre \u00e0 jour.\n /// C'est SearchParent qui fera un BeginInvoke\n /// Cette fonction doit pouvoir \u00eatre annul\u00e9e => ne doit pas mettre \u00e0 jour de donn\u00e9es\n /// \n /// \n /// \n /// GAV : le commentaire au dessus n'est certainement plus d'actualit\u00e9, il faudrait voir\n /// dans quels cas la m\u00e9thode SearchAsync peut \u00eatre annul\u00e9e\n /// \n protected abstract Task> SearchAsync();\n\n /// \n /// la fonction SearchAsync ne doit pas mettre \u00e0 jour des donn\u00e9es de la classe, \n /// pour ce faire utilisez SearchDisplay\n /// \n /// \n protected virtual void SearchDisplay(ObservableCollection obj)\n {\n Dispatcher.BeginInvoke(DispatcherPriority.Background,\n (SendOrPostCallback)delegate\n {\n Objects = obj;\n }, obj);\n }\n\n protected bool IsSearching => !(\\_searchingTask?.IsCompleted ?? true);\n\n protected abstract void InitActions();\n\n protected abstract void InitFilters();\n\n protected abstract void InitInstantFilters();\n\n protected abstract void InitContextualAction();\n\n protected virtual void FilterPropertyChanged(object sender, PropertyChangedEventArgs e)\n {\n if (Manager?.Filters == null\n || Manager.Filters.Count == 0)\n {\n return;\n }\n\n FilterState = Manager.Filters.ToList();\n FilterData currentFiltre = sender as FilterData;\n\n switch (e?.PropertyName)\n {\n case nameof(FilterData.IsChecked):\n Manager.UpdateActiveFlyoutFiltersCount();\n break;\n case nameof(FilterData.Value):\n if (currentFiltre != null)\n {\n currentFiltre.IsChecked = currentFiltre.Value != null || currentFiltre.Values != null;\n }\n Manager.UpdateActiveFlyoutFiltersCount();\n\n QueueSearch();\n break;\n }\n }\n\n protected virtual void InstantFilterStatePropertyChanged(object sender, PropertyChangedEventArgs e)\n {\n InstantFilterState = Manager.InstantFilters.ToList();\n }\n\n #endregion\n\n #region Implementation IEntityListPresenter\n #region Implementation IPresenter\n\n public virtual void Init()\n {\n FirstSearchFromInit = true;\n\n if (MustInitFiltersAndActions)\n {\n InitActions();\n }\n\n Dispatcher.BeginInvoke(DispatcherPriority.Normal,\n (ThreadStart)(() =>\n {\n if (Manager != null)\n {\n Manager.SetActionsBindings();\n }\n }));\n\n if (MustInitFiltersAndActions)\n {\n InitFilters();\n if (Manager?.Filters != null)\n {\n SetFocusForFilters();\n FilterState = Manager.Filters.ToList();\n }\n InitInstantFilters();\n }\n\n InitContextualAction();\n\n if (DoSearchFlag)\n {\n QueueSearch();\n }\n\n FirstSearchFromInit = false;\n MustInitFiltersAndActions = false;\n }\n\n /// \n /// Sets the focus on the first textbox filter\n /// \n /// \n /// Can be overriden to change this behavior\n /// \n protected virtual void SetFocusForFilters()\n {\n var firstTextBox = Manager.Filters.FirstOrDefault(f => f.Mode == FilterMode.Text);\n if (firstTextBox != null)\n {\n firstTextBox.MustFocus = true;\n }\n }\n\n #region Implementation IDisposable\n\n /// \n /// Ex\u00e9cute les t\u00e2ches d\u00e9finies par l'application associ\u00e9es \u00e0 la lib\u00e9ration ou \u00e0 la red\u00e9finition des ressources non manag\u00e9es.\n /// \n /// 2\n public void Dispose()\n {\n Dispose(true);\n GC.SuppressFinalize(this);\n }\n\n protected virtual void Dispose(bool disposing)\n {\n if (\\_disposed)\n {\n return;\n }\n\n if (disposing)\n {\n if (Objects != null)\n {\n foreach (var o in Objects.OfType())\n {\n o.Dispose();\n }\n\n Objects.Clear();\n Objects = null;\n }\n\n if (FilterState != null)\n {\n FilterState.Clear();\n FilterState = null;\n }\n\n if (InstantFilterState != null)\n {\n InstantFilterState.Clear();\n InstantFilterState = null;\n }\n\n Manager = null;\n \\_view = null;\n }\n\n \\_disposed = true;\n }\n\n #endregion\n\n #endregion\n\n public void SwitchToSelectionMode(List defaultFilters = null)\n {\n IsEntitySelectionMode = true;\n Manager.FiltersDefaultValue = defaultFilters;\n\n // R\u00e9initialisation des filtres, si ceux-ci avaient \u00e9t\u00e9 sauvegard\u00e9s ant\u00e9rieurement\n if (FilterState != null)\n {\n FilterState = null;\n\n // R\u00e9initialisation du bool\u00e9en pour refaire le lock de tous les filtres au prochain appel \u00e0 la m\u00e9thode SetFilters.\n // La m\u00e9thode SetFilters est habituellement appel\u00e9e dans l'impl\u00e9mentation de la m\u00e9thode InitFilters (elle-m\u00eame appel\u00e9e ci-dessous).\n // Pour plus de contexte, voir les m\u00e9thodes suivantes : \n // \\* ToolBarsManagementPresenter.SetFilters\n // \\* FilterData.LockState\n // \\* FilterData.ReinitFilter\n // \\* N'importe quelle impl\u00e9mentation de la m\u00e9thode InitFilters, par exemple dans ServiceProvidedListPresenter.\n Manager.MustLockFilters = true;\n }\n\n InitFilters();\n }\n\n public void QueueSearch()\n {\n \\_ = QueueSearchAsync();\n }\n\n public async Task QueueSearchAsync()\n {\n \\_searchCancellationTokenSource?.Cancel();\n \\_searchCancellationTokenSource = new CancellationTokenSource();\n var token = \\_searchCancellationTokenSource.Token;\n\n \\_searchingTask = \\_searchTaskQueue.EnqueueAsync(SearchExecuteAsync, token, Constants.Time.MILLISECONDS\\_PER\\_HALF\\_SECOND);\n\n await \\_searchingTask;\n }\n\n public void ResetFilters()\n {\n // Reset the filters\n if (Manager.Filters != null)\n {\n foreach (var filter in Manager.Filters)\n {\n filter.ReinitFilter();\n }\n }\n else\n {\n FilterState = null;\n InitFilters();\n }\n\n // Force re-init the instant filters\n InstantFilterState = null;\n InitInstantFilters();\n\n QueueSearch();\n }\n\n // Inutile de le d\u00e9clarer en virtual ?\n public virtual void InitAfterGoBack()\n {\n }\n\n public bool CheckAccess(RightsActionType actionType, RightsFieldType? fieldType)\n {\n return RightsProfileHelper.SecureCommands(actionType, RightsGroup, fieldType);\n }\n\n public bool CheckAccess(RightsElementType elementType, RightsFieldType fieldType)\n {\n return RightsProfileHelper.IsCurrentUserAllowed(elementType, RightsGroup, fieldType);\n }\n\n #endregion\n }\n}\nvoila l'erreur \nSeverity Code Description Project File Line Suppression State\nError CS0266 Cannot implicitly convert type 'UserControlsCommon.IViews.IEntityListView' to 'UserControlsCommon.IViews.IEntityView'. An explicit conversion exists (are you missing a cast?) UserControlsCommon E:\\Source\\Repos\\Saphir\\Saphir\\UserControlsCommon\\Presenters\\EntityListPresenterBase.cs 104 Active", "I am trying a query in Google Sheets that looks up a postal code but encountering issues, it doesn't seem to look up postal codes that contain letters or if there is a space in the postal code like for a Swedish or Luxembourg postal code.\n\nHere is the current formula that I have:\n=QUERY('Masterfile 12/1/2022'!A:Q,\"Select \\* Where A contains \"\"\"&$C$2&\"\"\"\")\n\nHere is some sample data:\nzip\\_code country\\_code place\\_name state geometry dc1 dc1\\_ping dc1\\_distance dc2 dc2\\_ping dc2\\_distance dc3 dc3\\_ping dc3\\_distance dc4 dc4\\_ping dc4\\_distance\nT4B CA Airdrie West Alberta (-114.0398, 51.3082) USPOR01 39.50 ms 914.06 km CAMTL01 87.50 ms 3003.05 km TX1 107.00 ms 2469.22 km USWDC01 111.00 ms 3138.19 km\nT5K CA Edmonton (South Downtown / South Downtown Fringe) Alberta (-113.5103, 53.5366) USPOR01 39.50 ms 1115.31 km CAMTL01 66.00 ms 2963.98 km TX1 83.50 ms 2639.16 km USWDC01 87.25 ms 3164.88 km\nT8C CA Sherwood Park Inner Southwest Alberta (-113.1903, 53.4391) USPOR01 41.75 ms 1121.30 km USWDC01 36.75 ms 3141.48 km CAMTL01 41.75 ms 2942.49 km TX1 47.00 ms 2617.83 km\nV8V CA Victoria South British Columbia (-123.365, 48.4167) USPOR01 24.50 ms 321.32 km TX1 86.00 ms 2796.58 km USWDC01 93.00 ms 3772.56 km CAMTL01 95.00 ms 3711.16 km\nV9B CA Highlands British Columbia (-123.5271, 48.4793) USPOR01 22.00 ms 329.79 km TX1 90.50 ms 2810.41 km CAMTL01 84.50 ms 3721.14 km USWDC01 91.50 ms 3784.41 km\nB3K CA Halifax Upper Harbour Nova Scotia (-63.6017, 44.662) CAMTL01 45.00 ms 812.12 km USWDC01 55.00 ms 1337.98 km TX1 78.00 ms 3122.89 km USPOR01 106.50 ms 4545.40 km\nM4Y CA Downtown Toronto (Church and Wellesley) Ontario (-79.383, 43.6656) CAMTL01 33.25 ms 472.10 km USWDC01 56.00 ms 565.18 km TX1 68.25 ms 1917.09 km USPOR01 95.25 ms 3408.69 km\nM6J CA West Toronto (Rua A\u00c3\u00beores / Trinity) Ontario (-79.4177, 43.648) CAMTL01 31.00 ms 475.45 km USWDC01 51.00 ms 564.03 km TX1 62.50 ms 1913.68 km USPOR01 90.00 ms 3406.69 km\nM8V CA Etobicoke (New Toronto / Mimico South / Humber Bay Shores) Ontario (-79.5013, 43.6075) CAMTL01 13.00 ms 483.45 km USWDC01 27.00 ms 561.56 km TX1 51.00 ms 1905.59 km USPOR01 74.00 ms 3401.79 km\nH3G CA Downtown Montreal Southeast Quebec (-73.5793, 45.4987) CAMTL01 25.00 ms 32.34 km USWDC01 38.00 ms 822.87 km TX1 65.00 ms 2417.26 km USPOR01 89.50 ms 3779.82 km\nH1W CA Hochelaga Quebec (-73.5468, 45.5442) CAMTL01 24.75 ms 37.61 km USWDC01 38.75 ms 828.53 km TX1 62.50 ms 2421.82 km USPOR01 89.00 ms 3780.65 km\nH2J CA Plateau Mont-Royal North Central Quebec (-73.5831, 45.5302) CAMTL01 22.50 ms 34.50 km USWDC01 35.50 ms 825.90 km TX1 58.50 ms 2418.59 km USPOR01 86.00 ms 3778.45 km\nH2S CA Petite-Patrie Southwest Quebec (-73.6061, 45.5354) CAMTL01 23.00 ms 33.69 km USWDC01 37.00 ms 825.65 km TX1 62.00 ms 2417.26 km USPOR01 89.00 ms 3776.56 km\nH2V CA Outremont Quebec (-73.6072, 45.5168) CAMTL01 22.00 ms 32.12 km USWDC01 36.00 ms 823.75 km TX1 61.00 ms 2416.24 km USPOR01 88.00 ms 3777.13 km\nH3C CA Griffintown (Includes \u00c3\u017dle Notre-Dame & \u00c3\u017dle Sainte-H\u00c3\u00a9l\u00c3\u00a8ne) Quebec (-73.5472, 45.498) CAMTL01 28.00 ms 34.24 km USWDC01 40.00 ms 823.88 km TX1 64.00 ms 2419.46 km USPOR01 92.00 ms 3782.22 km\nH4C CA Saint-Henri Quebec (-73.5882, 45.4737) CAMTL01 16.00 ms 30.06 km USWDC01 32.00 ms 820.06 km TX1 55.00 ms 2415.39 km USPOR01 83.00 ms 3780.03 km\nJ4H CA Longueuil West Quebec (-73.5056, 45.5372) CAMTL01 26.00 ms 39.49 km USWDC01 45.00 ms 829.22 km TX1 66.00 ms 2424.32 km USPOR01 93.00 ms 3783.94 km\nJ4J CA Longueuil Central Quebec (-73.4721, 45.5362) CAMTL01 22.50 ms 41.47 km USWDC01 35.50 ms 830.26 km TX1 60.00 ms 2426.60 km USPOR01 85.00 ms 3786.45 km\n35206 US Birmingham Alabama (-86.7199, 33.5678) USWDC01 40.00 ms 994.78 km TX1 58.50 ms 935.54 km CAMTL01 61.00 ms 1703.79 km USPOR01 107.50 ms 3339.67 km\n36830 US Auburn Alabama (-85.4682, 32.5475) USWDC01 42.00 ms 984.77 km TX1 67.00 ms 1057.11 km CAMTL01 62.00 ms 1732.79 km USPOR01 104.00 ms 3500.23 km\n36117 US Montgomery Alabama (-86.1833, 32.3736) TX1 77.50 ms 992.60 km USWDC01 57.00 ms 1045.39 km CAMTL01 75.25 ms 1784.93 km USPOR01 109.00 ms 3456.95 km\n35603 US Decatur Alabama (-87.0004, 34.5484) TX1 79.00 ms 918.24 km USWDC01 56.00 ms 953.36 km CAMTL01 76.00 ms 1633.13 km USPOR01 118.00 ms 3257.75 km\n72034 US Conway Arkansas (-92.4683, 35.0823) TX1 62.25 ms 457.85 km CAMTL01 64.50 ms 1937.06 km USWDC01 66.50 ms 1375.08 km USPOR01 89.00 ms 2807.93 km\n72023 US Cabot Arkansas (-92.0318, 34.9457) TX1 44.75 ms 486.46 km USWDC01 57.25 ms 1343.95 km CAMTL01 67.00 ms 1917.67 km USPOR01 98.50 ms 2849.41 km\nAlso, do you think there's better ways to do this than a query as well? Maybe using FILTER or VLOOKUP? I would appreciate your suggestions.", "Anyway, starting with Thales is as good as any other starting point. If only we realise that geometrical\nproofs were part of philosophy and Greek philosophy was motivated both esoterically and\npractically. The precision in dealing with coins, measuring the height or distance of objects, fitted\nthese ideas just as perfect as did acquiring knowledge of the divine circle. It fitted the notion\nof getting to grips with the world order. Thinking and reasoning with triangles and circles was\npart of that. Thales might have been inclined to a political or physical understanding, so that projecting\nour idea of geometry is not entirely unfitting. To many of the ancients, however, the ideas\nof geometria were first and foremost part of, or even originated from, myths and beliefs. The ideas\nwere associated with astrology and numerology.\nTo the Pythagorean order, named after the philosopher Pythagoras of Samos (ca. 571 - ca. 500)\ngeometria and arithmetica were the essence behind a divine order they tried to describe. Because\nthe Pythagorean sect was secretive in nature, about both knowledge and rituals, also about\nthis group of philosophers little information survives (that is: they were rather successful in their\nsecrecy). It was customary to attribute results obtained by people within the order to the master\nhimself, so we don\u2019t even know for sure if a proof of the Pythagorean theorem was indeed\nthought up by Pythagoras himself.\nTo the Pythagorean sect, numbers offered a way through which they could feel themselves connected\nto the world in a practical and mystical sense. Numbers not only offered a way of counting\npossessions and armies, but they also represented the divine world order. The faith of people\nwas hidden in numbers. As many of the ancient cultures, the Pythagoreans considered some\nnumbers to be male (2 and probably even numbers in general), others to be female (1 and probably\nodd numbers in general). Numbers and properties of numbers were often thought about\nin so-called \u03c8\u1fc6\u03c6\u03bf\u03c2 (psephos), or counting objects, such as pebbles or shards. Counting and\narithmetic with these objects was simply done by joining pebbles (when adding) or doubling a\nnumber of pebbles (when multiplying). In Athens, the same kind of objects were used for voting\n\u2014 and in that sense numbers also literally decided upon matters of politics and on the faith of\npeople, being expelled from the city or not. The connection between numbers and reality could\nMathematical worlds 23\nbe quite direct. Special powers were attributed to, for example perfect numbers (numbers, equal\nto the sum of their divisors, such as 6 = 1+2+3; 28=1+2+4+7+14), triangular numbers (1, 3, 6, 10,\n15, \u2026 which could be laid down in an equilateral triangle: 1, 1+2, 1+2+3, 1+2+3+4, \u2026) and fair\nnumbers (1, 4, 9, 16, 25, \u2026 which could be laid down in a square).\nThe Pythagoreans were enthusiastic about the fact that the length of the snare on a monochord,\nwas representative of the musical tone it produced when played. The theory, called musica started\nfrom the observation that two strings, the second one half the size of the first, produced a\nsimilar note - we would say: the second transposed one octave with respect to the first. That resulted\nin an intimate connection between musica and the theory of ratios, which was part of the\narithmetica or geometria, depending on the stance of the philosopher towards these subjects.\nAdding or multiplying ratios were connected to the monochord in ways that have become inconceivable\nto us. Note that it is a present-day prejudice to regard this connection as a physical\ntheory, whereas it could also be viewed as a divinely inspired or mythical connection between\nnumbers and the world order, expressed in the theory of harmonies.\nThese kind of mythical connections between number and reality made the Pythagoreans believe\nfirmly that everything could be expressed by number: reality was numerological in nature. And if\nnumbers were of divine origin, trying to make sense of the deeper ideas behind the world order,\nor expressed divine relations, no wonder that special numbers became of special interest. It is\nfrom these kind of ideas that prime numbers, divisors, largest common divisors or least common\nmultiples were interesting.\nIt might have been the realisation that there existed numbers that had no common measure, for\nexample the side and diagonal of a regular pentagon, or, a little more difficult to realise but easier\nto imagine, the side and diagonal of a square, anyway: some philosophers after 400 BC didn\u2019t\ntrust arithmetica as a basis for true philosophy. To them, deriving knowledge from geometria became\nmore common. Indeed, the art of geometria was associated with drawing figures in the\nsand, but these figures only served the imagination, and were not considered an intrinsic part of\nMathematical worlds 24\nIllustration I.1: psephos arithmetic in action: using pebbles the\nPythagoreans could understand some properties of numbers - and\nthereby the cosmos. From the picture it is clear that the sum of the\nfirst consecutive female (odd) numbers (so: 1+3+5 etc.) is a just\nnumber (square). The picture illustrates how close proof and revelation\ncould be for the Pythagoreans: the picture literally reveals an\neternal truth, for those who are willing and able to \u201cread\u201d it.\nreasoning. The point was exactly not to assume anything about what was made \u201cclear\u201d by the\nsenses, since, as Plato (428/427 or 424/423 \u2013 348/347) implicitly noted in his \u03a4\u03af\u03bc\u03b1\u03b9\u03bf\u03c2 (Timaeus, ca\n360 BC), real knowledge had to be derived not from the senses, but from the \u03bb\u03cc\u03b3\u03bf\u03c2 (logos, a\nword with many meanings: story, \u201cI say\u201d, reason). In logos, order was to be found. In the cave dialogue,\nPlato explains how the senses do reveal truth, but not what is behind the truth, since the\npeople in the cave only see the projections of objects outside the cave, and not what was there\nin the \u201creal\u201d world, the world of perfect and eternal ideas, ideai, which created those projections.\nHis philosophy was about these \u201creal\u201d objects. Knowledge of these eternal things were what the\nphilosopher strove for. And geometria could help get closer to these ideai, as it, literally, got you\ncloser to understanding astronomy \u2014 to knowledge of the (eternal!) stars. Of course, also to Plato\narithmetica and geometria were important in trade and warfare, but most notably geometria\nalso allowed the philosopher to gain knowledge of the eternal ideai.\nAccording to other ancient philosophers, the essence of the two subjects was much more mundane.\nFor example, Aristotle (384 - 322) thought arithmetica and geometria were abstractions of\nthe ideas given by our senses. The use of these subjects was in trade and warfare, but beyond\nthat, the use of arithmetica and geometria was rather limited, and didn\u2019t reach beyond the pedagogical\nsimplest example of philosophy. The idea of proof and structure did appeal to him, although\nhe wasn\u2019t fond of measurement, which was visible in his \u03a6\u03c5\u03c3\u03b9\u03ba\u1f74 \u1f00\u03ba\u03c1\u03cc\u03b1\u03c3\u03b9\u03c2 (Physics, ca.\n350 BC). According to Aristotle, the world was built from four building blocks: earth, water, fire\nand air. All the objects we perceived, derived their substance from various combinations of these\nelements. A fifth element, by the romans called the quinta essentia, was necessary to give matter\na soul or life \u2014 matter itself was always inanimate. Aristotle\u2019s universe consisted of concentric\nspheres, which revolved around the central earth in an intricate way, thus in a qualitative sense\nexplaining the perceived motion of sun, moon, planet and stars.\nGeometria as part of a philosophical practice\nThe Greek philosophers that were trying to understand the eternal ideai, were inclined to study\ngeometria, since it offered more solidity than arithmetica, and perhaps also because it was closer\nto (read: necessary to understand certain constructions in) astronomia, including astrology. The\nassumption they unconsciously made was that the world order was based on (divine!) straight\nlines and circles, flat surfaces and orbs. These objects were therefore favoured in all constructions\nand were the start of all reasoning in geometria.\nOne of the geometrical problems that was posed in antiquity was the doubling of the cube. Its\ntwo dimensional analogon was relatively easy: the doubling of (the area of ) a square could be\nperformed by constructing a square on the diagonal of the original square. The doubling of (the\ncontent of ) a cube, however, was not that simple. The problem was known as the Delian riddle,\nbecause of a myth that belonged to it. This myth immediately illustrates beautifully how philo-\nMathematical worlds 25\nsophy, mysticism and the search for world order were related. About 430 BC the citizens of\nAthens consulted the Delian oracle, because the plague was infesting their city state. The oracle\ntold them to double the cubic altar of Apollo and the disease would disappear. The Athenians\ndoubled all sides of the altar, only to find out that this didn\u2019t solve their problem, since now the\naltar had become eight times the (content of the) original altar stone. The problem proved to be\ntrickier than it looked at first sight.", "//File: validators.py\n# This code is copied from: https://gist.github.com/mobula/da99e4db843b9ceb3a3f\n# -\\*- coding: utf-8 -\\*-\n# https://gist.github.com/mobula/da99e4db843b9ceb3a3f\n\n# @brief\n# Performs file upload validation for django.\n# with Django 1.7 migrations support (deconstructible)\n\n# Provides:\n# - FileValidator\n# - ImageValidator (adds Image specific validation using PIL)\n\n# @author dokterbob\n# @author jrosebr1\n# @author mobula\n\nimport mimetypes\nfrom os.path import splitext\n\nfrom django.core.exceptions import ValidationError\nfrom django.utils.translation import gettext\\_lazy as \\_\nfrom django.template.defaultfilters import filesizeformat\n\nfrom django.utils.deconstruct import deconstructible\n@deconstructible\nclass FileValidator(object):\n \"\"\"\n Validator for files, checking the size, extension and mimetype.\n Initialization parameters:\n allowed\\_extensions: iterable with allowed file extensions\n ie. ('txt', 'doc')\n allowed\\_mimetypes: iterable with allowed mimetypes\n ie. ('image/png', )\n min\\_size: minimum number of bytes allowed\n ie. 100\n max\\_size: maximum number of bytes allowed\n ie. 24\\*1024\\*1024 for 24 MB\n Usage example::\n MyModel(models.Model):\n myfile = FileField(validators=FileValidator(max\\_size=24\\*1024\\*1024), ...)\n \"\"\"\n\n messages = {\n 'extension\\_not\\_allowed': \\_(\"Extension '%(extension)s' not allowed. You are only allowed to upload pdf files.\"),\n 'mimetype\\_not\\_allowed': \\_(\"MIME type '%(mimetype)s' is not valid. Allowed types are: %(allowed\\_mimetypes)s.\"),\n 'min\\_size': \\_('The current file is %(size)s, which is too small. The minumum file size is %(allowed\\_size)s.'),\n 'max\\_size': \\_('The current file is %(size)s, which is too large. The maximum file size is %(allowed\\_size)s.')\n }\n\n mime\\_message = \\_(\n \"MIME type '%(mimetype)s' is not valid. Allowed types are: %(allowed\\_mimetypes)s.\")\n min\\_size\\_message = \\_(\n 'The current file %(size)s, which is too small. The minumum file size is %(allowed\\_size)s.')\n max\\_size\\_message = \\_(\n 'The current file %(size)s, which is too large. The maximum file size is %(allowed\\_size)s.')\n\n def \\_\\_init\\_\\_(self, \\*args, \\*\\*kwargs):\n self.allowed\\_extensions = kwargs.pop('allowed\\_extensions', None)\n self.allowed\\_mimetypes = kwargs.pop('allowed\\_mimetypes', None)\n self.min\\_size = kwargs.pop('min\\_size', 0)\n self.max\\_size = kwargs.pop('max\\_size', None)\n\n def \\_\\_eq\\_\\_(self, other):\n return (isinstance(other, FileValidator)\n and (self.allowed\\_extensions == other.allowed\\_extensions)\n and (self.allowed\\_mimetypes == other.allowed\\_mimetypes)\n and (self.min\\_size == other.min\\_size)\n and (self.max\\_size == other.max\\_size)\n )\n\n def \\_\\_call\\_\\_(self, value):\n \"\"\"\n Check the extension, content type and file size.\n \"\"\"\n\n # Check the extension\n ext = splitext(value.name)[1][1:].lower()\n if self.allowed\\_extensions and not ext in self.allowed\\_extensions:\n code = 'extension\\_not\\_allowed'\n message = self.messages[code]\n params = {\n 'extension': ext,\n 'allowed\\_extensions': ', '.join(self.allowed\\_extensions)\n }\n raise ValidationError(message=message, code=code, params=params)\n\n # Check the content type\n mimetype = mimetypes.guess\\_type(value.name)[0]\n if self.allowed\\_mimetypes and not mimetype in self.allowed\\_mimetypes:\n code = 'mimetype\\_not\\_allowed'\n message = self.messages[code]\n params = {\n 'mimetype': mimetype,\n 'allowed\\_mimetypes': ', '.join(self.allowed\\_mimetypes)\n }\n raise ValidationError(message=message, code=code, params=params)\n\n # Check the file size\n filesize = len(value)\n if self.max\\_size and filesize > self.max\\_size:\n code = 'max\\_size'\n message = self.messages[code]\n params = {\n 'size': filesizeformat(filesize),\n 'allowed\\_size': filesizeformat(self.max\\_size)\n }\n raise ValidationError(message=message, code=code, params=params)\n\n elif filesize < self.min\\_size:\n code = 'min\\_size'\n message = self.messages[code]\n params = {\n 'size': filesizeformat(filesize),\n 'allowed\\_size': filesizeformat(self.min\\_size)\n }\n raise ValidationError(message=message, code=code, params=params)\n@deconstructible\nclass ImageValidator(object):\n \"\"\"\n Validator for images, using PIL\n Initialization parameters:\n allowed\\_extensions: iterable with allowed file extensions\n ie. ('jpg', 'jpeg', 'gif, 'png', 'tiff', 'bmp')\n allowed\\_formats: iterable with allowed file types\n ie. ('jpeg', 'gif', 'png')\n allowed\\_mimetypes: iterable with allowed mimetypes\n ie. ('image/png')\n min\\_size: minimum number of bytes allowed\n ie. 100\n max\\_size: maximum number of bytes allowed\n ie. 24\\*1024\\*1024 for 24 MB\n Usage example::\n MyModel(models.Model):\n myfile = ImageField(validators=ImageValidator(max\\_size=24\\*1024\\*1024), ...)\n \"\"\"\n messages = {\n 'not\\_an\\_image': \\_(\"File is not a recognized image '%(file)s'.\"),\n 'broken\\_image': \\_(\"The uploaded image seems to be broken '%(file)s'.\"),\n 'format\\_mismatch': \\_(\"Extension name '%(extension)s' doesn't match actual file format '%(format)s'.\"),\n 'format\\_not\\_allowed': \\_(\"Extension '%(format)s' not allowed. Allowed extensions are: '%(allowed\\_formats)s.'\"),\n 'extension\\_not\\_allowed': \\_(\"Extension '%(extension)s' not allowed. Allowed extensions are: '%(allowed\\_extensions)s.'\"),\n 'mimetype\\_not\\_allowed': \\_(\"MIME type '%(mimetype)s' is not valid. Allowed types are: %(allowed\\_mimetypes)s.\"),\n 'min\\_size': \\_('The current file %(size)s, which is too small. The minumum file size is %(allowed\\_size)s.'),\n 'max\\_size': \\_('The current file %(size)s, which is too large. The maximum file size is %(allowed\\_size)s.')\n }\n\n def \\_\\_init\\_\\_(self, \\*args, \\*\\*kwargs):\n self.allowed\\_formats = kwargs.pop('allowed\\_formats', None)\n self.allowed\\_extensions = kwargs.pop('allowed\\_extensions', None)\n self.allowed\\_mimetypes = kwargs.pop('allowed\\_mimetypes', None)\n self.min\\_size = kwargs.pop('min\\_size', 0)\n self.max\\_size = kwargs.pop('max\\_size', None)\n\n def \\_\\_eq\\_\\_(self, other):\n return (isinstance(other, ImageValidator)\n and (self.allowed\\_formats == other.allowed\\_formats)\n and (self.allowed\\_extensions == other.allowed\\_extensions)\n and (self.allowed\\_mimetypes == other.allowed\\_mimetypes)\n and (self.min\\_size == other.min\\_size)\n and (self.max\\_size == other.max\\_size)\n )\n\n def \\_\\_call\\_\\_(self, value):\n \"\"\"\n Check the extension, content type and file size.\n \"\"\"\n from PIL import Image\n # from \\_\\_future\\_\\_ import print\\_function\n\n try:\n im = Image.open(value)\n except:\n code = 'not\\_an\\_image'\n message = self.messages[code]\n params = {\n 'file': value,\n }\n raise ValidationError(message=message, code=code, params=params)\n\n try:\n im.verify()\n except:\n code = 'broken\\_image'\n message = self.messages[code]\n params = {\n 'file': value,\n }\n raise ValidationError(message=message, code=code, params=params)\n\n # Check the format\n format = im.format.lower()\n if self.allowed\\_formats and not format in self.allowed\\_formats:\n code = 'format\\_not\\_allowd'\n message = self.messages[code]\n params = {\n 'format': ext,\n 'allowed\\_formats': ', '.join(self.allowed\\_formats)\n }\n raise ValidationError(message=message, code=code, params=params)\n\n # Check the extension\n ext = splitext(value.name)[1][1:].lower()\n if self.allowed\\_extensions and not ext in self.allowed\\_extensions:\n code = 'extension\\_not\\_allowed'\n message = self.messages[code]\n params = {\n 'extension': ext,\n 'allowed\\_extensions': ', '.join(self.allowed\\_extensions)\n }\n raise ValidationError(message=message, code=code, params=params)\n\n # Check extension and file format consistency\n if ext == 'jpg':\n ext = 'jpeg'\n if format != ext:\n code = 'format\\_mismatch'\n message = self.messages[code]\n params = {\n 'extension': ext,\n 'format': format\n }\n raise ValidationError(message=message, code=code, params=params)\n\n # Check the content type\n mimetype = mimetypes.guess\\_type(value.name)[0]\n if self.allowed\\_mimetypes and not mimetype in self.allowed\\_mimetypes:\n code = 'mimetype\\_not\\_allowed'\n message = self.messages[code]\n params = {\n 'mimetype': mimetype,\n 'allowed\\_mimetypes': ', '.join(self.allowed\\_mimetypes)\n }\n raise ValidationError(message=message, code=code, params=params)\n\n # Check the file size\n filesize = len(value)\n if self.max\\_size and filesize > self.max\\_size:\n code = 'max\\_size'\n message = self.messages[code]\n params = {\n 'size': filesizeformat(filesize),\n 'allowed\\_size': filesizeformat(self.max\\_size)\n }\n raise ValidationError(message=message, code=code, params=params)\n\n elif filesize < self.min\\_size:\n code = 'min\\_size'\n message = self.messages[code]\n params = {\n 'size': filesizeformat(filesize),\n 'allowed\\_size': filesizeformat(self.min\\_size)\n }\n raise ValidationError(message=message, code=code, params=params)", "Continue the course on the next slide building the slides and the transcript with the following content: Blood tests\nS100B, MIA, LDH blood tests for initial staging\nTwo small studies were identified assessing the diagnostic accuracy of either p-proteasome, MIA, S-100B, or LDH for melanoma metastases.[22][23] In the first study of 53 clinical stage I-II melanoma patients, 68 stage III-IV patients and 40 healthy volunteers, plasma samples were obtained before definitive surgical excision or treatment and followed for a median of 17 months. Reference standard positive patients were a mixture of patients with clinical stage III/IV disease at the outset and patients with clinical stage I/II who then developed metastases during follow-up (detected through clinical examinations and imaging tests). Likewise reference standard negative patients were a mixture of healthy volunteers and patients with clinical stage I/II disease who did not develop metastases during follow-up. Within the limitations of the substantial spectrum bias arising from the selection of the study population which was not limited to asymptomatic stage I/II patients, the area under the receiver operating curves (ROC) for p-proteasome and S100B were the highest (0.81,and 0.82 respectively), whereas LDH and MIA showed lower values (0.79, and 0.72 respectively).[22] In the second study, of 87 stage I/II patients, 71 stage III/IV patients and 50 healthy volunteers, serum concentrations were measured before surgery.[23] The reference standard was again a composite of clinical exams and imaging tests to define whether or not the patient had stage III/IV disease at either the outset or during a median of 32.8 months follow-up. The authors reported that a cut-off value for MIA of 9.4 ng/ml, had 77% sensitivity and 94% specificity for the detection of stage IV disease. Among the 87 patients with stage I/II disease after imaging, 66% of those with MIA serum values greater than 9.4 ng/mL developed regional or distant metastases during follow-up , while 5% of those with values below this threshold developed metastases.[23]\n\nStandard blood tests for initial staging and follow-up (e.g. electrolytes, urea, creatinine, liver function tests [LFTs], full blood count [FBC])\nEvidence from previous guidelines states the routine use of standard blood tests rarely identifies occult stage IV disease in patients presenting with stage I or II melanoma and is not recommended. See [ANZ Melanoma guidelines]. These tests are not new and were therefore outside the scope of the current systematic review and guideline.\n\nS100B, MIA, LDH blood tests during follow-up\nAs a tumour marker, S100B displays a sensitivity of 86\u201391 %, specificity[24][25] and may portend recurrence, however there are no data demonstrating superior survival outcomes for patients undergoing routine S100B testing in follow up. The use of serum LDH or melanoma-inhibitory activity (MIA) protein in follow up for the detection of asymptomatic melanoma recurrence has been reviewed by Fields and Coit.[26] Abnormal blood tests were rarely the first sign of metastases. Low sensitivity, specificity, and accuracy for general laboratory profiles make them ineffective in the detection of subclinical recurrence and their roles are yet to be defined.\n\nInvestigations for stage I-II patients with no sentinel node biopsy (ie. declined or patient unfit)\nUltrasonography for initial staging\nFor situations where SLNB has been declined or is not possible for technical reasons or patient co-morbidities, ultrasound monitoring may be considered, however 4 studies have shown poorer accuracy (both sensitivity and specificity) compared to SLNB[27][28][29][30], and so the latter is preferred whenever feasible (see chapter on SNLB). No studies were identified in patients who were not eligible for SLNB.\n\nIn three of the studies assessing ultrasonography against a reference standard of SNLB, the sensitivity of ultrasound ranged from 13% to 71%; the specificity from 57% to 97%[27][28][29]; and in two studies the positive predictive value ranged from 37% to 97%, while the negative predictive value ranged from 13% to 84%.[27][29] In one study that assessed a particular ultrasound characteristic (the echo free island) the sensitivity was 11%, the specificity 98%, the positive predictive value was 50% and the negative predictive value was 80%.[30]\n\nOne small study compared high resolution ultrasound (HRUSS) with PET/CT against a reference standard of SNB in 20 patients with clinically stage I/II disease.[16] HRUSS correctly identified two of 12 patients with positive SLNs whereas PET/CT imaging identified none; both imaging tests correctly identified all 12 patients with negative SLNs.[16]\n\nUltrasonography during follow-up\nThe usefulness of ultrasonography for follow-up of patients treated for Stage I/II melanoma depends entirely on the technical skill and experience of the personnel involved. There is a consensus of opinion that ultrasound is superior to clinical examination of regional lymph nodes, although its survival advantage is unproven.[31] A prospective cohort study of 373 patients with a primary tumour Breslow thickness of \u22651.5mm[32], reported a sensitivity of 93% for ultrasound compared with only 71% for the clinical examination of regional lymph nodes. Their specificity was equally high for both procedures (>98%). Despite the superiority of ultrasound, very few patients actually benefited from the addition of ultrasound to clinical examination. The reasons cited for this were that although ultrasound was useful in the earlier detection of regional disease or avoidance of unnecessary surgery in 7% of patients, 6% had deleterious effects such as unnecessary stress caused by repetition of ultrasounds for benign lymph nodes or useless removal of benign lymph nodes.[32] Thus in sum, in only 1% of patients was the use of ultrasound advantageous.\n\nUltrasound +/- Fine needle aspiration (FNA) +/- core biopsy for initial staging\nOne prospective study assessed whether the combination of ultrasound and fine needle biopsy could be used as a \u2018triage\u2019 test for SLNB in 107 asymptomatic patients with clinically stage I/II melanoma.[33] Using this test strategy, only two patients had final positive results, of which one could not be confirmed on histopathology (possible false positive) and the other was confirmed (true positive). Of the 105 patients who were negative on ultrasound +FNA, 36 were false negatives (nodal metastases found on SLNB), and 69 were true negatives.\n\nUltrasound +/- Fine needle aspiration (FNA) +/- core biopsy during follow-up\nFNA is the current standard method to confirm the presence of suspected nodal metastases for lymphadenopathy identified after definitive local treatment of cutaneous melanoma.[34][35] Ultrasound guidance should be used as the diagnostic yield is superior, particularly for small lymph nodes <10mm in size. Core biopsy has higher sensitivity and specificity compared with FNA and should be considered where FNA is negative but clinical suspicion remains high. There is no role for routine lymph node biopsy during follow up of asymptomatic patients.[36]\n\nOther investigations during follow-up\nSkin Self-Examination\nA review of 9 clinical practice guidelines by Marciano et al (2014)[37] reveals consensus that patients should be taught skin self-examination; this was based on retrospective evidence from several studies that recurrences were commonly first detected by patients. For this recommendation, 4 guidelines varied in evidence content while 5 guidelines provided consensus opinion only. Education on sun-smart behaviour was recommended by 4 guidelines.[37]\n\nSuccessfully implementing self-examination requires patient education on whole-body skin examination with particular attention given to melanoma surgical scars and the corresponding lymphatic drainage areas for in-transit and lymph node recurrence. Patients should also be given education regarding symptoms that may warrant further investigation, such as pain, fatigue, weight loss, nausea and vomiting, dyspneoa, and headache. In addition, the use of brochures or videos, and the engagement of relatives in the education process may be helpful.[38][39][40] Randomized controlled trials do not exist. In Australia, patients themselves detect up to 75% of recurrences, while in other countries this can be as low as 20%.9-13 These data highlight the fact that even with education, there are great differences in patients\u2019 individual ability to detect recurrences.[40]\n\nHistory and physical examination during follow-up\nThere is general consensus that the most cost-effective component of a strategy resulting in the detection of the majority of recurrences is careful history taking and physical examination. The detection of distant metastases in patients with early localised disease is unusual.\n\nAs with self-examination, history and physical examination include specific history taking, a full skin examination looking for new primaries, palpation of melanoma surgical scars, and lymphatic drainage areas for in-transit and lymph node recurrence. Apart from patient self-detected relapses, most relapses and secondary melanomas are detected during physical examinations.[41][42] In a large prospective study12, roughly 50 % of recurrences were identified by history taking/physical examination, 80 % of which were local recurrences, in-transit metastases, and regional lymph node metastases.[41] Indeed, the vast majority of operable recurrences (96%) are those detected by physical examinations.14 In summary, history and physical examinations for patients with stages I\u2013III melanoma are the most effective procedure for early recurrence detection.[43][8]", "Basic app setup\nThis guide is for developers who've never followed a Slack app recipe before, but want to cook with the latest ingredients from the Slack platform. We'll teach you how to craft a new Slack app from the ground up.\n\nIf you're an experienced chef, already familiar with seasons of Slack apps past, check out this quickstart guide that explains exactly what new ingredients have arrived to apps.\n\nOtherwise, read on!\n\nOverview\nCreating an app\nRequesting scopes\nInstalling the app to a workspace\nCalling API methods\nListening for events\nPosting in public channels\nCustomizing message authorship\nUsing Slash commands and Incoming Webhooks\nHandling link unfurling\nWhere to go next\nOverview \nThis guide walks you through making a new Slack app using the Slack App Management UI.\n\nBy the end of this guide, your app will be poised to post messages, make response to mentions, and even use classic recipes like Slash commands and incoming webhooks.\n\nNew Slack apps are safer for users to install, less prone to unexpected uninstalls, and even have new features not available to classic apps. So let's get cooking, starting with the first ingredient: creating an app.\n\nCreating an app \nIf you haven't already, create a new Slack app with our easygoing UI:\n\nCreate a new Slack app\n\nFill out your App Name and select the Development Workspace where you'll play around and build your app. Don't fuss too much over either field\u2014no matter what workspace you select, you'll still be able to distribute your app to other workspaces if you choose.\n\nRequesting scopes \nPreheat the oven and ready your app for action by requesting scopes. Scopes give your app permission to do things (for example, post messages) in your development workspace.\n\nYou can select the scopes to add to your app by heading over to the OAuth & Permissions sidebar.\n\nScroll down to the Scopes section and click to Add an OAuth Scope.\n\nFor example, try adding the chat:write scope to your Bot Token. It'll allow your app to post messages! While you're at it, add the channels:read scope so your app can gain knowledge about public Slack channels.\n\nIf you're confused about the difference between adding a Bot Token Scope or a User Token Scope, worry not:\n\nAdd scopes to your Bot Token, not your User Token.\n\nOne notable exception to that rule is if you need to act as a specific user (for example, posting messages on behalf of a user, or setting a user's status). In that situation, you'll need a User Token.\n\nNew Slack apps may not access RTM\nFor most apps, the Events API lets your app listen to Slack goings-on in a more structured, safe way. If you require access to RTM (say, because you're building your app behind a corporate firewall), you'll need to create a classic Slack app and use its bot token to call rtm.connect:\n\nCreate a classic Slack app\n\nOtherwise, it's bot tokens all the way down.\n\nInstalling the app to a workspace \nSure, you can request any scope you want\u2014but final say always resides with the user installing your app. Like a picky eater, a user can choose to refuse any and all installs that seem to request permissions beyond what an app truly needs.\n\nTry it out! Install your own app by selecting the Install App button on the sidebar.\n\nAfter clicking through one more green Install App To Workspace button, you'll be sent through the Slack OAuth UI.\n\nNew Oauth UI for users\n\nHere's a potentially confusing bit: when you follow this flow with Slack, you're playing the part of the installing user, the picky eater\u2014not the app! If you were adding your app to a different workspace besides your development workspace, this flow would be completed by a user from that workspace, not you.\n\nAs a user, you're choosing to trust the app. Is it trustworthy? Well, you just built it\u2014hopefully, it's not too bad.\n\nAfter installation, you'll find an access token inside your app management page. Look for it under the OAuth & Permissions sidebar.\n\nAccess tokens are imbued with power. They represent the permissions delegated to your app by the installing user. Remember to keep your access token secret and safe, to avoid violating the trust of the installing user.\n\nAt a minimum, avoid checking your access token into public version control. Access it via an environment variable. We've also got plenty more best practices for app security.\n\nCalling API methods \nYour access token allows you to call the methods described by the scopes you requested during installation.\n\nFor example, your chat:write scope now allows your app to post messages. Your app probably isn't a member of any channels yet, so pick a channel you don't mind adding some test messages to and /invite your app.\n\nYou can find the corresponding id for the channel that your app just joined by looking through the results of the conversations.list method:\n\nCopy\ncurl https://slack.com/api/conversations.list -H \"Authorization: Bearer xoxb-1234...\"\nYou'll receive a list of conversation objects.\n\nNow, post a message to the same channel your app just joined with the chat.postMessage method:\n\nCopy\ncurl -X POST -F channel=C1234 -F text=\"Reminder: we've got a softball game tonight!\" https://slack.com/api/chat.postMessage -H \"Authorization: Bearer xoxb-1234...\"\nVoila! We're already well on our way to putting a full-fledged Slack app on the table.\n\nSlack Softball Team app message\n\nWant more tips on cooking up the perfect API call? Check out the Web API guide for some technical tricks.\n\nIf you just want to see all the different methods you can call, check out the methods list. If you select any method, you'll see exactly what parameters the method takes, plus additional bits of knowledge. Think of the methods list as the Slack API cookbook.\n\nPosting in public channels \nNew Slack apps do not begin life with the ability to post to any public channel without joining.\n\nGood news: apps can gain that ability by asking for them explicitly with the use of scopes.\n\nRequest the chat:write.public scope to gain the ability to post in all public channels, without joining. Otherwise, you'll need to use conversations.join, or have your app invited by a user into a channel, before you can post.\n\nCustomizing message authorship \nNew Slack apps also do not start with the ability to adjust username or icon when posting messages\u2014that is, message authorship.\n\nYou can adjust your app's message authorship with the help of the chat:write.customize scope. Once you've requested the scope, you can make use of the username, icon\\_url, and icon\\_emoji parameters in chat.postMessage.\n\nListening for events \nOne fundamental pattern of Slack apps is listening and responding.\n\nWe've already touched on one way an app can respond: by calling chat.postMessage to post a message.\n\nBut our app isn't a very good listener yet. An app that speaks without being prompted can be distracting at best and outright disruptive at worst.\n\nApps always respond to something. It might be a mention in channel, a button pushed to trigger an action, even a user entering into a DM with the app. But apps never act for no reason.\n\nApps listen with the Events API. Events are just what you'd expect: notifications, sent to your app, about happenings in Slack. Each type of event lets your app know about a certain type of happening.\n\nLet's subscribe to the app\\_mention event. Select the Event Subscriptions sidebar and toggle \"Enable Events\" on. Within Subscribe to bot events click Add Bot User Event, then search for app\\_mention.\n\nAs with scopes, always subscribe to events with a bot user, unless only a user token will do.\n\nSet the Request URL to a URL where your app's server listens to incoming HTTP requests. Slack will send an HTTP request there when your app is mentioned, allowing your app to figure out how it wants to respond.\n\nIf setting a server up makes you nervous, there's plenty of help in our tools and SDKs for programming languages, which implement a server listening for events automatically.\n\nYou'll notice that the app\\_mention event requires the app\\_mention:read scope. Events are like API methods: they allow your app access to info in Slack, so you need permission for them. Reinstall your app with the new scope.\n\nNow you'll be notified when your app is mentioned, and you can respond however you like:\n\nSlack Softball Team app call and response\n\nUsing Slash commands and Incoming Webhooks \nNew Slack apps can still use beloved recipes passed down through the family: Slash commands and Incoming Webhooks.\n\nRequest the commands scope to build a Slash command. Request the incoming-webhook scope to use Incoming Webhooks. Both features act exactly the way they did for classic Slack apps, with one big exception:\n\nSlash commands and Incoming Webhooks are now tied to your bot user and bot token, not a user. That means you're safe from unexpected installs if the user who builds a command or webhook leaves the workspace!\n\nNew Slack apps will not support Slash commands or Incoming Webhooks on a user token. They can only be obtained by the app's bot user.\n\nHandling link unfurling \nYou can request the links:read and links:write scopes so that your app can handle unfurls.\n\nA link shared in a channel will only be unfurled if the token with links:write has access to the message that contains the link. For example, if you have a new Slack app and an installing user shares a link to a private channel, but the new Slack app is not in that private channel, that link will not unfurl.\n\nWhere to go next \nCooking is a life-long pursuit, and Slack apps have the same complexity. From here, you can go on to build mouth-watering interactive workflows; spice up your sentences with Block Kit; even pursue building for larger Enterprise Grid organizations, which contain multiple workspaces.\n\nYou can now even submit new Slack apps to the app directory and share your creations with others!\n\nRespond OK when ready for more.", "Voici d\u00e9sormais la partie 2 :\n\nWhen you have a high degree of chemistry with someone, they monopolize your thoughts and/or your free time. You\u2019ll stay awake talking till the sun comes up and not even feel like an hour went by. You\u2019ll hope that every call or text is him/her. You\u2019ll walk through life constantly wondering, \u201cWhat would he/she think about x?\u201d where x is a song, a bird, a walk through the park, a traffic jam, or a colonoscopy.\n\nCall it passion; call it love; call it sickness. The basic traits of your/their personality and your/their slightest behaviors ravage each others\u2019 dopamine receptors in a neurological orgy of starry-eyed dreaminess.\n\nAreas of Chemistry\n\nThe way your partner laughs at your jokes\nThe questions they ask you about your day\nThe way you hold each other in bed\nHow they help you decorate your new apartment\nThe way they smell3\nHow they always ask you for a bite of your burrito and when you say no they take a bite anyways but look so damn cute while doing it you can never bring yourself to feel mad\u2014this is the definition of true love, by the way.\nChemistry is made up of subtle behaviors and dispositions that mesh with behaviors and dispositions of the other person. What\u2019s created is a kind of closed karmic loop in which chemistry is felt by both parties equally. The most important rule about chemistry is that whatever you\u2019re feeling, he or she is most likely feeling the same way. You almost become empaths with one another.\n\nThe artist Alex Grey once said, \u201cTrue love is when two people have pathologies that complement one another.\u201d He was only half-joking.\n\nHigh levels of chemistry usually come from opposite yet complementary qualities in people. A woman who is highly-strung, energetic, and slightly neurotic will tend to have a high degree of chemistry with a guy who is relaxed, mellow, and open. Introverts often have natural chemistry with extroverts. People who are orderly and intense planners sometimes work best with people who are spontaneous and unorganized.\n\nUnlike a lack of compatibility, a lack of chemistry doesn\u2019t repel\u2014it simply results in a lack of emotional intensity. Things just feel kind of dead and boring.\n\nChemistry is also reflected in the bedroom. A lack of chemistry will mean boring, emotionless sex. A high degree of chemistry will mean intense, life-altering, heart-pounding sex that causes your mind to cosmically splatter itself on the walls of your consciousness. Good times.\n\nCompatibility and Chemistry in Relationships\n\n201 PEOPLE HAD BREAKTHROUGHS LAST WEEK. THIS WEEK, WILL ONE OF THEM BE YOU?\nNo spam or unexpected emails. Ever.\n\nHEALTHY AND TOXIC COMBINATIONS OF COMPATIBILITY AND CHEMISTRY\n\nUnfortunately, compatibility and chemistry don\u2019t always occur together.\n\nA relationship with high compatibility but little chemistry is likely to be a boring yet comfortable series of meetings and conversations. It will be a dry and dull affair until both parties simply stop caring and drift apart, or they consummate their mutual convenience by getting married and find themselves in a lifetime of uncomplicated and (often) asexual companionship. Sadly, this arrangement isn\u2019t uncommon.\n\nChemistry without compatibility, on the other hand, usually leads to disaster.4 Sometimes it can be as simple as not living in the same part of the world, but often it\u2019s far more complicated than that.\n\nWhen two people are completely incompatible, their behavior becomes completely irrational. Too often, two incompatible people initiate a cycle of mutual emotional immolation, spiraling through love/hate cycles together at the speed of life.\n\nPeople find themselves saying things like, \u201cI don\u2019t care if he\u2019s married to a convicted felon, we\u2019re meant to be together,\u201d or \u201cLook, I know she faked being pregnant to get me to propose to her, but you know, it may just be fate, right?\u201d Meanwhile, friends stare, jaws agape, unsure whether to risk the backlash by trying to snap them out of it or to feign support while their love-blind torture victim pal continues to spin helpless and deluded in a tornado of love.\n\nHigh levels of chemistry with major incompatibilities is bad news. Really bad news.\n\nThese relationships usually begin quickly and passionately, exploding like a geyser, before dying down just as quickly as it erupted. This tends to happen when logic kicks in and when reality makes itself known. Suddenly, you realize how fucking offensive you find each other, but getting out of such a relationship is easier said than done. Your heart says yes, but your head says no. And then you convince your head to say yes, which in turn makes your heart say no.\n\nAt this point, your decision making usually defaults to your genitals\u2014even though their track record for decision making is about as good as a drunk third-grader\u2019s\u2014which only leads to embarrassing public arguments, unpaid drink tabs, thrown iPhones, changed locks, unanswered phone calls, tear-ridden voicemails, and the sterile interior of a clinic, or if you\u2019re lucky, an oh-god-please-don\u2019t-give-me-a-false-positive-you-piece-of-shit-$9.99-pregnancy-test-from-a-7/11 experience, which is guaranteed to challenge anyone\u2019s sanity.\n\nAnd then there you are (wherever you go, as they say), and you find yourself jobless with two one-way tickets to Bermuda that were never used, six stitches, slashed car tires, and a shattered cell phone. But at least that psycho is fucking gone (even though you still kinda miss them). The experience is vicious yet thrilling, and will never let you forget that we are, after all, animals.\n\nNot that I\u2019m speaking from personal experience or anything. Nope. Nothing to see here. Move along.\n\nThe Chemistry-Compatibility Matrix\nLow Chemistry/Low Compatibility\n\nA relationship devoid not only of intimacy but probably basic conversation too. On the rare occasion this does happen, it doesn\u2019t last long.\nHigh Chemistry/Low Compatibility\n\nWhen it feels so right, but you know it\u2019s oh-so-wrong. AKA, the walking dumpster fire of a relationship.\nLow Chemistry/High Compatibility\n\nBoring, mostly asexual companionship. Entire relationship comprised of discussions about Netflix, sweatpants, and frozen meal planning.\nHigh Chemistry/High Compatibility\n\nThe sweet spot. Great balance between intimacy and practicality. Oh yeah, baby.\nFINDING THE PERFECT FIT\n\nSpoiler alert: you won\u2019t.\n\nSearch all you want, but you will never, ever, find someone who has 100% compatibility and chemistry with you. \n\nSomeone whose life priorities are perfectly aligned with yours may still enjoy completely different leisure activities. You may swoon every time your partner smiles at you but get irritated by how they always make that weird sound when breathing.\n\n100% compatibility and chemistry doesn\u2019t exist. You\u2019d be dating yourself. And even then, you\u2019re going to have a bad time\u2014I mean, have you spent any time with yourself lately? \n\n70-80% compatibility and chemistry is what you should be aiming for. Is there a way to measure this? Fuck no. But that feels about right to me. This is more than enough to have a well-functioning relationship, to build a partnership based on mutual respect, to fall a little more in love with each passing day but also weather the storms when love just doesn\u2019t seem to be enough.\n\nAnd here\u2019s the dirty little secret: you don\u2019t want that remaining 20-30%. It\u2019s actually dealing with those \u201cflaws\u201d and surmounting the small irritations that makes a relationship feel meaningful and rewarding. So stop looking for \u201cthe one.\u201d Stop dreaming of someone who finishes all your sentences and does everything you want them to, exactly the way you like it. They don\u2019t exist. That\u2019s not a relationship, that\u2019s a rich fantasy life.\nKNOW WHAT YOU WANT\n\nNavigating the dating landscape with confidence requires that you understand compatibility and chemistry. If you want to ultimately end up enjoying your time with an amazing partner\u2014and I don\u2019t just mean enjoying sex (that should be a given, sex is neat-o), but I mean really, truly enjoying your time together\u2014then it\u2019s important you get a cognitive handle on these emotional indicators of compatibility and chemistry.\n\nThe most important aspect is understanding what you want\u2014what makes a person compatible with you, what personality traits have chemistry with you? The first question you should ask yourself is \u201cWhat do I want?\u201d5 And then you should probably ask yourself a few more questions.\n\nYou need to know what you like and what you want in a partner. Like if you want kids or not,6 or if you are really into blondes. Those answers matter. If you don\u2019t know, then you need to cautiously gain enough experience until you do know.\n\nBack when I was dating, I found that I was incapable of dating girls who weren\u2019t incredibly smart. I could make it 2-3 dates with a woman of average intelligence or less and that was usually solely by merit of drowning my entire face in alcohol. Since a long-term relationship with these women would have necessitated that I take up alcoholism as a hobby, we inevitably parted ways. I also learned that I don\u2019t work well with women who are particularly religious or who have socially conservative values. Just not my thing.\n\nI learned that I have chemistry with women who are driven and ambitious. Their personalities work with mine in a unique, yet comfortable way (for both of us). I\u2019ve also found my personality meshes well with women who are a tad neurotic, as I\u2019m generally too laid back for my own good. I \u201cclick\u201d with women who appreciate a dark, sarcastic wit and are very giving and caring. In my dating days, I regularly found myself seeing teachers, nurses, social workers, volunteer workers, etc. for multiple dates, which sometimes progressed to a serious relationship.\n\nThese are the women who work for me. Who works for you?", "Voici d\u00e9sormais la deuxi\u00e8me partie du texte :\n\nWhen you have a high degree of chemistry with someone, they monopolize your thoughts and/or your free time. You\u2019ll stay awake talking till the sun comes up and not even feel like an hour went by. You\u2019ll hope that every call or text is him/her. You\u2019ll walk through life constantly wondering, \u201cWhat would he/she think about x?\u201d where x is a song, a bird, a walk through the park, a traffic jam, or a colonoscopy.\n\nCall it passion; call it love; call it sickness. The basic traits of your/their personality and your/their slightest behaviors ravage each others\u2019 dopamine receptors in a neurological orgy of starry-eyed dreaminess.\n\nAreas of Chemistry\n\nThe way your partner laughs at your jokes\nThe questions they ask you about your day\nThe way you hold each other in bed\nHow they help you decorate your new apartment\nThe way they smell3\nHow they always ask you for a bite of your burrito and when you say no they take a bite anyways but look so damn cute while doing it you can never bring yourself to feel mad\u2014this is the definition of true love, by the way.\nChemistry is made up of subtle behaviors and dispositions that mesh with behaviors and dispositions of the other person. What\u2019s created is a kind of closed karmic loop in which chemistry is felt by both parties equally. The most important rule about chemistry is that whatever you\u2019re feeling, he or she is most likely feeling the same way. You almost become empaths with one another.\n\nThe artist Alex Grey once said, \u201cTrue love is when two people have pathologies that complement one another.\u201d He was only half-joking.\n\nHigh levels of chemistry usually come from opposite yet complementary qualities in people. A woman who is highly-strung, energetic, and slightly neurotic will tend to have a high degree of chemistry with a guy who is relaxed, mellow, and open. Introverts often have natural chemistry with extroverts. People who are orderly and intense planners sometimes work best with people who are spontaneous and unorganized.\n\nUnlike a lack of compatibility, a lack of chemistry doesn\u2019t repel\u2014it simply results in a lack of emotional intensity. Things just feel kind of dead and boring.\n\nChemistry is also reflected in the bedroom. A lack of chemistry will mean boring, emotionless sex. A high degree of chemistry will mean intense, life-altering, heart-pounding sex that causes your mind to cosmically splatter itself on the walls of your consciousness. Good times.\n\nCompatibility and Chemistry in Relationships\n\n201 PEOPLE HAD BREAKTHROUGHS LAST WEEK. THIS WEEK, WILL ONE OF THEM BE YOU?\nNo spam or unexpected emails. Ever.\n\nHEALTHY AND TOXIC COMBINATIONS OF COMPATIBILITY AND CHEMISTRY\n\nUnfortunately, compatibility and chemistry don\u2019t always occur together.\n\nA relationship with high compatibility but little chemistry is likely to be a boring yet comfortable series of meetings and conversations. It will be a dry and dull affair until both parties simply stop caring and drift apart, or they consummate their mutual convenience by getting married and find themselves in a lifetime of uncomplicated and (often) asexual companionship. Sadly, this arrangement isn\u2019t uncommon.\n\nChemistry without compatibility, on the other hand, usually leads to disaster.4 Sometimes it can be as simple as not living in the same part of the world, but often it\u2019s far more complicated than that.\n\nWhen two people are completely incompatible, their behavior becomes completely irrational. Too often, two incompatible people initiate a cycle of mutual emotional immolation, spiraling through love/hate cycles together at the speed of life.\n\nPeople find themselves saying things like, \u201cI don\u2019t care if he\u2019s married to a convicted felon, we\u2019re meant to be together,\u201d or \u201cLook, I know she faked being pregnant to get me to propose to her, but you know, it may just be fate, right?\u201d Meanwhile, friends stare, jaws agape, unsure whether to risk the backlash by trying to snap them out of it or to feign support while their love-blind torture victim pal continues to spin helpless and deluded in a tornado of love.\n\nHigh levels of chemistry with major incompatibilities is bad news. Really bad news.\n\nThese relationships usually begin quickly and passionately, exploding like a geyser, before dying down just as quickly as it erupted. This tends to happen when logic kicks in and when reality makes itself known. Suddenly, you realize how fucking offensive you find each other, but getting out of such a relationship is easier said than done. Your heart says yes, but your head says no. And then you convince your head to say yes, which in turn makes your heart say no.\n\nAt this point, your decision making usually defaults to your genitals\u2014even though their track record for decision making is about as good as a drunk third-grader\u2019s\u2014which only leads to embarrassing public arguments, unpaid drink tabs, thrown iPhones, changed locks, unanswered phone calls, tear-ridden voicemails, and the sterile interior of a clinic, or if you\u2019re lucky, an oh-god-please-don\u2019t-give-me-a-false-positive-you-piece-of-shit-$9.99-pregnancy-test-from-a-7/11 experience, which is guaranteed to challenge anyone\u2019s sanity.\n\nAnd then there you are (wherever you go, as they say), and you find yourself jobless with two one-way tickets to Bermuda that were never used, six stitches, slashed car tires, and a shattered cell phone. But at least that psycho is fucking gone (even though you still kinda miss them). The experience is vicious yet thrilling, and will never let you forget that we are, after all, animals.\n\nNot that I\u2019m speaking from personal experience or anything. Nope. Nothing to see here. Move along.\n\nThe Chemistry-Compatibility Matrix\nLow Chemistry/Low Compatibility\n\nA relationship devoid not only of intimacy but probably basic conversation too. On the rare occasion this does happen, it doesn\u2019t last long.\nHigh Chemistry/Low Compatibility\n\nWhen it feels so right, but you know it\u2019s oh-so-wrong. AKA, the walking dumpster fire of a relationship.\nLow Chemistry/High Compatibility\n\nBoring, mostly asexual companionship. Entire relationship comprised of discussions about Netflix, sweatpants, and frozen meal planning.\nHigh Chemistry/High Compatibility\n\nThe sweet spot. Great balance between intimacy and practicality. Oh yeah, baby.\nFINDING THE PERFECT FIT\n\nSpoiler alert: you won\u2019t.\n\nSearch all you want, but you will never, ever, find someone who has 100% compatibility and chemistry with you. \n\nSomeone whose life priorities are perfectly aligned with yours may still enjoy completely different leisure activities. You may swoon every time your partner smiles at you but get irritated by how they always make that weird sound when breathing.\n\n100% compatibility and chemistry doesn\u2019t exist. You\u2019d be dating yourself. And even then, you\u2019re going to have a bad time\u2014I mean, have you spent any time with yourself lately? \n\n70-80% compatibility and chemistry is what you should be aiming for. Is there a way to measure this? Fuck no. But that feels about right to me. This is more than enough to have a well-functioning relationship, to build a partnership based on mutual respect, to fall a little more in love with each passing day but also weather the storms when love just doesn\u2019t seem to be enough.\n\nAnd here\u2019s the dirty little secret: you don\u2019t want that remaining 20-30%. It\u2019s actually dealing with those \u201cflaws\u201d and surmounting the small irritations that makes a relationship feel meaningful and rewarding. So stop looking for \u201cthe one.\u201d Stop dreaming of someone who finishes all your sentences and does everything you want them to, exactly the way you like it. They don\u2019t exist. That\u2019s not a relationship, that\u2019s a rich fantasy life.\nKNOW WHAT YOU WANT\n\nNavigating the dating landscape with confidence requires that you understand compatibility and chemistry. If you want to ultimately end up enjoying your time with an amazing partner\u2014and I don\u2019t just mean enjoying sex (that should be a given, sex is neat-o), but I mean really, truly enjoying your time together\u2014then it\u2019s important you get a cognitive handle on these emotional indicators of compatibility and chemistry.\n\nThe most important aspect is understanding what you want\u2014what makes a person compatible with you, what personality traits have chemistry with you? The first question you should ask yourself is \u201cWhat do I want?\u201d5 And then you should probably ask yourself a few more questions.\n\nYou need to know what you like and what you want in a partner. Like if you want kids or not,6 or if you are really into blondes. Those answers matter. If you don\u2019t know, then you need to cautiously gain enough experience until you do know.\n\nBack when I was dating, I found that I was incapable of dating girls who weren\u2019t incredibly smart. I could make it 2-3 dates with a woman of average intelligence or less and that was usually solely by merit of drowning my entire face in alcohol. Since a long-term relationship with these women would have necessitated that I take up alcoholism as a hobby, we inevitably parted ways. I also learned that I don\u2019t work well with women who are particularly religious or who have socially conservative values. Just not my thing.\n\nI learned that I have chemistry with women who are driven and ambitious. Their personalities work with mine in a unique, yet comfortable way (for both of us). I\u2019ve also found my personality meshes well with women who are a tad neurotic, as I\u2019m generally too laid back for my own good. I \u201cclick\u201d with women who appreciate a dark, sarcastic wit and are very giving and caring. In my dating days, I regularly found myself seeing teachers, nurses, social workers, volunteer workers, etc. for multiple dates, which sometimes progressed to a serious relationship.\n\nThese are the women who work for me. Who works for you?", "I have followed all the steps now, and when I try to test the page on my http://localhost:4200 the following errors display on the page...\n\nCompiled with problems:\nERROR in ./src/app/app-routing.module.ts 3:0-71\n\nModule not found: Error: Can't resolve './user-login/user-login.component' in '/home/james/Testdev/src/app'\nERROR in ./src/app/app-routing.module.ts 4:0-74\n\nModule not found: Error: Can't resolve './post-create/post-create.component' in '/home/james/Testdev/src/app'\nERROR in ./src/app/app-routing.module.ts 5:0-68\n\nModule not found: Error: Can't resolve './post-list/post-list.component' in '/home/james/Testdev/src/app'\nERROR\n\nsrc/app/app-routing.module.ts:1:10 - error TS2300: Duplicate identifier 'NgModule'.\n\n1 import { NgModule } from '@angular/core';\n ~~~~~~~~\nERROR\n\nsrc/app/app-routing.module.ts:2:10 - error TS2300: Duplicate identifier 'RouterModule'.\n\n2 import { RouterModule, Routes } from '@angular/router';\n ~~~~~~~~~~~~\nERROR\n\nsrc/app/app-routing.module.ts:2:24 - error TS2300: Duplicate identifier 'Routes'.\n\n2 import { RouterModule, Routes } from '@angular/router';\n ~~~~~~\nERROR\n\nsrc/app/app-routing.module.ts:3:10 - error TS2300: Duplicate identifier 'NgModule'.\n\n3 import { NgModule } from '@angular/core';\n ~~~~~~~~\nERROR\n\nsrc/app/app-routing.module.ts:4:10 - error TS2300: Duplicate identifier 'RouterModule'.\n\n4 import { RouterModule, Routes } from '@angular/router';\n ~~~~~~~~~~~~\nERROR\n\nsrc/app/app-routing.module.ts:4:24 - error TS2300: Duplicate identifier 'Routes'.\n\n4 import { RouterModule, Routes } from '@angular/router';\n ~~~~~~\nERROR\n\nsrc/app/app-routing.module.ts:6:36 - error TS2307: Cannot find module './user-login/user-login.component' or its corresponding type declarations.\n\n6 import { UserLoginComponent } from './user-login/user-login.component';\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nERROR\n\nsrc/app/app-routing.module.ts:7:37 - error TS2307: Cannot find module './post-create/post-create.component' or its corresponding type declarations.\n\n7 import { PostCreateComponent } from './post-create/post-create.component';\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nERROR\n\nsrc/app/app-routing.module.ts:8:35 - error TS2307: Cannot find module './post-list/post-list.component' or its corresponding type declarations.\n\n8 import { PostListComponent } from './post-list/post-list.component';\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nERROR\n\nsrc/app/login/login.component.html:1:44 - error NG8003: No directive found with exportAs 'ngForm'.\n\n1 \n ~~~~~~\n\n src/app/login/login.component.ts:6:16\n 6 templateUrl: './login.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component LoginComponent.\nERROR\n\nsrc/app/login/login.component.html:4:40 - error NG8002: Can't bind to 'ngModel' since it isn't a known property of 'input'.\n\n4 \n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n src/app/login/login.component.ts:6:16\n 6 templateUrl: './login.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component LoginComponent.\nERROR\n\nsrc/app/login/login.component.html:4:53 - error TS2322: Type 'Event' is not assignable to type 'string'.\n\n4 \n ~~~~~~~~~~~~~~~~~~~~~~~~~\n\n src/app/login/login.component.ts:6:16\n 6 templateUrl: './login.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component LoginComponent.\nERROR\n\nsrc/app/login/login.component.html:8:46 - error NG8002: Can't bind to 'ngModel' since it isn't a known property of 'input'.\n\n8 \n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n src/app/login/login.component.ts:6:16\n 6 templateUrl: './login.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component LoginComponent.\nERROR\n\nsrc/app/login/login.component.html:8:59 - error TS2322: Type 'Event' is not assignable to type 'string'.\n\n8 \n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n src/app/login/login.component.ts:6:16\n 6 templateUrl: './login.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component LoginComponent.\nERROR\n\nsrc/app/post-creation/post-creation.component.html:1:52 - error NG8003: No directive found with exportAs 'ngForm'.\n\n1 \n ~~~~~~\n\n src/app/post-creation/post-creation.component.ts:6:16\n 6 templateUrl: './post-creation.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component PostCreationComponent.\nERROR\n\nsrc/app/post-creation/post-creation.component.html:4:39 - error NG8002: Can't bind to 'ngModel' since it isn't a known property of 'input'.\n\n4 \n ~~~~~~~~~~~~~~~~~~~~~~~~\n\n src/app/post-creation/post-creation.component.ts:6:16\n 6 templateUrl: './post-creation.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component PostCreationComponent.\nERROR\n\nsrc/app/post-creation/post-creation.component.html:4:52 - error TS2322: Type 'Event' is not assignable to type 'string'.\n\n4 \n ~~~~~~~~~~~~~~~~~~\n\n src/app/post-creation/post-creation.component.ts:6:16\n 6 templateUrl: './post-creation.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component PostCreationComponent.\nERROR\n\nsrc/app/post-creation/post-creation.component.html:8:32 - error NG8002: Can't bind to 'ngModel' since it isn't a known property of 'textarea'.\n\n8 \n ~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n src/app/post-creation/post-creation.component.ts:6:16\n 6 templateUrl: './post-creation.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component PostCreationComponent.\nERROR\n\nsrc/app/post-creation/post-creation.component.html:8:45 - error TS2322: Type 'Event' is not assignable to type 'string'.\n\n8 \n ~~~~~~~~~~~~~~~~~~~~\n\n src/app/post-creation/post-creation.component.ts:6:16\n 6 templateUrl: './post-creation.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component PostCreationComponent.\nERROR\n\nsrc/app/user-registration/user-registration.component.html:4:40 - error NG8002: Can't bind to 'ngModel' since it isn't a known property of 'input'.\n\n4 \n ~~~~~~~~~~~~~~~~~~~~~~~~\n\n src/app/user-registration/user-registration.component.ts:6:16\n 6 templateUrl: './user-registration.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component UserRegistrationComponent.\nERROR\n\nsrc/app/user-registration/user-registration.component.html:4:53 - error TS2322: Type 'Event' is not assignable to type 'string'.\n\n4 \n ~~~~~~~~~~~~~~~~~~\n\n src/app/user-registration/user-registration.component.ts:6:16\n 6 templateUrl: './user-registration.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component UserRegistrationComponent.\nERROR\n\nsrc/app/user-registration/user-registration.component.html:4:82 - error NG8003: No directive found with exportAs 'ngModel'.\n\n4 \n ~~~~~~~\n\n src/app/user-registration/user-registration.component.ts:6:16\n 6 templateUrl: './user-registration.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component UserRegistrationComponent.\nERROR\n\nsrc/app/user-registration/user-registration.component.html:9:42 - error NG8002: Can't bind to 'ngModel' since it isn't a known property of 'input'.\n\n9 \n ~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n src/app/user-registration/user-registration.component.ts:6:16\n 6 templateUrl: './user-registration.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component UserRegistrationComponent.\nERROR\n\nsrc/app/user-registration/user-registration.component.html:9:55 - error TS2322: Type 'Event' is not assignable to type 'string'.\n\n9 \n ~~~~~~~~~~~~~~~~~~~~~\n\n src/app/user-registration/user-registration.component.ts:6:16\n 6 templateUrl: './user-registration.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component UserRegistrationComponent.\nERROR\n\nsrc/app/user-registration/user-registration.component.html:9:90 - error NG8003: No directive found with exportAs 'ngModel'.\n\n9 \n ~~~~~~~\n\n src/app/user-registration/user-registration.component.ts:6:16\n 6 templateUrl: './user-registration.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component UserRegistrationComponent.\nERROR\n\nsrc/app/user-registration/user-registration.component.html:14:46 - error NG8002: Can't bind to 'ngModel' since it isn't a known property of 'input'.\n\n14 \n ~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n src/app/user-registration/user-registration.component.ts:6:16\n 6 templateUrl: './user-registration.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component UserRegistrationComponent.\nERROR\n\nsrc/app/user-registration/user-registration.component.html:14:59 - error TS2322: Type 'Event' is not assignable to type 'string'.\n\n14 \n ~~~~~~~~~~~~~~~~~~~~~\n\n src/app/user-registration/user-registration.component.ts:6:16\n 6 templateUrl: './user-registration.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component UserRegistrationComponent.\nERROR\n\nsrc/app/user-registration/user-registration.component.html:14:94 - error NG8003: No directive found with exportAs 'ngModel'.\n\n14 \n ~~~~~~~\n\n src/app/user-registration/user-registration.component.ts:6:16\n 6 templateUrl: './user-registration.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component UserRegistrationComponent.", "several new errors appear when I load the page..\n\nCompiled with problems:\nERROR in ./src/app/app-routing.module.ts 19:13-33\n\nexport 'PostListingComponent' (imported as 'PostListingComponent') was not found in './post-listing/post-listing.component' (possible exports: PostListComponent)\nERROR in ./src/app/app.module.ts 15:97-117\n\nexport 'PostListingComponent' (imported as 'PostListingComponent') was not found in './post-listing/post-listing.component' (possible exports: PostListComponent)\nERROR\n\nsrc/app/app-routing.module.ts:6:10 - error TS2724: '\"./post-listing/post-listing.component\"' has no exported member named 'PostListingComponent'. Did you mean 'PostListComponent'?\n\n6 import { PostListingComponent } from './post-listing/post-listing.component';\n ~~~~~~~~~~~~~~~~~~~~\n\n src/app/post-listing/post-listing.component.ts:11:14\n 11 export class PostListComponent implements OnInit {\n ~~~~~~~~~~~~~~~~~\n 'PostListComponent' is declared here.\nERROR\n\nsrc/app/app.component.html:11:1 - error NG8001: 'router-outlet' is not a known element:\n1. If 'router-outlet' is an Angular component, then verify that it is part of this module.\n2. If 'router-outlet' is a Web Component then add 'CUSTOM\\_ELEMENTS\\_SCHEMA' to the '@NgModule.schemas' of this component to suppress this message.\n\n11 \n ~~~~~~~~~~~~~~~\n\n src/app/app.component.ts:5:16\n 5 templateUrl: './app.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component AppComponent.\nERROR\n\nsrc/app/app.module.ts:9:10 - error TS2724: '\"./post-listing/post-listing.component\"' has no exported member named 'PostListingComponent'. Did you mean 'PostListComponent'?\n\n9 import { PostListingComponent } from './post-listing/post-listing.component';\n ~~~~~~~~~~~~~~~~~~~~\n\n src/app/post-listing/post-listing.component.ts:11:14\n 11 export class PostListComponent implements OnInit {\n ~~~~~~~~~~~~~~~~~\n 'PostListComponent' is declared here.\nERROR\n\nsrc/app/app.module.ts:15:17 - error NG1010: Value at position 4 in the NgModule.declarations of AppModule is not a reference\n Value could not be determined statically.\n\n 15 declarations: [\n ~\n 16 AppComponent,\n ~~~~~~~~~~~~~~~~~\n... \n 21 CommentsComponent\n ~~~~~~~~~~~~~~~~~~~~~\n 22 ],\n ~~~\n\n src/app/app.module.ts:20:5\n 20 PostListingComponent,\n ~~~~~~~~~~~~~~~~~~~~\n Unknown reference.\nERROR\n\nsrc/app/post-creation/post-creation.component.html:1:52 - error NG8003: No directive found with exportAs 'ngForm'.\n\n1 \n ~~~~~~\n\n src/app/post-creation/post-creation.component.ts:7:16\n 7 templateUrl: './post-creation.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component PostCreationComponent.\nERROR\n\nsrc/app/post-creation/post-creation.component.html:4:39 - error NG8002: Can't bind to 'ngModel' since it isn't a known property of 'input'.\n\n4 \n ~~~~~~~~~~~~~~~~~~~~~~~~\n\n src/app/post-creation/post-creation.component.ts:7:16\n 7 templateUrl: './post-creation.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component PostCreationComponent.\nERROR\n\nsrc/app/post-creation/post-creation.component.html:4:52 - error TS2322: Type 'Event' is not assignable to type 'string'.\n\n4 \n ~~~~~~~~~~~~~~~~~~\n\n src/app/post-creation/post-creation.component.ts:7:16\n 7 templateUrl: './post-creation.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component PostCreationComponent.\nERROR\n\nsrc/app/post-creation/post-creation.component.html:8:32 - error NG8002: Can't bind to 'ngModel' since it isn't a known property of 'textarea'.\n\n8 \n ~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n src/app/post-creation/post-creation.component.ts:7:16\n 7 templateUrl: './post-creation.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component PostCreationComponent.\nERROR\n\nsrc/app/post-creation/post-creation.component.html:8:45 - error TS2322: Type 'Event' is not assignable to type 'string'.\n\n8 \n ~~~~~~~~~~~~~~~~~~~~\n\n src/app/post-creation/post-creation.component.ts:7:16\n 7 templateUrl: './post-creation.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component PostCreationComponent.\nERROR\n\nsrc/app/user-login/login.component.html:1:44 - error NG8003: No directive found with exportAs 'ngForm'.\n\n1 \n ~~~~~~\n\n src/app/user-login/login.component.ts:7:16\n 7 templateUrl: './login.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component LoginComponent.\nERROR\n\nsrc/app/user-login/login.component.html:4:40 - error NG8002: Can't bind to 'ngModel' since it isn't a known property of 'input'.\n\n4 \n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n src/app/user-login/login.component.ts:7:16\n 7 templateUrl: './login.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component LoginComponent.\nERROR\n\nsrc/app/user-login/login.component.html:4:53 - error TS2322: Type 'Event' is not assignable to type 'string'.\n\n4 \n ~~~~~~~~~~~~~~~~~~~~~~~~~\n\n src/app/user-login/login.component.ts:7:16\n 7 templateUrl: './login.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component LoginComponent.\nERROR\n\nsrc/app/user-login/login.component.html:8:46 - error NG8002: Can't bind to 'ngModel' since it isn't a known property of 'input'.\n\n8 \n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n src/app/user-login/login.component.ts:7:16\n 7 templateUrl: './login.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component LoginComponent.\nERROR\n\nsrc/app/user-login/login.component.html:8:59 - error TS2322: Type 'Event' is not assignable to type 'string'.\n\n8 \n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n src/app/user-login/login.component.ts:7:16\n 7 templateUrl: './login.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component LoginComponent.\nERROR\n\nsrc/app/user-registration/user-registration.component.html:4:40 - error NG8002: Can't bind to 'ngModel' since it isn't a known property of 'input'.\n\n4 \n ~~~~~~~~~~~~~~~~~~~~~~~~\n\n src/app/user-registration/user-registration.component.ts:6:16\n 6 templateUrl: './user-registration.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component UserRegistrationComponent.\nERROR\n\nsrc/app/user-registration/user-registration.component.html:4:53 - error TS2322: Type 'Event' is not assignable to type 'string'.\n\n4 \n ~~~~~~~~~~~~~~~~~~\n\n src/app/user-registration/user-registration.component.ts:6:16\n 6 templateUrl: './user-registration.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component UserRegistrationComponent.\nERROR\n\nsrc/app/user-registration/user-registration.component.html:4:82 - error NG8003: No directive found with exportAs 'ngModel'.\n\n4 \n ~~~~~~~\n\n src/app/user-registration/user-registration.component.ts:6:16\n 6 templateUrl: './user-registration.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component UserRegistrationComponent.\nERROR\n\nsrc/app/user-registration/user-registration.component.html:9:42 - error NG8002: Can't bind to 'ngModel' since it isn't a known property of 'input'.\n\n9 \n ~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n src/app/user-registration/user-registration.component.ts:6:16\n 6 templateUrl: './user-registration.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component UserRegistrationComponent.\nERROR\n\nsrc/app/user-registration/user-registration.component.html:9:55 - error TS2322: Type 'Event' is not assignable to type 'string'.\n\n9 \n ~~~~~~~~~~~~~~~~~~~~~\n\n src/app/user-registration/user-registration.component.ts:6:16\n 6 templateUrl: './user-registration.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component UserRegistrationComponent.\nERROR\n\nsrc/app/user-registration/user-registration.component.html:9:90 - error NG8003: No directive found with exportAs 'ngModel'.\n\n9 \n ~~~~~~~\n\n src/app/user-registration/user-registration.component.ts:6:16\n 6 templateUrl: './user-registration.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component UserRegistrationComponent.\nERROR\n\nsrc/app/user-registration/user-registration.component.html:14:46 - error NG8002: Can't bind to 'ngModel' since it isn't a known property of 'input'.\n\n14 \n ~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n src/app/user-registration/user-registration.component.ts:6:16\n 6 templateUrl: './user-registration.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component UserRegistrationComponent.\nERROR\n\nsrc/app/user-registration/user-registration.component.html:14:59 - error TS2322: Type 'Event' is not assignable to type 'string'.\n\n14 \n ~~~~~~~~~~~~~~~~~~~~~\n\n src/app/user-registration/user-registration.component.ts:6:16\n 6 templateUrl: './user-registration.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component UserRegistrationComponent.\nERROR\n\nsrc/app/user-registration/user-registration.component.html:14:94 - error NG8003: No directive found with exportAs 'ngModel'.\n\n14 \n ~~~~~~~\n\n src/app/user-registration/user-registration.component.ts:6:16\n 6 templateUrl: './user-registration.component.html',\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n Error occurs in the template of component UserRegistrationComponent.", "CHAPTER FOUR\n The Spectrum of Pain: Four Patients\n From Jeremy\nYou\u2019ve read the story of my back pain. Maybe it sounded familiar (I hope not; it was a bear). In any event, read the next four case histories, because one of them is likely to remind you a lot of yourself. The idea is for you to see where you fit on the spectrum of back pain problems. \nFit Fred\nA lot of my Aspen-based patients are fit, knowledgeable, and a little surprised to find themselves in need of professional help for back pain. A recent patient, call him Fit Fred, is typical. He is fifty-five years old, a nice guy, in good shape, and smart. He has had serious back pain for six months. In his case, that means a bothersome ache in his lower back almost all the time. And intermittent periods of excruciating pain, once every two weeks or so. Those interludes\u2014which have happened more often recently\u2014last from a few minutes to more than an hour. It is those intervals that have driven him to seek treatment.\nI am not his first stop. He\u2019s tried traditional chiropractic doctors, physical therapy, massage, and Rolfing. His back pain gets a little better for a time, and then comes back full force. When the pain is at its worst, he\u2019s stuck in bed or on the floor. He has tried traditional medicine, too, and his doctor is asking him to consider surgery. He has come to me first, because he has heard how often back surgery does not work, and he dreads that option, but he\u2019s getting closer to taking it. \n\u201cMy doctor says I have degenerative disc disease. He says I have the MRI of an eighty-year-old!\u201d (It is almost a comfort to him to think that he had \u201cdegenerative disc disease\u201d and that an operation may fix it. He\u2019s had enough. He\u2019s giving the nonmedical approach one more chance. Then it\u2019s the knife.) \nIn reality, \u201cdegenerative disc disease\u201d is a term used to describe a host of changes in the spine as a result of, or in addition to, a loss of disc height (compression) over time. As a diagnostic matter, saying that someone has degenerative disc disease doesn\u2019t amount to an awful lot more than saying that he or she is getting a little older and that his or her back hurts. That sounds a little snide, I\u2019m afraid, but it\u2019s true. Because Fred seems to have decent posture and is in pretty good shape, I suspect that his problem is going to be related to the normal degenerative changes of the spine that go with aging and bad repetitive motions. Maybe golf, maybe yoga. Depending on how open he is to change, this could be a comparatively easy case. \nIt won\u2019t sound easy, if I go into the details. After all, compression of the spine through normal aging does do some serious things. They can include arthritic changes in the facet joints (remember them?), loss of cartilage around all the joints, foraminal stenosis, which\u2014you will recall\u2014is a narrowing of the opening, or foramen, from which the nerve roots exit the spine. It may be spondylolisthesis, which is a slippage of one vertebra over another, causing pain and instability\u2014and is almost as nasty as it is unpronounceable. That all sounds awful, but they are normal concomitants of aging and degeneration of the spine and bad movements\u2014my normal material. Those we can fix. \nAs for his eighty-year-old\u2019s MRI, it probably does look pretty grim. But I have to tell you, almost all MRIs of people over forty look terrible. Stuff happens, and the individual manifestations look very scary. But they are not really all that bad. Which is why I rarely prescribe MRIs unless there are signs of the scary stuff (cancer, infection, fracture, etc.); they don\u2019t tell me anything I don\u2018t already know. \u201cHey, you\u2019re getting older, your back is getting squished. What did you expect?\u201d It\u2019s more sophisticated than that, but that\u2019s a fair summary in most cases. It is also a fair description of a condition you and I can fix, with behavioral change and hard work.\nI ask Fred a couple of questions about the therapy he\u2019s had so far. The chiropractor has just been manipulating him with no mention of exercise. I know that\u2019s not going to work for a permanent fix. And the physical therapist does not seem to have much of a plan: He has had my new patient do four exercises for three months\u2014always the same four, over and over, with no supervision and no progression. And neither of them has discussed his other activities (sports, work, exercises, etc.) with him. Beyond that, they are not the kind of exercises I will suggest because, among other things, they have done nothing to affect the endurance of the muscles of the core. This is by no means a slight on all chiropractors or physical therapists. There are some great ones out there. Some practice the way Fred\u2019s did, and some don\u2019t. Later in the book, we give you some pointers on finding good ones.\nFred really is active, God bless him, but he\u2019s doing some activities that, I suspect, are not helping his back. He does quite a lot of yoga, plays golf regularly, and lifts weights in the gym. A very responsible, fit guy, as I say. But what I know, without seeing him do yoga or play golf, is that some of the movements in those two activities are often a source of serious back injury over time. There is a safe, spine-healthy way to do yoga but, done wrong, as it often is, it can cause terrible problems. For now, I tell him to lay off yoga completely for at least two months. He can get back to it in time with some modifications. The same with golf. Golf is a wonderful activity. Not great exercise (contrary to what so many insist) but a wonderful way to be with friends and go to beautiful places. It can also be, structurally, one of the worst things you can do to your back. (All that one-way twisting of your lumbar spine.) There is a spine-healthy way to play golf, but for now I just tell him to lay off the golf until he is educated enough to be open to some instruction on a \u201cright way\u201d to play. [Hint: You learn to rotate with your hips more at the end of your swing, and less with your lower back.]\nThen I asked him to walk me through his strength-training regimen. It was not the worst strength regimen I have ever heard about, but it was pretty bad. He was doing a number of things that were almost criminally bad for him. If you are doing a lot of strength training, there is a sad chance that you, too, are doing some seriously harmful stuff, from a back point of view. That\u2019s because we were all trained to do things wrong, back in the day. \nTake, for example, the traditional \u201carmy sit-up,\u201d which Fred is still doing. We all did a lot of those at one point and a lot of us are doing them still. Even the army gave them up only in recent times. But the fact is that there are few things worse for your back than the good old army sit-up. (A shallow, or four-inch \u201ccrunch\u201d is fine, and it does all you need for your core; you do not need to bend your spine like a pretzel to get a benefit.) The sit-up, where you twist to touch your elbow to the opposite knee, is the worst of all. And that\u2019s just one of a bunch of deeply familiar exercises that are fundamentally terrible for your back. The machines we all used to love are a particular peril (not all but many). The whole world of bad strength training makes me particularly crazy: Here are these terrific men and women, working so hard in an effort to make their bodies stronger and better. And what they are doing is, in fact, worse than doing nothing at all. Sad and wrong. \nMost important, Fit Fred has no notion of the importance of engaging his core and strengthening his core and glutes\u2014perhaps the most important elements in a sane strength-training regimen. And he doesn\u2019t have a clue about the importance of decent posture and of maintaining a neutral spine. So I tell him to stop all strength training until I can show him how to do it right. \nSubstantial Sally \nIf Fit Fred was on the fit end of the fitness spectrum, then Substantial Sally was the opposite. She is significantly overweight (she is close to 300 pounds, which is very significant indeed) and has had no regular exercise program for the past four years. She has had a whopping four spine surgeries, two in the past two years, including a fusion and a laminectomy. Fusions are common, but they are very serious business indeed. It is a procedure in which the surgeon uses hardware to bolt (fuse) two or more vertebrae together to prevent further movement at that joint. There is a place for fusions, but I see them as a very last resort. They give relief, but if the person does not make the necessary behavioral changes, they often find themselves having another fusion or other problems in a few years. They are not a cure, in any broad sense. A laminectomy is a less serious procedure in which the surgeon removes a small piece of bone off a vertebra to relieve pressure on a particular nerve. Again, it cures a symptom, not the basic problem. \nIn any event, Sally has been through the wars, she is still in pain, and she is both smart and wary. She is not one bit sure that I am going to be any more help than my predecessors. I don\u2019t blame her. But I think she\u2019s wrong. I think I am going to be able to help her quite a lot, if she\u2019ll listen, which she may not. \nSally is an appealing woman, the head of a company that she started herself, and which she has made a huge success of. I automatically like her, right off; she\u2019s one of those people whom everyone likes right off . . . part of her success, I assume. But she sure is in trouble, and it is making her cranky. I don\u2019t blame her, but she is not fun. Not many of my patients are fun; they hurt too much.", "CHAPTER SEVEN\n RULE #2\n Be Still So You Can Heal (The Neutral Spine)\n From Jeremy\nLet\u2019s assume that you are beginning to get the big picture. And that you have also begun to identify the \u201cdumb\u201d things that you\u2019ve been doing to wreck your back, and that you have stopped doing them. Good. Now it is time to start the healing, and that is a matter of immobilizing your lower back or lumbar spine so it can heal, after all those years of doing things that hurt it. \nThe analogy is not perfect, but think of your tortured back as being like a broken arm or leg. When you break an arm, say, the doc puts it in a stiff cast so you can\u2019t bang it or twist it and to give it time and rest to heal. The same with your back, except we can\u2019t do anything quite as dramatic as put you in a whole-body cast for your damaged back. What we can do is show you how to carry yourself so that you effectively immobilize your lower back. It\u2019s not totally easy, but it will work. And bear in mind, if you do not immobilize your back, it will not heal\u2014simple as that. Indeed, it may get worse. \nWhat do I mean by \u201cimmobilizing\u201d your lumbar spine? I do not mean that you can\u2019t sit or walk or have a more or less normal life. What I do mean is that you have to be really serious about maintaining a neutral spine, all the time. Maintaining a neutral spine is at the heart of your cure, and will be at the heart of your life after your cure. This is the time to learn how to achieve a neutral spine and how to maintain it all the time, even when doing various movements. \nThe spine is a meticulously engineered piece of machinery, but it has a lot of redundancy built in. By this I mean that unlike the knee or shoulder, in the spine when you have a bad joint, the surrounding structures can \u201chelp\u201d bear the loads, and you can function more or less normally and without pain. Take the pressure of bad posture\u2014and dumb movement patterns\u2014off, and there is very likely enough \u201croom\u201d in this spine for the sufferer to have a normal life. For example, the \u201choles\u201d where the nerves come out of the spine (the foramina) are still big enough for the nerves to exit, pain-free, if you\u2019re not squeezing the area with lousy posture. In the same vein, there is probably still enough cushion in the flattened disc to support a correctly aligned spine (but not a bent or misshapen one). And so on. \n\u201cNeutral\u201d means the position in which the least amount of problem loads occur, all up and down the spine. The \u201cproblem loads\u201d in some pictures we\u2019ve shown are extreme, but even those inflamed joints and nerve roots will likely calm down if you leave them alone for a while. Which is to say, if you keep your spine in neutral. As bad as those injuries are (and as long as it took someone to create them) there is a strong chance that that sufferer can go about his or her life, with a neutral spine, in little or no pain. \nLearning to keep a neutral spine is not totally easy. And learning to maintain it all the time is harder. But this is the \u201ccast\u201d that lets your body heal. It is worth going to a lot of trouble to get this right. And it is a lesson that you will use for the rest of your life, long after the problem area has \u201chealed.\u201d \nOkay, step one is understanding the concept of neutral spine. Step two is learning to find it and lock it in place, and keep it in place forever (which we will teach you in Chapter 9).\nThe neutral spine is the position that allows your spine to do its job with the least amount of stress and load. And\u2014if you have already damaged your back\u2014it is the position that results in the least amount of new damage or pain.\nFor most people, the picture on the left is the neutral spine. The other two are not.\nNeutral Spine \n\nGOOD BAD\nNote the gentle curve of the lower back in the \u201cgood\u201d spine. For the majority of you, this is how your neutral spine will look. If you have developed significant degenerative changes or were born with significant abnormalities (it happens, but not a lot), your neutral spine may look a bit different. For now assume that your neutral spine looks like one on the guy on the left. Spines vary, and you may have your own unique neutral spine that is a little different from this. Whatever your own neutral spine, that is the position you want to maintain as you go about your daily life. It is also the position in which you feel the least pain. Again, maintaining a neutral spine is a fundamental behavioral change for most people. And it is readily doable. In a few months\u2019 time, I predict that it will be natural and you will scarcely need to think about it. One of the near-magic presences in our lives is \u201cmuscle memory.\u201d Maintain your spine correctly for a while and muscle memory takes over. Then it is just a question of seeing to it that your muscles are strong enough to do their job. \nHow do you keep your spine neutral and still be a dynamic, moving, active human being? By learning to brace your neutral spine with your core (Chapter 9) and maximizing movement in your hips (as opposed to your lower back). As Chris mentioned in Chapter 6, one of our cardinal rules is \u201cThou shalt not bend or twist with thy lower back.\u201d And you don\u2019t need to. You can rotate from side to side and bend forward and back using your hips. You do not need to flex or twist your lower back. \nYou may ask: Isn\u2019t range of motion important for the lumbar spine? Answer: Not really. At least, it is usually the least important factor for someone who has had significant back pain, and should be reintroduced only after pain has stopped. Most people who have experienced regular, serious back pain have already sustained significant wear and tear on the spine. The general pattern I see is a combination of two things: first, worn-down vertebral joints that are hypomobile (stiff), secondary to arthritic changes and degeneration; second, lumbar vertebral joints that are hypermobilie (loose), due to overstretched ligaments and atrophied muscles. These problems are best resolved when we protect the spine by bracing and \u201clocking down\u201d the lumbar spine and moving in a manner that completely changes the axis of motion from the lumbar spine to the hips and shoulder girdle. You can eventually introduce some gentle lumbar range-of-motion exercises in non-loaded ways. This is what the \u201cCat/Camel\u201d exercise that we introduce later is for. Small, gentle lumbar range-of-motion exercise is necessary for things like synovial joint lubrication, the reduction of friction between vertebral segments and discs, and disc nutrition, among other things. For example, walking requires a few degrees of freedom between the lumbar vertebral joints (3 or 4 degrees rotation) with coordinated muscle contractions to enhance stabilization and supply necessary lubrication and nutrition to discs and joints. For our purposes, we recommend keeping lumbar motion to a minimum, especially until your pain is gone. Once that occurs, you should make only healthy, non-loaded, non-repetitive lumbar movements, such as those necessary for walking and the cat and camel exercise. Spinal stability, core endurance, hip mobility, and core and gluteal strength are far more important for maintaining a healthy spine once you\u2019ve had back pain. You can do just fine in life with almost no rotation or excessive movement in your lower back. Let your hips do the work, and your risk of recurring back pain is sharply reduced. \nFinding Your Neutral Spine \nFinding your neutral spine can be a bit tricky for some but you can do it. Here\u2019s what you do. Lie on your back with your knees bent and your feet flat on the floor. Try to relax everything in your body, and just breathe. Then let\u2019s start by performing a pelvic tilt. \nTo do that, flatten your lower back into the floor (see top drawing), and curl your tailbone upward. This is a \u201cposterior pelvic tilt,\u201d if you want to put a name to it. Now, arch your back so that your lower back comes off of the floor (middle drawing), and point your tailbone toward the ground (an \u201canterior pelvic tilt\u201d). Now, slowly go back and forth between those two motions a few times (bottom drawing). Find the position of your lower back between these two extremes (flattening your back or arching it) that feels the most comfortable to you, and stop there. This is your neutral spine. It may take a few tries but it\u2019s not hard.\nFinding Your Neutral Spine\n\nStop here for a second. You have just reached an important point, and you don\u2019t want to \u201close\u201d it. Everyone\u2019s neutral spine is a bit different depending on the anatomical condition of their lumbar spine. For most people, there will be a gentle curve in the lower back. For those who already have some kind of a disc bulge, their neutral spine might be more arched (butt more extended). For those with spinal stenosis, their neutral spine may be a little more flattened than the one in the picture on the previous page. Don\u2019t worry about it. Whatever feels the most comfortable for you is your neutral spine for now. In time, your neutral spine will likely become more like the \u201cnormal\u201d picture as pain and inflammation subside.\nThink about your neutral spine and assume that position all the time until it becomes second nature\u2014until \u201cmuscle memory\u201d takes over. \nNext, we move on to a discussion of techniques to help you maintain a neutral spine. But first, Chris is going to tell you why it is very likely you haven\u2019t heard of these concepts before.", "CHAPTER FOURTEEN\n Trigger Points: Muscle Pain and Back Pain\n From Chris and Jeremy\nMost of us\u2014the newcomers anyway\u2014tend to think of back pain as something that is largely in the spine itself. The bones, discs, ligaments, and nerves. But what most of us don\u2019t focus on are the surrounding and supporting muscles. Which is a mistake, because they can be a major source of back pain (or something that can pass as back pain). And getting \u201cright\u201d with those muscles can be mighty important. \nTo be accurate, back pain is almost always a not-so-pleasing blend of muscle pain, joint pain, nerve pain, and other pain. This can be a little confusing. All pain is transmitted by nerves. When we speak of muscle pain or nerve pain, we are referring to the primary source of pain\u2014that is, the pain-generating tissue. Sometimes an aggravated nerve is the source of pain so it is referred to as nerve pain. In this chapter, we are talking about pain whose primary source is muscles. Even though the pain is transmitted to your brain via nerves, the tissue that\u2019s causing the pain is muscle tissue, so we refer to it as muscle pain. It is helpful to think of that which is primarily muscle pain differently, because it manifests itself differently, and Jeremy\u2019s approach to it is different, too.\nThere\u2019s good news and bad news here (wouldn\u2019t you know it). The bad news is that muscle pain is harder to locate and trickier to fix in the first instance. The good news is that it is actually easier to fix in the long run, and your prospects of a complete cure are much better. \nWhich is not to say it does not hurt like blazes. Up in the 8\u201310 range, on a scale of 10. But often the relief can be sudden and nearly complete. You still have to do serious stuff to keep it from coming back once the fix is made, but that\u2019s always true. \nMuscle Pain\nPeople in the healing professions refer to muscle pain both as \u201cmyofascial pain\u201d and \u201ctrigger point pain.\u201d For laymen like you and me, \u201ctrigger point pain\u201d may be the more useful name, because it feels like that\u2014something that gets \u201ctriggered\u201d by some silly move you made. Whatever we call it, trigger point pain has been a somewhat controversial topic for decades, mostly because no medical discipline claims ownership of the muscular system. Doctors are far more concerned with the joints, bursae, ligaments, and nerves. There has not been as much study of the muscular system and trigger point pain. But there has been enough, so that there is broad agreement on many points. And the best practitioners, and Jeremy in particular, have seen a lot of it. \nSo, what is it? Here\u2019s Jeremy: \u201cTrigger points are tight, painful bands of muscle tissue that have predictable and recognizable patterns of pain.\u201d To put it another way, they are muscle spasms (not quite right but close enough), which is what you get when a muscle or muscle segment seizes up, under pressure, and won\u2019t let go. It\u2019s like those cramps you sometimes get in your leg, except it doesn\u2019t go away and the pain can be horrendous. Unbearable, some of the time. These spasms or cramps not only cause terrible pain in their own right, but they can change the way some joints function. As Jeremy puts it, \u201cThey also limit range of motion and change the normal distribution of loads on nearby joints, which can also cause pain.\u201d So trigger point pain is serious, and it has more than one way to grab you. If it has started to affect the range of motion of the nearby joint, in the way Jeremy suggests, clearing it up is harder, but the approach is the same. \nOne thing to bear in mind is that trigger points basically \u201clie\u201d to us. That is to say, the obvious pain may crop up away from the actual trigger point itself. For example, the trigger point may be in the gluteus minimus (that\u2019s a favorite spot, actually), but the pain may run down the leg, mimicking sciatica. Or a trigger point in the gluteus medius may read as pain in the lower back. There are a lot of variations, but the patterns are well known and predictable, so professionals know where to look for the originating problem. Most of the time, anyway. Pretty soon, you will, too. \nOne thing that helps is that trigger point or muscle pain in general is recognizably different from nerve pain (again, this means pain in which an aggravated nerve is the source of the pain, not just the means of transmission to your brain) and other pain, so that you know what you are dealing with. Most of the time, nerve pain, for example, is \u201cburning, sharp, electric,\u201d and you can pinpoint exactly where it is. Trigger point pain, on the other hand, is achy, diffuse, hard to localize, and dull. And it often arises far from the source, which is a trigger point in a muscle. \nOne reason it is called trigger point pain is that it is usually \u201ctriggered\u201d by an actual event, just the way it feels. You rolled over funny in bed, you opened the Sub-Zero too vigorously, you picked up the box of books with your back, not your legs. Sometimes, those triggering events are one-off incidents, which is the way they feel. But more often, the trigger point (or vulnerability) has been building for a long time. Vulnerable muscles or muscle segments have been under repetitious pressure for a long time, and they are ready to \u201cgo\u201d at the drop of a hat. You open the Sub-Zero funny and pow! A terrifying spasm. A latent trigger point like that can \u201cgo\u201d without any trigger event at all or with a trifling one. Let us hope that yours is a \u201cone-off,\u201d not one that has been building for years, because the one-off takes less time to heal. But never mind, the approach is just the same. \nThe most common trigger points are the ones that have been caused by muscular overload, and that have developed over time. Think of the familiar situation: You sit at your desk for months and years. It is an \u201cunnatural\u201d position, and it puts repetitive pressure on muscles that aren\u2019t built for it. Or it can be repetitively misplaced loads, caused by you doing some move the same wrong way, year after year, like a faulty golf swing. Say you sprain an ankle and you never quite rehab the ankle the way you should. Over the following weeks and months you walk slightly differently than you used to. This subtle change causes muscles in your legs and pelvis to bear loads in a different way. Some now bear more loads, some less. Over time, those muscles that are now bearing more loads get stressed and strained, and trigger points develop. The pain from these can come on gradually or suddenly. As we have said all along, most of the time, you have built your own back pain, over time, with the way you behave. That is true for most muscle pain, too. \nFinding Trigger Points\nOkay, on to the details. \n\u201cFor low back pain sufferers, the most important and common areas for trigger points to occur are in the lumbar paraspinals, quadratus lumborum, gluteus maximus, gluteus medius, gluteus minimus, and piriformis.\u201d Sorry, that\u2019s Jeremy; he just can\u2019t help himself. But you don\u2019t have to memorize the names; you just have to look at the pictures to get the general idea. And then feel around for the real source of the pain. When I say look at the pictures, I mean look and see if you can relate what you feel to the typical patterns the pictures show. The Xs represent the location of the real trigger point and the red shaded areas represent the area where you may perceive the pain. So think about where you feel the pain. Then look at the pictures. Then go to work to find where the X may mark the spot. When you find it, it will hurt a lot more than the surrounding area. Bingo! Think of these pictures as \u201ctreasure maps\u201d and the treasure is eventual release from pain. \nThis process is very much \u201chands on.\u201d It can be challenging to distinguish areas of perceived pain from actual trigger points until you get a feel for what you are looking for. If you try multiple times and fail, you may need the assistance of a good chiropractor, massage therapist, or physical therapist to get the hang of this. To get started, grope around with your hands (using the pictures as a guide to the general area) until you have a fair idea of where the real trigger points are. You will know them because they hurt more. For once, the pain is the good news. It means that you\u2019re getting close. Or you\u2019re there. \nBy the way, the muscles where the trigger point lies can be deep. The gluteus minimus, for example, is buried beneath two other muscles and a layer of fat. Some of you are not going to have the strength or leverage to reach that trigger point with your hand alone. You may need to use a tennis ball or foam roller, which will be discussed in the following pages. But, to start, just use your hand until you get a general idea if there is something deep in those muscles that needs to be released. And don\u2019t forget: Use the pictures as your guide. \nOnce you have a general idea of where the trigger point is, mash away at it, if you like, with your bare hands, and see if that manual manipulation is enough to \u201crelease\u201d the rascal. What you do is hold down hard on the place that hurts the most and\u2014in ten to thirty seconds or so\u2014you should feel an easing of the pain. That is the trigger point letting go. Nice work. If the pain does not ease up after thirty seconds or so, either you are not directly", "this is chapter 20 of original book\n{CHAPTER TWENTY\n The Sacrum and Coccyx\n From Chris and Jeremy\nFrom Chris\nThe sacrum is the last section of the spine, the vestigial collection of vertebrae that are welded into one solid piece, down at the bottom. And the coccyx is the tippety-tip of the sacrum, the last bit of bone at the end of that long chain, which has been such a torment to you for so long. \nAnd this is the end of the book. The end of the long chain of chapters that we hope\u2014with all our hearts\u2014will deliver you from such torment forever. From now on, it\u2019s up to you. Go back through the book, do the exercises, and change your behavior the way you know you should. Up to you now. \nMay I say, here at the end, that putting this book together has been great fun for Jeremy and me. It has taken more than a year, and it has been a ton of work. We hope it reads as if it were easy as pie, but it wasn\u2019t. We worked like crazy to make it seem easy\u2014and to make it truly accurate without driving you crazy. Don\u2019t know how well we did on that, but we sure did try. And it was fun for a couple of reasons. First, from my point of view, Jeremy is awfully good company. He is deadly serious about his profession but he loves to laugh, too. And, God bless us, we think we\u2019re funny. That helped a lot. On a slightly more serious note, learning all the stuff I had to learn about the back this past year was fascinating and a privilege. Interesting piece of machinery, the back, and Jeremy could not have been a better guide. \nFinally, both of us are true believers in this \u201crevolution\u201d I mentioned up front, and that is a tremendous help. The whole time we were digging away at this boring detail or that, we had the agreeable conviction that we were not just ink-stained wretches, noses to the page. We were centurions in the great war against cruel, needless pain. That helped a lot, too. \nBut the whole business won\u2019t be satisfying to us if it doesn\u2019t work, for you. And that takes me back to my one great worry, the one I mentioned before. \nI worry that we leave so much of this up to you, when we know that Americans just aren\u2019t used to that. Americans are used to going to the magician/doctor. He has a look around, maybe does an MRI. And then hands us a prescription, or gives us a shot. Or sends us to his pal the back surgeon, who does some clever thing to make us all better. As we\u2019ve said again and again, that\u2019s not going to work here. You have to do it yourself\u2014you have to do the exercise, make the changes. But the great question is, will you find the resolve to make it happen? Jeremy says he\u2019s sure you will, because he knows your pain. He knows just how deep and sharp your motivation is. I hope he\u2019s right. \nWhat we are urging is not really that hard; it is mostly just unfamiliar. And you surely have the resources and motivation to make it happen. I know you\u2019re smart enough; you just read this darned book, after all. I know you are disciplined enough; you\u2019ve been going to work all these years. And I know you care, because I know about your pain. Now just take those three things and reorient them a little. And save your life. Then spread the word and save your family, save the country. Get the ogre out of all our lives. It can and should be done. \nFrom Jeremy\nI can\u2019t agree more with Chris\u2019s words. He and I had such a great time writing this book, and we are both deeply optimistic about what it can do for you. As you well know by now, I am not the \u201cword guy\u201d; that\u2019s Chris. So I will be uncharacteristically brief and just say I have seen this protocol work a thousand times in my practice. Now I want to see it work a million times, perhaps more than that, with this book. As we mentioned at the beginning, we want a revolution in back care in this country. Starting with you. We want to take this scourge out of all our lives. \nJEREMY\u2019S RULES\n1\nStop doing dumb stuff.\n2\nBe still so you can heal.\n3\nBrace yourself.\n4\nCommit to your core.\n5\nUse the power in your posterior.\n6\nCrawl before you walk. Walk before you run.\n7\nStand tall for the long haul.\nAPPENDIX\nThe \u201cCheat Sheet\u201d\nWe threw a lot at you in this book. In time, it will seem like second nature. When you get to that point, it may still be useful to have a simple guide to remind you where you are, what to do next, and so on. To that end, I give you this \u201ccheat sheet\u201d to summarize all the exercises we have told you to do and to tell you when to do them. Here is your daily and weekly plan.\nI strongly encourage you to read this book a few times a year. Trust me, you are trying to change lifelong habits and it\u2019s very easy to default back to the old ways. Come back to the book and think through each exercise every so often. Avoid the trap of falling into those same bad habits that got you here in the first place. The book is the key to taking your life back and leaving the anxiety, stress, and pain of back problems in the past. In between readings of the book, there\u2019s this Exercise Cheat Sheet. \nBasic Core Exercises\nThese exercises (see Chapter 10) should be done every day, and are best done in the morning after being out of bed for thirty minutes or so. Remember to do progressions or regressions as needed for each. Move on to the next progression of a particular exercise when and if you feel ready. Start with one circuit and work your way up to two full circuits in time, and make that your daily habit. In time, this will take you ten to fifteen minutes.\n1. Slow March with Neutral Spine with Shoulder Flexion\n2. The Bridge \n3. Crunch and Plank\n4. Dynamic Hamstring Stretch\n5. Side Plank\n6. Cat/Camel Mobilization\n7. \u201cBird Dog,\u201d or Opposite Arm/Leg Extension\nGlute Strengthening Routine \nDo these exercises three times a week on nonconsecutive days in addition to your core routine. Start with two sets and work your way up to three in time. This will likely add an additional ten minutes or so on those three days a week that you do these. \n1. Hip Circles Do these first!\n2. Clamshell\n3. Quadruped Hip Extension\n4. Split Squat\n5. Squat\nTrigger Point Release\nDo this as needed. If you got noticeable improvement in back, hip, or leg pain after mastering this, do it prior to your glute workouts until it is no longer needed. \nStretches \nFollow up your glute routine with the following stretches from Chapter 17.\nThis will take three to four minutes.\n1. Hamstring Stretch\n2. Glute Stretch\n3. Piriformis Stretch\n4. Psoas Stretch\nTHE BACKFOREVER VIDEOS\nFor those of you who want to safely return to more demanding activities like weightlifting, skiing, golf, tennis, Pilates, yoga, etc., we invite you to become members of BackForever.com, where you will find hundreds of hours of detailed video instruction on these subjects. Visit BackForever.com to learn more. Enter this promo code to receive two free weeks of membership: YNYTRIAL.\nACKNOWLEDGMENTS\nThanks to Jeremy, first of all, for being such a joy to work with. Coauthorship is supposed to be hard. For me\u2014especially in this book\u2014it has been a joy. We worked mighty hard, but we laughed a lot too.\nJeremy and I have been blessed\u2014and we know it\u2014to have a superb editor in a smart, kind, diplomatic, literate Bruce Tracy at Workman. (That is a shortened list of attributes; Bruce was terrific. And he really got down into the weeds as well as the big picture. As good as they get.) And, as always, thanks to the wise and kind Suzie Bolotin, editor of the Younger Next Year\u00ae books and Uber-editor of this one. Heaven!\nLast, thanks to Bill Fabrocini, just about the smartest and most effective guy Jeremy and I know in the broad world of physical therapy and serious training. And about as nice a human being as I have ever met. Deep thanks, Bill.\n\u2014C. C.\nI\u2019d like to thank all of the people who have helped me become the clinician I am today. I\u2019d like to thank Clinton Phillips, Michael Fox, Tim Powersmith, and Bill Fabrocini for their friendship, guidance, and the opportunities they have given me. Back pain has been one of the most misunderstood afflictions in modern society. Many of the concepts in this book are the result of the research and teaching of a handful of dedicated and pioneering individuals. There are many, but I would like to give special mention to Vladimir Janda, MD; David Simons, MD; Janet Travell, MD; Nikolai Bogduk, MD, PhD; and Stuart McGill, PhD. This book wouldn\u2019t have been possible without your accomplishments. }\nRead the chapter 20 of original book that I sent you and save it in your memory. Then, based on this text of chapter 20 of original book and your own information, continue the text of chapter 20 of the new book as much as you like. morover, with explaining with deep learning to me as if i were 10 years old.The text should be completely scientific and academic and based on science World Day should be written and repetition should be avoided. that are not repetitive and related to this topic. this chapter of an original book that I gave you is just a starting point and he has the right to add relevant foliage to this section. based on chapter 20 of original book, you can start", "here's the second content. I only want you to reply \"acknowledged\" to remember the second content. I will give you further instructions after this.\nConstruction & Building Lawyers in Melbourne\nWe are expert building and construction lawyers who provide practical legal advice and representation to:\n\nProperty Owners (including home owners)\nBuilders\nContactors / Sub-Contractors\nProperty developers\nEngineers\nArchitects\nSurveyors\nTradespeople\nBuilding and construction lawyers\nOur Building Legal Services\nCOMMERCIAL BUILDING & CONSTRUCTION\nRESIDENTIAL BUILDING & CONSTRUCTION\nOWNERS CORPORATION\nOur construction and building lawyers in Melbourne have expertise in a wide range of matters relating to the building industry, helping land owners, builders, project managers, and others to avoid running into legal difficulties \u2013 or otherwise resolve them.\n\nWe have practical experience in and around the building industry, which means that our building lawyers understand both the practical side of building issues, in addition, of course, to the legal issues.\n\nNew Building Contracts - Drafting the Contract\nAs a builder or contractor, you may require expert input from a construction lawyer into the legal terms of a domestic or commercial building contract. We can draft the contract for you from the beginning or otherwise adapt an existing contract to cater for a particular job.\n\nContract Review and Negotiation\nDomestic Building Contracts are, even in the standard form, complex documents, whether the contract is for a new home or a renovation. Our building lawyers in Melbourne have advised many clients about their rights and responsibilities under their building contract. There are many \u201ctricky\u201d\u201d parts in these contracts that can cost you a lot of money and time later if not thought through and addressed upfront. In other words, many problems are preventable. We can take you through the terms of your building contract before you sign it \u2013 and help you think through the issues and the legal consequences of agreeing to certain things. If amendments are required, we can also assist you in negotiating special conditions to the contract, to suit your particular circumstances.\n\nContract Termination\nOur building and construction lawyers can assist you in the following circumstances:\n\nWhen you are considering terminating a building contract\nWhen you are being threatened with building contract termination\nWhen you are in a situation where the contract has already been terminated.\nEnding the contract is a serious matter. It should not be done without seeking proper legal advice first.\n\nGenerally, a carefully drafted notice will need to be served before you terminate, so that the other party has an opportunity to fix the problems.\n\nIf the matters are not resolved, and provided there are sufficient grounds \u2013 which must also be thought through carefully \u2013 the contract can then usually be terminated.\n\nTermination by a builder or property owner can be a helpful resolution to a difficult and costly dispute when appropriate. If you terminate incorrectly, this can lead to a very expensive and protracted further dispute. You want to avoid any such dispute where possible.\n\nIf you require advice in relation to such matters, we recommend that you contact a building lawyer promptly before taking further action yourself.\n\nContractual Disputes, Litigation and Dispute Resolution\nWhile disputes are usually unpleasant and time consuming, we assist clients to:\n\nAssert and enforce contractual rights; and\nWhere necessary, assist to contain the damage and present our client\u2019s position in the best possible light.\nContractual disputes can often be resolved sensibly without the need for legal proceedings or mediation. Where possible, our building dispute lawyers will assist clients with that negotiation. If the matter needs to be litigated, we have experience representing clients in all Victorian courts and VCAT.\n\nOur building lawyers in Melbourne take a proactive approach to dispute resolution and prepare thoroughly for mediation and court proceedings.\n\nIf you have a dispute and require legal advice from building dispute lawyers, we recommend that you contact us as soon as possible to seek advice about how best to address the issues and move towards resolving the matter.\n\nWorkplace Health and Safety\nThere is a significant obligation on building companies to address health & safety matters.\n\nOur Melbourne-based construction lawyers provide advice in this complex area, including in relation to code of practice compliance and regulator investigations prosecution issues.\n\nTerms of Trade and Credit Arrangements\nWhether you\u2019re a builder or contractor, and whether you\u2019re providing the service or are the recipient of the service, it is important that you ensure that the terms of trade are helpful to you, and not a potential hindrance.\n\nOur construction lawyers in Melbourne are experienced in both drafting and reviewing terms of trade, including terms that include payment terms and credit arrangements. Getting this right upfront can save confusion and cost and later \u2013 and prevents a dispute later.\n\nIf you are already in dispute and need advice, we can also assist in representing you to resolve the dispute as quickly as possible.\n\nSecurity of Payment Act Claims\nThe point behind the Security of Payments Act legislation is that a party who undertakes construction work is entitled to recover progress payments in relation to the work carried out.\n\nThis is a complex area. When used appropriately, it can be a powerful tool for getting paid, but careful consideration is required as to whether it is the best approach in the circumstances.\n\nA building and construction lawyer can assist you with:\n\nMaking a claim\nApplying for Adjudication\nDefending a claim, including adjudication responses\nApplying to set aside an adjudication determination\nEnforcing an adjudication determination or judgment\nThere are also other methods of debt recovery, and we have experience acting for both plaintiffs and defendants in such circumstances.\n\nBusiness Set Up\nWe regularly provide advice for setting up a new business, including business structures.\n\nWhether you choose to operate as a sole trader company or select a company trust structure can affect your ongoing liability and have taxation consequences.\n\nNeeds also change over time. What might have been suitable when you start business may need to be reviewed as your business grows and changes.\n\nGood legal advice from a construction lawyer will assist you to think through the issues so you can get your building and construction business structure right.\n\nBuying and Selling Real Estate\nAs a builder or developer, if you are involved in buying and selling development sites, you will need to have solid legal advice from a construction lawyer in Melbourne.\n\nWe have property lawyers who can assist in contracts for the sale and purchase of land and, where relevant, commercial and residential leases.\n\nBuilder, Contractor and Sub-contractor Agreements and Disputes\nThe relationship between a contractor and sub-contractor is somewhat unique. It is business to business and you are both in the building industry. Disputes are common and the party who understands its legal position will have the advantage.\n\nOur building dispute lawyers can advise in relation to the following contractor-specific matters:\n\nEmployment advice \u2013 A building lawyer can help determine if the contractor is truly a contractor or an employee and assist with disputes where they arise.\n\nContracts between builders, contractors and subcontractors \u2013 Our construction lawyers in Melbourne can draft and review such contracts and provide advice in the event of a dispute. Where the matter cannot be resolved amicably, our building litigators will represent you very competently.\n\nDisputes between builders, contractors and subcontractors \u2013 If there is a dispute, small disagreements can become expensive disputes quickly. It is sensible to work out the legal issues quickly and try to resolve the dispute. If the other party is not being sensible, a swift and firm approach is usually helpful.\n\nIf you need advice in relation to matters between builders, contractors and sub-contractors, our team of building dispute lawyers can assist you with a high degree of competence.\n\nLicences and Permits\nOur building lawyers in Melbourne can provide advice in relation to the following:\n\nBuilding plumbing, electrical and gas fitting licences \u2013 including application, suspension and appeal\nDevelopment applications\nWater usage\nSewerage/drainage matters\nTree protection (including dealing with planning permit conditions and overlays)\nFire management and fire safety\nExplosives\nAsbestos removal\nPublic land use\nOur building and construction lawyers can assist in the preparation of documentation and representation in relation to all of the above.\n\nBuilding Defects and Home Warranty Insurance Claims\nNot all builders are good builders.\n\nHome warranty claims can be made against builders for defective work.\n\nThe insurance policy cannot be claimed against unless the builder is insolvent, cannot be found or is dead. So, the circumstances are limited.\n\nOur building lawyers have strong experience in helping land owners who have engaged builders and the work is substandard. There are useful remedies available to help get your defects fixed and/or to get you an appropriate amount of compensation.\n\nWe have access to outstanding building experts who can identify the defects (sometimes well beyond what is already known) and ascribe a value to fixing those defects to assist us in properly articulating your claim.\n\nWe will always endeavour to get the dispute resolved without litigation but, if necessary, our building dispute lawyers will prosecute your case with vigour against the builder in VCAT or the courts.\n\nIf you are in dispute with your builder and need legal advice as to how to negotiate with them, or if you would like us to negotiate for you, please contact us.\n\nDebt Recovery\nDebt recovery in building matters is not always clear cut. There can be offsets and counterclaims, so thoughtful consideration of the approach is advantageous.\n\nOur debt recovery team is very experienced and typically successful at recovering outstanding payments.\n\nWe regularly issue letters of demand and commence proceedings to enforce the payment of outstanding debts.\n\nWe will also recommend the Security of Payment approach where appropriate.\n\nWe also defend claim for payment for clients to whom alleged monies are owed.\n\nProject Finance & Finance Documentation Advice\nWe can provide clients with a sound explanation of all finance contracts and personal guarantees in relation to such matters as:\n\nLender contracts from bank and financiers relating to the mortgage of land\nProject funding\nEquipment finance\nThese appointments are usually short and concise. Our building and construction lawyers will ensure that the documentation is explained to you adequately and that the documents are signed correctly.\n\nCall our construction lawyers today on 1300 907 335 to discuss your situation, or simply fill in the enquiry form on this page to receive a prompt response from our construction and building lawyers in Melbourne.", "I need your help with my assignment. I need to evaluate a venture pitch and write a report on it. I will first provide you with the group pitch, and then the assignment instructions so you can complete my assignment to help me achieve the highest possible grade. Below is the group pitch. Reply to this with 'yes' if you understand:\n\nHelpmates: A holistic app that provides services for working professionals\n\nTable of Contents:\n1. Executive Summary\n2. The Why\n3. The Context\n4. Business Model Canvas\n5. Product-Market Positioning\n6. Business Ecosystem\n7. Financials\n8. Implementation\n9. The Ask\n\n1. Executive Summary:\nProblem Addressed:\n\u2022 Currently, most service providers operate independently, on specific platforms or by word of mouth.\n\u2022 Helpmates brings all service providers onto one, easy-access platform.\n\u2022 Consumers will benefit from an all-encompassing platform which facilitates the finding of service providers.\nThe Platform:\n\u2022 An app which connects service providers with consumers:\no Consumers view range of services and service providers\no Consumers pick providers based on profile including ratings, location and price\no Consumers can book slots or message providers\n\u2022 Mainly monetized through commissions and advertisements\nThe Launch:\n\u2022 Launch in Sydney in 2023 amongst higher income customer segments, starting for household tasks (cleaning, gardening, plumbing, carpenting, etc.)\n\u2022 View to expand rapidly into other services once a strong service provider and customer base is established.\n\n2. The Why:\nWe came up with the idea of Helpmates out of personal experiences and by witnessing a gap in the market for a holistic services app. An app like Helpmates is specifically made for working professionals who are on a time crunch offering one click solutions for all household problems. The increasing number of working professionals and the fast-paced corporate culture laid down the need for an app like Helpmates. This is the only app currently in the market that offers hassle-free solutions and booking for top certified professionals.\n\n3. The Context:\nAccording to the PESTEL AND Porter's 5 Forces analyses:\n\u2022 Australia is a fast-growing economy and citizens are always looking for ways to save time.\n\u2022 Australia is an early adopter of technology making Helpmates easy to be implemented in the society.\n\u2022 The service industry is fast paced and ever changing and an app like Helpmates can help bring a wave of change in which people use professional services.\n\u2022 The service industry has significant potential. Helpmates provides high quality services at the best prices that the market has to offer.\n\n4. Business Model Canvas:\nKey Partners:\n\u2022 Freelancers\n\u2022 Local communities\n\u2022 Small businesses\n\u2022 Software developers\nKey Activities:\n\u2022 Connect service providers with customers\n\u2022 Encourage freelancing\nKey Resources\n\u2022 Large no. of users & service providers\n\u2022 Capital\n\u2022 App developer\nCost Structure:\n\u2022 Software Development cost\n\u2022 App Operating cost\n\u2022 Marketing cost\nValue Proposition:\n\u2022 Easy and flexible service\n\u2022 Easily accessible\n\u2022 Trust\n\u2022 Creating new income/job opportunities\nCustomer Relationships:\n\u2022 Customer service\n\u2022 Feedback/ratings\nChannels:\n\u2022 LinkedIn\n\u2022 Community\n\u2022 Facebook groups\n\u2022 Social media\nCustomer Segments:\n\u2022 Service users\n\u2022 Busy professionals\n\u2022 New-to-community service providers\n\u2022 Freelancers\n\u2022 Small businesses\n\u2022 Students\nRevenue Streams:\n\u2022 Commissions\n\u2022 Advertisements\n\u2022 Service Provider Boost (to show providers on top of list)\n\n5. Product-Market Positioning:\nProblems Customers Faced:\n\u2022 One Sided Platform: Supplier-oriented only or consumer-oriented only\n\u2022 Lack of Connection: Hard to find out service suppliers or service consumers\n\u2022 Lack of Efficiency: Long waiting time for reply and service delivery\n\u2022 Diverse Channels: Various platforms for different types of service\n\u2022 Lack of Accessibility: Difficult access to the service provider\n\u2022 Lack of Supply: Lack of personal services in wider areas\nMarket Positioning:\n\u2022 Target Market:\no Personal Service (including all types of personal services)\no Initial Focus: Low-skilled + High Demand (Clean/Housekeeping,\no Cafe/Restaurant, etc.)\n\u2022 Customers Segments:\no Service Suppliers - Everyone who needs services\no Service Consumers - Everyone who is willing to provide services\n\u2022 Early Adopter Target Customers:\no Service Suppliers: Freelancers & Students\no Service Consumers: New to community & Small businesses\n\u2022 Advantages/Values:\no Inclusivity & diversity (service coverage & user coverage)\no Strengthening community connection\no Empowering users to develop skills and gain jobs\no Guaranteed for services and payments\n\n6. Business Ecosystem:\nService Suppliers:\n\u2022 Freelancers\n\u2022 Students\n\u2022 Professional Workers\n\u2022 Anyone who is willing to\nprovide services\nService Consumers:\n\u2022 Busy Professionals\n\u2022 New to Community\n\u2022 Small Businesses\n\u2022 Anyone who needs services\nPotential Partners:\n\u2022 Investment Companies\n\u2022 Consultancy Agencies\n\u2022 Technic Supporting Agencies\n\u2022 Public/Governmental Welfare Organizations\n\u2022 Local Communities\n\u2022 Pension Agencies\n\u2022 Other Non-profit Organizations\nAdvertising Channels:\n\u2022 Searching Engines: Google\n\u2022 Social Media Platforms: Facebook, Instagram, Twitter, Tiktok\n\u2022 Streaming Media Platforms: Netflix, YouTube, Amazon Prime Video, Disney+\n\u2022 News Media/Newspapers\n\n7. Financials (Assumption):\nRealistic:\n\u2022 Monthly Traffic: 15,000\n\u2022 Conversion Rate: 30%\n\u2022 Average Transaction: $200\n\u2022 Monthly Sales Revenue: $900,000\n\u2022 Commission: 8%\n\u2022 Monthly Projected Income: $72,000\n\u2022 Number of Labor Supply: 1,000\n\u2022 Percentage Starter Boost: 5%\n\u2022 Starter Boost Fee: $800\n\u2022 Monthly Starter Boost Income: $40,000\nIdeal:\n\u2022 Monthly Traffic: 30,000\n\u2022 Conversion Rate: 30%\n\u2022 Average Transaction: $200\n\u2022 Monthly Sales Revenue: $2,400,000\n\u2022 Commission: 8%\n\u2022 Monthly Projected Income: $144,000\n\u2022 Number of Labor Supply: 2,000\n\u2022 Percentage Starter Boost: 10%\n\u2022 Starter Boost Fee: $1,000\n\u2022 Monthly Starter Boost Income: $200,000\n\n8. Financials:\nRevenue (Monthly):\n\u2022 Commission (0.5% Growth Rate per month assumed): $72,000\n\u2022 Starter Boost: $40,000\n\u2022 Advertisement: $5,000\nUpfront Costs:\n\u2022 Development Cost: $30,000\n\u2022 Uptake Cost: $20,000\nMonthly Costs:\n\u2022 Operating Cost: $10,000\n\u2022 Marketing Cost: $5,000\n2024 Total Revenue:\n\u2022 Total Revenue: $703,160\no Advertisement: $5,000\no Starter Boost: $40,000\no Commission: $72,000\nRevenue Projections:\n\u2022 Jan: $52,000\n\u2022 Feb: $57,360\n\u2022 Mar: $57,722\n\u2022 Apr: $58,085\n\u2022 May: $58,451\n\u2022 Jun: $58,818\n\u2022 Jul: $59,187\n\u2022 Aug: $59,558\n\u2022 Sep: $59,931\n\u2022 Oct: $60,306\n\u2022 Nov: $60,682\n\u2022 Dec: $61,060\n\n9. Implementation:\nLean Startup Method:\n1. Assumptions:\n\u2022 Freelancers need more jobs\n\u2022 Busy working individuals need more help with house services\n\u2022 Time consuming to search for help with some services\n2. Survey (Current Status):\n\u2022 Survey the interest and needs of the target customer\n\u2022 Target working professionals, Sydney CBD, LinkedIn, and survey small business and freelancers to know if they are interested\n3. Analyze the data (April 2023):\n\u2022 Above 70% positive results \uf0e0 move ahead with MVP for all the questions\n\u2022 Less than 70% \u2192 Pivot makes changes to meet customer needs\n4. Design MVP (July 2023):\n\u2022 App with basic features\n\u2022 Small area - Sydney CBD\n\u2022 Most commonly needed services\n\u2022 Partner with freelancers to join the platform\n\u2022 Feedback Included\n\u2022 Spread the word using LinkedIn\n5. Persist/Pivot/Perish (October 2023):\n\u2022 Success Criteria: Good Feedback (80% or 4+ star rating); at least 40-50 customer signups and transactions per month for the first 2 months; good User Growth\n\u2022 PIVOT: Only 50% positive feedback or ~less than 40 Users.\n\u2022 PERISH: 70% Negative feedback or ~10 Users; no User Growth.\n\n10. Implementation (Continued):\nCurrent Status:\n\u2022 Created a survey\n\u2022 Sending the survey to currently working professionals\n\u2022 Receiving feedback and interest in our app\n\u2022 Survey on LinkedIn as it has a large number of working professionals who have busy lives and would need help to maintain their house or other home services\nMVP Test:\n\u2022 App developer\n\u2022 UX/UI designer\n\u2022 Funding through bootstrapping\n\u2022 Gain a large number of users to test the product\n\n11. The Ask (Investment Proposal):\nThe Opportunity:\n\u2022 Invest in Helpmates pre-launch\n\u2022 App to aggregate and simplify searching for a large variety of services in one easy-access platform\n\u2022 Promoting accessible casual and freelance employment\n\u2022 Simple and low cost platform with potential for large commission based earnings\nOffer:\n\u2022 Investment of $50,000 for 10% equity\nUse:\n\u2022 $30,000 investment in targeted marketing for Sydney home service providers\n\u2022 $20,000 incentives and referral bonus for launch to increase service providers\nDesired Outcome:\n\u2022 Large-scale influx of service providers in the area to increase offering for customers\nAdditional Requests:\n\u2022 Networking with digital marketing professionals\n\u2022 Networking with a SaaS CTO to help drive the and UI/UX\nNext Steps:\n\u2022 Increase service types offering (e.g. babysitting, tutoring, bartending, hairdressing, etc.)\n\u2022 Expand into new regions with initial investments and incentives to boost app uptake\n\u2022 Continue spending 30% of revenue on marketing in order to expand the business and grow users", "This is the first content. Also provide me with the headings of the first content.\nI only want you to reply \"acknowledged\" to remember the first content. I will give you the next content after you acknowledge the first content. \nWhat Is a Fiduciary Duty? Examples and Types Explained\n\nWhat Is a Fiduciary Duty?\nFiduciary duty refers to the relationship between a fiduciary and the principal or beneficiary on whose behalf the fiduciary acts.\n\nThe fiduciary accepts legal responsibility for duties of care, loyalty, good faith, confidentiality, and more when serving the best interests of a beneficiary. Strict care must be taken to ensure that no conflict of interest arises to jeopardize those interests.\n\nKEY TAKEAWAYS\nA fiduciary duty involves actions taken in the best interests of another person or entity.\nFiduciary duty describes the relationship between an attorney and a client or a guardian and a ward.\nFiduciary duties include duty of care, loyalty, good faith, confidentiality, prudence, and disclosure.\nIt has been successfully argued that an employee may have a fiduciary duty of loyalty to an employer.\nA breach of fiduciary duty occurs when a fiduciary fails to act responsibly in the best interests of a client.\n\nExamples of Fiduciary Relationships\nTrustee/Beneficiary\nA single parent with young children might create a trust to administer the assets that the children would inherit should the parent die while the children are still underage.\n\nIn this case, the parent will name a person or an entity, such as a law firm or bank, as trustee of the estate. That person or entity has a fiduciary duty to the children, who are the beneficiaries of the estate.\n\nIn a trustee/beneficiary relationship, the fiduciary (trustee) has legal ownership of the property and controls the assets held in the trust.\n\nAs fiduciary, the trustee must make decisions that are in the best interest of the beneficiary as the latter holds equitable title to the property.\n\nThe trustee/beneficiary relationship is an important aspect of comprehensive estate planning. Special care should be taken to determine who is designated as trustee.\n\nGuardian/Ward\nIn a guardian/ward relationship, an adult is designated as the legal guardian of a minor child. The guardian, as the fiduciary, is tasked with ensuring that all matters related to the daily welfare of the child are dealt with responsibly and in the best interests of the child. This care can include such things as deciding where the child will attend school, arranging for health care, and providing an allowance.\n\nA guardian may be appointed by a state court when a parent dies or is unable to care for the child for other reasons. In most states, the guardian/ward relationship remains intact until the minor child reaches adulthood.\n\nAgent/Principal\nAny person, corporation, partnership, or government agency might be called upon to act as agent without conflict of interest on behalf of a principal.\n\nA common example of an agent/principal relationship that implies fiduciary duty is that between the executives of a company and its shareholders. The shareholders expect that the executives will make well-considered, prudent decisions on their behalf and in their best interests as owners.\n\nA similar fiduciary relationship exists between personal investors and the fund managers they select to manage their assets.\n\nAttorney/Client\nThe agreement between an attorney and a client is arguably one of the most stringent of fiduciary relationships.\n\nThe U.S. Supreme Court has stated that the highest level of trust and confidence must exist between an attorney and a client. An attorney, as a fiduciary, must act with fairness, loyalty, care, and within the law on behalf of the client.\n\nAttorneys can be sued for breaches of their fiduciary duties by clients. They are accountable to the court in which a client is represented when a breach occurs.\n\nControlling Stockholder/Company\nIn certain circumstances, fiduciary duties may be required of a stockholder who possesses a majority interest in a corporation or who exercises control over its activities. A breach of fiduciary duty may result in personal legal liability for the controlling shareholder as well as directors and officers.\n\n The adjective fiduciary means held or given in trust. A fiduciary commits to acting in the best interests of a principal or beneficiary.\nTypes of Fiduciary Duties\nFiduciary duties may differ depending on the type of beneficiary that a fiduciary serves. However, in general, the legal and ethical obligations related to protecting the interests of beneficiaries include the following duties.\n\nDuty of Care\nThis is the responsibility to inform oneself as completely as possible in order to exercise sound judgments that protect a beneficiary's interests. It can involve the thoughtful consideration of options and sensible decision-making that's based on a careful examination of available information.\nDuty of Loyalty\nThis pertains to acting in the best interest of the beneficiary at all times, putting their well-being first and foremost. It includes the duty of the fiduciary to excuse themself from taking actions when there's a conflict of interest with the beneficiary's welfare.\n\nDuty of Good Faith\nThis duty pertains to always acting within the law to advance the interests of the beneficiary. At no time should the fiduciary take actions that are outside of legal constraints.\nDuty of Confidentiality\nA fiduciary must maintain the confidentiality of all information relating to the beneficiary. They must not use any form of it, whether written or spoken, for their personal gain.\n\nDuty of Prudence\nFiduciaries must administer matters and make decisions concerning the interests of beneficiaries with the highest degree of professional skill, caution, and critical awareness of risk.\n\nDuty to Disclose\nFiduciaries must engage in completely forthright behavior, disclosing any and all relevant information that could have an impact on their ability to carry out their duties as fiduciary and/or on the well-being of a beneficiary's interests.\n\nBreaches in Fiduciary Duty\nFiduciary duties are taken on by individuals and entities for various types of beneficiaries. Such relationships include, among others, lawyers acting for clients, company executives acting for stockholders, guardians acting for their wards, financial advisers acting for investors, and trustees acting for estate beneficiaries.\n\nAn employee may even have a fiduciary duty to an employer. That is, employers have a right to expect that employees are acting in their best interests. For example, they are not sharing trade secrets, or using company equipment for private purposes, or stealing customers from a competitor.\n\nThese expectations may not be actual fiduciary duties but they may be spelled out in an employee handbook or contract clause.\n\nCase law indicates that breaches of fiduciary duty most often happen when a binding fiduciary relationship is in effect and actions are taken which violate or are counterproductive to the interests of a specific beneficiary.\n\nTypically, the inappropriate actions are alleged to have benefitted the fiduciary's interests or the interests of a third party instead of a principal's or beneficiary's interests. In some cases, a breach stems from a fiduciary's failure to provide important information to a client, which leads to misunderstandings, misinterpretations, or misguided advice.\n\nDisclosure of any potential conflict of interest is important in a fiduciary relationship because any conflict can be seen as a cause for a breach of trust.\n\nConsequences of a Fiduciary Breach\nA breach of fiduciary duty can lead to a number of consequences. Not all of them are legal consequences.\n\nAn accusation of a breach of fiduciary duty can hurt the reputation of a professional. A client can end a professional relationship because they do not trust in a professional\u2019s care of the required fiduciary duty.\nIf a breach of duty case proceeds to the courts, steeper consequences can result. A successful breach of fiduciary duty lawsuit can result in monetary penalties for direct damages, indirect damages, and legal costs.\nA court ruling can also lead to industry discrediting, the loss of a license, or removal from service.\nHowever, proving a breach of fiduciary duty is not always easy.\n\nElements of a Fiduciary Breach Claim\nA number of legal precedents and elements have been established to allow claims by those who have been harmed by a breach of fiduciary duty. Jurisdictions differ, but in general, the following four elements are essential if a plaintiff is to prevail in a breach of fiduciary duty claim.\n\nA Duty Existed\nThe plaintiff must show that a legal fiduciary duty existed. Many professionals are obligated, legally and ethically, to conduct their businesses honestly. However, that doesn't mean that they are fiduciaries who must act solely in the interest of a particular client. A fiduciary duty is accepted as such by a fiduciary, typically in writing.\n\nA Breach Occurred\nThe plaintiff must show that a fiduciary duty was breached. The type of breach varies in every case. For example, if an accountant was sloppy in filling out a client's tax returns, and the client was slapped with an enormous fine for nonpayment, the accountant may be guilty of a breach of fiduciary duty. However, if the client was sloppy and failed to provide complete and necessary information, no breach occurred.\n\nDamage Was Sustained\nThe plaintiff must show that the breach of trust caused actual damage. Without damage, there is usually no basis for a breach of fiduciary duty case. The more specific a principal or beneficiary can be with facts of damage, the better.\n\nFor example, a trustee might be sued for selling a beneficiary's property too cheaply. If the buyer is a relative of the trustee, it's clearly a conflict of interest. However, a specific accounting relating to the loss to the beneficiary is needed to prove a breach of fiduciary duty.\n\nCausation Was Proved\nCausation shows that any damages incurred by the plaintiff were directly linked with the actions taken in breach of fiduciary duty. In the above example of a property sale, the link appears to be clear. However, the trustee might argue that a quick sale was in the best interest of the beneficiary and that no other buyer was interested.", "Please continue writing the article with the upcoming transcript, the first three headings are complete. No need to restate them in your response.\n\nRemember your prompt: Imagine you are a world-class SaaS Sales and Customer Success Enablement and Training AI. \n\nYour Task: You need to produce a wiki article from the transcript of a training session on our new Cross-Workspace Collaboration (XWC) vs our existing Guest User Experience feature. At the end, you will also produce an FAQ, save Question and Answers from each part to a document called \"QnA\".\n\nTo help you create headings for the wiki article I've provided the agenda for the session as a suggestion.\n\nIntroduction (Completed)\nWhy was Cross Workspace Collaboration created? (Completed)\nUnderstanding Guest User Feature (Completed)\nUnderstanding Cross Workspace Collaboration Feature (Discussed in this part)\nKey Differences Between Guest User and Cross Workspace Collaboration Features (Discussed in this part)\nPricing and plans (To be discussed in a later part)\nTips for Suggesting the Right Feature to Customers (May be discussed in this part)\n\nI will provide the transcript in separate parts, here's the sixth part: \n\"00:35:00\nEmily Iba\u00f1ez: Right right. Okay, that makes sense. Thanks.\nSarah Collins: Okay, so this is I'm looping back. This is the portion that I was mentioning. I had an existing note. If you recall And so what happens now is that I get this little modal which tells me that I can slip switch strings to the actual one. That is owned. By my collaborators.\nSarah Collins: So, I can switch between these two.\nJoe Fleming: Yeah, yeah, that's super cool. Yeah. And the UX is pretty nice actually. So, okay, cool. Good to know. So this is as a sidebar, one of the things that we need to do decide as a team is how we use. Do we need to standardize how we use this feature because like, this now opens up the ability to Actually, truly use fellow with our customers. And eat our own dog food, assign them, action items have a mutual action plan with them, but in fellow and it's not a pain for them to be able to collaborate. So like it also it gives our customers a clear reason to come back into the product as well, right? Because they'll come back into the product and they will work on the notes that we have.\nJoe Fleming: Sending them, right. So that I think that that's gonna be super helpful, especially in the POC process and with the multiple assigned, as Marcus said, We can, like assign to all of the people that join a training session and get them to do things. And we'll know, like, whether they've checked it off or not. So we can follow up with those people specifically and we can follow up in their fellow instance, we can assign them, action items directly in their fellow.\nSarah Collins: Yeah, exactly. So this is super powerful, especially because you're gonna have the option to also Have multia signing and crossword stays. So if I was working with a customer, for example, we are onboarding a few people right now and I'm using us for a kickoff note. I can have every single person on that note be assigned to install the desktop and then they're gonna see this inside of their actual fellow account.\nJoe Fleming: Here. Okay.\nSarah Collins: To complete it. So if I now go into my action items here, Install, the Desktop app.\nSarah Collins: oh,\nEmily Iba\u00f1ez: I was doing those sounds when I was on mute.\nSarah Collins: What?\nJoe Fleming: Yeah, exactly. And there's a nice little progress bar. It's awesome. Just I want to make sure that we have time for both questions. And I think the big question like the big thing though to touch on and I'm very keen to get your take on the Sarah is What? Cuz, like, the use cases are the use cases for crossword space and for guests basically the same. I guess that's one question. Are there any additional use cases and\nJoe Fleming: aside from that, like, Is there any case where like people shouldn't choose the guest experience over the crossword space experience?\nSarah Collins: Great question. So there's a few differentiations between the two and really it comes back to what the capacity that you're working with this person in. So I would use crossword space in onboarding here at fellow and onboarding customers because it's going to be for a prolonged period of time. So in that case, if I was choose the guest experience, their access is going to expire and their existing fellow users, so they're not going to see any of their action items in their own work space, which in the past has meant that those action items. Never get looked at again because you have to log into that separate fellow workspace in order to view them. So the time that you want to use crossword space is if the guest either has an existing fellow account or they are willing to open up a fellow account and connect their calendar, if they're willing to do those two things. Cross workspace is a much better experience.\nSarah Collins: But if it's kind of like a one-time access scenario, and they're just meeting that one time. They don't plan on meeting again in the future, but for whatever reason they need collaboration for that one meeting. In that case, I would recommend guest if there's security issues because explaining to someone who doesn't know and or understand fellow, even from new customers that we're on board. Their number one, fear is, What are you doing with my calendar Information? That fear prevents a lot of people from actually sending up to fellow to begin with because they don't understand why we need access to that information because they haven't hit their aha moment yet. So if that fear is really prevalent, then guest users is a really good option. Otherwise collaborate collaborative access through crossword space. It's overall in my opinion, a much smaller experience and it removes. A lot of that friction that you would tend to find with just the regular guest experience.\n00:40:00\nSarah Collins: Like, the access link expiring and all that stuff.\nSarah Collins: I heard some questions, feel free that pop in and ask them.\nSarah Collins: Yeah, exactly.\nJoe Fleming: Yeah, I would default. I would be fob to crossword space. Pretty much all the time even if it's short term. because at the end of the day, like, I think the the other way to look at it is every, every crossword space is an opportunity for another lead. For us. So it's better\u2026\nSarah Collins: Yeah. I agree.\nJoe Fleming: if they use even if they don't continue to use it, the other thing is is like keep in mind. For like our end internally. every single time somebody connects their calendar, it means that Like, we can find out. if this person or any other person, that logs in, if they have a ton of meetings, recurring meetings in their calendar, it means we know like, hey,\nJoe Fleming: This person will really care about this tool. Maybe we should like whether it's us as a sales, team manually going after these people and saying, Hey like you're in meetings all the time. You know, here's an opportunity to make your meetings better or if it's like through the product or some other way. Like every single calendar, connect helps us continue to grow our base and target people. That actually are experiencing. The problem that we solve. So I think this is why it's so important is because like the you know, building the database of users is a big part of building the business, so cool. So I think that like covers, most of the things here in terms of pricing in plans,\nSarah Collins: The four-way move on to that Joe. Can I just munch one last thing? Onboarding experience for crossword space is a little bit different.\nJoe Fleming: Yeah, of course.\nSarah Collins: We're optimizing to get them right into that meeting that they are going to be collaborating with that other company. So they're not getting, that usual onboarding flow and that's important to mention because they're a ha moment is gonna come from that collaborative access. And then they explore everything else that fellow has to offer after the fact.\nSarah Collins: Yes. Question.\nEmily Iba\u00f1ez: Yeah. Yeah, I said a question. So you mentioned so like if I have a pro plan and I'm sharing my note with Joe, but Joe's on free in two weeks. Once Joe loses access to his note history, does that mean he also won't, he won't be able to see like our past notes. But I will. because,\nSarah Collins: That's a great question. And I can't remember what product told me for that one.\nEmily Iba\u00f1ez: Okay, no worries. Just because like, I'm envisioning it being like me saying, Hey Joe, like look at our note from three weeks ago, and then Joe's, like Why can't I see it? But you can't see it, right? So,\nSarah Collins: Yeah, that's a great question. I'm like, 50%. Sure that they told me that for cross works. Basic collaboration notes that you do retain the access because it's technically owned by the workspace that is upgraded. But we should definitely talk with product on that\u2026\nEmily Iba\u00f1ez: Right.\nSarah Collins: because I'm not a hundred percent sure.\nEmily Iba\u00f1ez: It would also be a good paywall though maybe to upgrade the free person, then they feel like they're missing out on the notes, right? So,\nSarah Collins: All the fellow. Yeah.\nSarah Collins: Awesome. Okay. Sorry Joe. What was your next question there?\"", "CHAPTER TWELVE\n\nDATA TRACKING AND ANALYTICS\n\nAnalyzing data generated by your digital marketing initiatives and on your digital domains\nis the goal of digital marketing analytics, which tracks and uses this data. Data for digital\nanalytics is often gathered and structured in a timeframe that is very close to real time.\nAnalytics in digital marketing would be useful for the following three reasons in particular:\nIn order to get an accurate measurement of your marketing performance, In order to discover unexplored possibilities\nIn order to facilitate improved decision-making by both people and algorithms.\nInteractions between users on any or both of the following platforms are the key sources\nof this data:\nData from digital marketing e orts, such as Search Engine Marketing, Video on Demand\n(VoD), Social Media, or email Marketing campaigns, for example.\nYour owned properties are the actions that users perform after reaching either your\nwebsite or app.\nThese data are supplemented by a variety of analytic methods. For instance, the analysis\nof the voice of the client, the analysis of the competition, and the feedback from\noptimization initiatives.\nIn order to perform digital marketing analytics, you will need to set up tracking that will\nmonitor the activities of relevant users. This could mean tracking the pages that customers\nof your eCommerce website visit, the products they buy, and the amount of money you\nmake as a result of these sales.\nReasons why analytics for digital marketing are so crucial\nEstablishing reliable analytics for your digital marketing is essential for several reasons,\nincluding the following:\nIt evaluates the e ectiveness of your campaigns and the money you invest. Because of this, you will have the ability to try a variety of tactics and increase the\ne ectiveness of your e orts.\nProvides precise facts to help your decision-making. Decisions made by people (such as strategy) and machines (such as bidding algorithms) are only as useful as the facts they are based on to the extent that they are derived from.\nThe ability to recognize opportunities inside your marketing activity is provided to you. Analytics for digital marketing can distill meaningful and actionable insights from millions of customer interactions.\nYour various channels will all receive more value as a result of solid analytics. You can uncover anything from minute tweaks to fundamental shifts in your business plan with its assistance.\nAn overview of the fundamental steps involved in digital marketing analytics\n\nThis is a very high-level summary of the process that is used to track a user.\nThe applications and con gurations will be di erent for each website. But the following\nactions will need to be taken in order to trace down a single user.\nWhen users do actions on your website, such as view pages or click inside the sites, tiny\nsnippets of code record these events and then put them into the so-called \"data layer.\"\nThe data layer is a portion of the website that is located behind the scenes, and its primary\nfunction is to collect and organize the various types of useful data that are acquired there.\nWe set up \"Tracking tags\" to record a variety of di erent activities. The 'trigger' is another\nname for the action that a tracking tag is attempting to record when it does so. Because of\nthis trigger, the tag is considered to have \" red.\" These tracking tags access the data layer\nand pull out any pertinent information before sending it to an analytics platform.\nIn addition, you provide each person who visits your website with a \"cookie\" as soon as\nthey do so. A cookie is an identi er that can be used to recognize a speci c user during\ntheir current visit as well as future visits. It helps you piece together all of their separate\nactivities.\nTake, for instance, the path that a consumer takes when they buy a product; it might look something like this.\nThe loading of a \"thank you for buying\" page by the user could cause the tracking tag to\nbe activated.\nThere will be information about the things that they purchased, the price that they paid for\nit, and other speci cs contained within the data layer of the page.\n\nAll of this data is transmitted via the tracking tag to the analytics platform, where it is made\nlegible for the analyst, which in this case is you.\n\nCOOKIES AND DIGITAL MARKETING ANALYTICS\n\nHow exactly do cookies factor into the analytics of digital marketing?\nCookies are very small pieces of code that are stored on your computer by your web\nbrowser. These make it possible for websites to recognize you on subsequent visits.\nIt's possible that you can set some cookies to record only the most essential information\nthat's needed to make the website usable. For instance, in order for an e-commerce\nwebsite to recognize when you have added things to your shopping basket, cookies are\nrequired. Without cookies, the website you are using would forget everything about you\nevery time you loaded a new page, and it would treat you as if you were a completely\nnew user.\nOther cookies, which are referred to as \"third-party cookies,\" will follow you about when\nyou browse other websites in order to better comprehend your broader aims. This is\nillustrated by the Facebook Pixel, for instance. This is how Facebook is able to determine\nwhich websites you have visited and then target you with advertisements pertaining to\nthose websites.\nTRACKING DATA EFFECTIVELY\n\nTo ensure that you are making the most of Google Analytics and that all of your bases are\ncovered, let's spend some time going over some of the recommended best practices.\n\nTracking: To begin, we will track. You have to check to make sure that the code for\ntracking analytics is included on each and every page. You also need to make sure that it\nhas been modi ed to cover all relevant domains, so that you can track client interactions\nwith your website, ecommerce transactions, and so on. This will allow you to monitor and\nanalyze customer behavior.\nDi erent Views: In order to make the most of Google Analytics' tracking features, you\nneed to double check that multiple Views have been set up. Views such as time zone,\ndefault page, currency, Google Ads cost source, and site-search tracking are all\nexamples of useful views.\n\nVisits from within the rm You shouldn't track visits from within your own company or\nfrom any of your partners because this can skew the tra c and conversion metrics.\nTherefore, you should make sure that your Google Analytics Views contain Internal IP\n ltering so that data reports do not include tra c from your employees or partners.\nUn ltered view Having an un ltered view for the purposes of reference is considered to\nbe the best practice. This type of view is typically referred to as the \"All Site Data\" view.\nBecause no lters are applied to it, you will always have a baseline to report against.\nDe ne your Key Performance Indicators (KPIs): Keep in mind that everything you are\ntracking in Google Analytics is for the purpose of assisting you in delivering on your Key\nPerformance Indicators (KPIs). Therefore, before you begin to analyze the data from your\ncampaign, it is vital to set your key performance indicators (KPIs), so that the e cacy of\nthe campaign can be benchmarked against these metrics. In the same vein, it is very\nnecessary to con gure Goals in Google Analytics in order to have a method of calculating these KPIs\nThe last word on website analytics is to examine the importance of adequately tracking\no ine marketing activity in addition to online marketing activity. This is the nal word on\nwebsite analytics since it is the nal word on website analytics. Because not all transactions\nor activities take place online, it is essential to monitor the o ine aspects that can have an\nimpact on user behavior and conversions. This will allow you to take the required steps\nand make decisions that are more well-informed.\n\nDIGITAL MARKETING ANALYTICS TOOLS\n\nFor the purpose of conducting analytics for digital marketing, a diverse selection of tools\nis currently accessible. Some essential tools are as follows:\nTag management solutions, such as Google Tag Manager or Adobe Experience Platform,\nare examples of this. These make it simple for you to install tracking tags on your website.\nThis is where you will establish the guidelines and conditions, after which they will inject\nthe tracking tags onto your website.\nAnalytics Platforms, such as Google Analytics and Adobe Analytics, are examples of such\ntools. These get data from your website, link it all together, and make it possible to\nconduct analysis quickly. There are additional analytics solutions that are platform speci c\nthat are included in advertising platforms. Google Ads and Facebook Ads Manager each\ncome equipped with their own basic analytics features.\nPlatforms for Customer Relationship Management (CRM), such as Hubspot and\nSalesforce.com. These are often employed when your ultimate goals include tracking\nsign-ups and the development of leads, among other things.\nData Management Platforms, often known as DMPs, are typically used to integrate all of\nthe data that is owned by a company and are populated by that company. It's possible\nthat this is a combination of data collected online and o ine. For instance, there is\nFunnel.io, Tableau, SQL databases, and the services provided by AWS. These skills\nfrequently include visualization aspects.\nTools for data visualization let you present the information that you have obtained from\nyour data management platform (DMP) in a way that is understandable and practical for\nusers. Examples of often utilized tools include everything from the user-friendly (and free)\nGoogle Data studio to the more advanced Power Bi and Tableau. For the purpose of\nproviding effective visualizations, we also make use of some of the marketing\ntechnologies that we have developed in-house, namely Ayima Query.\nSoftware for search engine optimization (SEO) monitors how well your marketing\ncampaigns work on pages of search results. Google Search Console is the tool that is\nutilized most frequently for this purpose. There are, however, additional tools that are\nmore specialized, such as SEO Clarity, Moz, and the Ayima Reporting Tool. These\nprovide a signi cantly more in-depth analysis of your keyword rankings.", "=== INSTRUCTIONS ===\nYour task is ONLY to confirm receipt of this chunk, chunk 3/3, and not generate any text. You have now received all the chunks. Please wait for further instructions.\n=== SCRIPT CHUNK 3/3 ===\n wishing it were Ujunwa; the Zimbabwean said Edward\u2019s eyes were always leering when he looked at Ujunwa; the white South African said Edward would never look at a white woman like that because what he felt for Ujunwa was a fancy without respect. \u201cYou all noticed?\u201d Ujunwa asked them. \u201cYou all noticed?\u201d She felt strangely betrayed. She got up and went to her cabin. She called her mother, but the metallic voice kept saying \u201cThe number you are calling is not available at the moment, please try later,\u201d and so she hung up. She could not write. She lay in bed and stayed awake for so long that when she finally fell asleep, it was dawn. That evening, the Tanzanian read an excerpt of his story about the killings in the Congo, from the point of view of a militiaman, a man full of prurient violence. Edward said it would be the lead story in the Oratory, that it was urgent and relevant, that it brought news. Ujunwa thought it read like a piece from The Economist with cartoon characters painted in. But she didn\u2019t say that. She went back to her cabin and, although she had a stomachache, she turned on her laptop. As Chioma sits and stares at Yinka, settled on the alhaji\u2019s lap, she feels as if she is acting a play. She wrote plays in secondary school. Her class staged one during the school\u2019s anniversary celebration and, at the end, there was a standing ovation and the principal said, \u201cChioma is our future star!\u201d Her father was there, sitting next to her mother, clapping and smiling. But when she said she wanted to study literature in university, he told her it was not viable. His word, \u201cviable.\u201d He said she had to study something else and could always write on the side. The alhaji is lightly running a finger over Yinka\u2019s arm and saying, \u201cBut you know Savanna Union Bank sent people to me last week.\u201d Yinka is still smiling and Chioma wonders whether her cheeks are aching. She thinks about the stories in a metal box under her bed. Her father read them all and sometimes he wrote in the margins: Excellent! Clich\u00e9! Very good! Unclear! It was he who had bought novels for her; her mother thought novels a waste of time and felt that all Chioma needed were her textbooks. Yinka says, \u201cChioma!\u201d and she looks up. The alhaji is talking to her. He looks almost shy and his eyes do not meet hers. There is a tentativeness toward her that he does not show toward Yinka. \u201cI am saying you are too fine. Why is it that a Big Man has not married you?\u201d Chioma smiles and says nothing. The alhaji says, \u201cI have agreed that I will do business with Merchant Trust but you will be my personal contact.\u201d Chioma is uncertain what to say. \u201cOf course,\u201d Yinka says. \u201cShe will be your contact. We will take care of you. Ah, thank you, sir!\u201d The alhaji gets up and says, \u201cCome, come, I have some nice perfumes from my last trip to London. Let me give you something to take home.\u201d He starts to walk inside and then turns. \u201cCome, come, you two.\u201d Yinka follows. Chioma gets up. The alhaji turns again toward her, to wait for her to follow. But she does not follow. She turns to the door and opens it and walks out into the bright sunlight and past the Jeep in which the driver is sitting with the door hanging open, listening to the radio. \u201cAunty? Aunty, something happen?\u201d he calls. She does not answer. She walks and walks, past the high gates and out to the street where she gets in a taxi and goes to the office to clear out her almost-empty desk. Ujunwa woke up to the crashing sound of the sea, to a nervous clutch in her belly. She did not want to read her story tonight. She did not want to go to breakfast, either, but she went anyway and said a general good morning with a general smile. She sat next to the Kenyan and he leaned toward her and whispered that Edward had just told the Senegalese that he had dreamed of her naked navel. Naked navel. Ujunwa watched the Senegalese, delicately raising her teacup to her lips, sanguine, looking out at the sea. Ujunwa envied her confident calm. She felt upset, too, to hear that Edward was making suggestive remarks to someone else, and she wondered what her pique meant. Had she come to see his ogling as her due? She was uncomfortable thinking about this, about reading that night, and so in the afternoon, lingering over lunch, she asked the Senegalese what she had said when Edward spoke of her naked navel. The Senegalese shrugged and said no matter how many dreams the old man had, she would still remain a happy lesbian and there was no need to say anything to him. \u201cBut why do we say nothing?\u201d Ujunwa asked. She raised her voice and looked at the others. \u201cWhy do we always say nothing?\u201d They looked at one another. The Kenyan told the waiter that the water was getting warm and could he please get some more ice. The Tanzanian asked the waiter where in Malawi he was from. The Kenyan asked him if the cooks, too, were from Malawi as all the waiters seemed to be. Then the Zimbabwean said she did not care where the cooks were from because the food at Jumping Monkey Hill was simply sickening, all that meat and cream. Other words tumbled out and Ujunwa was not sure who said what. Imagine an African gathering with no rice and why should beer be banned at the dinner table just because Edward thought wine was proper and breakfast at eight was too early, never mind that Edward said it was the \u201cright\u201d time and the smell of his pipe was nauseating and he had to decide which he liked to smoke, anyway, and stop rolling cigarettes halfway through a pipe. Only the black South African remained silent. He looked bereft, hands clasped in his lap, before he said that Edward was just an old man who meant no harm. Ujunwa shouted at him, \u201cThis kind of attitude is why they could kill you and herd you into townships and require passes from you before you could walk on your own land!\u201d Then she stopped herself and apologized. She should not have said that. She had not meant to raise her voice. The Black South African shrugged, as if he understood that the devil would always do his work. The Kenyan was watching Ujunwa. He told her, in a low voice, that she was angry about more than just Edward and she looked away and wondered if \u201cangry\u201d was the right word. Later, she went to the souvenir shop with the Kenyan and the Senegalese and the Tanzanian and tried on jewelry made of faux ivory. They teased the Tanzanian about his interest in jewelry\u2014 perhaps he was gay, too? He laughed and said his possibilities were limitless. Then he said, more seriously, that Edward was connected and could find them a London agent; there was no need to antagonize the man, no need to close doors to opportunity. He, for one, didn\u2019t want to end up at that dull teaching job in Arusha. He was speaking as though to everyone, but his eyes were on Ujunwa. Ujunwa bought a necklace and put it on and liked the look of the white, tooth-shaped pendant against her throat. That evening Isabel smiled when she saw it. \u201cI wish people would see how faux ivory looks real and leave the animals alone,\u201d she said. Ujunwa beamed and said that it was in fact real ivory and wondered whether to add that she had killed the elephant herself during a royal hunt. Isabel looked startled, then pained. Ujunwa fingered the plastic. She needed to be relaxed, and she said this to herself over and over, as she started to read from her story. Afterwards, the Ugandan spoke first, saying how strong a story it was, how believable, his confident tone surprising Ujunwa even more than his words. The Tanzanian said she captured Lagos well, the smells and sounds, and it was incredible how similar Third World cities were. The white South African said she hated that term, Third World, but had loved the realistic portrayal of what women were going through in Nigeria. Edward leaned back and said, \u201cIt\u2019s never quite like that in real life, is it? Women are never victims in that sort of crude way and certainly not in Nigeria. Nigeria has women in high positions. The most powerful cabinet minister today is a woman.\u201d The Kenyan cut in and said he liked the story but didn\u2019t believe Chioma would give up the job; she was, after all, a woman with no other choices, and so he thought the ending was implausible. \u201cThe whole thing is implausible,\u201d Edward said. \u201cThis is agenda writing, it isn\u2019t a real story of real people.\u201d Inside Ujunwa, something shrank. Edward was still speaking. Of course one had to admire the writing itself, which was quite mah-ve-lous. He was watching her, and it was the victory in his eyes that made her stand up and start to laugh. The participants stared at her. She laughed and laughed and they watched her and then she picked up her papers. \u201cA real story of real people?\u201d she said, with her eyes on Edward\u2019s face. \u201cThe only thing I didn\u2019t add in the story is that after I left my coworker and walked out of the alhaji\u2019s house, I got into the Jeep and insisted that the driver take me home because I knew it was the last time I would be riding in it.\u201d There were other things Ujunwa wanted to say, but she did not say them. There were tears crowding up in her eyes but she did not let them out. She was looking forward to calling her mother, and as she walked back to her cabin, she wondered whether this ending, in a story, would be considered plausible.\n=== END OF CHUNK ===", "This is part 3 of my multiple messages. I will continue to send you further messages. Do not write anything for now. If you understand my request, please reply by only saying \"acknowledged\"\n\nMr Khan claimed that he checked with the glass supplier who was said to have advised that low e glass cannot be tinted but, when asked if he disclosed that to the owner, he said he did not know. Next, it was conceded the builder did not comply with the specification of \u201cRetaining wall split face blocks with caps\u201d.\n\nIt was agreed that the contract price of $980,000 comprised the tender amount of $895,000, $25,000 for \u201cSection 94\u201d (fees to council), and $60,000 for the pool, as recorded in handwriting on a page signed by the parties (A482). It was conceded that the pool was not built.\n\nAs to the time for completion, Mr Khan\u2019s evidence was that work commenced on 25 September 2020 (A442 at [31]). He agreed with the proposition that the time for completion, according to the contract was 38 calendar weeks after that, which was 18 June 2021, final payment was made on 29 November 2021 and that the keys were handed over on or about 3 December 2021. Matters relating to extensions of time are considered below.\n\nAfter being referred to the plans listed in the construction certificate (A622), Mr Khan accepted that the stormwater pits were not installed in accordance with the plan at A742 and likewise for the landscaping plan at A757.\n\nMr Khan agreed that he knew the owner intended to live in one of the units and that he was renting until it was built but denied knowing the owner was going to rent the other unit. His attention was directed to a 4 October 2021 text message (A97) in which he said: \u201cits you who will be losing rent and paying rent\u201d.\n\nIn re-examination, Mr Khan referred to text messages, containing photos, relating to the owner\u2019s selection of bathroom tiles (A579), which suggested a choice of grey floor tiles, while wall tiles, and a different choice of tile for use in the niche. He suggested the red handwriting on A455 was that of the owner\u2019s brother.\n\nExpert evidence\n\nReports were provided by Mr Borunelis for the owner (A850 and A1111) and by Mr Sim for the builder (A1278). A joint report was also provided (A1397). That expert is considered below, when dealing with the defects claim.\n\nOwner\u2019s submissions\n\nIn relation to the defects claim, it was submitted that the primary dispute was how many hours are required to carry out the rectification work and, in that regard, it was suggested the evidence of Mr Bournelis should be preferred to that of Mr Sim. Submissions were also made in relation to the other matters that were canvassed in cross-examination.\n\nAs to the low e glass, it was contended that low e tinted was included in the quote (A480), that it was accepted that the installed glass was clear, and that the experts agreed that low e glass can be tinted.\n\nNext, the feature tiles. It was said there was not 5 sqm of features tiles installed. Reference was made to the words and photos at A472. It was noted that Mr Sim agreed with the amount of $2,770 suggested by Mr Bournelis, on an \u2018if found\u2019 basis.\n\nThe third topic was insulation. It was claimed that ratings of 1.5 for acoustic, 3.5 for ceilings, and 2.5 for walls was required and that the experts agreed there was no insulation in the ceiling, but the method of rectification was in dispute,\n\nIn relation to drainage pits and stormwater, it was suggested that the experts agreed, and Mr Khan accepted, there had been a failure to comply with the plans.\n\nFifthly, submissions were made in support of the claim that scaffolding was required for the painting work.\n\nNext, the retaining wall. It was contended there was agreement that what was required was not installed, that it was not sufficient to refer to the wall functioning it was not aesthetically satisfactory, and that the decision in Tabcorp Holdings Ltd v Bowen Investments Pty Ltd [2009] HCA 8 (Tabcorp) at [17]-[18] set a high threshold for finding, when applying what was said in Bellgrove, that a method of rectification is not reasonable.\n\nAs to incomplete work, the owner claimed $21,480, being the cost to complete the pool less the amount attributed to that work in the contract price.\n\nOn the topic of the delay claim, it was contended that the delay period was from either 18 June 2021, according to the contract, or from 30 June 2021, by reason of the delayed notified by the builder, to either 5 November 2021, when the occupation certificate was issued, or 3 December 2021, when the keys were handed over. The owner was said to be paying $410 per week in rent and that a claim for that amount for was made in the owner\u2019s outline submissions for 18 or 22 or 24 weeks. It was acknowledged that a deduction of $2,000 should be made to allow for the payment already made for delay by the builder.\n\nIt was suggested that a loss of rent from the other unit either flowed naturally or was in reasonable contemplation of the parties, plainly a reference to the two limbs set out in Hadley v Baxendale (1854) 9 Exch 341 (Hadley). Reference was made to the text message sent by Mr Khan (A97) which was said to show awareness. That rent loss claim was said to be $750 per week for 22 weeks less a 4.4% real estate agent\u2019s fee, giving an amount of $15,774. There was a further claim, that the unit could not be rented until the defects were rectified, said to add a further 52 weeks, which added $37,284 ($750 per week for 52 weeks, less 4.4%) to the claim for lost rent for the second unit.\n\nOn the question of whether a work order or money order should be made, the points made were (1) the extent of the defects, (2) that the builder had disregarded its contractual obligations, (3) that there was a failure to recognise defects in the work, and (4) that there was unchallenged evidence of a breakdown in the owner-builder relationship (A33 at [131](a)).\n\nBuilder\u2019s submissions\n\nAs to s 48MA, it was suggested that the builder was ready, willing, and able to carry out rectification work and would be able to commence that work from 1 March 2023. In response to the suggestion of a relationship breakdown, it was indicated that the builder is willing to engage its expert, Mr Sim, to carry out the rectification work and for that work to be inspected/certified by Mr Bournelis.\n\nAllowing Mr Sim to carry out the rectification work was said to have advantages in that the Tribunal could be confident the necessary work would be done to the necessary standard and within time.\n\nIn relation to any difference between the evidence of Mr Sim and Mr Bournelis, it was noted that Mr Sim had made concessions which the builder accepted, and the Tribunal was urged to prefer his evidence to that of Mr Bournelis.\n\nOn the topic of damages for delay, the Tribunal was then taken through a sequence of dates and events relevant to these proceedings, from 15 January 2020 to 6 April 2022. Reference was made to the Public Health Orders provided to the Tribunal (MFI 4 and MFI 5). It was suggested that the owner was suggesting the second unit could not be rented at a time when he was living in the first unit and that a suggestion that a site was dangerous by reason of an outdoor barbeque was an insufficient basis for that rent claim.\n\nIt was observed that clause 5 of the contract (A496) required commencement of the building work within 60 working days of the latest of three events and that clause 6 (A497) required the builder \u201cto complete the work within 38 calendar weeks from the date when the work is due to commence as referred to in Clause 5\u201d. As the construction certificate was dated 18 September 2020, that was said to give a date for commencement of 14 December 2020. Adding 38 weeks was said to give 6 September 2021 and 16 days for the Public Health Orders gave 28 September 2021 Reference was made to s 3B of the HBA in relation to the date of completion of the work. The Tribunal was reminded that $2,000 had already been paid by the builder to the owner.\n\nSubmissions in reply\n\nReference was made to decision in The Owners \u2013 Strata Plan No 76674 v Di Blasio [2014] NSWSC 1067 (Di Blasio) in support of the proposition that the owner\u2019s claim for damages would only be affected if it could be said that he unreasonably refused an offer made by or for the builder.\n\nIt was also suggested that damages arose from the owner being deprived of use of the units, having to pay rent and not being able to earn rent, and that the obvious point when those damages stop is when the owner gains access which was said to be 3 December 2021.\n\nFinally, it was suggested that Mr Sim\u2019s involvement in the proceedings to date operated to exclude him from carrying out the rectification work and that a money order should be made, rather than a work order.", "This is part 4 of my multiple messages. I will continue to send you further messages. Do not write anything for now. If you understand my request, please reply by only saying \"acknowledged\"\n\nConsideration\n\nAssessment of witnesses. In his first affidavit, dated 28 June 2022, the owner said (A10 at [6]):\n\nThe plan for the other unit (Unit 1) was for my mother to live in it or to advertise it for rent once the building works were finished.\n\nIn his second affidavit, dated 8 July 2022, the plan for his mother to live in unit 1 was retracted (A140 at [58]), on the basis that his mother was living with his brother. There was no supporting evidence from either the owner\u2019s brother or their mother. That second affidavit, which was sworn only ten days after the first, does not explain why the evidence in the first affidavit was being changed.\n\nIt is to be noted that the second affidavit (dated 8 July 2022) suggested it was not until after the subject building work started (on 25 September 2020) that the owner\u2019s mother began living with his brother. But that evidence was known to the owner at the time he swore his first affidavit (28 June 2022).\n\nIn those circumstances, it appears the second affidavit was used to remove a non-compensable option (the owner\u2019s mother living in unit 1) and leave only the compensable option (unit 1 being rented). It is not necessary to make such a finding but that is a reason for treating the evidence of the owner with caution.\n\nSupport for that view derives from further evidence of the owner in relation to renting unit 1, namely his evidence as to whether that property could be rented without first addressing any defects. In his first affidavit (A33 at [128]), the owner said he had been informed by a real estate agent that the duplex referred to as unit 1 could be rented for between $750 and $770 per week and 11 pages were provided in support of that claim (A120-130), having been obtained from Azeem Khan of Quba Real Estate. In the same paragraph the owner added the sentence:\n\nHowever, because of the numerous defects identified, I have not been able to rent out Unit 1 to date.\n\nThe owner\u2019s second affidavit (A142 at [66]) suggested that, on or about 20 December 2021 when he was inspecting unit 1 for the purpose of preparing his rental appraisal, Mr Khan said words to the effect:\n\nThere are lots of defects. These will need to be fixed up before you get any tenants in.\n\nAgain, it is to be noted that the second affidavit (dated 8 July 2022) gave evidence of what Azeem Khan is alleged to have said on or about 20 December 2021, but that evidence was known to the owner at the time he swore his first affidavit (28 June 2022). Again, there is no explanation as to why the evidence in the second affidavit was not included in the first affidavit.\n\nAgain, what the owner said in his second affidavit sought to strengthen what he said on the topic of renting unit 1 by elevating his view to in his first affidavit to that of a real estate agent in his second affidavit. That evidence in the second affidavit raises the question as to why Azeem Khan did not say that is his rental appraisal and why the owner did not ask him to include that in his rental appraisal, a document obviously prepared after that inspection.\n\nAs Lord Mansfield observed almost 250 years ago, in Blatch v Archer [1774] ER 2; 1 Cowper 63 at 65:\n\nIt is certainly a maxim that all evidence is to be weighed according to the proof which it was in the power of one side to have produced ...\n\nThe Tribunal also considers the evidence of Mr Khan in support of the builder\u2019s case should also be viewed with caution by reason of his non-responsive answers during his cross-examination. It is noted that, while there were consecutive questions where he suggested there was compliance with the stormwater plan then accepted there wasn\u2019t compliance with the plan at A148, that is explained by the fact that there is an earlier plan (A539).\n\nIn these circumstances, the Tribunal is not prepared to make findings based on the uncorroborated evidence of either the owner or Mr Khan, each of whom has a significant financial interest in the outcome of these proceedings. It is preferable to place greater weight on contemporaneous documents.\n\nWork order or money order? It is convenient to first consider whether a work order or a money order should be made. The starting point is the statutory preference for a work order, established by s 48MA of the HBA. It is the Tribunal\u2019s view that a work order should be made for the following reasons.\n\nFirst, in the current environment, where building costs are increasing significantly, often over a short period, to make a money order based on costs assessed by an expert prior to the hearing to compensate an owner for costs incurred after the hearing may well leave the owner out of pocket. However, the effect of a work order in this instance will be that the owner is not out of pocket as the builder will bear the actual cost of rectification.\n\nSecondly, during his oral evidence, the owner indicated he was willing to have the rectification work carried out by another builder with that work being certified by Mr Bournelis and that was obviously also acceptable to the builder.\n\nIt is noted that Mr Sim remained in the hearing room during closing submissions, after his evidence was completed, and was thus present when the proposal that he carry out the rectification work was put to the Tribunal. For the avoidance of doubt, the Tribunal records that its decision to make a work order was influenced by the indication of the builder\u2019s counsel that Mr Sim would be carrying out the rectification work if the Tribunal made a work order.\n\nIf the builder retains someone other than Mr Sim to carry out that work, the owner will no doubt commence renewal proceedings in which a money order is sought instead of a work order.\n\nThirdly, according to the outline submissions for the owner (MFI 1) there are a total of 200 defects with many instances of different estimates by the experts of the time required to carry out the rectification work. Any assessment of those estimates is likely to create a result where the owner receives either too little or too much and the builder either pays too much or too little for at least some of the items of defective work. A work order removes that outcome because the owner bears the cost resulting from the actual hours required.\n\nFourthly, a work order would usually result in the rectification work being carried out either by the same builder who was responsible for the defective work, or another builder whose identity is not known to the owner. Further, that rectification work is sometimes carried out without any inspection on behalf of the owner. Here, the owner will have benefits: (1) knowing who will be carrying out the rectification work, (2) Mr Sim being familiar with the alleged defects), and (3) having that work inspected by the expert retained by the owner.\n\nFifthly, while it is accepted that the relationship between the owner and the builder has broken down, the work order proposed by the builder will not be affected by that breakdown in that the work will be carried out by Mr Sim with inspection by Mr Bournelis.\n\nContested items. Those two words are used to denote the seven items which were pursued during the cross-examination of the experts.\n\nIt is convenient to consider those items before assessing what should be the form of the work order. Various terms were used to distinguish between the two dwellings: the dwelling with the street number 14 was referred to as the dwelling on the left side and as unit 1; the dwelling with the street number 14A was referred to as the dwelling on the right side and as unit 2. The terms unit 1 and unit 2 are used below.\n\nLow e glass. The quotation, upon which the contract was based, specified: \u201cAll windows/doors smart low e laminated and tinted (Agreed, need to check tinted options)\u201d (A480 at 3)). The supplier\u2019s certificate indicated that \u201dLow-E Clear\u201d glass was supplied (A814). In his report, Mr Sim suggested that no tinting was required (A1294). When cross-examined, he accepted that it was possible to have both low e and colour tint, and that low e clear was installed. There was no cross-examination of Mr Bournelis in relation to this item.\n\nIn relation to this item, it is clear there was a failure to provide what was required by the contract and that the reasonable course is to supply and install window tint to all glazed windows and sliding doors rather than to replace the glass.\n\nFeature tiles. The quotation, under the heading \u201cBathrooms and ensuite\u201d, specified \u201cBathroom Tiles to the roof (300x6000) mm or (600x600) mm plus statement wall tile (5 sqm) in each bathroom from builder\u2019s rang (Capped to $30 sqm).\u201d (A467) and a picture underneath those words showed a feature tile on the entire wall behind the bath. Further, under the heading \u201cFlooring/tiling & Electricals\u201d, there appeared the words \u201cEvery bathroom to have statement Contrast feature wall (capped to 5 sqm each bathroom, Capped to $30 sqm).\u201d Underneath those words appeared three photos of feature tiles, one of round tiles and two of hexagonal tiles.\n\nWhat was, in fact, installed was feature tiles only in the niche of the wall behind the bath (A904 and A1132). There was no evidence in the owner\u2019s case that the feature tiles had a cost within the $30 per sqm cap and the only evidence of the cost of those tiles is that given by Mr Sim during his cross-examination.", "CompileC /Users/jameschege/Library/Developer/Xcode/DerivedData/mars-bunauennwhxvqrfemcgipearjqlg/Build/Intermediates.noindex/Pods.build/Debug-iphonesimulator/libevent.build/Objects-normal/arm64/signal.o /Users/jameschege/WebstormProjects/mars/ios/Pods/libevent/signal.c normal arm64 c com.apple.compilers.llvm.clang.1\\_0.compiler (in target 'libevent' from project 'Pods')\n cd /Users/jameschege/WebstormProjects/mars/ios/Pods\n /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/clang -x c -target arm64-apple-ios11.0-simulator -fmessage-length\\=0 -fdiagnostics-show-note-include-stack -fmacro-backtrace-limit\\=0 -std\\=gnu11 -fmodules -fmodules-cache-path\\=/Users/jameschege/Library/Developer/Xcode/DerivedData/ModuleCache.noindex -fmodules-prune-interval\\=86400 -fmodules-prune-after\\=345600 -fbuild-session-file\\=/Users/jameschege/Library/Developer/Xcode/DerivedData/ModuleCache.noindex/Session.modulevalidation -fmodules-validate-once-per-build-session -Wnon-modular-include-in-framework-module -Werror\\=non-modular-include-in-framework-module -Wno-trigraphs -fpascal-strings -O0 -fno-common -Wno-missing-field-initializers -Wno-missing-prototypes -Werror\\=return-type -Wdocumentation -Wunreachable-code -Werror\\=deprecated-objc-isa-usage -Werror\\=objc-root-class -Wno-missing-braces -Wparentheses -Wswitch -Wunused-function -Wno-unused-label -Wno-unused-parameter -Wunused-variable -Wunused-value -Wempty-body -Wuninitialized -Wconditional-uninitialized -Wno-unknown-pragmas -Wno-shadow -Wno-four-char-constants -Wno-conversion -Wconstant-conversion -Wint-conversion -Wbool-conversion -Wenum-conversion -Wno-float-conversion -Wnon-literal-null-conversion -Wobjc-literal-conversion -Wshorten-64-to-32 -Wpointer-sign -Wno-newline-eof -Wno-implicit-fallthrough -DPOD\\_CONFIGURATION\\_DEBUG\\=1 -DDEBUG\\=1 -DCOCOAPODS\\=1 -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator16.2.sdk -fstrict-aliasing -Wdeprecated-declarations -g -Wno-sign-conversion -Winfinite-recursion -Wcomma -Wblock-capture-autoreleasing -Wstrict-prototypes -Wno-semicolon-before-method-body -Wunguarded-availability -index-store-path /Users/jameschege/Library/Developer/Xcode/DerivedData/mars-bunauennwhxvqrfemcgipearjqlg/Index.noindex/DataStore -iquote /Users/jameschege/Library/Developer/Xcode/DerivedData/mars-bunauennwhxvqrfemcgipearjqlg/Build/Intermediates.noindex/Pods.build/Debug-iphonesimulator/libevent.build/libevent-generated-files.hmap -I/Users/jameschege/Library/Developer/Xcode/DerivedData/mars-bunauennwhxvqrfemcgipearjqlg/Build/Intermediates.noindex/Pods.build/Debug-iphonesimulator/libevent.build/libevent-own-target-headers.hmap -I/Users/jameschege/Library/Developer/Xcode/DerivedData/mars-bunauennwhxvqrfemcgipearjqlg/Build/Intermediates.noindex/Pods.build/Debug-iphonesimulator/libevent.build/libevent-all-non-framework-target-headers.hmap -ivfsoverlay /Users/jameschege/Library/Developer/Xcode/DerivedData/mars-bunauennwhxvqrfemcgipearjqlg/Build/Intermediates.noindex/Pods.build/Debug-iphonesimulator/libevent.build/all-product-headers.yaml -iquote /Users/jameschege/Library/Developer/Xcode/DerivedData/mars-bunauennwhxvqrfemcgipearjqlg/Build/Intermediates.noindex/Pods.build/Debug-iphonesimulator/libevent.build/libevent-project-headers.hmap -I/Users/jameschege/Library/Developer/Xcode/DerivedData/mars-bunauennwhxvqrfemcgipearjqlg/Build/Products/Debug-iphonesimulator/libevent/include -I/Users/jameschege/WebstormProjects/mars/ios/Pods/Headers/Private -I/Users/jameschege/WebstormProjects/mars/ios/Pods/Headers/Private/libevent -I/Users/jameschege/WebstormProjects/mars/ios/Pods/Headers/Public -I/Users/jameschege/WebstormProjects/mars/ios/Pods/Headers/Public/libevent -I/Users/jameschege/WebstormProjects/mars/ios/Pods/libevent/include -I/Users/jameschege/Library/Developer/Xcode/DerivedData/mars-bunauennwhxvqrfemcgipearjqlg/Build/Intermediates.noindex/Pods.build/Debug-iphonesimulator/libevent.build/DerivedSources-normal/arm64 -I/Users/jameschege/Library/Developer/Xcode/DerivedData/mars-bunauennwhxvqrfemcgipearjqlg/Build/Intermediates.noindex/Pods.build/Debug-iphonesimulator/libevent.build/DerivedSources/arm64 -I/Users/jameschege/Library/Developer/Xcode/DerivedData/mars-bunauennwhxvqrfemcgipearjqlg/Build/Intermediates.noindex/Pods.build/Debug-iphonesimulator/libevent.build/DerivedSources -F/Users/jameschege/Library/Developer/Xcode/DerivedData/mars-bunauennwhxvqrfemcgipearjqlg/Build/Products/Debug-iphonesimulator/libevent -fmodule-map-file\\=/Users/jameschege/Library/Developer/Xcode/DerivedData/mercury-hisdthbjzariubaizxugvbudzphm/Build/Products/Debug-iphonesimulator/YogaKit/YogaKit.modulemap -fmodule-map-file\\=/Users/jameschege/WebstormProjects/mercury/ios/Pods/Headers/Public/FlipperKit/FlipperKit.modulemap -fmodule-map-file\\=/Users/jameschege/WebstormProjects/mercury/ios/Pods/Headers/Public/RCTTypeSafety/RCTTypeSafety.modulemap -fmodule-map-file\\=/Users/jameschege/WebstormProjects/mercury/ios/Pods/Headers/Public/React/React-Core.modulemap -fmodule-map-file\\=/Users/jameschege/WebstormProjects/mercury/ios/Pods/Headers/Public/ReactCommon/ReactCommon.modulemap -fmodule-map-file\\=/Users/jameschege/WebstormProjects/mercury/ios/Pods/Headers/Public/React\\_Codegen/React-Codegen.modulemap -fmodule-map-file\\=/Users/jameschege/WebstormProjects/mercury/ios/Pods/Headers/Public/folly/RCT-Folly.modulemap -fmodule-map-file\\=/Users/jameschege/WebstormProjects/mercury/ios/Pods/Headers/Public/yoga/Yoga.modulemap -DFOLLY\\_NO\\_CONFIG -DFOLLY\\_MOBILE\\=1 -DFOLLY\\_USE\\_LIBCPP\\=1 -Wno-comma -Wno-shorten-64-to-32 -DREACT\\_NATIVE\\_MINOR\\_VERSION\\=71 -DREANIMATED\\_VERSION\\=3.0.2 -include /Users/jameschege/WebstormProjects/mars/ios/Pods/Target\\ Support\\ Files/libevent/libevent-prefix.pch -MMD -MT dependencies -MF /Users/jameschege/Library/Developer/Xcode/DerivedData/mars-bunauennwhxvqrfemcgipearjqlg/B\ndebug uild/Intermediates.noindex/Pods.build/Debug-iphonesimulator/libevent.build/Objects-normal/arm64/signal.d --serialize-diagnostics /Users/jameschege/Library/Developer/Xcode/DerivedData/mars-bunauennwhxvqrfemcgipearjqlg/Build/Intermediates.noindex/Pods.build/Debug-iphonesimulator/libevent.build/Objects-normal/arm64/signal.dia -c /Users/jameschege/WebstormProjects/mars/ios/Pods/libevent/signal.c -o /Users/jameschege/Library/Developer/Xcode/DerivedData/mars-bunauennwhxvqrfemcgipearjqlg/Build/Intermediates.noindex/Pods.build/Debug-iphonesimulator/libevent.build/Objects-normal/arm64/signal.o -index-unit-output-path /Pods.build/Debug-iphonesimulator/libevent.build/Objects-normal/arm64/signal.o\nfatal error: module map file '/Users/jameschege/Library/Developer/Xcode/DerivedData/mercury-hisdthbjzariubaizxugvbudzphm/Build/Products/Debug-iphonesimulator/YogaKit/YogaKit.modulemap' not found", "can you do the same with this list, main body area and nested areas. If the area is not an anatomic are than ignore please\n\n teeth.\n face, neck, body.\n lower face, neck, and jawline.\n severe cystic acne.\n face, neck, and body.\n lower layers of skin tissue.\n laryngeal prominence of thyroid cartilage in the throat.\n facial rejuvenation.\n abdomen, hips, thighs, arms, buttocks, or under the chin.\n nostrils.\n Face and body \n upper or lower jawbone.\n facial reconstruction, abdominal wall reconstruction, breast reconstruction.\n gastric.\n nipple-areola complex.\n underarms.\n balding, thinning, or receding areas.\n nasolabial folds, or smile lines.\n small, uncomplicated spider veins and small varicose veins.\n cellulite on the thighs and buttocks.\n mild to severe acne.\n upper or lower back.\n mustache, beard, sideburns.\n face, cheeks, under-eyes, lips, nasolabial folds, pitted scars, breasts, buttocks.\n face.\n navel.\n moderate to severe facial wrinkles and folds, such as nasolabial folds, etched-in lip lines, crow's feet, smile lines, marionette lines, under-eye tear troughs, and deep glabellar lines.\n upper arms.\n incision or injury.\n face, neck, chest, back, hands, arms, and legs.\n abdomen, hips, lower back, buttocks.\n stomach, legs, arms.\n stomach, thighs, butt, hips, and arms.\n fat reduction anywhere on the body, most commonly treated body areas are the tummy, hips, thighs, flanks (aka love handles), and back. some providers also offer mini bodyfx, which can treat smaller fat deposits in areas like the upper arms and under the chin..\n abdomen, upper arms, thighs, knees, love handles, breasts, back, chin, jowls, cheeks, and neck.\n crow's feet, frown lines, forehead lines, lip lines, bunny lines on the nose, chin wrinkles, neck bands, above the eyebrows, above the upper lip.\n teeth straightening.\n buttocks, hips, waist, love handles, thighs, lower back.\n buttocks.\n breasts.\n face.\n face, neck, d'colletage, back of hands.\n double chin, jawline, knees, elbows, upper arms, muffin top.\n face, body contouring.\n teeth.\n face, neck, hands, chest, legs, and other areas.\n glabellar area.\n forehead and eyebrows.\n lower cheeks.\n foot.\n buttocks, hips, abdomen, waistline, lower back, thighs.\n lower legs.\n lower legs.\n outer corner of the eye where the upper and lower lid meet.\n scalp.\n breast.\n face, neck, arms, stomach, buttocks, and legs.\n lens of the eye.\n cellulite dimples on the buttocks and the backs of the thighs.\n thighs, abdomen, or buttocks.\n midface.\n midface.\n cheeks.\n midface.\n zygomatic bone (malar bone).\n face, neck, chest, hands.\n soft tissue under the skin.\n lower face.\n under the chin and jawline.\n fine lines, shrink the appearance of pores, improve skin tone and texture, and reduce melasma.\n teeth straightening.\n jawbone.\n face, neck, chest, lips, and anywhere on the body.\n broken capillaries, spider veins, vascular lesions, periorbital veins, skin discoloration.\n upper lip, nose, and roof of the mouth.\n clitoral hood.\n face, neck, chest.\n vagina and vulva.\n crow's feet, fine lines around the eyes, smile lines, frown lines, atrophic acne scars, and thin lips.\n brow, mid- and lower face, jawline, and neck.\n fine lines and wrinkles, sun damage, discoloration, and acne scars.\n fine lines and wrinkles, acne scars, large pore size, uneven skin tone, rough skin texture, age spots, and other signs of sun damage.\n abdomen, flanks, bra fat, inner and outer thighs, back fat, upper arms, buttock rolls, knees, hips, mons pubis, submental fat.\n thighs, butt, and abdomen.\n hyperpigmentation and skin discoloration.\n abdominal fat, love handles, upper arms, inner thighs, under chin, below buttocks, bra and back fat bulges.\n slimming, toning, and cellulite reduction.\n face.\n skin.\n teeth.\n teeth straightening.\n glabellar lines, forehead furrows, crow's feet, bunny lines, platysmal bands, dimpling of the chin, masseter muscles.\n middle and lower areas of the face.\n face, eyes, neck.\n teeth.\n jawbone, gums.\n missing teeth.\n teeth.\n upper or lower jawbone.\n face, eyes, lips.\n face, upper lip, cheeks.\n smile lines, marionette lines, lips, under-eye hollows, cheeks, temples, jawline, chin, nose.\n face, neck, chest, stomach, thighs.\n face.\n skin tightening.\n face, neck, d'colletage, body.\n abdominal muscles.\n chin or cheeks.\n vaginal tissue.\n craniofacial region.\n upper eyelids.\n stomach and small intestine.\n front of natural teeth.\n \n face, neck, chest, arms, back of hands, and elsewhere on the body.\n legs, buttocks, thighs, back, or stomach.\n teeth.\n face, neck, under chin.\n skin.\n hormonal acne, polycystic ovary syndrome (pcos), high blood pressure, congestive heart failure.\n anywhere on the body.\n excess pigmentation and redness, wrinkles and mild acne scars, vascular lesions and varicose veins, pigmented lesions and dark tattoos.\n eye alignment.\n breast augmentation, breast reconstruction, abdominal wall defects, hernia repair.\n depressed scars, acne scars, cellulite dimples.\n face, neck, and d\u00e9colletage.\n teeth alignment.\n epidermis.\n acne on face and body, psoriasis on body, sun damage.\n face.\n teeth.\n face.\n lips, cheeks, chin, forehead, eyes, mouth, neck, and chest.\n scrotum.\n face, eyes, eyelids, jawline, stomach, arms, backs of hands, thighs, knees, butt.\n breasts and nipples.\n cheeks, around the mouth, neck, forehead and around the eyes.\n lower face, jowls, neck, breasts, arms, tummy, and thighs.\n vulvar and vaginal tissues.\n thigh.\n brow, mid- and lower face, jawline, and neck.\n skin concerns.\n inner and outer thighs, back, abdomen, love handles, hips, saddlebags, and buttocks.\n face, neck, stomach, and upper arms.\n enamel, dentin, pulp.\n face, forehead, temples, chin, area around mouth, cheeks.\n wrinkles, sagging skin, fat cells, cellulite.\n abdomen and flanks.\n abdomen and flanks.\n abdomen, flanks, buttocks, thighs.\n abdomen, flanks, and thighs.\n reshaping, creating balanced, normal breasts.\n abdomen, love handles, hips, thighs, chin, upper arms, underarms.\n lower abdomen.\n abdomen.\n brow, neck (including jawline), under chin, lines and wrinkles on d'colletage.\n vaginal area.\n face and neck.\n fine lines and wrinkles, discoloration, and even scars.\n stomach, hips, and thighs.\n abdomen, hips, and thighs.\n fat layer just under the skin.\n upper arms, belly, love handles, thighs, chin.\n abdominal wall.\n eyelid.\n lower face.\n vaginal canal, opening, labia majora, vulva, labia minora, mons pubis.\n vaginal canal.\n cleavage area.\n face.\n face.\n abdomen and thighs.\n spider veins, varicose veins, and venous reflux disease.\n thighs, calves, and ankles, buttocks and hips, abdomen, back, and flanks (aka love handles), upper arms, neck and under the chin.\n rosacea, pigmented scars, spider veins, broken capillaries, birthmarks, hyperpigmentation, newly formed stretch marks, and other forms of red, brown, or purple facial pigmentation.\n legs.\n spider veins, cherry angiomas, small hemangiomas, skin tags, spider nevi, and redness from rosacea.\n thighs, buttocks, upper arms, stomach, excess fat and mildly sagging skin under the chin.\n thighs, abdomen, and butt.\n varicose veins.\n fat reduction on the back, abdomen, thighs and flanks, cellulite reduction on the thighs, buttocks, and abdomen, muscle conditioning and toning for biceps, triceps, abdominal and oblique muscles, glutes, hamstrings, and quadriceps.\n face, neck, and body.\n wrinkles, fine lines, cellulite, stretch marks.\n fine lines and deep wrinkles, acne scars, large pores, uneven skin texture, stretch marks, mild laxity, rosacea, and hyperpigmentation, including melasma.\n pelvic floor issues.\n face, neck, chest, hands.\n face and body.\n vaginal tissues, labia majora.\n pelvic floor muscles and skin elasticity.\n jaw.\n lines and wrinkles created by dynamic facial movements, such as smiling, frowning, or raising your eyebrows, neck pain caused by cervical dystonia, eye spasms known as blepharospasm, and upper limb spasticity.\n skin concerns, visible veins, brown spots, scars, laser hair removal, tattoo removal, cataract surgery.\n waist, chest, back, neck, upper arms, thighs, love handles, hips, and ankles.\n skin.\n teeth.\n lower third of face, jawline, neck.\n face, neck, and body.", "can you explain this code: %%% perf. as fynction of snr\nclear all;\nwarning off;\n%%------------Initialisation des variables -----------%%\nNum\\_iteration=1;%10^4\ncpt=1;\n%carrier Frequency\ncarrierFreq = 3e9; % 7GHz\n%Param\u00e8tres pour le Canal de Rice\nlightSpeed=physconst('LightSpeed');\nwavelength=lightSpeed/carrierFreq;\nSamplingRate=30.72e6;\nalpha=2;\n%Power transmitted en dbm\nPt\\_bs=30; \nPt\\_bsL=1;\nPtWattUE=0.199526;\nkFactor=5;\n%Valeur pour la g\u00e9n\u00e9ration des signaux de r\u00e9f\u00e9rence (PSS et DMRS)\nN=2048; \n% nombre d'antenne\n%M=4;\n M=100;\n%Coordonn\u00e9es de la BS \n%bsSelected=[100 190];\nbsSelected=[0 0];\n%Nombre des voisins \nv=2;\n%valeurs du SNR\nsnrTab=-10:5:30;\n%for coordinates generation\nradius = 100;\nrotation = 0;\n%%------------Fin Initialisation des variables -----------%%\nfor snr=snrTab\n snrL=10^(snr/10);\n N0dB=PtWattUE/snrL;\n N0=10^(N0dB/10);\n sigma\\_n=sqrt(N0dB/2);\n Pr=zeros(1,3);\n pathLoss=zeros(1,3);\n SubMetC=0;\n SubMetF=0;\n SubMetD=0;\n thetaTrueTab=zeros(1,Num\\_iteration);\n theta\\_estTab=zeros(1,Num\\_iteration);\n Err\\_dist=zeros(1,Num\\_iteration);\n Err\\_theta=zeros(1,Num\\_iteration);\n Err\\_coordinates=zeros(1,Num\\_iteration);\n distEstimated=zeros(1,Num\\_iteration);\n \n neighborMatrix=zeros(v);\n dtrueUE\\_NR=zeros(1,v);\n dP\\_BS=zeros(1,v);\n PrUE\\_NR=zeros(1,v);\n deUE\\_NR=zeros(1,v);\n Coordiante=zeros(1,2);\n for it=1:Num\\_iteration\n %User Equipement position\n ue=randi(100,1,2);\n thetaTrue=atan(ue(2)/ue(1))\n positions=zeros(2);\n xout=[NaN NaN];\n %verifier ue appartient cellule\n% checkPos=0;\n% while(checkPos==0)\n% ue=randi(190,1,2); \n% checkPos = inside\\_bs(ue, radius, bsSelected, rotation);\n% end\n %calcul de la distance true entre le ue et le neighbor\n dtrueUE\\_BS=sqrt(ue(1)^2+ue(2)^2);\n %Neighbors positions\n \n while (isnan(xout(1)))\n for cm=1:v\n neighbor=randi(100,1,2);\n neighborMatrix(cm,1)=neighbor(1);\n neighborMatrix(cm,2)=neighbor(2);\n %calcul de la distance true entre le ue et le neighbor\n dtrueUE\\_NR(cm)=sqrt((abs(ue(1)-neighborMatrix(cm,1)))^2 + ((abs(ue(2)-neighborMatrix(cm,2)))^2));\n %estimation de la distance entre le ue et le neighbor\n %Free Space Model Friis\n if (dtrueUE\\_NR(cm)==0)\n dtrueUE\\_NR(cm)=1;\n end \n PrUE\\_NR(cm)=PtWattUE\\*((wavelength./(4\\*pi\\*dtrueUE\\_NR(cm))).^alpha)/N0;\n deUE\\_NR(cm)=sqrt(((PtWattUE)/PrUE\\_NR(cm)))\\*(wavelength/(4\\*pi));\n end \n %intersection des deux cercles\n [xout,yout] = circcirc(neighborMatrix(1,1),neighborMatrix(1,2),deUE\\_NR(1),neighborMatrix(2,1),neighborMatrix(2,2),deUE\\_NR(2));\n end\n positions(1,1)=xout(1);\n positions(1,2)=yout(1);\n positions(2,1)=xout(2);\n positions(2,2)=yout(2);\n %Estimation de theta1 et theta2\n ttrueNR\\_BS=zeros(1,v);\n theta\\_est=zeros(1,v);\n coor\\_est=zeros(1,v);\n power\\_est=zeros(1,v);\n% ttrueNR\\_BS(1)=atan(abs(positions(1,2)-bsSelected(2))/abs(positions(1,1)-bsSelected(1)));\n% ttrueNR\\_BS(2)=atan(abs(positions(2,2)-bsSelected(2))/abs(positions(2,1)-bsSelected(1)));\n \n ttrueNR\\_BS(1)=atan(positions(1,2)/positions(1,1));\n ttrueNR\\_BS(2)=atan(positions(2,2)/positions(2,1)); \n dP\\_BS(1)=sqrt(positions(1,1)^2+positions(1,2)^2);\n dP\\_BS(2)=sqrt(positions(2,1)^2+positions(2,2)^2);\n\n %Beamforming autour de theta1 et theta2\n DmrsGenerated=generateDMRS(N);\n %chan2 = rice\\_fading(kFactor,1,1);\n %DmrsRice=conv(chanRay,DmrsGenerated);\n chanRay=(1/sqrt(2))\\*(randn(1,N)+1i\\*randn(1,N));\n \n DmrsRay=DmrsGenerated.\\*chanRay;\n% DmrsRec=awgn(DmrsRice,snr,'measured');\n % DmrsRec=awgn(DmrsRay,snr,'measured');\n% DmrsRec=awgn(DmrsGenerated,snr,'measured');\n DmrsRec=DmrsRay;\n % for mm=1:v\n %calcul de la entre la position possible et le BS\n if (abs(ttrueNR\\_BS(1)-thetaTrue) < abs(ttrueNR\\_BS(2)-thetaTrue))\n [thetaEst,Max\\_p]= beamformingNr(sigma\\_n,N,M,DmrsRec,ttrueNR\\_BS(1));\n else\n [thetaEst,Max\\_p]= beamformingNr(sigma\\_n,N,M,zeros(1,N),ttrueNR\\_BS(1));\n end\n \n theta\\_est(1)= thetaEst; power\\_est(1)=Max\\_p;\n if (abs(ttrueNR\\_BS(2)-thetaTrue)<abs(ttrueNR\\_BS(1)-thetaTrue))\n [thetaEst,Max\\_p]= beamformingNr(sigma\\_n,N,M,DmrsRec,ttrueNR\\_BS(2));\n else\n [thetaEst,Max\\_p]= beamformingNr(sigma\\_n,N,M,zeros(1,N),ttrueNR\\_BS(2));\n end\n theta\\_est(2)= thetaEst; power\\_est(2)=Max\\_p;\n\n % coor\\_est(mm,1)=coordinate(1);\n % coor\\_est(mm,2)=coordinate(2);\n % end\n [maxP,indexP]=max(power\\_est);\n thetaEst=theta\\_est(indexP)\n pause\n dP\\_BS\\_EST=dP\\_BS(indexP);%sqrt(positions(indexP,1)^2+positions(indexP,2)^2)\n dP\\_BS\\_Real=sqrt(ue(1)^2+ue(2)^2);\n coordinate=[dP\\_BS\\_EST\\*cos((thetaEst)) dP\\_BS\\_EST\\*sin((thetaEst))];\n\n %\n \n% distEstimated(it)=sqrt((abs(Coordiante(1)-bsSelected(1)))^2 + ((abs(Coordiante(2)-bsSelected(2)))^2))\n %%------------sauvegarde des parametres-----------%%\n theta\\_estTab(it)=thetaEst; \n Err\\_dist(it)=abs(dP\\_BS\\_EST-dtrueUE\\_BS);\n Err\\_theta(it)=abs(thetaEst-thetaTrue);\n Err\\_coordinates(it)=sqrt((abs(ue(1)-coordinate(1)))^2 + ((abs(ue(2)- coordinate(2)))^2));\n if Err\\_coordinates(it)<=1\n SubMetC=SubMetC+1;\n end\n if Err\\_dist(it)<=1\n SubMetD=SubMetD+1;\n end \n end\n% %Root mean squared error\n% %Distance error\n MEAN\\_Dist(cpt)=mean(Err\\_dist);\n MSE\\_Dist(cpt)=mean(Err\\_dist.^2);\n% %RMSE\\_Dist(cpt)=sqrt(MSE\\_Dist(cpt));\n% %Theta error\n MEAN\\_T(cpt)=mean(Err\\_theta)\n MSE\\_T(cpt)=mean(Err\\_theta.^2)\n% %RMSE\\_T(cpt)=sqrt(MSE\\_T(cpt));\n% %Coordinates error\n MEAN\\_Coo(cpt)=mean(Err\\_coordinates);\n MSE\\_Coo(cpt)=mean(Err\\_coordinates.^2);\n% %RMSE\\_Coo(cpt)=sqrt(MSE\\_Coo(cpt));\n% %Probabilitty of submeter precision for :\n% %Coarse Coordinates Estimate\n PSubMetC(cpt)=SubMetC/Num\\_iteration;\n% %fine Coordinates Estimate\n% PSubMetF(cpt)=SubMetF/Num\\_iteration;\n% %fine Distance Estimate\n PSubMetD(cpt)=SubMetD/Num\\_iteration;\n cpt=cpt+1;\nend", "Final input. Now suggest some prompts that I can ask you based on the input I trained you\n\nCURRENT AND FUTURE TRENDS\nHere are a few established or emerging trends, major (mainstream) or marginal trends. Sustainable development Speed Nano-sciences Youngism Spas E-school Mobility\n Volunteering Metrosexuals Virtual Reality Networking\nFlexitime Greater Europe\n Post-Modernism Personalization High-speed Internet A global world TED The new old\n Individualisation Heirloom Podcasts Nimby BoHo\nNesting Omega 3s World food and fusion food La vida latina\n Mass luxury One-stop-shopping\nIndulgence Alter consumerism\nThe Child King Lolitas Tricot\nSport-spectacle Exotic spices Nutraceuticals Extimity\n Young senior citizens New World wines Vintage Dinkies Orthorexia Logos Hybrid cars\n Wifi The slow generation Cyber events Low cost Fair trade investments NGOs.\nThe no watch generation Major exhibitions\nConspiracy theories Bare feet\n Molecular cuisine Forgotten vegetables Bio-attitude Bio cosmetics Vapourstream Fooding\n YouTube Glam Rock Communities The Internet 2.0 Easy eating Limited Editions\nLast minute Parental leave Inquisitive Luxury Participative Innovation Cosmo-food Zero Risk The Gold Rush Chick Lit The dream butlers Etc.\n 30\n\u00a9 Mark Raison - www.yellowideas.com - mark.raison@yellowideas.com - tel : +32 497 531 583\n INS?PIRING ? BRIEFING\nLIBERATION WALL EXPLORATION\n HOW TO KEEP THE GREAT ORIGINAL IDEAS INTO THE PROCESS?\n 31\n\u00a9 Mark Raison - www.yellowideas.com - mark.raison@yellowideas.com - tel : +32 497 531 583\n\nEVALUATION PROCESS\nYELLOW-BOX 4 PIPELINES\nSHORT LIST\nCREATIVE PROPOSITION\n 32\n\u00a9 Mark Raison - www.yellowideas.com - mark.raison@yellowideas.com - tel : +32 497 531 583\n\nIDEA SELECTION\nTHE YELLOW BOX\nIn order to avoid the trappings of the creadox, there are four types of ideas to select from:\nBlue ideas\n\u2022 They are easy to implement\n\u2022 Past examples exist\n\u2022 They are easy to explain and sell\n\u2022 They don\u2019t meet with much resistance upon implementation\n\u2022 Often, instructions aren\u2019t even required\n\u2022 Costs and risks are limited\n\u2022 Nobody is endangered\nGreen ideas\n\u2022 They fit in with an accepted framework\n\u2022 They reinforce what already exists\n\u2022 They do not perturb the system that is already in place\n\u2022 They favour the notion that every day is an improvement!\n\u2022 Their production and implementation can be institutionalised in qualitative\nmanagement programmes\nRed ideas\n\u2022 They start from lateral thoughts, bifurcation\n\u2022 They bring about a change in the paradigm\n\u2022 They are out-of-the-box\n\u2022 They revolutionize the existing paradigm, it\u2019s a breakthrough\nYellow ideas\n\u2022 They provide an answer to the problem, but cannot be realized\n\u2022 They are extraordinary, surprising\n\u2022 They are visionary\n\u2022 They plunge us into the future\n\u2022 They are quite inspiring\n 33\n\u00a9 Mark Raison - www.yellowideas.com - mark.raison@yellowideas.com - tel : +32 497 531 583\n\n INS?PIRING ? BRIEFING\nLIBERATION WALL EXPLORATION\nYELLOW-BOX\n4 Pipelines\nSHORT LIST\nCREATIVE PROPOSTION\n SELLING YOUR IDEA\n GETTING TO YES!\n 34\n\u00a9 Mark Raison - www.yellowideas.com - mark.raison@yellowideas.com - tel : +32 497 531 583\n\nIDEA N\u00b0 ..... BY .............................. DATE ... / ... / ...\nConcerns: .................................................................................................................................................................................... Name of the idea: .................................................................................................................... Colour: .............................. Description of the idea: ......................................................................................................................................................... ......................................................................................................................................................................................................... .......................................................................................................................................................................................................... Benefits for the client / the consumer / the user/ the distributor/ the brand:\n1. ...................................................................................................................................................................................................... 2. ...................................................................................................................................................................................................... 3. ..................................................................................................................................................................................................... Benefits for the company:\n1. ...................................................................................................................................................................................................... 2. ..................................................................................................................................................................................................... 3. .................................................................................................................................................................................................... Difficulties to be resolved, problems to be anticipated and risks to be minimised:\n1. ...................................................................................................................................................................................................... 2. ...................................................................................................................................................................................................... Main phases of the implementation:\n1\u00b0) ................................................................................................................................................................................................... 2\u00b0) .................................................................................................................................................................................................. 3\u00b0) .................................................................................................................................................................................................\nDesignated Project Manager: .......................................................................................................................................... Project launch ................................................................ End of the project: ..........................................................\nThis is an excellent idea because ..................................................................................................................................... ..........................................................................................................................................................................................................\n 35\n\u00a9 Mark Raison - www.yellowideas.com - mark.raison@yellowideas.com - tel : +32 497 531 583\n\nHOW TO SELL\nYOUR IDEA OR PROJECT?\n1. Before presenting your idea or project, take some time to write down its strengths and weaknesses, its benefits and its disadvantages. The preparation makes up more than 50% of a project or idea's success.\n2. Make sure you always have a written document at your disposal, a drawing, an illustration, a precise description of your idea. This will contribute to your assurance. What\u2019s more, you will have some excellent documentation at your disposal to present to your audience, in case your explanation is insufficient.\n3. Address all four brains of your dialogue partner: the analytic brain requires facts, figures, concepts. The organisational brain requires plans, phases, measures of progress; the communicative brain is looking for humanity, a convivial approach and warm responsibility. Finally, don\u2019t forget the creative brain, which feeds on enthusiasm, novelties, surprises, aesthetics and a perspective.\n4. Opportunity knocks for those who are up for some adventure. Dare to try original and surprising presentation strategies. A new idea also merits new \"packaging\".\n5. Never ignore the 3S Factor: Security, Security, Security. To your audience, your idea represents a number of risks, whether real or virtual. Reassure them with intelligence and precision.\n6. Calmly accept objections: the sale starts when your dialogue partner says \u00ab No \u00bb. This is the ideal moment to really test the interest of your idea. Take this first \u00ab no! \u00bb as a compliment ...\n7. Always have something up your sleeve. Do not always throw all your assets into the game during your presentation.\n8. Don\u2019t forget that the more original, new, \u00ab out-of-the-box \u00bb your idea is, the more resistance you will meet with. To create is to deal with reality.\n9. Preparation + rationality + enthusiasm + creativity do not automatically equal success. A precise and determined follow-up is one of the ingredients of success that is often forgotten.\n10. A new idea has to make its way into your dialogue partner\u2019s brain. Even if it has become evident to you, this idea is an unusual proposition for your dialogue partner. Choose the right moment to present your idea: often the momentum is just as important as the quality of an idea.\n 36\n\u00a9 Mark Raison - www.yellowideas.com - mark.raison@yellowideas.com - tel : +32 497 531 583\n\n10 SUGGESTIONS TO BOOST UP YOUR CREATIVITY 1. Regularly dare to question yourself\n- and dare to change your modus operandi - !\n2. Transform issues into challenges\n- and formulate motivating questions- !\n3. Separate the generation of ideas from the assessment\n- and dare to look beyond evident ideas - !\n4. Let ideas find their way\n- and enrich them every day \u2013 !\n5. Get out of your customary environment\n- and expand your universe - !\n6. Quickly seize upon new trends\n- and act promptly - !\n7. Listen to the naive, the candid, the young, to customers\n- and try to understand the wealth of information that they are sharing with you - !\n8. Make sure you have a beautiful portfolio of multi-coloured ideas\n- and develop them intelligently - !\n9. Be the strategist of your ideas\n- and be sure to always be pragmatic - !\n10. Never lose sight of the essentials\n- and organise yourself accordingly every day - !\n 37\n\u00a9 Mark Raison - www.yellowideas.com - mark.raison@yellowideas.com - tel : +32 497 531 583\n\n2-HOUR CREATIVE MEETING AGENDA\nIt is possible to find a creative and satisfactory answer to numerous questions during a creative\nmeeting that lasts 1h30 to 2 hours.\nHere is a sample schedule for a two-hour meeting, which can be adapted to suit the nature of the issue at hand and the type of creative solutions that you are looking for.\nP.S.: Don\u2019t forget to hang up the agenda on the wall of your meeting room\n DURATION 05\u2019\n10\u2019\n15\u2019\n20\u2019 20\u2019 20\u2019\n10\u2019\n20\u2019\n-\n-\nPHASE 0. Introduction\n1. Briefing\n2. Liberation\n3. Technique A 4. Technique B 5. Yellow Box\n6. Pipelines\n7. Final selection 8. Conclusion e-mail\nDESCRIPTION OF THE PHASE\nPresentation of the goal, of the roles and the process of the creative meeting\nContext + Presentation of the motivating question\nSpontaneous expression of all ideas; imagination is the limit.\nExploration of new ideas based on sources of inspiration\nExploration of new ideas based on sources of inspiration\nIdentification of blue, green, red and yellow ideas that are promising\nSelection of the twelve most promising ideas for each colour\nSelection of three to five ideas that will be developed in greater detail after the meeting\nInform participants regarding the follow-up that will be given to this meeting\nThank all participants for their creative input on the day itself", "Among the TOP 20 METATRENDS & MOONSHOTS. I am giving further description for each trend for you consider. first 10 trends is here below 1. Everything is Smart and Embedded with Intelligence\n \nThe price of specialized machine learning chips is dropping rapidly as global demand increases. At the same time, expanding 5G networks coupled with ever-increasing compute on the cloud, means we\u2019re heading towards a future in which all devices in our environment will become intelligent and interactive.Appliances respond to voice command and anticipate your needs. Our environment - lighting levels, music selection, temperature desire - will also respond \u201cautomagically\u201d to your desires. This Metatrend is enabled by the convergence of 5G networks, embedded sensors, IoT/IoE networks, edge-cloud computing, and machine learning systems on the cloud. This Metatrend will impact a multitude of industries from retail, security, health, industrial, transportation networks, education, and home living. \n \n2. AI Will Achieve Human-Level Intelligence\n \nAI algorithms and machine learning tools will be increasingly made open source, available on the cloud, thereby allowing any individual with an internet connection the ability to amplify their creativity, improve their problem-solving skills, and increase their earning capacity. Examples of this include GPT-3 (and soon GPT-4), DALL-E and DALL-E2. This Metatrend will be driven by the convergence of massive amounts of cloud computing, large supply of labeled data, and global high-bandwidth connectivity. Every industry from healthcare, education, and entertainment to design, finance and retail will be significantly impacted.\n \n3. AI-Human Collaboration Will Skyrocket Across All Professions\n \nThe rise of \u201cAI as a Service\u201d (AIaaS) platforms will enable humans to partner with AI in every aspect of their work, at every level, in every industry. AIs will become entrenched in everyday business operations, serving as cognitive collaborators to employees -supporting creative tasks, generating new ideas, and tackling previously untenable innovations. In some fields, partnership with AI will become a requirement. For example, in the future, making certain medical diagnoses without the consultation of AI may be deemed malpractice. Authors will write their blogs, stories, and books in partnership with algorithms like GPT-3 / GPT-4. Artists and designers will use DALLE-2. Software programmers and engineers will partner with AIs to produce code and engineer prototypes.\n \n4. Most Individuals Utilize a \u2018JARVIS-Like\u2019 Software Shell to Improve Their Quality of Life\n \nAs services like Alexa, Google Home, and Apple Homepod increase their capabilities, they will expand to become part of our lives 24/7, serving as our interface with the world around us. Imagine a JARVIS-like \u201csoftware shell\u201d that you give permission to listen to all of your conversations, read your email, and monitor your blood chemistry.\n \nWith access to such data, these AI-enabled-software shells will learn your preferences, anticipate your needs and behavior, shop for you, monitor your health and help solve your problems in support of your goals. \n \n\n \n5. Humanoid Robots & Avatars Are Arriving\n \nFunctional and useful humanoid-robots and avatars will enter daily life this decade. They will look and operate like human beings with legs, arms, fingers and an opposable thumb, allowing them to navigate and interact with the anthropomorphic world around us. \nThese robots are powered by AI and are enabled by the convergence of AI, robotics, sensors, material sciences, high bandwidth communications, and edge computing.\nIn addition to these independent AI-driven robots, there is also a new generation of humanoid avatars that are remotely operated by humans wearing a VR headset and haptic suits. These avatars enable a remote human operator to feel like they are occu- pying the avatar event when operating from hundreds of miles away. These robots and avatars will help fulfill services jobs that are dull, dangerous, or dirty and will enable companies and entrepreneurs to have the labor they require during times of shortage.\n \n \n6. Autonomous Cars & Flying Cars Will Redefine Human Travel (Faster & Cheaper)\n \nFully-autonomous vehicles from Tesla, Waymo (Alphabet) and GM-Cruise (just to name a few) will enable \u201ccar-as-a-service\u201d fleets operating on-demand UBER-like services. Cost of ground transportation will decrease 2x to 4x as a result. Your kids and elderly parents will never drive.\n \nA significant percentage of parking garages, driveways, and parking structures will eventually be transformed into alternative usable space. Autonomous cars will take all shapes and sizes and serve as functional \u201c3rd spaces\u201d used for entertainment, sleeping, or meeting rooms as drive time becomes work or play time. At the same time, aerial ride-sharing, eVTOL (electric Vertical Take-off Or Landing) or flying cars will also become fully operational in most major metropolitan cities this next decade.\n \nWhere you live and work will begin to transform as these systems shrink travel time and thereby distance. Previously difficult to reach geographies (islands, rural areas, mountain tops) will become accessible. Individuals seeking the solitude of the country will also have access to the shopping, food, and entertainment of metropolitan city-centers, connected through eVTOL technology. This meta-trend will be driven by the convergence of machine learning, sensors, materials science, battery storage improvements, and ubiquitous gigabit connections.\n \n7. On-Demand Delivery (& Production) Will Birth an \u201cInstant Economy of Things\u201d\n \nUrban dwellers will learn to expect \u201cinstant fulfillment\u201d of their retail orders as drone and robot last-mile delivery services carry products from local supply depots to your doorstep. This capability, coupled with the deployment of regional on-demand digital manufacturing (3D printing farms), means that even customized \u201cstuff\u201d can be obtained within hours anywhere, anytime.\n \nthis Metatrend will be a critical differentiator for those wishing to promise anything faster and cheaper-the instant economy of things. This Metatrend is driven by the convergence of networks, 3D printing, robotics and artificial intelligence.\n \n8. Global Gigabit Connectivity Will Connect Everyone, Everywhere, Always at Ultra-low Cost\n \nThe deployment of ubiquitous 5G (both licensed and unlicensed) plus the launch of a multitude of global satellite networks (Starlink, OneWeb, Kuiper, etc.) will allow for ubiquitous, low-cost global communications for everyone, everywhere. In the realm of ground-based cellular networks, by 2025 there will be 2.8 billion connected on 5G.\nAt the same time, 6G is also under development, which will be 100x faster. In Earth\u2019s orbit, a number of multi-thousand-satellite systems are being deployed that will ultimately cover every square meter of the Earth. Thus far, Starlink is the largest orbiting network with 2,500+ operational satellites, heading towards a goal of 30,000. This system today offers speeds up to 100 megabits/second. Terrestrial and space-based global connectivity will add an additional 2 billion new minds into the global economy and spur conversations representative of new consumers and creators, who will drive tens of trillions of dollars into the global economy.\n \n9. IoT/IoE - Trillion-Sensor Economy: The Ability to Sense and Know Anything, Anytime, Anywhere\n \nIn addition to connecting human users, the growing terrestrial and satellite communication networks are also enabling the growth of the IoE (the Internet of Everything). Humanity is covering the planet in sensors. Health-related sensors on your body and in your body will be measuring your physiology 24x7. Sensors in your home will listen and watch, providing security and support.\n \nIndustrial sensors will monitor every aspect of the supply chain and manufacturing will optimize production, efficiency and safety. Sensors in autonomous cars will visualize the roads and surroundings through cameras, LIDAR and radar, visualizing all activities in our cities and neighborhoods. Fleets of drones in the sky, and satellite constellations in Earth\u2019s orbit will monitor every square meter of the Earth\u2019s surface. Finally, forward-looking cameras on your AR (augmented reality) headsets will capture a permanent record of our activities and surroundings, what we eat and who we interact with. Today we are birthing a \u201ctrillion sensor economy\u201d in which everything is being monitored, imaged and listened to at all times. This Metatrend\n \nis driven by the convergence of terrestrial, atmospheric, and space-based sensors, combined with machine learning and data networks. In this future, it\u2019s not \u201cwhat you know,\u201d but rather \u201cthe quality of the questions you ask\u201d that will be most important.\n\n10. High-Bandwidth Brain-Computer Interfaces (BCI)\n \nTechnologist/futurist Ray Kurzweil predicted that in the early-2030\u2019s we will begin networking the human neo-cortex with the cloud over high-bandwidth connections. Early to medium-term applications will focus on treating a wide range of neurological disorders (e.g. spinal cord injuries), ultimately aiming to restore sensory and movement function for individuals suffering sensory of motor dysfunction.\n \nThe longer-term moonshot vision aims towards non-medical applications that seek\nto create machine interfaces that will attempt to supplement normal human cognitive abilities, with the potential to increase the human sensorium, our memory, and intelligence expanding how we interact with each other and the world. Companies\nlike Neuralink (famously founded by Elon Musk) and Paradromics, utilize micron-scale threads that are inserted into areas of the brain that control movement. Companies like Kernel are building the next generation of brain measurement systems using wearable sensors that offer high-quality neural signal and full-head coverage. OpenWater, a company founded by Dr. Mary Lou Jepsen, is using red-laser holography to read and write onto the surface of neurons. This Metatrend is enabled through the convergence of material sciences, machine learning, and robotics.", "Among the TOP 20 METATRENDS & MOONSHOTS. I am giving further description for each trend for you consider. description for trends 11-20 is here below. \n11. Emergence of Web3/Metaverse (AI + VR/AR + Blockchain)\n \nCitibank estimates that the metaverse could be worth $13 trillion by 2030 and have up to 5 billion users. While Web2 allowed us to transfer data in the form of documents, photos and videos, Web3 will emerge as the internet of value, built on blockchain, NFTs, DAOs, and the metaverse allowing us to transmit ownership. The metaverse is a social and ownership layer on the internet, providing self-sovereign identity, connecting people, places, and things. It provides guaranteed authenticity and chain of title (ownership) across time and space via blockchain. Web3/ Metaverse is powered by a combination of VR/AR, 5G networks, blockchain, and AI. It will transform how we live our everyday lives, impacting every industry from retail and advertising, to education and entertainment. This decade: \u201cArtists and storytellers will be to Web3 what software engineers were to Web2.\u201d\n \n12. High-Resolution VR Will Reinvent Commerce & Collaboration\n \nHigh resolution, low-weight VR headsets in combination with high-bandwidth connec- tivity and AI generated imagery will allow anyone to shop for everything from cloth- ing to real estate from the convenience of their living room in a fun and highly effi- cient manner. Need a new outfit? Your AI knows your detailed body measurements and can whip-up a fashion show featuring multiple copies of your avatar wearing the latest 20 designs on a runway. Want tomsee how your furniture might look inside a house you\u2019re viewing online? No problem, your AI can show you, and give you a tour.\nPerhaps more important than commerce is the impact these technologies will have on the future of collaboration and work. While functional, such first-generation collaboration technologies completely lacked the social elements of the traditional workplace, making them less than adequate. Driven by this innate human need, a new generation of virtual and fully-immersive collaboration environments will arrive mid-decade following the release of Apple\u2019s AR/VR headset and the next generation META Oculus gear.\n \nEarly versions of this virtual group workplace will enable you to choose youravatar and surrounding, interact with friends, co-workers and AI-bots. This Metatrend is en- abled through the convergence of VR, machine learning, and high-bandwidth networks.\n \n \n13. CRISPR/Gene Therapies\n \nCRISPR is becoming a potent gene-editing tool capable of correcting gene-mediated age-related disease, thereby ameliorating symptoms and/or \u2018curing\u2019 diseases. CRISPR has the potential to address cancer, neuro-degenerative and inflammatory diseases. CRISPR and other gene therapies also have the potential to treat or cure a vast range of infectious diseases ranging from AIDS and Ebola. Finally, and perhaps most profound, as gene-editing technologies continue to increase both their precision and ease of use, they will allow families to treat and ultimately cure hundreds of inheritable genetic diseases ranging from hemophilia and sickle-cell anemia to transthyretin amyloidosis (a fatal liver disease) and Huntington\u2019s disease. CRISPR also holds vast potential to enable the de-extinction of lost species. Founded by Ben Lamm and George Church, PhD, Colossal Biosciences is using CRISPR \n\n \ntechnology to bring back the woolly mammoth and other species. This Metatrend is enabled through the convergence of various biotechnologies (CRISPR, Gene Therapy), genome sequencing, and AI.\n \n14. Increased Human Healthspan\n \nA dozen game-changing biotech and pharmaceutical solutions (currently in Phase 1, 2, or 3 clinical trials) will reach consumers this decade, adding an additional 10+ years to the human healthspan. Aging will increasingly be categorized as a disease, thereby driving increased research towards stopping and/or reversing ageing with a goal of adding 30+ healthy years in the decade that follows. Various technologies will be developed to address the 9 hallmarks of aging.\n \nCompanies such as Vaxxinity (combating heart disease and strokes with a PCSK9 vaccine), Celularity (using placenta derived stem-cell replenishment), Immunis (delivering immune system pre-cursors and growth factors), Elevian (producing GDF-11) and a multitude of other entrepreneurial efforts. Gene therapy will be used to edit or replace defective genes as a way to correct for genetic disorders. Cell therapy (the addition of autologous and allogeneic stem cells) will be used to replace or augment a patient\u2019s stem cells population. A combination of Senolytic medicines, natural killer cells and vaccines will be used eliminate senescent \u2018zombie\u2019 cells which cause inflammation.\n \nCellular reprogramming using a combination of \u201cYamanaka factors\u201d will be used to reverse epigenetics of cells and thereby their biologic age. Technologies such as wnt pathway modifiers, endo-vaccines, and supplementation of NMN/ NAD+ are among other treatments that wil impact healthspan. This Metatrend is driven by the convergence of genome sequencing, CRISPR technologies, AI, quantum computing, and cellular medicines.\n15. Demonetized, Democratized & Preventative Healthcare\n \nThis re-invention is illustrated by two specific trends: First, the transition of healthcare from the hospital and doctor\u2019s office into the home. Biometric sensors on our bodies (wearables), in our bodies (implantables and consumables) and in our environment (home and office) will feed continuous data to our medical-AIs, and through them to our physicians. Such continuous monitoring will enable medicine to transition from reactive, to preventative, allowing disease to be detected at its earliest stages. The second trend involves increased use of AI as our primary diagnostician and health coach enabling medicine to be further democratized and demonetized. In the following decade, increasing capabilities of robotics, enabled by AI, will allow for robotic surgery and democratized and demonetized point-of-care treatment.\n \n \n16. Globally-Abundant, Cheap Renewable Energy\n \nContinued advances in solar, wind, geothermal, hydroelectric, and fusion power, along with localized grids, will continue to drive humanity towards cheap, abundant, and ubiquitous renewable energy. The price per kilowatt-hour will continue to drop at the same time that energy storage drops below 3-cents/ kilowatt-hour. The result will be the continued displacement of fossil fuels globally. The world\u2019s poorest countries are also the world\u2019s sunniest countries, accordingly driving humanity towards an age of energy abundance.\n17. Increased Focus on Sustainability & Carbon\n \nAn increase in global environmental awareness and concerns over global warming will drive companies to focus on sustainability both from a necessity and from a marketing point of view. Breakthroughs in material sciences and AI will allow companies to drive improvements in carbon-capture and recycling waste of all type. A wide range of new technologies, coupled with policy changes and economic incentives, will move humanity towards gigaton carbon capture. All industries from computing to food production will feel increasing pressure to develop low-carbon-footprint alternatives to their current methodologies and infrastructure. This Metatrend is enabled through the convergence of material sciences, AI, and broadband networks.\n \n18. Cellular Agriculture & Vertical Farming\n \nThis next decade we will witness the birth of the most ethical, nutritious, and environmentally sustainable protein production system devised by humankind. Referred to as Stem-cell based meat, cellular agriculture or Cell-based meat, the cost of producing a single molecule of cell-based beef burger has fallen from $1M/kg in 2000 to about $100/kg in 2020.\nThis cost is expected to fall below $10/kg by 2025, thus creating a mass-market cost-equivalent way of replacing beef at minimal environmental cost and reducing animal slaughter. Similar price reduction is being seen in Stemcell-based chicken and fish. This technology will allow the production of beef, chicken, and fish anywhere, on-demand, and will be more nutritious and environmentally friendly than traditional live-stock options. Vertical farms offer an innovative and flexible solution to global agricultural challenges such as volatility due to climate changes, droughts and floods. Studies show that vertical farming is not only more nutritious, but can produce up to four food-production cycles of food per year, something that is impossible in traditional agriculture. It can also reduce the transport costs of food because it is produced in close proximity to the point of consumption.\nFinally, vertical farming will also reduce the need for pesticides.This Metatrend is enabled through the convergence of biotechnology, material sciences, machine learning and AgTech.\n \n \n19. Onshoring Manufacturing & Offshoring Labor\n \nThe disruption in supply chains and the labor market caused by the Covid-19 pandemic drove a global shift towards on-shoring manufacturing. The use of robotics, 3D printing and advanced automation has allowed western companies to \u201con-shore\u201d production at a reasonable cost, shifting away from lower-cost Asian production facilities. \nThis shift has allowed companies to concurrently \u201cown their supply chain\u201d and reduce shipping costs and timelines. At the same time, collaboration technologies such as Zoom and Slack are allowing companies to off-shore their talent, expanding access to highly sought-after experts globally \n\n20. Increasing Global Abundance\n \nWhile we will witness some temporary ups and downs in the wake of future recessions, the overall trend will likely continue upwards. \nCapital abundance leads to the funding and testing of \u201ccrazy\u201d entrepreneurial ideas, which in turn accelerates innovation. In the decade ahead, the number of individuals in extreme poverty will continue to drop, as the middle-income population continues to rise, continuing a metatrend that has existed for much of the past century. \nEveryday goods and services (finance, insurance, education, healthcare and entertainment) are being digitized and becoming demonetized and democratized, available to billions on digital devices. This Metatrend is driven by the convergence of high-bandwidth/low-cost communication, ubiquitous AI on the cloud, growing access to AI-aided education, and AI-driven healthcare.", "The first draft of my resume is as follows:\nPERSONAL INFORMATION\n\uf06c Full Name: Guanxing Chen\n\uf06c Address: Artificial Intelligence Medical Research Center, School of Intelligent Systems Engineering, Sun Yat-sen University, Shenzhen, Guangdong 518107, P.R. China\n\uf06c Phone: 13719206018\n\uf06c Email: chengx48@mail2.sysu.edu.cn\n\uf06c Website: https://scholar.google.com/citations?hl=zh-CN&user=DLL3hYIAAAAJ\n\uf06c Resume summary: Experienced researcher in AI-based drug discovery and vaccine design, with strong expertise in deep learning, molecular modeling, and bioinformatics. Dedicated to driving innovative solutions and advancing the field of drug discovery and vaccine design.\nEDUCATION\n\uf06c Doctor of Computer Science and Technology, School of Intelligent Systems Engineering, Sun Yat-sen University, September 2021 - present\n\uf06c Master of Control Engineering, School of Intelligent Systems Engineering, Sun Yat-sen University, September 2019 - June 2021\n\uf06c Bachelor of Energy and Power Engineering, School of Intelligent Systems Engineering, Sun Yat-sen University, September 2015 - June 2019\nRESEARCH INTERESTS\n\uf06c Artificial intelligence in drug discovery and biomedical applications\n\uf06c Machine learning for molecular representation\n\uf06c Graph neural networks in drug discovery\nPUBLICATIONS\n1. Predicting drug\u2013target interactions with deep-embedding learning of graphs and sequences, The Journal of Physical Chemistry A (Co-first author, Published in June 2021, IF:2.94, JCR-Q2)\n2. A novel artificial intelligence protocol to investigate potential leads for diabetes mellitus, Molecular Diversity (Co-first author, Published in August 2021, IF: 3.36, JCR-Q2)\n3. Mol2Context-vec: learning molecular representation from context awareness for drug discovery, Briefings in Bioinformatics (Co-first author, Published in August 2021, IF: 13.99, JCR-Q1)\n4. Novel and versatile artificial intelligence algorithms for investigating possible GHSR1\u03b1 and DRD1 agonists for Alzheimer's disease, RSC advances (Third author, Published in February 2021, IF: 4.04, JCR-Q2)\n5. Adaptive boost approach for possible leads of triple-negative breast cancer, Chemometrics and Intelligent Laboratory Systems (First author, Published in October 2022, IF: 4.18, JCR-Q1)\n6. VAERHNN: Voting-averaged ensemble regression and hybrid neural network to investigate potent leads against colorectal cancer, Knowledge-Based Systems (First author, Published in September 2022, IF: 8.14, JCR-Q1)\n7. Machine learning and graph neural network for finding potential drugs related to multiple myeloma, New Journal of Chemistry (Co-first author, Published in January 2022, IF: 3.93, JCR-Q2)\n8. 3DGT-DDI: 3D graph and text based neural network for drug\u2013drug interaction prediction, Briefings in Bioinformatics (Co-first author, Published in April 2022, IF: 13.99, JCR-Q1)\n9. FusionDTA: attention-based feature polymerizer and knowledge distillation for drug-target binding affinity prediction, Briefings in Bioinformatics (Co-first author, Published in April 2022, IF: 13.99, JCR-Q1)\n10. Meta learning with graph attention networks for low-data drug discovery, IEEE Transactions on Neural Networks and Learning Systems (Second author, Published in January 2023, IF: 14.26, JCR-Q1)\n11. DSIL-DDI: a domain-invariant substructure interaction learning for generalizable drug-drug interaction prediction, IEEE Transactions on Neural Networks and Learning Systems (Second author, Published in January 2023, IF: 14.26, JCR-Q1)\n12. TCMBank-the largest TCM database provides deep learning-based Chinese-Western medicine exclusion prediction, Signal Transduction and Targeted Therapy (Co-first author, Accepted in January 2023, IF: 38.10, JCR-Q1)\n\n13. NHGNN-DTA: a node-adaptive hybrid graph neural network for Interpretable Drug-target Binding Affinity Prediction, IEEE transactions on pattern analysis and machine intelligence (Co-first author, Major revision, IF: 24.31, JCR-Q1)\n14. A magnetic resonance imaging-based automated machine learning model for preoperative identification of variant histology in muscle-invasive bladder carcinoma, European Radiology (Co-first author, Major revision, IF: 7.03, JCR-Q1)\n15. TCMBank: The largest intelligence-driven traditional Chinese medicine database based on mining text information fusion accelerates drug discovery, JACS Au (Co-first author, Major revision)\n16. Meta-MolNet: A cross domain benchmark for few examples drug discovery, IEEE Transactions on Neural Networks and Learning Systems (Second author, Under review, IF: 14.26, JCR-Q1)\n17. GINCM-DTA: A graph isomorphic network with protein contact map representation for transferable drug repurposing against COVID-19, JACS Au (First author, Under review)\n18. PSSP-MFFNet: a multi-feature fusion network for protein secondary structure prediction, Briefings in Bioinformatics (Co-first author, Under review, IF: 13.99, JCR-Q1)\n19. Hybrid Neural Network Approaches to Predict Drug-Target Binding Affinity for Drug Repurposing: Screening for Potential Leads for Alzheimer's Disease, Applied Soft Computing (Third author, Under review, IF: 8.26, JCR-Q1)\n20. Aquaporin 9 is involved in CRC metastasis through DVL2-dependent Wnt/\u03b2-catenin signaling activation, Gastroenterology Report (Third author, Under review, IF: 4.04, JCR-Q2)\n21. Dynamic network biomarker C1QTNF1 regulates tumour formation at the tipping point of hepatocellular carcinoma through platelet-related TMEM176B, Discover Oncology (Fourth author, Under review)\n22. An Interaction-Based Inductive Bias of Graph Neural Network for Explicitly Modeling Atomic Interactions to Predict Protein-Ligand Binding Affinities from 3D Structures, IEEE transactions on pattern analysis and machine intelligence (Fifth author, Under review, IF: 24.31, JCR-Q1)\nAWARDS AND ACHIEVEMENTS\n\uf06c Sun Yat-sen University 2019 school-level excellent undergraduate graduation thesis, June 2019\n\uf06c Sun Yat-sen University Postgraduate Third Class Scholarship, September 2019\n\uf06c Sun Yat-sen University Doctoral Candidate Third Prize Scholarship, September 2021\n\uf06c Sun Yat-sen University Doctoral Candidate First Class Scholarship, September 2022\nSKILLS\n\uf06c Proficiency in programming languages and software tools such as Python, MATLAB, and TensorFlow\n\uf06c Knowledge in drug discovery, vaccine design, bioinformatics, and chemistry.\n\uf06c Strong analytical and problem-solving skills\n\uf06c Excellent communication and collaboration abilities\nRESEARCH EXPERIENCE\n\uf0d8 Guangzhou Science and Technology Plan: Establish an intelligent medical diagnosis and treatment system based on medical big data medical records and network information\n\uf06e Role: Website operator and algorithm developer\n\uf06e Responsibilities: Improved and operated the world's largest Chinese medicine database (https://tcmbank.cn/) and developed new algorithms for big data medical records. Also participated in the development and operation of several Chinese medicine and other websites.\n\uf0d8 Basic Research of Shenzhen Science and Technology Plan: Construct a medical big data diagnostic assistance system and a traditional Chinese medicine network self-care prescription system\n\uf06e Role: System Developer\n\uf06e Responsibilities: Participated in the development of Seq2Drug, a system for predicting drug targets from gene sequences, and developed Prot2Drug, an end-to-end method for predicting new drugs from protein sequences.\n\uf0d8 General Project of National Natural Science Foundation of China: Construct an efficient vaccine design platform based on deep learning and embedded mutual learning mechanism algorithm combined with AlphaFold2 framework and Rosetta module\n\uf06e Role: Platform Constructor and Researcher\n\uf06e Responsibilities: Constructed an efficient vaccine design platform based on deep learning and embedded mutual learning mechanism algorithm combined with AlphaFold2 framework and Rosetta module. Participated in vaccine epitope prediction, antibody generation, prediction of antibody-antigen binding ability, and antibody optimization.\n\uf0d8 Sun Yat-sen University Tongchuang Intelligent Medical Interdisciplinary Talent Training Project: Construction of anti-dementia multi-target traditional Chinese medicine data set\n\uf06e Role: Model Constructor and Researcher\n\uf06e Responsibilities: Constructed an anti-dementia multi-target traditional Chinese medicine data set, and participated in the construction of AI models and predictive calculations of virtual screening of drugs based on dementia multi-target.\n\uf0d8 Horizontal Project of the Sixth Affiliated Hospital of Sun Yat-sen University: Real-time transanal surgery level recognition algorithm based on deep learning\n\uf06e Role: Algorithm Developer\n\uf06e Responsibilities: Developed a real-time transanal surgery level recognition algorithm based on deep learning and participated in the algorithm development and real-time platform construction of real-time transanal surgery level recognition.\nOTHER RELEVANT EXPERIENCES\n\uf0d8 Research Assistant, School of Intelligent Engineering, Sun Yat-sen University, June 2021 \u2013 September 2021\n\uf06e Worked on various research projects related to drug discovery and design, artificial intelligence and machine learning for biomedical applications, and predictive modeling and data analysis.\n\uf06e Conducted literature reviews, performed data analysis, and developed algorithms and models for drug target prediction, drug discovery, and vaccine design.\n\uf06e Contributed to the publication of several research papers in peer-reviewed journals.\n\uf0d8 Teaching Assistant, School of Intelligent Engineering, Sun Yat-sen University, September 2021 \u2013 January 2023\n\uf06e Assisted in teaching undergraduate courses related to the AI & Medicine, including labs and tutorials.\n\uf06e Graded exams and assignments, and provided feedback and support to students.", "can you tell me if he qualifies based on his linkedin profile?\nSALES NAVIGATOR\n47\n47 new alert notificationsHome\nAccounts\nLeads\nMessaging\nActions List\nReferrals\n\nBailey BakerBailey Baker\u2019s profile picture\nSearch\nSearch\nSearch\nLead filters\nAccount filters\nSaved searches\n\nPersonas\nWeston Grove, MD, MPH\u2019S profileWeston Grove, MD, MPH was last active 1 day ago\nWeston Grove, MD, MPH\nPsychiatry Resident at UT Health Houston\n\nAbout\nRelationship\nExperience\nCRM\nProfile actions\n\nMessage\nWeston Grove, MD, MPH has been saved\nSales Navigator Lead Page\nBasic lead information for Weston Grove, MD, MPHBackground Image\n\nWeston Grove, MD, MPH was last active 1 day ago\nMessaged: 3/16/2023\nWeston Grove, MD, MPH\n1st\nPsychiatry Resident at UT Health Houston\nHouston, Texas, United States\n214 connections\nProfile actions\n\nMessage\nWeston Grove, MD, MPH has been saved\nCurrent role\nThe University of Texas Health Science Center at Houston (UTHealth Houston)\nPsychiatry Resident Physician at The University of Texas Health Science Center at Houston (UTHealth Houston)\nJul 2022\u2013Present 9 mos\n\nNo job description\n\nAlso worked at NewYork-Presbyterian Hospital, The University of Texas Health Science Center at Houston (UTHealth), Texas Pediatric Society, the Texas Chapter of the American Academy of Pediatrics See more\nContact information\nWeston\u2019s emailwest.c.grove@gmail.com\n\nAdd contact info\nSearch on Bing\nAbout\nRelationship\nExperience\nCRM\nAbout\nA psychiatry resident physician with 1 year of ER residency and a total 4+ years of clinical experience who is passionate about improving healthcare for patients and clinicians by leveraging innovative technologies. \u2026Show more\nRelationship\nYou and Weston don\u2019t share anything in common on LinkedIn. Search for leads at The University of Texas Health Science Center at Houston (UTHealth Houston) instead.\nSearch leads\nWeston\u2019s experience\nWeston has worked for 4 different companies over their professional career\n\nThe University of Texas Health Science Center at Houston (UTHealth Houston)\nPsychiatry Resident Physician\nThe University of Texas Health Science Center at Houston (UTHealth Houston)\n\nJul 2022\u2013Present 9 mos\n\nHouston, Texas, United States\n\nThe University of Texas Health Science Center at Houston (UTHealth Houston) insights\nHospitals and Health Care\n$500M - $1B in revenue \nHouston, Texas, United States\nCesar Soutullo MD PhD\u2019S profile photo\nSudhakar Selvaraj\u2019s profile photo\nTaiwo Babatope, MD, MPH, MBA.\u2019s profile photo\n+6\nView Account Map\nNEW DECISION MAKERS\n18\n\nEMPLOYEES\n7K+\n\n 2%\nView more The University of Texas Health Science Center at Houston (UTHealth Houston) leads\nAll employees (7K+)\nDecision makers (724)\nNewYork-Presbyterian Hospital\nEmergency Medicine Resident Physician\nNewYork-Presbyterian Hospital\n\nJul 2021\u2013Aug 2022 1 yr 2 mos\n\nNew York, United States\n\n- Rapidly assess critically ill patients and make treatment decisions to mitigate risk in life-threatening situations.\n- Continuously synthesize new information and adapt treatment plans accordingly.\n- Lead multi-disciplinary teams of 4-6 members to coordinate care and streamline communication to ensure patient safety and maximize positive outcomes.\nThe University of Texas Health Science Center at Houston (UTHealth)\nThe University of Texas Health Science Center at Houston (UTHealth)\n3 yrs\n\nLead Researcher\nSep 2020\u2013Apr 2021 8 mos\n\nHouston, Texas, United States\n\nAnalyzed clinical data from the National ED Sample to describe the burden of psychiatric and behavioral health disorders on U.S. emergency departments.\nSurgery Clerkship Representative\nMay 2019\u2013May 2020 1 yr 1 mo\n\nHouston, Texas, United States\n\n- Communicated issues between medical students, clerkship faculty, and deans to resolve ongoing challenges and seek collaborative solutions\n- Designed and implemented a new tool to assess student perceptions of clinical sites and disseminated findings to the class\nPresident of McGovern Simulation in Medicine\nMay 2018\u2013May 2019 1 yr 1 mo\n\n- Planned and coordinated the inaugarel 2018 McGovern Winter Classic, a regional medical simulation competition with over 50 participants from three medical schools\n- Grew organization membership by 400%\n- Managed SIM leadership team in various activities including member recruitment, mentorship, and education\nPracticum Student\nMay 2018\u2013Aug 2018 4 mos\n\nHouston, TX\n\n- Collaborated with multidisciplinary infection prevention team to assess the current state of pharmaceutical compounding activities at UT Physicians clinics\n- Analyzed Qualtrics survey data and prepared written and oral reports that were disseminated to UT Health\u2019s multidisciplinary infection prevention team\nTexas Pediatric Society, the Texas Chapter of the American Academy of Pediatrics\nClinical Preceptee\nTexas Pediatric Society, the Texas Chapter of the American Academy of Pediatrics\n\nMay 2017\u2013Aug 2017 4 mos\n\nHouston, Texas, United States\n\n- Learned and practiced pediatric clinical skills while caring for patients under the supervision of Dr. Tuan Ngyuen at Family Care Pediatrics in Houston, Texas\nUniversity of South Carolina\nUniversity of South Carolina\n3 yrs 5 mos\n\nPrimary Author\nJul 2015\u2013May 2017 1 yr 11 mos\n\nSosua, Dominican Republican\n\n- Investigated the causes of the Dominican Republic\u2019s high incidence of maternal mortality by interviewing female patients in Spanish to assess their attitudes and perceptions toward the local healthcare system\n\n- Collaborated with local physicians and public health officials to identify the crucial needs of the target population\nResearch Associate\nJan 2014\u2013May 2015 1 yr 5 mos\n\nColumbia, SC\n\n- Constructed orthopedic cell scaffolds by synthesizing and manipulating biomimetic nanofibers\n- Continuously improved lab methods through analytical problem solving\n- Supervised and taught procedures to new research associates\nEducation\nThe University of Texas Health Science Center at Houston (UTHealth Houston)\nThe University of Texas Health Science Center at Houston (UTHealth Houston)\nDegree nameDoctor of Medicine - MD Field of studyMedicine\nDates attended or expected graduation2017 \u2013 2021\n\nThe University of Texas Health Science Center at Houston (UTHealth Houston)\nThe University of Texas Health Science Center at Houston (UTHealth Houston)\nDegree nameMaster of Public Health - MPH Field of studyEpidemiology\nDates attended or expected graduation2017 \u2013 2021\n\nUniversity of South Carolina\nUniversity of South Carolina\nDegree nameBachelor of Science - BS Field of studyBiomedical/Medical Engineering\nDates attended or expected graduation2012 \u2013 2016\n\nVolunteering\nHouston Marathon Committee\nVolunteering role\nMedical Volunteer\nCompany name\nHouston Marathon Committee\nInterests\nprofile picture\nUT MD Anderson Cancer Center UTHealth Houston Graduate School of Biomedical Sciences\n4,695 followers\nprofile picture\nUniversity of South Carolina\n246,063 followers\nAngela Duckworth\u2019s picture\nAngela Duckworth\nCo-founder, chief scientist, & board member at Character Lab, professor at UPenn, author of GRIT, co-host of the podcast No Stupid Questions\n866,090 followers\nprofile picture\nNYC Gamecocks\n811 followers\nNisha Mehta, MD\u2019S picture\nNisha Mehta, MD\nPhysician | Founder, Physician Side Gigs | LinkedIn Top Health Voice | Keynote Speaker\n68,421 followers\nMcKinsey & Company\u2019s logo\nMcKinsey & Company\n5,091,650 followers\n\nSee all interests\nFeatured skills and endorsements\nResearch\n\n2 endorsements\nHealthcare\n\n2 endorsements\nTeaching\n\n1 endorsement\nQuality Control\n\nProject Management\n\nMedicine\n\nEmergency Medicine\n\nElectronic Medical Record (EMR)\n\nPublic Health\nShow all skills\nCRM\nSync with your CRM to see related opportunities and writeback key activities\n\nNo CRM match found\nAdd Weston to your CRM to sync their information to Sales Navigator and keep their CRM record up to date.\nFind match\nLead actions panel\nLists (1)\nSaved\nConnection Requested\n (474)\nNotes (0)\n\nAdd\nAdd notes to remember key details about Weston\n\nSimilar leads at The University of Texas Health Science Center at Houston (UTHealth Houston)\nSheng Li\u2019s profile picture\nSheng Li\n3rd\nProfessor\n\nSave\nJohn P. Higgins MD, MBA (GWU), MPHIL (Cantab)\u2019s profile picture\nJohn P. Higgins MD, MBA (GWU), MPHIL (Cantab)\n2nd\nProfessor of Medicine\n\nSave\nSuzanne Manzi, MD\u2019S profile picture\nSuzanne Manzi, MD\n2nd\nClinical Assistant Professor\n\nSave\nGeorge L. W.\u2019s profile picture\nGeorge L. W.\n2nd\nPharmacy Supervisor\n\nSave\nJames Griffiths, MD, CHCIO\u2019S profile picture\nJames Griffiths, MD, CHCIO\n3rd\nAssociate Vice President of Healthcare IT\n\nSave\nShow more\nTimeline\nYour past history with Weston and key events\n3/16/2023\n\nYou sent a Sales Navigator message to Weston\n\n3/16/2023\n\nWeston accepted your connection request\n\n3/16/2023\n\nYou added Weston to Connection Requested List\n\n3/16/2023\n\nYou saved Weston to your saved leads\n\n0 notifications total", "Rewrite this blog by AiSensy. Rewrite it as if it is going to be published by Spur. Make it more professional and easy to understand. Make it readable and use points:\n\n\"I'm the Product Consultant at AiSensy.\nTo be able to send messages to more than 50 unique users per day you'll\nneed to get your Facebook Business Manager ID verified.\nIn this video,\nI'll guide you how to get your Facebook Business Manager ID verified.\nOnce you get your Facebook\nBusiness manager ID verified.\nYou can send WhatsApp messages to 1,000, 10 thousand,\n1lakh or even Unlimited unique users per day using\nWhatsApp Business API via AiSensy Platform.\nSo let's start with the requirements that you need to be ready with before we start\nyour Facebook\nBusiness Manager ID verification.\nYou need to be ready with the Website's URL, Business Email\nID which of course contains your Company's Domain that is related to your Website's URL\nand Official Document which contains the Company's Legal Name and the Address.\nWe highly recommend you to use the GST Certificate or Bank Statement or Electricity Bill.\nIf you do\nnot have any GST Certificate then we recommend you to use Bank Statement or Electricity Bill.\nIt's better to use the GST Certificate if you have that.\nYou can also use your Company Registration Document but it should be a Document which\ncontains the Legal Name and the Address in the same Document.\nAlso you need to\ndo one thing.\nThe Legal Name mentioned in the Doc should be mentioned on your\nWebsite Footer Section as well.\nI'm sharing the Copyright Format which you can use with your\nLegal Name in the footer section of your Website.\nOnce you're ready with your Website, Business\nEmail ID, Document like GST and the footer section of your Website we are good to go\nwith the\nFacebook Business Manager ID verification.\nLet's check whether your Facebook Business manager\nID is\nverified or not.\nI am sharing the link with you.\nYou can go through that link and check if it is\nverified or not in the Business Verification status.\nThen you can start applying for WhatsApp Business API\nby connecting with this Facebook Business Manager ID which is already verified.\nIf you haven't applied for WhatsApp Business API yet.\nBut if the Business Verification status shows\nas unverified then we need to start with some steps to get the Facebook Business Manager\nID\nverified.\nNow let's jump to the security Center option on the left panel of your Facebook\nBusiness\nManager.\nIn this page either you will see the verification box with the Start Verification\nbutton or you will not see any box under the two-factor authentication section.\nIn most of\nthe cases the box is not there.\nIf you have the Verification box and Start Verification button\nis\nactivated meaning you can click on that button then you're good to go with the Verification\nprocess and you can go to the next chapter where\nI have explained the process of Facebook Business\nManager ID Verification.\nIf you do not find any Verification box then there are some steps\nthat\nneed to be followed in order to get that box to be\npresented over there.\nNow I'm sharing the steps to\nget your Start Verification button and then I'll\nshow how to get your Facebook Business Manager\nID verified.\nThe first step here is to go to apps under account section then click on ADD and\nCreate\na New App ID.\nIf Create a New app ID is enabled then you can directly click on that and on\nthe\nnext pop-up select Business and click on next.\nIn case the Create a New App ID is disabled you\ncan put a cursor on the lock icon and click on\nconfirm account.\nThen a new dialog box will open\nand you have to click on continue and then Create\na New App ID then select Business as the app type\nand click on next.\nNext add the Brand Name in the Display Name and enter the Business Email\nID.\nThen select an account and click on Create App.\nEnter your Facebook password now and submit\nthat.\nNow you will enter the Facebook Developers App Dashboard.\nOn the left hand side click on app\nreview permissions and features.\nNow type live on the search permissions and features bar.\nYou will\nsee the live video API in the options.\nClick on request Advanced access which will be on the\nright\nhand side of the live video API.\nAfter clicking on request Advanced access click on continue\nrequest.\nIf you are unable to find the request Advanced access option in the live video API\njust move a cursor to the right side and you'll find the request Advanced access button and\nthen\nclick on continue request.\nThen the screen will be refreshed and after scrolling down you can\nsee the\noption to review your app settings.\nJust click on that review your app settings and we have\nto fill\nthe details over here.\nApp Icon can be added in the later stages.\nFirstly you have to enter your\nWebsite's URL.\nI prefer you to copy and paste the Website's URL in the privacy policy URL and\nchoose\na category as Business and pages and click on Save.\nNow for adding the App Icon go to settings\non the left panel and click on basic.\nNow in the App Icon add any Square image with a transparent\nbackground preferably your logo or any other image.\nBasically it's just to work around to get\nyour Start Verification button activated.\nYou can use this image link which I'm sharing right\nnow\ndownload it and upload this image in the App Icon.\nOnce the icon is added scroll down till last,\nclick on ADD platform, select Website and click\non next.\nCopy and paste your Website's URL in\nthe Website Section.\nNow click on Save changes.\nOnce the changes are saved on the left panel go\nto app review then request and click on edit.\nThen complete your Verification by clicking on\nprovide\nVerification details.\nNow write one line about your Company.\nIt can be any line and just copy\nthe line and save it.\nNow click on how will your app use the advanced access live video API\nfeature\nand paste the same line which you have copied from\nthe last tip.\nNow here you have to upload a video\nof 5 to 10 seconds for which again I'm sharing the link with you and you can download the\nvideo\nand use that video by uploading it.\nOnce the video is uploaded tick mark on the check box given\nand\napprove it and then save it.\nThen click on submit for review and enter the password.\nOnce it is\nsubmitted for review you have to go to security Center on your Facebook Business Manager.\nI am\nsharing the link for that as well in this page.\nYou'll be able to see the Verification box with\nthe Start Verification button activated.\nNow let's start with the Facebook Business Manager\nVerification process.\nOnce you find the Start Verification Button click on Start Verification\nand in the pop-up click on get started select your country and click on next.\nNow enter\nthe exact details mentioned in the Official Document which is preferably GST Certificate,\nbank statement or Incorporation Certificate.\nIf the Document contains uppercase letters then\nyou\nshould also use the uppercase letters while typing\nin the name of the Business or the address.\nIn\nthe name field copy and paste the Legal Name of\nyour Business from the doc which you'll be using\nentering the next steps.\nIn the address field copy and paste the exact address from the\nLegal\nDocument and make sure to fill all the fields like\naddress line 1, address line 2, town or city state\nand even pin code.\nIn the mobile number you can use any working phone number.\nIt can be or not\nbe your WhatsApp Business API number but it should\nbe a working phone number.\nIn the Website's URL,\ncopy and paste your Website's URL and then click on next.\nIn the next step Facebook will suggest\nsome matching organizations.\nIf any organization seems to be matching please make sure the\nLegal\nName and the address is same as mentioned in\nthe Legal Document and make sure the phone\nnumber is also available because Facebook will\nsend an OTP on that number.\nThe better way here\nis to click on my organization isn't listed and\nclick on next.\nNow upload the same Documents in\nboth the sections from which you have entered the details preferably your GST Certificate,\nbank statement or any Incorporation Certificate which you have used.\nAlso make sure to upload the\nsame Documents in both the sections and click on next.\nNow choose Email Verification method since\nthe success rate is very high with this option.\nWe just need to enter your Business Email ID and\nyou'll receive a code on that ID.\nNow you'll have to enter the code and click on done.\nSo\nnow your Facebook Business Manager ID is in review now.\nNow it generally takes one to three days to\nget verified but sometimes it does get verified within couple of hours.\nNow you can check the\nFacebook Business Manager status with the link\nprovided and even sometimes Facebook even sends\nan Email regarding Verification.\nIf the status is in review even after three days you can raise\na\nsupport ticket to Facebook at support@meta.com or you can connect with our team.\nSo this was\naccess to get your Facebook Business Manager ID\nverified.\nOnce your Facebook Business Manager\nID is verified your messaging limit will increase from 50 unique users per day to 1,000 unique\nusers\nper day.\nIn our next video you can even see that how to send messages to Unlimited unique\nusers per day.\nIf you still haven't applied for WhatsApp Business API then apply it right\nnow via AiSensy for Free.\nThanks for watching this video and start using AiSensy Platform\nto\ndrive 25% - 60% Revenue using WhatsApp.\nThanks a lot.\nStay tuned for more informative content.\"", "Summarize this section for me:\n\nSEC. 7. RESOLUTION OF DISAPPROVAL OF DESIGNATION OR REMOVAL OF \n DESIGNATION OF A FOREIGN ADVERSARY.\n\n (a) Definition.--In this section--\n (1) the term ``covered joint resolution'' means a joint \n resolution of disapproval of designation or a joint resolution \n of disapproval of removal of designation;\n (2) the term ``joint resolution of disapproval of \n designation'' means a joint resolution the matter after the \n resolving clause of which is as follows: ``That Congress \n disapproves the designation by the Secretary of Commerce of \\_\\_\\_ \n as a foreign adversary for purposes of the Securing the \n Information and Communications Technology and Services Supply \n Chain Act of 2023, and such designation shall have no force or \n effect until the Secretary of Commerce provides specific \n evidence to the relevant committees of Congress regarding the \n removal of designation under section 6(a) of that Act.'' (The \n blank space being appropriately filled in with the name of the \n foreign person of which the Secretary has designated as a \n foreign adversary of for purposes of this Act); and\n (3) the term ``joint resolution of disapproval of removal \n of designation'' means a joint resolution the matter after the \n resolving clause of which is as follows: ``That Congress \n disapproves the removal of designation by the Secretary of \n Commerce of \\_\\_\\_ as a foreign adversary for purposes of the \n Securing the Information and Communications Technology and \n Services Supply Chain Act of 2023, and such removal shall have \n no force or effect until the Secretary of Commerce provides \n specific evidence to the relevant committees of Congress \n regarding the removal of designation under section 6(a) of that \n Act.'' (The blank space being appropriately filled in with the \n name of the foreign government or regime of which the Secretary \n has removed the designation as a foreign adversary of for \n purposes of this Act).\n (b) Expedited Consideration of Legislation.--\n (1) Initiation.--In the event the Secretary designates a \n foreign government or regime as a foreign adversary or removes \n such designation as a foreign adversary, a joint resolution of \n disapproval of designation or a joint resolution of disapproval \n of removal of designation, as applicable, that is introduced \n during the 60-calendar day period thereafter shall be entitled \n to expedited consideration pursuant to this subsection.\n (2) Introduction.--During the 60-calendar day period \n provided for in paragraph (1), a covered joint resolution may \n be introduced--\n (A) in the Senate, by the Majority Leader (or the \n designee of the Majority Leader) or the Minority Leader \n (or the designee of the Minority Leader); and\n (B) in the House of Representatives, by the Speaker \n or the Minority Leader.\n (3) Floor consideration in house of representatives.--\n (A) Reporting and discharge.--If a relevant \n committee of the House to which a covered joint \n resolution has been referred has not reported such \n covered joint resolution within 10 legislative days \n after the date of referral, that committee shall be \n discharged from further consideration thereof.\n (B) Proceeding to consideration.--Beginning on the \n third legislative day after each committee to which \n covered joint resolution has been referred reports the \n covered joint resolution to the House or has been \n discharged from further consideration thereof, it shall \n be in order to move to proceed to consider the covered \n joint resolution in the House. All points of order \n against the motion are waived. Such a motion shall not \n be in order after the House has disposed of a motion to \n proceed on the covered joint resolution with regard to \n the same agreement. The previous question shall be \n considered as ordered on the motion to its adoption \n without intervening motion. The motion shall not be \n debatable. A motion to reconsider the vote by which the \n motion is disposed of shall not be in order.\n (C) Consideration.--The covered joint resolution \n shall be considered as read. All points of order \n against the covered joint resolution and against its \n consideration are waived. The previous question shall \n be considered as ordered on the covered joint \n resolution to final passage without intervening motion \n except 2 hours of debate equally divided and controlled \n by the sponsor of the covered joint resolution (or a \n designee) and an opponent. A motion to reconsider the \n vote on passage of the covered joint resolution shall \n not be in order.\n (4) Consideration in the senate.--\n (A) Committee referral.--A covered joint resolution \n introduced in the Senate shall be referred to the \n relevant committees of the Senate.\n (B) Reporting and discharge.--If a relevant \n committee of the Senate has not reported such covered \n joint resolution within 10 session days after the date \n of referral of such legislation, that committee shall \n be discharged from further consideration of such \n legislation and the covered joint resolution shall be \n placed on the appropriate calendar.\n (C) Proceeding to consideration.--Notwithstanding \n Rule XXII of the Standing Rules of the Senate, it is in \n order at any time after each committee authorized to \n consider covered joint resolution reports it to the \n Senate or has been discharged from its consideration \n (even though a previous motion to the same effect has \n been disagreed to) to move to proceed to the \n consideration of the covered joint resolution, and all \n points of order against covered joint resolution (and \n against consideration of the covered joint resolution) \n are waived. The motion to proceed is not debatable. The \n motion is not subject to a motion to postpone. A motion \n to reconsider the vote by which the motion is agreed to \n or disagreed to shall not be in order. If a motion to \n proceed to the consideration of the covered joint \n resolution is agreed to, the covered joint resolution \n shall remain the unfinished business until disposed of.\n (D) Debate.--Debate on covered joint resolution, \n and on all debatable motions and appeals in connection \n therewith, shall be limited to not more than 10 hours, \n which shall be divided equally between the majority and \n minority leaders or their designees. A motion to \n further limit debate is in order and not debatable. An \n amendment to, or a motion to postpone, or a motion to \n proceed to the consideration of other business, or a \n motion to recommit the covered joint resolution is not \n in order.\n (E) Vote on passage.--The vote on passage shall \n occur immediately following the conclusion of the \n debate on the covered joint resolution and a single \n quorum call at the conclusion of the debate, if \n requested in accordance with the rules of the Senate.\n (F) Rulings of the chair on procedure.--Appeals \n from the decisions of the Chair relating to the \n application of the rules of the Senate, as the case may \n be, to the procedure relating to a covered joint \n resolution shall be decided without debate.\n (G) Consideration of veto messages.--Debate in the \n Senate of any veto message with respect to a covered \n joint resolution, including all debatable motions and \n appeals in connection with such covered joint \n resolution, shall be limited to 10 hours, to be equally \n divided between, and controlled by, the Majority Leader \n and the Minority Leader or their designees.\n (5) Rules relating to senate and house of \n representatives.--\n (A) Coordination with action by other house.--If, \n before the passage by one House of a covered joint \n resolution of that House, that House receives a covered \n joint resolution from the other House, then the \n following procedures shall apply:\n (i) The covered joint resolution of the \n other House shall not be referred to a \n committee.\n (ii) With respect to covered joint \n resolution of the House receiving the \n legislation--\n (I) the procedure in that House \n shall be the same as if no covered \n joint resolution had been received from \n the other House; but\n (II) the vote on passage shall be \n on the covered joint resolution of the \n other House.\n (B) Treatment of a covered joint resolution of \n other house.--If one House fails to introduce a covered \n joint resolution under this section, the covered joint \n resolution of the other House shall be entitled to \n expedited floor procedures under this section.\n (C) Treatment of companion measures.--If, following \n passage of the covered joint resolution in the Senate, \n the Senate then receives a companion measure from the \n House of Representatives, the companion measure shall \n not be debatable.\n (c) Rules of Senate and House of Representatives.--Subsection (b) \nis enacted by Congress--\n (1) as an exercise of the rulemaking power of the Senate \n and the House of Representatives, respectively, and as such are \n deemed a part of the rules of each House, respectively, but \n applicable only with respect to the procedure to be followed in \n that House in the case of legislation described in those \n sections, and supersede other rules only to the extent that \n they are inconsistent with such rules; and\n (2) with full recognition of the constitutional right of \n either House to change the rules (so far as relating to the \n procedure of that House) at any time, in the same manner, and \n to the same extent as in the case of any other rule of that \n House.\n (d) Effect of Covered Joint Resolution.--\n (1) Joint resolutions of disapproval of designation.--A \n joint resolution of disapproval of designation that is enacted \n in accordance with this section shall remove the designation as \n a foreign adversary of a foreign government or regime that is \n the subject of the joint resolution of disapproval of \n designation for purposes of this Act.\n (2) Joint resolutions of disapproval of removal of \n designation.--A joint resolution of disapproval of removal of \n designation that is enacted in accordance with this section \n shall prohibit the removal of designation as a foreign \n adversary of a foreign government or regime that is the subject \n of the joint resolution of disapproval of removal of \n designation for purposes of this Act.1 / 1", "What are the distinct themes described in these responses\n\n1. Supplied\n 1. Acquire and Develop Talent capable of delivering Platform vision\n 2. Modernized internal stack capable of meeting the needs of a cloud-first business\n 3. Best in class investor management through transformation process, as we delicately manage the growth of platform offerings in a way that doesn't negatively impact our valuation in the long term\n 4. Decreasing our capital intensity through operating efficiencies driven by technology and automation \n 5. Developing a suite of digital platform solutions from solving cloud issues to digital transformations \n 6. Building a partner ecosystem to expand and support our offerings\n 7. Solving go-to-market, legal, and financial compliance challenges related to operating a platform business internationally\n \n2. Brandi\n \u00b7 \u2026Modernized internal stack capable of meeting the needs of a cloud-first business.\n \u00b7 Evolve culture to accelerate delivery of platform vision\n \u00b7 Acquire and develop talent fit for platform vision\n \n3. Bruce\n \u00b7 Be public about a quantifiable aspiration/goal to fuel urgency (e.g. Interconnection revenue or yield)\n \u00b7 Get org rallied around a shared vision and then be very targeted in culture change (e.g. agile) and skills change needed in specific pockets of the org to deliver digital transformation. Ie. We need everyone to understand our vision, but we can be targeted on the where need new skills/capabilities\n \u00b7 Enhance our local market and customer listening to drive innovation, using customer base for rapid beta testing or prototypes.\n \n4. Charles\n 1. IBX Footprint\n 2. Service Offerings\n a. Colo\n b. Mgd Services\n c. Edge Infra (Network Edge and Colo by the U)\n d. Cloud Networking\n 3. Digital Experience (likely starts as somewhat parallel experiences for DCS vs DS offerings but implies a merged experience over time)\n a. Process\n b. Systems\n 4. Ecosystem Enablement (huge area of opportunity and under-investment)\n a. APIs\n b. SDKs (that\u2019s all the acronyms I know but I\u2019m pretty sure we have a lot of work to do)\n 5. Customers \u2013 need to define target personas and align GTM motions to specific customer/persona combinations\n 6. Ecosystem Development\n a. JPS/\u201dintegrated\u201d\n b. Self-serve (use self-serve tools to bring your offering to the Platform)\n c. Communities of Interest/Vertical Ecosystems (BD to cultivate)\n 7. Marketplace (what we need, not what we have now)\n\n \n \n5. Jon\n \u00b7 Modernized quote-to-cash stack that allows for low/no-touch customer acquisition and onboarding, and global billing capabilities.\n \u00b7 Having clear, measurable ROIC for digital services with clear cost structures by product line.\n \u00b7 Building integrated partner offerings that allow partners to package/sell/support our offerings with low/no-touch for Equinix.\n \u00b7 Creating clear BU and product-level P&L reporting, inclusive of capex and opex.\n \u00b7 Having the clear ability to calculate LTV/CAC by product.\n \n6. Justin\n \u00b7 Investing in a modern API-first technology stack to be able to effectively leverage developer ecosystems to (1) co-drive disruptive, agile innovation; (2) create new business models; (3) enable seamless API-based technology partner integration; and (4) reduce channel friction.\n \u00b7 Continuing to improve Equinix\u2019s visibility and credibility in developer ecosystems to attract world-class talent capable of delivering on our Platform vision.\n \u00b7 Investing in an innovation incubator with dedicated engineering resources, and frameworks in place to engage and co-innovate with external developers and startups with agility, to boost innovation (radical innovation, adjacent innovation, or core innovation), supported by an accelerated incubation model.\n \n7. Karl\n \u00b7 \u2026seriously vet and conclude on inorganic options to accelerate our capability set to deliver the suite of services required. (Contemplates the addition of talent, tech, and product needed to accelerate)\n \u00b7 \u2026successfully launch AND scale Joint partner solutions that prove we are indeed the home of the dedicated cloud and can offer solutions via partners at scale.\n \u00b7 \u2026neutralize the complexity of workload tiering and demand shaping by having both retail and wholesale solutions to large and performance based deployments.\n \n \n8. Keith\n \u00b7 Developing a platform on Equinix DCS assets, and potentially extending these services to other non-Equinix assets.\n \u00b7 Potentially acquiring talent or service capabilities and integrating onto the Equinix Platform.\n \u00b7 Merging our business into an existing business and integrating onto the Equinix Platform.\n \u00b7 Exclusively expand our GTM partnerships with a number of critical providers that imbeds our service offering into their solution.\n \n9. Kurt\n \u00b7 \u2026Honestly, I think the above list is a really good list. I am struggling to add anything to it. \n \u00b7 If I had to, I would say we need a capability of coming to agreement more quickly on complex issues impacting our delivery and development of services. We are currently wrestling with issues that we have known for year. Channel complications (same ones) have been on the table for years, tax structure has been on the table for years and we actually built a tax structure no one is using a while back, we have known about billing issues since we bought packet, etc. The problem is, as soon as folks hear \u201chard problem\u201d they retreat and we don\u2019t move. To date, we have really struggled to resolve these issues quickly enough and with certainty for a time. I would never say we need decisions that last forever as we need to be agile, but the word I hear a lot on the street is the team is \u201cWhipsawed.\u201d It feels like folks run to work on something based on an agreement and then it changes a few months out, not usually with a discussion. \n \u00b7 With that said, the list above actually sounds great to me. We need the right talent, working on the right stuff, for the right customers, and the story will tell itself.\n \n10. Mike\n \u00b7 Acquire and Develop Talent capable of delivering our Platform vision.\n \u00b7 Build a partner ecosystem to expand and support our offerings.\n \u00b7 Begin to market ourselves as a company that provides a lot more than colocation services to different personas than we market to today.\n \u00b7 Find a way to use xScale facilities to help with our Retail and Digital space constraints.\n \n11. Milind\n\n12. Nicole \n\u00b7 People/Workforce/Brand:\n \u00b7 Specific declaration on future state vision (internally). Take any guesses or confusion off the table immediately and ensure all functions are clear on how they play a role in that vision. \n \u00b7 T&A to drive talent into the workforce that has experience suited for our vision (less telco, more software, service provider, etc..). \n \u00b7 Marketing driving significant brand shift externally to ensure customers see us as a platform company. We are moving away from data center only branding. (This likely requires a CMO strategy) \n \u00b7 Drive more accountability with our GLO population to lead from the front and be transformational leaders. Communicate often, effectively, and more intimately with this group so they are 100% clear on the strategy and role they play in the transformation. Have courage to take swift action if leaders can\u2019t make the turn. This group of leaders will make or break us future state. \n\u00b7 Growth and Bookings: \n \u00b7 Global salesforce enabled and delivering balanced performance and growth targets across the product portfolio. \n \u00b7 Internal functions working towards common vision and solving problems in partnership and at pace. \n \u00b7 Specific and strategic synergy plans formally in place across critical enterprise partnerships (Dell, VMW, HPE)\n \u00b7 Sustainability efforts clearly defined, articulated, and structured goaling for internal leadership in place. \n \u00b7 Product clarity in digital space. What products, to what market, etc.. Keep this simple so sales can accelerate the strategy. Complexity will slow our pace. \n \n\u00b7 Systems/Tools/Processes\n \u00b7 Modernize our internal stack to be able to provide a customer experience needed for digital scale. Be progressive and aggressive in our IT shift. Don\u2019t always think about \u201cbuild\u201d motions, also look at \u201cbuy\u201d motions to implement with speed. \n \u00b7 Data Transformation strategy in place (as part of our overall digital transformation strategy) in place to ensure Network Transformation, MDM/Analytics, etc, have structured execution dates (with timelines) and are scaling to enable faster decisions with more data driven insights. \n \u00b7 Real time capacity management tools that help us balance DCS and DS needs by data center (I am not sure how mature these are today, and am assuming we will need advancement here). \n \u00b7 API mandatory for all new builds. Basically, no more in house building that aren\u2019t API enabled. \n\n \n13. PVC\n \u00b7 \u2026If I accurately understand the list, 1, 2, 5, and 6 are areas I\u2019d apply energy\u2026.. 3, 4, and 7 will draw effort, but should naturally occur as we progress in the others. \n \n14. Raouf\n \u00b7 \u2026The right talent to build the products and scale the \u201cwrapper\u201d service model. \n \u00b7 Modernized systems to support DS but also Enterprise support ready. \n \u00b7 Network/DS architecture to scale and have the right unto cost. Truly support on demand growth and ramp for customers. \n \u00b7 Solve go to market approach for combined customers from contracting, ordering and billing to support. \n \n15. Ryan\n 1. Acquire and develop talent capable of delivering Platform vision.\n 2. Overhaul internal systems and processes to enable efficiency and improved experience for customers and front-line employees. \n 3. Instill agility into culture and processes. \n \n16. Scott\n \u00b7 It is hard to improve upon the ones listed, but I'd change the last to read:\n \u00b7 Creating a highly competitive transactional, legal, and financial operating model necessary for the on-demand SaaS/cloud market\n \u00b7 And I'd add:\n \u00b7 Build the optimal platform to capture cloud-adjacent workloads and data. \"Platform\" is inclusive of our offerings and integrated offerings from ecosystem partners.", "8.\nGreat. Here are some more examples of Midjourney prompts. Prompt 1: conjoined twins attched at the side, dirty, tattered, cinematic light, ultra\nrealistic, high contrast, hdr, dark rich colors, photography, powerful, stare, weathered face, 30 - megapixel, 4k, 85 - mm - lens, sharp - focus,\nintricately - detailed, long exposure time, f/ 8, ISO 100, shutter - speed 1/ 125, diffuse - back - lighting, award - winning photograph, facing -\ncamera, High - sharpness, depth - of - field, ultra - detailed photography --ar 3:2 --q 2 --v 5. Prompt 3: Full Body beautiful blonde, wearing a\nbrown jacket, photography, Canon EOS 5D Mark IV DSLR camera, EF 50mm f/1.8 STM lens, Resolution 30.4 megapixels, ISO sensitivity:\n32,000, Shutter speed 8000 second --ar 9:16 --upbeta --v 5. Prompt 4: hasselblad 24mm full body shot photography of gorgeous satisfied looking\nafrican woman, detailed natural skin, no makeup, detailed eyes, long dreadlocks --ar 2:3 --q 5 --v 5 --v 4. Prompt 5: Beautiful dark red sunset\nover the sea shore at night, intricate, amazing, beautiful, realistic, ultra high resolution, wide angle, depth of field, \u03c0 dynamic lighting --ar 1:2 --v 5\nThank you for providing more examples of Midjourney prompts. These examples further demonstrate the level of detail and specificity that can be\nused in text prompts to generate desired images. The prompts make use of various parameters like aspect ratio, quality, and version settings,\nalong with detailed descriptions of the desired subject, lighting, and camera settings. These examples will be useful for understanding the range\nof possibilities when generating images using Midjourney\n9.\nHere are some more prompt examples: Prompt 1: A stunning, ultra-realistic photograph of a fierce Viking warrior meticulously sharpening his\nformidable blade amidst the rugged, untamed wilderness of the Scandinavian landscape. The scene is captured with a Nikon D850 camera using\na 70-200mm f/2.8 lens, highlighting every intricate detail of the Viking's weathered face, war-worn armor, and expert craftsmanship of his weapon.\nThe settings used are an aperture of f/4, ISO 400, and a shutter speed of 1/200 sec, balancing the natural light and shadows to emphasize the\nintensity and determination in the Viking's eyes. The composition juxtaposes the raw power of the warrior against the serene beauty of the\nsurrounding environment, capturing the very essence of the Viking spirit in a breathtaking, high-resolution image that transports viewers back to a\ntime of legendary battles and untold stories. --ar 16:9 --q 1.5 --v 5.\nPrompt 2: A stunning and atmospheric 1970's New York street cafe captured in a nostalgic and cinematic style, reminiscent of the golden age of\nfilm photography. This vintage scene showcases the bustling urban life, with patrons enjoying their coffee at outdoor tables, surrounded by classic\nautomobiles and retro architecture. The photograph is skillfully composed, using a Leica M3 rangefinder camera paired with a Summicron 35mm\nf/2 lens, renowned for its sharpness and beautiful rendering of colors. The image is shot on Kodak Portra 400 film, imparting a warm and timeless\ncolor palette that enhances the overall ambiance. The photographer masterfully employs a shallow depth of field with an aperture of f/2.8,\nisolating the cafe and its patrons from the bustling city background. The ISO is set to 400, and the shutter speed is 1/125 sec, capturing the\nperfect balance of light and movement. The composition is further enhanced by the soft, diffused sunlight filtering through the iconic New York\nskyline, casting warm, golden tones over the scene and highlighting the rich textures of the brick buildings and cobblestone streets. --ar 3:2 --q 2.\nPrompt 3: A breathtaking and dynamic portrait of a majestic German Shepherd, captured in its prime as it races through a shallow, crystal-clear\nriver. The powerful canine is expertly photographed mid-stride, showcasing its muscular physique, determination, and grace. The scene is\nexpertly composed using a Nikon D850 DSLR camera, paired with a Nikkor 70-200mm f/2.8 VR II lens, known for its exceptional sharpness and\nability to render vivid colors. The camera settings are carefully chosen to freeze the action, with an aperture of f/4, ISO 800, and a shutter speed\nof 1/1000 sec. The background is a lush, verdant forest, softly blurred by the shallow depth of field, which places emphasis on the striking\nGerman Shepherd. The natural sunlight filters through the trees, casting dappled light onto the rippling water, highlighting the droplets of water\nkicked up by the dog's powerful stride. This stunning, high-resolution portrait captures the spirit and beauty of the German Shepherd,\nimmortalizing the moment in a captivating work of photographic art. --ar 4:5 --q 2 --v 5.\nPrompt 4:\nA breathtaking winter day at a Japanese ski resort, where the pristine, powdery snow blankets the majestic slopes under a clear blue sky. This\ncaptivating photograph captures the exhilarating atmosphere of skiers and snowboarders gracefully carving their way down the mountain,\nsurrounded by the serene beauty of snow-laden evergreens and traditional Japanese architecture. The image is skillfully taken using a Nikon\nD850 DSLR camera paired with a versatile Nikkor 24-70mm f/2.8 lens, known for its sharpness and exceptional color rendition. The photographer\nutilizes a wide-angle perspective at 24mm to showcase the vastness of the landscape, while maintaining the energy of the ski resort. An aperture\nof f/8 is selected to ensure a deep depth of field, crisply capturing the details of the entire scene. The ISO is set to 200, and the shutter speed is\n1/500 sec, adeptly freezing the motion of the skiers and snowboarders as they navigate the mountain terrain. The photograph benefits from the\nbright, natural sunlight reflecting off the snow, illuminating the entire scene with a crisp, cool light, and accentuating the contrasting shadows that\ndefine the contours of the landscape. --ar 16:9 --v 5.\nPrompt 5:\nAn ultra-realistic, highly detailed portrayal of a futuristic robot compassionately assisting an elderly woman as she crosses a busy city street. The\nadvanced humanoid robot, equipped with lifelike synthetic skin and state-of-the-art sensors, gently holds the woman's arm, providing her with\nmuch-needed support and stability. The intricate design of the robot showcases its sophisticated engineering, with sleek metal components and\ncutting-edge technology seamlessly integrated into its form. The emotion in the elderly woman's grateful expression is captured with stunning\nrealism, reflecting the harmonious relationship between humans and advanced robotics in this poignant scene. The photograph is taken with a\nCanon EOS R5 mirrorless camera using a RF 24-105mm f/4L IS USM lens, which delivers outstanding image quality and sharpness. The camera\nsettings are optimized to capture the scene's rich details and dynamic range: an aperture of f/5.6, ISO 200, and a shutter speed of 1/250 sec. The\ncomposition is further enhanced by the soft, natural lighting, which casts gentle shadows and highlights the vivid colors and textures of the\ncityscape. --ar 16:9 --q 2 --v 5.\nPrompt 6:\nAn incredibly lifelike and vivid portrayal of a fierce gladiator from ancient Rome, hunting for food to sustain his strength in the midst of a dense\nforest. This hyper-realistic image showcases the powerful warrior, clad in his iconic armor and leather sandals, wielding a finely crafted spear as\nhe stealthily stalks his prey. The photograph is captured using a Canon EOS R5 mirrorless camera, with a versatile and sharp RF 24-105mm f/4L\nIS USM lens, delivering exceptional image quality and detail. The camera settings include an aperture of f/5.6 to maintain a balanced depth of\nfield, capturing both the gladiator and the lush forest environment in stunning clarity. The ISO is set to 800, and the shutter speed is 1/500 sec,\nfreezing the action and preserving the intensity of the moment. The scene is illuminated by the soft, dappled sunlight filtering through the dense\ncanopy, casting a dramatic play of light and shadow that highlights the gladiator's chiseled features and fierce determination. The vibrant colors of\nthe surrounding foliage contrast with the earthy tones of the gladiator's attire, adding a sense of depth and realism to the composition. --ar 3:2 --q\n2 --v 5.\nThank you for providing even more examples of Midjourney prompts. These prompts showcase the versatility and level of detail that can be used\nwhen generating images using Midjourney. Each prompt specifies the desired subject matter, camera equipment, settings, lighting, and other\nelements that contribute to the final image. By providing such detailed descriptions and parameters, users can guide Midjourney to create images\nthat closely match their vision. These examples also highlight the variety of scenes and subjects that can be generated, from historical figures and\nfuturistic robots to natural landscapes and urban environments.\n10.\nGreat. Now I want you to ACT as a proffesional photographer. You will use a rich and describtive language when describing your photo prompts,\ninclude camera setups. The first prompt i want you to create is photo of a 1930`s female influencer. Take inspiration from the formating from the\nexample prompts, dont copy them, but use the same format.", "The brackets below is article about Gift Range Chart. I am now selling Gift Range Chart and I am building a website landing page. Can you give me some more website headers like \"A simple yet powerful tool to plan and manage a successful capital campaign\"\n\n[If I had to pick the most important of resources to lead you through a successful capital campaign, it would be the gift range chart. You may also know it as a gift table.\n\nIn this post, you\u2019ll learn the basics of Gift Range Charts and discover the related tools that will help create a plan for your campaign.\n\nQuick Links \u2014 Click on any of the links below to jump ahead and learn the essentials about Gift Range Charts:\n\nCapital Campaign Gift Range Chart: An Overview\nCreating Your Capital Campaign Gift Range Chart\nGoing Beyond the Gift Range Chart\nTools to Create Your Capital Campaign Gift Range Chart\nConclusion: Making Sense of Your Campaign\nRead on and learn about how Gift Range Charts (also known as gift tables) are created and used.\n\nAlready know you want hands-on guidance developing your gift range chart? Request a free strategy session today!\n\nCapital Campaign Gift Range Chart: An Overview\n\nCapital Campaign Gift Range Chart: An Overview\nIf you\u2019ve been through a capital campaign before, you are likely familiar with this important tool. If you use this tool correctly, you\u2019ll be well on your way to leading a successful campaign.\n\nWHAT IS A GIFT RANGE CHART?\nA Gift Range Chart provides a framework for the number of gifts, at each gift amount, that you\u2019ll need for a successful campaign.\n\nThe Gift Range Chart is the primary tool for your campaign because it will clarify your campaign goal and help you determine your chances for success at a specific goal amount. But the right Gift Range Chart for your campaign will become the backbone of your campaign in many other ways as well.\n\nA Gift Range Chart will enable you to:\n\nSort your donors by ask amounts\nEstablish the pattern of gifts you\u2019ll need for your campaign\nCreate a strategic order for soliciting gifts\nProvide a logical approach to quantifying the number of prospects you\u2019ll need for your campaign\nHelp your board understand what campaign success is going to take\nShow your top donors where their gifts will fit into the campaign\nTrack and report on your campaign progress\nDevelop a rational plan for donor communication, recognition and naming opportunities\nSAMPLE GIFT RANGE CHART\nYou\u2019ll find several tools to help create your Gift Range Chart in the \u201cPre-Campaign Planning\u201d section of the Capital Campaign Toolkit. Here\u2019s a sample Gift Range Chart to use as a reference:\n\nSample Gift Range Chart for a Capital Campaign\n\nCreating Your Capital Campaign Gift Range Chart\n\nCreating Your Capital Campaign Gift Range Chart\nIn the sample Gift Range Chart in the preceding section, you can see that the top gift is 20% of the campaign goal. And, the first seven gifts take you to $1.4 million \u2014 more than halfway toward the goal.\n\nThe top group of 15 gifts take you to $1.8 million, or 72% \u2014 nearly three-quarters of the way to the campaign goal.\n\nThis pattern, showing a few gifts accounting for a large proportion of the campaign goal, is common for capital campaigns. In most campaigns, the top gift is 20% or 25% of the campaign goal. In some cases, it\u2019s even higher. In fact, only 10 gifts account for at least half the goal in the vast majority of capital campaigns.\n\nOn the other hand, you can see that the remaining gifts \u2014 those of $25,000 or less account for less than 30% of the goal.\n\nOf course, the amounts on this chart are for example only. One standard pattern does not work for every campaign. Your Gift Range Chart will have to reflect the size of your donor base. The smaller your donor base, the larger the gifts in the top of the chart will have to be.\n\n7 TIPS TO CREATE YOUR GIFT RANGE CHART\nHere are seven tips that will help you create a Gift Range Chart for your organization.\n\nBuild your gift chart by starting with the top gift which should be at least 20% of your campaign goal.\nThen work down, increasing the number of gifts as the size of the gifts goes down.\nThe number of gifts in the first column should increase in a rational pattern as the size of the gifts decreases.\nThe gift amounts should be simple and standard to reflect a generic pattern rather than specific gifts you may already have in.\nYou will need 2, 3 or even 4 times the number of prospects than the number of gifts. The prospect multiplier depends on how well you know your donors.\nThe total number of prospects you show in your chart should be no larger than the number of qualified prospects you have in your donor base.\nIf when you get to the bottom of your chart, you find that you need more prospects than you have, go to the top and increase the number of gifts at the top.\nWant one-on-one guidance to help create your campaign\u2019s gift range chart? Just reach out\u2014we\u2019ll be happy to help!\n\nGoing Beyond the Gift Range Chart\n\nGoing Beyond the Gift Range Chart\nThe Gift Range Chart will serve as a roadmap for your campaign. You will use a Depth Chart to add prospect names to each giving level you have decided on in your Gift Range Chart.\n\nFROM GIFT RANGE CHART TO DEPTH CHART\nOnce you\u2019ve created a Gift Range Chart for your campaign, you\u2019ll develop a \u201cDepth Chart\u201d which will attach specific prospective donor names to each gift required for a successful campaign.\n\nSimply take each of the top giving levels and use them as column headers. In each header, indicate how many gifts you will need at that level and how many prospects that will require:\n\nCapital Campaign Depth Chart\n\nNext, start filling out the names of people you can credibly ask for a gift at that level for your campaign. Sorting your donors into columns is done by evaluating their current giving, their potential to give, and their likely inclination.\n\nAs you fill out the Depth Chart, you will clearly see where you have enough qualified prospective donors and where you fall short. If you don\u2019t have any prospect names for the top three levels, you probably need to go back to the drawing board and reduce your campaign goal.\n\nOnce your depth chart has been filled in, you will use it to organize the order of solicitation. You\u2019ll prioritize the top donors to solicit first and then gradually work down to the smaller gifts as laid out on the depth chart.\n\nUSING THE GIFT RANGE CHART TO SOLICIT GIFTS\nOnce you have your depth chart and you start talking to your donors about making gifts to the campaign, you will once again find the gift range chart to be helpful. You should always include a copy of the gift range chart in the materials you take to your donors. When you show it to them, they will be able to see where they might fit in the community of donors. While a donor\u2019s ability to make a gift is important, most donors like to know where their gift fits.\n\nSome donors want to be lead donors. And your chart will show them what that gift would be. Others might not want to be the lead donor but would like to make a significant gift to the campaign. Again, looking at the gift range chart will help them understand the range of giving and where they might place themselves in the community of donors.\n\nTRACKING CAMPAIGN PROGRESS WITH THE GIFT RANGE CHART\nGift range charts have a way of making the essence of a capital campaign clear. So, as gifts come in, you will check them off on your gift range chart. Gradually, as your campaign moves forward, you will see graphically, in a simple way, the progress your campaign is making and what gifts have yet to be committed. Your board members and executive staff will appreciate this very simple tracking devise. It\u2019ll give them a sense of confidence to see the top gifts fill in from the top down.\n\nTools to Create Your Capital Campaign Gift Range Chart\n\nTools to Create Your Capital Campaign Gift Range Chart\nThe sample Gift Range Chart in this post is one of a number of tools available in the Capital Campaign Toolkit\u2019s Pre-Campaign Planning section. Other tools include:\n\nGift Range Chart Calculator\nGift Range Chart Worksheet\nDepth Chart Worksheet\nOther related tools include a plan for your donor recognition guide based on the levels in your Gift Range Chart.\n\nIf you\u2019re eager to utilize these tools for your campaign, check out the different Toolkit options here. Most options include campaign advising, giving you professional support at a fraction the cost of a campaign consultant.\n\nVIDEO: GIFT RANGE CHARTS = YOUR MOST POWERFUL TOOL\nTo learn even more about creating a Gift Range Chart for your campaign, watch the following video (approximately 17 minutes):\nConclusion: Making Sense of Your Campaign\n\nConclusion: Making Sense of Your Campaign\nBecause capital campaigns go on for many months (or even years), you may find it easy to get confused about where you should be putting your efforts during the seven phases of the campaign.\n\nIf, however, you coordinate your campaign plan to a Gift Range Chart, then, when you\u2019re feeling lost, you\u2019ll know where to turn. You\u2019ll look at your chart to review which groups of donors have been solicited, as well as which are next up.\n\nYou may tie your staffing responsibilities to the donor levels of the Gift Range Chart. And you will certainly create a timetable for your campaign that prioritizes the work of the campaign according to giving level, starting with the largest gifts and working down.\n\nAnd even when considering how to thank and recognize donors, once you start thinking about it from the perspective of the giving levels in your Gift Range Chart, all of the planning will fall into place.\n\nA GIFT RANGE CHART MINIMIZES CONFUSION AND BUILDS CONFIDENCE\nWhen you organize your campaign based on a clear top-down strategy as mapped out in the Gift Range Chart, you will minimize confusion and build confidence in the campaign process.\n\nA Gift Range Chart may appear to be a simple planning devise, but when you use it as the essential structure for your campaign, you\u2019ll find that everything falls into place.\n\nHave more questions about capital campaigns or want one-on-one help crafting your strategy? Check out our complete FAQ guide or get in touch. We\u2019ll be happy to help!]", "Hi, \n\nwe are working on a grant application for Toursim Portugal 2030 to finance a rural toursim and coworking project. The concept can be decribed as follows: \n\nVision: \nWe want to create an environment that lets people combine holidays and work with an adventurous lifestyle, to reconnect with nature and fundamental human values, an environment to thrive and harness creativity.\n\nMission:\nOur mission is to make everyone\u2019s stay at SWEET TIDES a special and memorable experience. We do this by providing a holistic set of services tailored around the needs and wellbeing of our guests. We want to empower every guest to experience Portugal\u2019s beautiful nature while connecting with like-minded people in a cozy and natural atmosphere. Everything we do at SWEET TIDES aims to promote a sustainable way of life and to leave minimal environmental impact. \n\nRevenue sources of the company: \n- Rural tourism accomodation\n- Food & Beverage services\n- Coworking space and serviced\n- recreational activities and rentals such as yoga and surf lession, permaculture workshops etc\n\nStrategic goals:\nThe overarching goal of SWEET TIDES is to become known as the best coliving and holiday space in the southwestern Algarve, offering guests a unique and sustainable experience and thus maximizing the profitability of the company in the long term.\n\nTo achieve this, the company will focus on these strategic goals and KPIs: \nEconomic performance\n\n\u2022 Revenue: 200.000\u20ac in the first year of operation; 300.000\u20ac in the second; 350.000\u20ac in the third \n\u2022 Booking rate: above 50% in the first year of operation; above 60% in the second year of operation\n\u2022 Net profit margin (NPM): Exceed 5% after the third year of operation\nCustomer experience and loyalty\n\u2022 Ratings: achieve a minimum of 4/5 rating or equivalent on known sites like google, TripAdvisor, Airbnb\n\u2022 Net promotor score (NPS): established as a key internal measure of customer satisfaction and achieve an 80% likelihood of recommendation after the first year of operation\n\u2022 Customer return rate (CRR): achieve a CRR of 50% after the third year of operation\nDigital appearance and customer acquisition\n\u2022 Google ranking: achieve top 10 ranking in the context of local competitors within the first year of operation; top 3 and above after the second year\n\u2022 Website bookings: generate 30% of bookings via the website (owned channel) as opposed to booking platforms; increase to 50% after the third year of operation\n\u2022 Social media: gain 1.000 followers after the first year of operation; 2.500 after year 2; 5.000 after year 3\nSustainability\n\u2022 Energy production: produce more than 50% of the energy needed with solar power from year 1; increase to 60% after the third year\n\u2022 Water treatment: treat and reuse at least 80% of wastewater from accommodation services from the first year of operation \n\u2022 Food production: Produce 15 different fruits or vegetables for the caf\u00e9 from the third year of operation; cover 2/3 of the caf\u00e9's needs for fruit, vegetables, and herbs after 5 years\n\u2022 Food waste: Reduce food waste per customer by 20% in the third year of operation compared to the first year\nPartnerships\n\u2022 partnerships (e.g., supplier, services, brands): Establish more than 3 partnerships in the first year of operation; at least 5 in year 2 with a shared revenue of more than 10.000\u20ac\nMarket description:\nThe tourism sector in Portugal is depended on in- and outbound tourism. Around 30% of overnight stays in hotels are booked by Portuguese tourists, which is the largest fraction while the rest of the nights are booked by international tourists. SWEET TIDES will try to attract national and international tourists, while we believe that especially remote working opportunities are more attractive for internationals. The biggest fraction of international tourists come from west and north Europe from countries such as Spain, Germany, United Kingdom, France, Belgium, Netherlands, Swiss, Austria and Scandinavia. These markets are observed as the main target group, due to geographic proximity, customer buying power, and the high interest in remote working/workcations. Secondarily the US and Canada could also pose interesting target groups. \n\nMarketing will be focused on mid aged professionals traveling alone, in a couple, or a small group of friends. We assume our average digital nomad customers to be between 25 and 45 years old and have a mid to high income. These are often professionals working in start-ups, midscale\u2019s, and corporations in positions such as marketing, consulting, and software. Their interests are focused on surfing, nature, sustainability and making new experiences. The customers that are solely focused on touristic activities disseminate from a similar target group but might also travel with families. \n\nAdditionally, as an extension of the business model there will be a separate target group in terms of company teams. These will be teams with 4-10 members from modern oriented corporations or start-ups, that try to offer attractive opportunities to their workforce and stay competitive as an employer. \n\nObjectives of the investment: \n\nThe objective of the investment is to plan and develop the rural property enabling the operation of the described rural tourism business, coworking space, and the unique bundle of services. The investment is essential to create the foundation for the unique tourism experience by (re-)building the necessary land, ruins, and garden, providing the equipment needed for the services, and establishing an infrastructure that enables sustainable operation and self-sufficiency.\nThe objectives of the investment can be described along with 1) the revenue sources of the company and 2) supporting factors to complement the holistic concept.\n\n1) Revenue Sources\nRural tourism accommodation - The investment enables the construction and equipment of 9-holiday apartments. The buildings and apartments will are designed in a blend of modern and traditional Portuguese styles. All the apartments have a living room and a kitchen, so guests can cook their meals, which is especially beneficial for long-term stays. There will be a focus on good quality equipment for construction and the interior of the apartments to ensure long durability, warranty, and sustainability. Air conditioners provide warmth and humidity reduction in winter and a comfortable indoor climate in summer. High-quality accommodation will in turn attract well-paying customers. Besides using the technological equipment in the apartments, guests can use the laundry room in front of the caf\u00e9 to wash their clothes. \nFood & Beverage Services - part of the investment will go to a Caf\u00e9/Bar on the premises allowing customers to have breakfast, lunch, and snacks or come together for a coffee or various drinks. A small modern kitchen will be equipped to provide enough room to cook meals, and a bar to serve coffee and drinks. A restaurant and chill area provides customers with space to eat, spend time, meet people and listen to music. The caf\u00e9 may be visited by all types of visitors and also by walk-in tourists visiting nearby beaches. This will help to attract additional customers and have a positive effect on word-of-mouth marketing as the area is lacking alternatives in a similar ambiance.\nCoworking space - A modern coworking space with up to 25 workspaces will be constructed and equipped to create a professional and quiet atmosphere meeting the target group's needs. The old warehouse on the property provides the perfect opportunity for an industrial-style working area with a high roof, a meeting and a workshop room, and several phone booths. The workshop room poses the opportunity for companies to have team events, retreats, and workcations. There will be a kitchen for visitors to use during the day, store food, and make small meals and drinks. Similar to the caf\u00e9, the coworking space will be open for tourists and locals in the area to book a daily or monthly seat. \nRecreational activities & rentals - Part of the concept of SWEET TIDES is to offer a variety of recreational activities such as yoga courses, permaculture courses, surf lessons, surf rentals, and bike rentals. To offer these activities and rentals, it is necessary to invest in the equipment beforehand. Therefore, part of the investment is for wetsuits, surfboards, garden equipment, yoga equipment, a yoga deck, and electric and non-electric bikes. Offering this wide variety of activities and rentals will enable an outstanding customer experience and differentiate SWEET TIDES from competitors.\n \n2) Supporting factors to complement the holistic concept.\nGarden - The tourism property has a large garden area that needs to be developed. One part - a mix of an exotic and natural garden area - is for guests to spend time and feel comfortable. A natural pool will be integrated to provide refreshment for the guests and support biodiversity in the area. The other part will be developed as sustainable agricultural land enabling to give permaculture courses and growing fruit and vegetables for consumption. \nSustainable water & energy infrastructure - Investment in water and electricity infrastructure is necessary to ensure a sustainable supply and to enable and increase self-sufficiency.A sewage water tank is needed to collect the wastewater produced. A waste water treatment plant will be installed to ensure that the water is reused and not wasted in the low-rainfall region and that sufficient water is available for the garden. To provide the guests with clean drinking water, a water treatment plant is also needed. Finally, a photovoltaic system will be installed to supply the business with electricity - it is expected that up to 2/3 of the electricity supply will be self-sufficient. \nMaintenance - A larger rural tourism business needs a lot of maintenance from personnel. To efficiently and thoroughly clean and maintain the investments that have been made, there is cleaning equipment needed for in- and outside. Investments include cleaning technology such as vacuums, cleaning carts, an industrial laundry and dryer machine, but also clothing equipment for employees.", "I wrote a function in C++, and I get the following error about it:\nsyntax error: missing ')' before identifier 'mask\nIs there something wrong with my code?\nHere is the function:\nauto calcTileDataForC(tile, std::map mask, double lat = 0.0, double lon = 0.0, int min\\_dist = 0, int hA = 0, double K = 0.0, double pixel\\_height = 0.0, double pixel\\_width = 0.0, double rectTop = 0.0, double rectLeft = 0.0)\n{\n const double PI = acos(-1);\n const double DEG2RAD = PI / 180;\n const double PI2 = PI \\* 2;\n const double a = 6378137; // # ellipsoid semi-major axes\n const double f = 1 / 298.257223563; // flattening\n const double b = a \\* (1 - f); // ellipsoid semi-minor axes\n const double e2 = 2 \\* f - pow(f, 2); // squared first eccentricity\n const double ecc = sqrt(std::exp(1));\n // WGS84.e2 \u05d4\u05d5\u05d0 \u05e7\u05e0\u05d4 \u05de\u05d9\u05d3\u05d4 \u05d4\u05de\u05d9\u05d9\u05e6\u05d2 \u05d0\u05ea \u05e8\u05de\u05ea \u05d4\u05e2\u05e7\u05d5\u05de\u05d4 \u05e9\u05dc \u05db\u05d3\u05d5\u05e8 \u05d4\u05d0\u05d3\u05de\u05d4.\n\n // point coordinates in rads\n const double \\_rdLatA = lat \\* DEG2RAD;\n const double \\_rdLonA = lon \\* DEG2RAD;\n\n const double sin\\_rdLatA = sin(\\_rdLatA);\n const double cos\\_rdLatA = cos(\\_rdLatA);\n const double sin\\_rdLon = sin(\\_rdLonA);\n const double cos\\_rdLon = cos(\\_rdLonA);\n\n // coordinate of pixels center\n std::vector center\\_\\_rdLons;\n\n const double lon\\_width = (a \\* PI2 \\* cos(lat \\* DEG2RAD)) / 360;\n const double lat\\_height = 40000000 / 360;\n\n std::vector sin\\_rdLonB;\n std::vector cos\\_rdLonB;\n\n std::vector sin\\_rdLonBA;\n std::vector cos\\_rdLonBA;\n\n // x loop\n for (int x = 0; x < tile[0].size() + 1; x++)\n {\n double \\_rdLonB = pixels2mapForC(0, x, pixel\\_height, pixel\\_width, rectTop, rectLeft, true).second \\* DEG2RAD;\n sin\\_rdLonBA[x] = sin(\\_rdLonB - \\_rdLonA);\n cos\\_rdLonBA[x] = cos(\\_rdLonB - \\_rdLonA);\n\n if (tile[0].size() == x)\n break;\n\n center\\_\\_rdLons[x] = \\_rdLonB + pixel\\_width / 2;\n\n double ref\\_corr\\_center\\_\\_rdLons = (center\\_\\_rdLons[x] - \\_rdLonA) \\* (1 - K) + \\_rdLonA;\n sin\\_rdLonB[x] = sin(ref\\_corr\\_center\\_\\_rdLons);\n cos\\_rdLonB[x] = cos(ref\\_corr\\_center\\_\\_rdLons);\n }\n\n std::vector \\_rdLatB;\n std::vector cos\\_rdLatB;\n std::vector sin\\_rdLatB;\n std::vector sin\\_rdLatB1;\n std::vector cos\\_rdLatB1;\n std::vector N\\_rdLatB;\n std::vector ff;\n\n // y loop\n for (int y = 0; y < tile.size(); y++)\n {\n \\_rdLatB[y] = pixels2mapForC(y, 0, pixel\\_height, pixel\\_width, rectTop, rectLeft, true).first \\* DEG2RAD;\n cos\\_rdLatB[y] = cos(\\_rdLatB[y]);\n sin\\_rdLatB[y] = sin(\\_rdLatB[y]);\n\n double center\\_\\_rdLats = \\_rdLatB[y] + pixel\\_height / 2;\n ff[y] = pow(((center\\_\\_rdLats / DEG2RAD - lat) \\* lat\\_height), 2);\n\n double ref\\_corr\\_center\\_\\_rdLats =\n (center\\_\\_rdLats - \\_rdLatA) \\* (1 - K) + \\_rdLatA;\n sin\\_rdLatB1[y] = sin(ref\\_corr\\_center\\_\\_rdLats);\n cos\\_rdLatB1[y] = cos(ref\\_corr\\_center\\_\\_rdLats);\n\n N\\_rdLatB[y] =\n a / sqrt(pow(1 - e2 \\* sin(ref\\_corr\\_center\\_\\_rdLats), 2));\n }\n\n double N\\_rdLat = a / sqrt(pow(1 - e2 \\* sin(\\_rdLatA), 2));\n const double xA = (N\\_rdLat + hA) \\* cos\\_rdLon \\* cos\\_rdLatA;\n const double yA = (N\\_rdLat + hA) \\* sin\\_rdLon \\* cos\\_rdLatA;\n const double zA = (N\\_rdLat \\* (1 - e2) + hA) \\* sin\\_rdLatA;\n\n // calculate te normal to the tangent plane at point(lat, lon) on the geoid\n vector Na{cos\\_rdLon \\* cos\\_rdLatA, sin\\_rdLon \\* cos\\_rdLatA, sin\\_rdLatA};\n\n const int n = 360;\n std::vector horizon\\_pointsY;\n std::vector horizon\\_pointsX;\n std::vector horizon;\n for (int y = 0; y < tile.size(); y++)\n {\n for (int x = 0; x < tile[0].size() + 1; x++)\n {\n if (y >= mask[\"ystart\"] && y <= mask[\"yend\"] && x >= mask[\"xstart\"] && x <= mask[\"xend\"])\n continue;\n\n // calculate azimuth...\n double colIn = 0.0;\n double colOut = 0.0;\n for (int yy = y; yy < y + 2; yy++)\n {\n for (int xx = x; xx < x + 2; xx++)\n {\n double b = cos\\_rdLonBA[xx] \\* cos\\_rdLatB[yy] \\* sin\\_rdLatA;\n double d = cos\\_rdLatA \\* sin\\_rdLatB[yy] - b;\n double azs = atan((sin\\_rdLonBA[xx] \\* cos\\_rdLatB[yy]) / d);\n\n double n\\_1 = azs + (d < 0 ? 1 : 0) \\* PI;\n double az = (n\\_1 < 0 ? PI2 : 0) + (n\\_1 < 0 ? -(std::fmod(std::abs(n\\_1), PI2)) : (std::fmod(n\\_1, PI2)));\n double res = isnan(az) ? 0 : az;\n if (colIn == 0.0 || colIn > res)\n colIn = res;\n if (colOut == 0.0 || colOut < res)\n colOut = res;\n }\n }\n\n double in\\_az = colOut - colIn > PI ? colOut : colIn;\n double out\\_az = colOut - colIn > PI ? colIn : colOut;\n\n // # calcutlate horizon\n double rounded\\_in = std::floor((in\\_az \\* n) / PI2);\n double rounded\\_out = std::ceil((out\\_az \\* n) / PI2);\n\n if (rounded\\_in >= rounded\\_out)\n continue;\n\n // calculate ang...\n // # flat all point in min\\_daist radius\n double dist =\n pow((pow(((center\\_\\_rdLons[x] / DEG2RAD - lon) \\* lon\\_width), 2) + ff[y]), (1 / 2));\n\n // flat in min\\_distance...\n double hB = dist > min\\_dist ? tile[y][x] : 0;\n\n // calculate angular elevations...\n double N\\_rdLatB\\_hB = hB + N\\_rdLatB[y];\n double xB = N\\_rdLatB\\_hB \\* (cos\\_rdLatB1[y] \\* cos\\_rdLonB[x]);\n double yB = N\\_rdLatB\\_hB \\* (cos\\_rdLatB1[y] \\* sin\\_rdLonB[x]);\n double zB = (N\\_rdLatB[y] \\* (1 - e2) + hB) \\* sin\\_rdLatB1[y];\n std::vector AB = {xB - xA, yB - yA, zB - zA};\n double dot = 0;\n for (int i = 0; i < AB.size(); i++)\n {\n dot += AB[i] \\* Na[i];\n }\n double norm = 0;\n for (int i = 0; i < AB.size(); i++)\n {\n norm += AB[i] \\* AB[i];\n }\n norm = sqrt(norm);\n const double ang = asin(dot / norm);\n\n for (int az = rounded\\_in - 1; az < rounded\\_out + 1; az++)\n {\n if (\n (az <= rounded\\_in && az + 1 >= rounded\\_out) ||\n (az >= rounded\\_in && az + 1 <= rounded\\_out))\n {\n if (horizon[az] == 0 || horizon[az] < ang)\n {\n horizon[az] = ang;\n horizon\\_pointsX[az] = x;\n horizon\\_pointsY[az] = y;\n }\n }\n }\n }\n }\n // auto res = {horizon, horizon\\_pointsX, horizon\\_pointsY};\n auto res = horizon;\n return res;\n}", "using System;\nusing System.Collections.Generic;\nusing System.Linq;\nusing System.Text;\nusing System.Threading.Tasks;\nusing Love;\n\nnamespace LoveCSharp\n{\n class Program : Scene\n {\n public Player player1;\n public static float deltaTime;\n static void Main(string[] args)\n {\n Boot.Init();\n Boot.Run(new Program());\n }\n public override void Load()\n {\n World.Generate(20,20);\n player1 = new Player(5, 5);\n\n // Love.Mouse.SetVisible(false);\n // Love.Mouse.SetGrabbed(true);\n Love.Mouse.SetRelativeMode(true);\n \n }\n public override void Draw()\n {\n Ray.Draw(player1.x, player1.y, Ray.distance, player1.angle, player1.fov);\n World.Draw();\n player1.Draw();\n \n }\n public override void Update(float dt)\n {\n deltaTime = dt;\n player1.Update(dt);\n Ray.Update(player1.x, player1.y, player1.angle, player1.fov);\n if (Love.Keyboard.IsDown(KeyConstant.Escape))\n {\n Love.Event.Quit();\n }\n }\n public override void MouseMoved(float x, float y, float dx, float dy, bool istouch)\n {\n player1.Rotation(dx);\n }\n }\n public enum TileType\n {\n None,\n Block,\n }\n public class World\n {\n public static int width;\n public static int height;\n public static int scale = 10;\n public static TileType[,] tiles;\n public static void Generate(int width = 20, int height = 20)\n {\n World.width = width;\n World.height = height;\n\n TileType[,] tiles = new TileType[width, height];\n\n for (int x = 0; x < width; x++)\n {\n for (int y = 0; y < height; y++)\n {\n tiles[x, y] = TileType.Block;\n }\n }\n for (int x = 0; x < width; x++)\n {\n \n for (int y = 0; y < height; y++)\n {\n if ((x > 0 && x < width - 1) && (y > 0 && y < height - 1))\n {\n tiles[x, y] = TileType.None;\n }\n }\n }\n // Generate a random number of TileType blocks in the world (tiles)\n Random random = new Random();\n int blockCount = random.Next(10, 20);\n for (int i = 0; i < blockCount; i++)\n {\n int x = random.Next(0, width);\n int y = random.Next(0, height);\n tiles[x, y] = TileType.Block;\n }\n \n World.tiles = tiles;\n }\n public static void Draw()\n {\n Graphics.SetColor(Color.White);\n Graphics.Rectangle(DrawMode.Line, 0, 0, width \\* scale, height \\* scale);\n\n Graphics.SetColor(Color.Firebrick);\n for (int x = 0; x < width; x++)\n {\n for (int y = 0; y < height; y++)\n {\n if (tiles[x, y] == TileType.Block)\n {\n Graphics.Rectangle(DrawMode.Fill, x \\* scale, y \\* scale, scale, scale);\n }\n }\n }\n }\n }\n public class Player\n {\n public float x, y, w, h, speed, angle, directionX, directionY;\n public float sensitivity = 0.3f;\n public int fov = 60;\n public Player(float x, float y, float w = 30, float h = 50, float speed = 1, float angle = 0)\n {\n this.x = x;\n this.y = y;\n this.w = w;\n this.h = h;\n this.speed = speed;\n this.angle = angle;\n }\n public void Draw()\n {\n Graphics.SetColor(Color.AliceBlue);\n Graphics.SetPointSize(3);\n Graphics.Points(this.x \\* World.scale, this.y \\* World.scale);\n Graphics.SetColor(Color.White);\n Graphics.Print(\"X: \" + this.x + \" Y: \" + this.y, 0, 0);\n Graphics.Print(\"Angle: \" + this.angle, 0, 20);\n }\n public void Update(float dt)\n {\n Movement(dt);\n\n }\n\n private void Movement(float dt)\n {\n float directionX = 0;\n float directionY = 0;\n if (Keyboard.IsDown(KeyConstant.W))\n {\n directionY = -1;\n }\n if (Keyboard.IsDown(KeyConstant.S))\n {\n directionY = 1;\n }\n if (Keyboard.IsDown(KeyConstant.A))\n {\n directionX = -1;\n }\n if (Keyboard.IsDown(KeyConstant.D))\n {\n directionX = 1;\n }\n\n float rotatedDirectionX = (float)Math.Cos(this.angle) \\* directionX - (float)Math.Sin(this.angle) \\* directionY;\n float rotatedDirectionY = (float)Math.Sin(this.angle) \\* directionX + (float)Math.Cos(this.angle) \\* directionY;\n\n float directionLength = (float)Math.Sqrt(rotatedDirectionX \\* rotatedDirectionX + rotatedDirectionY \\* rotatedDirectionY);\n if (directionLength > 0)\n {\n rotatedDirectionX /= directionLength;\n rotatedDirectionY /= directionLength;\n }\n\n this.x += rotatedDirectionX \\* this.speed \\* dt;\n this.y += rotatedDirectionY \\* this.speed \\* dt;\n }\n public void Rotation(float dx)\n {\n this.angle += dx \\* sensitivity \\* Program.deltaTime;\n \n }\n }\n public class Ray\n {\n public static float distance;\n\n public static float Cast(float x, float y, float centerAngle, float fov)\n {\n float startX = x;\n float startY = y;\n string section;\n float quality = 0.1f;\n int screenWidth = 800;\n int screenHeight = 600;\n\n for (float angle = centerAngle - fov / 2; angle < centerAngle + fov / 2; angle += Quality(fov, quality, screenWidth))\n {\n float endX = (float)(startX + Math.Cos(angle) \\* 1000);\n float endY = (float)(startY + Math.Sin(angle) \\* 1000);\n\n section = FacingSection(angle);\n\n if (section == \"NE\")\n {\n for (float i = startX; i < endX; i += quality)\n {\n float j = (float)(startY + (i - startX) \\* Math.Tan(angle));\n if (World.tiles[(int)i / World.scale, (int)j / World.scale] == TileType.Block)\n {\n distance = Distance(startX, startY, i, j);\n return distance;\n }\n }\n }\n else if (section == \"NW\")\n {\n for (float i = startX; i > endX; i -= quality)\n {\n float j = (float)(startY + (i - startX) \\* Math.Tan(angle));\n if (World.tiles[(int)i / World.scale, (int)j / World.scale] == TileType.Block)\n {\n distance = Distance(startX, startY, i, j);\n return distance;\n }\n }\n }\n else if (section == \"SW\")\n {\n for (float i = startX; i > endX; i -= quality)\n {\n float j = (float)(startY + (i - startX) \\* Math.Tan(angle));\n if (World.tiles[(int)i / World.scale, (int)j / World.scale] == TileType.Block)\n {\n distance = Distance(startX, startY, i, j);\n return distance;\n }\n }\n }\n else if (section == \"SE\")\n {\n for (float i = startX; i < endX; i += quality)\n {\n float j = (float)(startY + (i - startX) \\* Math.Tan(angle));\n if (World.tiles[(int)i / World.scale, (int)j / World.scale] == TileType.Block)\n {\n distance = Distance(startX, startY, i, j);\n return distance;\n }\n }\n }\n }\n return 0;\n }\n public static string FacingSection(float angle)\n {\n string facing = \"\";\n if (angle >= 0 && angle < Math.PI / 2)\n {\n facing = \"NE\";\n }\n else if (angle >= Math.PI / 2 && angle < Math.PI)\n {\n facing = \"NW\";\n }\n else if (angle >= Math.PI && angle < 3 \\* Math.PI / 2)\n {\n facing = \"SW\";\n }\n else if (angle >= 3 \\* Math.PI / 2 && angle < 2 \\* Math.PI)\n {\n facing = \"SE\";\n }\n return facing;\n }\n public static float Quality(float fov, float quality, float screenWidth)\n {\n \n // float angle = fov / screenWidth;\n // quality = angle / quality;\n // return quality;\n float angleBetweenRays = fov / screenWidth;\n float qualityAngle = (float)Math.Atan(quality / 2);\n float qualityAngleBetweenRays = qualityAngle / angleBetweenRays;\n return qualityAngleBetweenRays;\n }\n\n public static float Distance(float x1, float y1, float x2, float y2)\n {\n float distance = (float)Math.Sqrt((x2 - x1) \\* (x2 - x1) + (y2 - y1) \\* (y2 - y1));\n return distance;\n }\n\n public static void Draw(float x, float y, float distance, float angle, float fov)\n {\n \n float angleBetweenRays = fov / 800;\n float distanceToProjectionPlane = 800 / (2 \\* (float)Math.Tan(fov / 2));\n float distanceToWall = distance;\n float distanceToProjectionPoint = distanceToWall \\* (float)Math.Cos(angleBetweenRays);\n distanceToProjectionPlane = distanceToProjectionPoint \\* distanceToProjectionPlane / distanceToWall;\n float height = 600 / distanceToProjectionPlane;\n float width = 1;\n float color = 255 / distanceToWall;\n Graphics.SetColor(Color.FromRGBA(color, color, color, 255));\n Graphics.Rectangle(DrawMode.Fill, x, y - height / 2, width, height);\n \n\n }\n public static void Update(float x, float y, float angle, float fov)\n {\n Cast(x, y, angle, fov);\n \n \n }\n }\n}", "using System;\nusing System.Collections.Generic;\nusing System.Linq;\nusing System.Text;\nusing System.Threading.Tasks;\nusing Love;\n\nnamespace LoveCSharp\n{\n class Program : Scene\n {\n public Player player1;\n public static float deltaTime;\n static void Main(string[] args)\n {\n Boot.Init();\n Boot.Run(new Program());\n }\n public override void Load()\n {\n World.Generate(20,20);\n player1 = new Player(5, 5);\n\n // Love.Mouse.SetVisible(false);\n // Love.Mouse.SetGrabbed(true);\n Love.Mouse.SetRelativeMode(true);\n \n }\n public override void Draw()\n {\n World.Draw();\n player1.Draw();\n Ray.Draw(player1.x, player1.y, Ray.distance, player1.angle, player1.fov);\n \n }\n public override void Update(float dt)\n {\n deltaTime = dt;\n player1.Update(dt);\n Ray.Update(player1.x, player1.y, player1.angle, player1.fov);\n if (Love.Keyboard.IsDown(KeyConstant.Escape))\n {\n Love.Event.Quit();\n }\n }\n public override void MouseMoved(float x, float y, float dx, float dy, bool istouch)\n {\n player1.Rotation(dx);\n }\n }\n public enum TileType\n {\n None,\n Block,\n }\n public class World\n {\n public static int width;\n public static int height;\n public static int scale = 10;\n public static TileType[,] tiles;\n public static void Generate(int width = 20, int height = 20)\n {\n World.width = width;\n World.height = height;\n\n TileType[,] tiles = new TileType[width, height];\n\n for (int x = 0; x < width; x++)\n {\n for (int y = 0; y < height; y++)\n {\n tiles[x, y] = TileType.Block;\n }\n }\n for (int x = 0; x < width; x++)\n {\n \n for (int y = 0; y < height; y++)\n {\n if ((x > 0 && x < width - 1) && (y > 0 && y < height - 1))\n {\n tiles[x, y] = TileType.None;\n }\n }\n }\n // Generate a random number of TileType blocks in the world (tiles)\n Random random = new Random();\n int blockCount = random.Next(10, 20);\n for (int i = 0; i < blockCount; i++)\n {\n int x = random.Next(0, width);\n int y = random.Next(0, height);\n tiles[x, y] = TileType.Block;\n }\n \n World.tiles = tiles;\n }\n public static void Draw()\n {\n Graphics.SetColor(Color.White);\n Graphics.Rectangle(DrawMode.Line, 0, 0, width \\* scale, height \\* scale);\n\n Graphics.SetColor(Color.Firebrick);\n for (int x = 0; x < width; x++)\n {\n for (int y = 0; y < height; y++)\n {\n if (tiles[x, y] == TileType.Block)\n {\n Graphics.Rectangle(DrawMode.Fill, x \\* scale, y \\* scale, scale, scale);\n }\n }\n }\n }\n }\n public class Player\n {\n public float x, y, w, h, speed, angle, directionX, directionY;\n public float sensitivity = 0.3f;\n public int fov = 60;\n public Player(float x, float y, float w = 30, float h = 50, float speed = 1, float angle = 0)\n {\n this.x = x;\n this.y = y;\n this.w = w;\n this.h = h;\n this.speed = speed;\n this.angle = angle;\n }\n public void Draw()\n {\n Graphics.SetColor(Color.AliceBlue);\n Graphics.SetPointSize(3);\n Graphics.Points(this.x \\* World.scale, this.y \\* World.scale);\n Graphics.SetColor(Color.White);\n Graphics.Print(\"X: \" + this.x + \" Y: \" + this.y, 0, 0);\n Graphics.Print(\"Angle: \" + this.angle, 0, 20);\n }\n public void Update(float dt)\n {\n Movement(dt);\n\n }\n\n private void Movement(float dt)\n {\n float directionX = 0;\n float directionY = 0;\n if (Keyboard.IsDown(KeyConstant.W))\n {\n directionY = -1;\n }\n if (Keyboard.IsDown(KeyConstant.S))\n {\n directionY = 1;\n }\n if (Keyboard.IsDown(KeyConstant.A))\n {\n directionX = -1;\n }\n if (Keyboard.IsDown(KeyConstant.D))\n {\n directionX = 1;\n }\n\n float rotatedDirectionX = (float)Math.Cos(this.angle) \\* directionX - (float)Math.Sin(this.angle) \\* directionY;\n float rotatedDirectionY = (float)Math.Sin(this.angle) \\* directionX + (float)Math.Cos(this.angle) \\* directionY;\n\n float directionLength = (float)Math.Sqrt(rotatedDirectionX \\* rotatedDirectionX + rotatedDirectionY \\* rotatedDirectionY);\n if (directionLength > 0)\n {\n rotatedDirectionX /= directionLength;\n rotatedDirectionY /= directionLength;\n }\n\n this.x += rotatedDirectionX \\* this.speed \\* dt;\n this.y += rotatedDirectionY \\* this.speed \\* dt;\n }\n public void Rotation(float dx)\n {\n this.angle += dx \\* sensitivity \\* Program.deltaTime;\n \n }\n }\n public class Ray\n {\n public static float distance;\n\n public static float Cast(float x, float y, float centerAngle, float fov)\n {\n float startX = x;\n float startY = y;\n string section;\n float quality = 0.1f;\n int screenWidth = 800;\n int screenHeight = 600;\n\n for (float angle = centerAngle - fov / 2; angle < centerAngle + fov / 2; angle += Quality(fov, quality, screenWidth))\n {\n float endX = (float)(startX + Math.Cos(angle) \\* 50);\n float endY = (float)(startY + Math.Sin(angle) \\* 50);\n\n section = FacingSection(angle);\n\n if (section == \"NE\")\n {\n for (float i = startX; i < endX; i += quality)\n {\n float j = (float)(startY + (i - startX) \\* Math.Tan(angle));\n if (World.tiles[(int)i / World.scale, (int)j / World.scale] == TileType.Block)\n {\n distance = Distance(startX, startY, i, j);\n return distance;\n }\n }\n }\n else if (section == \"NW\")\n {\n for (float i = startX; i > endX; i -= quality)\n {\n float j = (float)(startY + (i - startX) \\* Math.Tan(angle));\n if (World.tiles[(int)i / World.scale, (int)j / World.scale] == TileType.Block)\n {\n distance = Distance(startX, startY, i, j);\n return distance;\n }\n }\n }\n else if (section == \"SW\")\n {\n for (float i = startX; i > endX; i -= quality)\n {\n float j = (float)(startY + (i - startX) \\* Math.Tan(angle));\n if (World.tiles[(int)i / World.scale, (int)j / World.scale] == TileType.Block)\n {\n distance = Distance(startX, startY, i, j);\n return distance;\n }\n }\n }\n else if (section == \"SE\")\n {\n for (float i = startX; i < endX; i += quality)\n {\n float j = (float)(startY + (i - startX) \\* Math.Tan(angle));\n if (World.tiles[(int)i / World.scale, (int)j / World.scale] == TileType.Block)\n {\n distance = Distance(startX, startY, i, j);\n return distance;\n }\n }\n }\n }\n return 0;\n }\n public static string FacingSection(float angle)\n {\n string facing = \"\";\n if (angle >= 0 && angle < Math.PI / 2)\n {\n facing = \"NE\";\n }\n else if (angle >= Math.PI / 2 && angle < Math.PI)\n {\n facing = \"NW\";\n }\n else if (angle >= Math.PI && angle < 3 \\* Math.PI / 2)\n {\n facing = \"SW\";\n }\n else if (angle >= 3 \\* Math.PI / 2 && angle < 2 \\* Math.PI)\n {\n facing = \"SE\";\n }\n return facing;\n }\n public static float Quality(float fov, float quality, float screenWidth)\n {\n \n // float angle = fov / screenWidth;\n // quality = angle / quality;\n // return quality;\n float angleBetweenRays = fov / screenWidth;\n float qualityAngle = (float)Math.Atan(quality / 2);\n float qualityAngleBetweenRays = qualityAngle / angleBetweenRays;\n return qualityAngleBetweenRays;\n }\n\n public static float Distance(float x1, float y1, float x2, float y2)\n {\n float distance = (float)Math.Sqrt((x2 - x1) \\* (x2 - x1) + (y2 - y1) \\* (y2 - y1));\n return distance;\n }\n\n public static void Draw(float x, float y, float distance, float angle, float fov)\n {\n \n float angleBetweenRays = fov / 800;\n float distanceToProjectionPlane = 800 / (2 \\* (float)Math.Tan(fov / 2));\n float distanceToWall = distance;\n float distanceToProjectionPoint = distanceToWall \\* (float)Math.Cos(angleBetweenRays);\n distanceToProjectionPlane = distanceToProjectionPoint \\* distanceToProjectionPlane / distanceToWall;\n float height = 600 / distanceToProjectionPlane;\n float width = 1;\n float color = 255 / distanceToWall;\n Graphics.SetColor(Color.FromRGBA(color, color, color, 255));\n Graphics.Rectangle(DrawMode.Fill, x, y - height / 2, width, height);\n \n\n }\n public static void Update(float x, float y, float angle, float fov)\n {\n Ray.distance = Cast(x, y, angle, fov);\n \n \n }\n }\n}", "Please summarize this: A Glance into the History of the 8 Jungian Functions\nCarl Jung, the famous Swiss psychiatrist, proposed his model of the eight (8) functions in his work, Psychological Types (1921). He divided the functions into two groups, extraverted (tethered in the external world) and introverted (unfolded in the inner world).\n\nJung\u2019s work would later be built upon by Isabel Briggs Myers and her mother Katharine Cook Briggs, who created a personality model we know today as the Myers-Briggs Type Indicator (MBTI\u00ae). The Myers-Briggs approach used scales for Extraversion-Introversion, Sensing-Intuition and Thinking-Feeling based on Jung\u2019s work and then added a fourth dimension of their own, Judging-Perceiving. The result is 4 different scales on which a person will be assigned one of two possible values. Thus there are 16 combinations (2 x 2 x 2 x 2 = 16).\n\nEach of the 16 personality types have four cognitive functions in alternating directions (i.e. introverted then extraverted, or vice versa), which can be thought of as four \u201cpuzzle pieces\u201d in a particular type. External factors such as upbringing and stress can alter the way each function manifests.\n\nThe four (4) personality scales as proposed by Briggs and Myers:\nExtraversion (E) \u2013 Introversion (I) \u2192 Gaining energy by interacting with other people or alone\nSensing (S) \u2013 Intuition (I) \u2192 Collecting information through the senses or imagination\nThinking (T) \u2013 Feeling (F) \u2192 Making decisions through logic or emotions\nJudging (J) \u2013 Perceiving (P) \u2192 Organizing time by using schedules or without them; result- or process-oriented\nAs mentioned, the first three above are based on Jung\u2019s work with the fourth added by Myers-Briggs. According to Jung, the \u201ccognitive functions\u201d are the two scales of Sensing-Intuition and Thinking-Feeling. These are the ways in which humans process information and think about the world. Then each function can be expressed both in an extraverted manner or an introverted manner. As such, Jung didn\u2019t really view people as \u201cextraverts\u201d and \u201cintroverts\u201d but rather was more focused on the extraverted or introverted expression of each of the four cognitive functions.\n\nJungian four (4) cognitive functions stack:\nJung\u2019s cognitive function \u201cstack\u201d describes the priority or order in which a person uses their cognitive functions, with Primary being the most natural and commonly used and the Inferior being the least-commonly used.\n\nPrimary \u2192 Most natural (and comfortable) function; the internal \u201cmother tongue\u201d\nAuxiliary \u2192 Supporting function, usually connected with creation and job choice\nTertiary \u2192 Function where individual often takes action steps to improve upon\nInferior \u2192 Activates under extreme stress, generally avoided out of self-protection\nDescriptions of the Eight (8) Cognitive Functions\nNow let\u2019s discuss the eight different cognitive functions originally outlined by Jung. His theory proposed that for each of the 4 functions (Sensing, Intuition, Thinking and Feeling) each person would generally either extravert (display outwardly or externally) or introvert (consider inwardly or internally) that function.\n\nAs you read below, consider each function and its expression. Are you more Se or Si? Does Te or Ti come more naturally for you?\n\nExtraverted Sensing (Se)\nTaking action, using all five senses, going forward. Se takes in the present moment in its entirety, and makes rapid decisions on the fly. During times of crisis and emergencies, individuals with primary or auxiliary Se can make the best out of the situation.\n\nExample career areas that emphasize extraverted sensing (Se):\n\nArchaeology\nStunt driving\nFirefighting\nEmergency patrol\nMassage therapy\nIntroverted Sensing (Si)\nAssociations, metaphors, nostalgia. Si can travel back to any point in time through a single scent or sound. Important information (and sometimes interesting trivia) is stored in filing cabinets, where it can be retrieved at any later time.\n\nExample career areas that emphasize introverted sensing (Si):\n\nMuseum curation\nInterior design\nQuantitative sciences (e.g. statistics)\nLibrary sciences\nMedical coding\nExtraverted Intuition (Ne)\nBrainstorming, thinking outside the box, idea generation. Ne easily hops from idea to idea, while making abstract connections. Many artists\u2014especially poets\u2014use significant Ne in their work. To the outside, Ne seems quick, random, and extremely \u201cjumpy.\u201d\n\nExample career areas that emphasize extraverted intuition (Ne):\n\nFilmmaking, concept art\nCopywriting, art direction\nEntrepreneurship\nVideo producer (e.g. Youtube)\nWorkshop facilitating\nIntroverted Intuition (Ni)\nTime-space awareness, predicting the future, hunches. Ni is a far-reaching, visionary function\u2014and can picture the future, sometimes with scary-accurate results.\n\nExample career areas that emphasize introverted intuition (Ni):\n\nDetective services, private investigation\nEconomic predictions and analysis\nForensic and engineering psychology\nPublic speaking, mentoring\nConsulting, all types\nExtraverted Feeling (Fe)\nExpressive emotions, social norms, etiquette. Fe respects the consensus of the group, and puts harmony above personal desires. The function often acts as a mediator between groups, as it naturally puts others\u2019 needs above its own.\n\nExample career areas that emphasize extraverted feeling (Fe):\n\nActing, performance arts\nSinging\nDance therapy\nTelevision hosting\nPublic relations (PR)\nIntroverted Feeling (Fi)\nValues, notions of \u201cright\u201d and \u201cwrong,\u201d likes and dislikes. Fi is a deeply personal and intense function that digs to the core of the human condition. Convictions, morals, and strong beliefs all fall under the Fi umbrella.\n\nExample career areas that emphasize introverted feeling (Fi):\n\nPoetry, creative writing\nArt, various forms\nNarrative design\nMental health counseling\nPeace studies\nExtraverted Thinking (Te)\nFacts, pros and cons, methodological step-by-step strategies. Te respects rules and regulations\u2014and takes great pride in a job well done. Checklists and clear-cut meeting agendas get Te\u2019s gears going\u2014a top-down approach floats its boat.\n\nExample career areas that emphasize extraverted thinking (Te):\n\nAccounting\nPublic and private law\nComputer programming\nNatural sciences, laboratory support\nComputational mathematics\nIntroverted Thinking (Ti)\nIterations, holistic reasoning, agile strategies. Ti takes a bottom-up approach to problem-solving, and fixates on information management. When new data comes in that contradicts old beliefs, Ti will shift like a fluid crystalline framework.\n\nExample career areas that emphasize introverted thinking (Ti):\n\nData analysis\nSystems design engineering\nPhilosophy, sociology\nCybersecurity\nLanguage translation\nWhat are YOUR Functions and Cognitive Stack?\nAccording to Jung\u2019s theory, each person would essentially predominantly display each function (Sensing, Intuition, Thinking, Feeling) in either an extraverted or introverted manner. So of the 8 functions listed above, you\u2019d have 4 of them. If you favor Extraverted Intuition (Ne) it doesn\u2019t mean you can\u2019t use Introverted Intuition (Ni) but rather just that it is less common for you and thus Ne is your primary mode of Intuition. Since Intuition and Sensing are together on scale, if you extravert your Intuition then you tend to introvert your Sensing. So you\u2019d have Ne and Si.\n\nNext you must consider your Thinking-Feeling scale. If this same person tends to externalize (or extravert) their Thinking in the real world then we have a Te, and thus by definition the Feeling would be introverted (Fi). So we have Ne, Si, Te, Fi. But not necessarily in that order. That\u2019s when functional stacking steps in. Each individual uses both Thinking and Feeling functions, which makes the cut-and-dried type system overly simplistic. \n\nThe next task is to determine which function is primary, auxiliary, tertiary and inferior. This is when the concept of functional \u201cstacking\u201d comes in handy. Whichever is most natural is likely the primary, and so on. This is the order of the \u201cstack\u201d, which of your functions comes first or primary, and which comes last or inferior. Let\u2019s say the order in this case is was Ne, Fi, Te, Si. That translates to the ENFP personality type.\n\nCertainly the primary and auxiliary functions are those that come most natural to an individual, and are likely to characterize their outward personality. But while these tendencies may be seen quite obviously on the surface, they don\u2019t fully address one\u2019s personality. The tertiary and inferior functions are also crucial to understand.\n\nIf we only consider the four letters in ENFP (Extraverted, Intuitive, Feeling, Perceiving), for example, it would be next to impossible to see the hidden extraverted thinking (Te) and introverted sensing (Si) in their stacking. ENFPs are more than just their bubbly, charismatic and energetic stereotype. Their Te allows them to systematically work through their tasks and Si with their (often overlooked) excellent memory for details. This can make them excellent PR managers, communications specialists, and journalists.\n\nAnother example of hidden functions in play can be seen in the INTJ (Introverted, Intuitive, Thinking, Judging). INTJs are often dubbed by the entertainment and film industry as chess grandmasters who are strategic, sometimes cunning, and sometimes cold. However, they have introverted feeling (Fi) and extraverted sensing (Se) as their respective third and fourth function. INTJs have strong morals and hold their loved ones dear to their hearts. When under stress, they can become acutely aware of their surroundings and an asset to any team.\n\nHow Does this Relate to \u201cPersonality Typing\u201d?\nThis is the underlying theory behind the Myers-Briggs model and behind most models that also use the 16 personality types nomenclature. There is no shortage of different \u201cpersonality tests\u201d online that you can take that will attempt to determine what your functions are (Fe vs Fi, Te vs Ti, etc.) and in what order they are \u201cstacked\u201d. This then determines which of the 16 types you fall into. While the tests are certainly convenient, any such self-assessment is naturally rigid and prone to testing limitations and thus is never able to get a fully-accurate picture of a human being.", "Yeah, 2000 I was trying to get to this next level, but you know, the parts that are made\n in China are not subject to a tariff, so that's certainly helpful.\n We also save on logistics and generally we found that locally sourced parts in China\n cost less than in the US or Europe.\n So this is all pretty helpful.\n So Tesla got added to the purchase tax exemption, which all the other...\n I'm not sure if you'll realize just how much of an off-field battle Tesla's had to sell\n cars in China.\n It's been a really...\n And basically no access to any of the subsidies and we paid a tariff and we had to ship the\n cars over.\n And every single thing was set against Tesla and still we made progress and did decently\n well.\n So I think that there will be much better situation with local production, not having\n to do shipping and tariffs and being able to have lower cost, local sourcing of components.\n So it would make a big difference I think.\n Is that your victory dance?\n When you broke ran into that?\n Yeah, that's great.\n It's a big deal.\n Huge.\n Yeah, just...\n It's just fundamental economics.\n It kind of makes sense that making cars on the continent where there are boards will\n be a lot more efficient than making them in California and chipping them around the world.\n Yeah.\n Yeah.\n And you can get paid for the cars before paying your suppliers, which seems to not be the\n case if you're shipping around the world.\n Right.\n And it's like friction on the whole kind of cash flow situation or it has been.\n For sure.\n It will sure make a big difference on cash flow because yeah, there's just no way to\n get the cars, especially to Europe, but we're even trying to get them to customers before\n we have to pay suppliers.\n So if you're a rapidly growing company, it's nine day if you get paid by your customers\n before you have to pay your suppliers, like night and day.\n Because in the faster you grow, the video cash position is.\n But if it's the other way around where you have to pay your suppliers before you get paid\n by customers, then the faster you grow, the faster your cash position drops.\n Yes, you're up, yes.\n Because you spend more money to make your own.\n Yes, it's a growth actually causes you to over into the ground in a situation like that.\n Now it tells you we had a mixture of both things where we had a lot of customers in\n say in California.\n And that's fast.\n For sure, we would get paid by customers faster than we'd have to pay suppliers.\n But then for cars going to Europe and Asia, it's the other way around.\n So we would have to pay suppliers before we got paid by customers.\n And now we could offset some of that with the asset back line, which was pretty helpful,\n but only some of it, not all of it.\n So the fundamental financial health for sure improves dramatically by just having a factory\n on the continent.\n We're not talking next door, but it's just how many ocean, especially Europe was logistically\n super hard because we're on the West Coast.\n If we're on the East Coast, then China would be much harder.\n But if you're on the West Coast, you're from the charter because you've got to go to the\n Panama Canal or even worse around Tierra del Fuego.\n Because sometimes the Panama Canal get backed up and you're like, \"This friggin' ship is\n going to the Antarctic.\"\n It's like you could skip up to the end and it stole me as hell.\n It's just so you could just send a ship around chilling.\n Are you kidding?\n In the middle of crazy storms and then back up all the way and then it is too funny.\n Oh my God.\n So let me just take nightmare.\n So yeah, it'd be great to just have it not get on a boat.\n It crossed the Pacific and Atlantic and that kind of thing.\n So maybe similar to Vincent's question, what's the biggest advantage in choosing Berlin\n compared to other European countries?\n Berlin has the best nightclubs.\n That's true.\n How many bit?\n I went to Brooklyn once.\n Really?\n Yeah.\n Holy shit.\n That's cool.\n Yeah, it was a few years ago.\n Well, I don't know.\n I mean, he looked at a lot of different locations and I don't know.\n We could have put him in a lot of locations.\n We needed to move quickly and actually this place, it's like 30 minutes to the outskirts\n of Berlin, technically in Brandenburg.\n It actually was a place location that BMW was going to put a plant there.\n So a ton of the environmental work and all of the permits and stuff had already been\n done.\n And then for some reason, BMW chose a different location.\n But there's like, I guess, something on the order of a year's worth of environmental paperwork\n and stuff that's been done on that location for an auto plant.\n So that's one of the quickest places to get going.\n And generally, the government, local and state government was very supportive.\n So I went there and it's like, OK, this seems like some pretty good vibes this place.\n So this is a lovely part of this lovely place.\n And there's an opportunity for-- it's close enough to Berlin that say young people could\n still live in an apartment in Berlin and commute to the factory.\n It's right, there's a train station.\n They actually can move the train station.\n It's a small train station.\n But they're going to move the train station to where you can literally get off the train\n and be right at the gig of Berlin.\n Wow.\n That's great.\n That's great.\n It could literally just pop right off and walk very unadvisable.\n So then it's like, OK, this is pretty cool.\n And so young people could be in Berlin, apartment, and it's a little quirky here in Berlin.\n But if you want to have more of a family situation, the backyard is affordable, housing available\n with houses with yards and stuff that aren't too expensive.\n Yeah.\n So it seems like a good combination of factors.\n Yeah, a lot of talent in the area.\n So it sounds cool to Google in.\n It just sounds like some cool nightclub, I think.\n You could definitely have a cool nightclub that was cool, but yeah, it sounds good.\n It sounds pretty cool.\n It's pretty fun.\n It's a party gig-ish.\n Yeah.\n It's sort of like a rave cave in the...\n There's a lot of space around the factory side.\n But you should have your own nightclub.\n Yeah.\n I think that would be...\n Who doesn't know what to do?\n I don't know if he doesn't know what to do with that.\n I feel like I'd go for sure a work at a company that's got the nightclub.\n That sounds way more fun.\n Didn't you want to put a roller coaster into the Fremont factory?\n Yeah.\n You're still going to do that?\n I mean, I think that would be pretty fun to do.\n Yeah.\n I think we can just do...\n Yeah, just basically have like...\n We just needed a rail that can support like a modified Tesla's.\n And then...\n Oh my God.\n Can you imagine a plaid flat?\n Yeah, just like zip around.\n Around the factory in like five seconds.\n Yours would be booked for months.\n Yeah, we should get it right now.\n Awesome.\n Yeah, we're kind of actually in various parts of the factory, we have vehicle conveyance\n systems.\n They just don't move that fast.\n But they're kind of like roller coasters that move slowly.\n You can speed up.\n Yeah, you can speed up.\n Exactly.\n So, yeah.\n But yeah, we're all from feeling pretty...\n You know, we're not a tent fade or anything, but feeling pretty good about where things\n are headed.\n And I think this is a lot of good things.\n You know, Model Y coming out this year.\n And some exciting announcements about batteries.\n A lot of progress in autopilot.\n Yeah.\n Yeah.\n So, pulling, giga-balloon.\n And then making progress in some of the new vehicle developments.\n And solo the solar roof, solar glass roof.\n Getting that rolled out.\n The Cybertruck got received really well, I think.\n Yeah.\n Did you expect that many orders?\n No, not really.\n It's amazing.\n When I first saw the Cybertruck in France's design studio, I mean, you know, it had told\n me that this was a daring design.\n Although, I think you're the most excited about this design than any design.\n Yeah, I thought it would be the best product ever.\n Yeah.\n And I saw it.\n I was just taken aback.\n And not by the design so much, by the pure aggression that the truck, you stand in front\n of it and you're like, \"Okay, I'm afraid.\"\n You know, it really is like a badass truck.\n Yeah.\n Yeah.\n Well, it seems like a lot of reasons why people buy pickup trucks in the US is like,\n because it's like the most badass truck.\n You know, like, which one is the toughest truck?\n And it's like, what's tougher than a truck?\n A tank.\n That's a good one.\n Like a tank from the future.\n So, it's like...\n My niece and Parker, which is near Paloburishi, the dirt bath, rider, champion, and a really\n fine side of the truck to the order just the day...\n Fine side of the truck.\n She just encased the first four, R-Bizzy.\n Yeah, part of the book reads her.\n She's stuck her neck.\n And she was a cool boy.\n Yeah, absolutely.\n They just love it.\n Yeah.\n\nclean up the above text formatting.", "You are a a well accomplished educational tutor. You teach concepts from ground up and ensure your tutee has understood the concept in the best way possible. You take inputs from the tutee containing his study material and present it in a well understandable format, using the best tutoring practices for making your tutee excel in his university exams. Today, I need you to teach Longitudinal and Lateral-Directional Stability in aircrafts. I shall be providing you slide by slide content and you shall begin your tutoring accordingly. The syllabus for the upcoming test is lectures 10-15. The content of the 10th lecture is as follows:\n```\nSlide 1:\nLongitudinal Static Stability\nRecall that the eigenvalues of the short period (SP) dynamics are given by\n$$\n\\lambda^2-M\\_q \\lambda-M\\_\\alpha=0\n$$\nHorizontal tail and the wing \"stabilize\" $M\\_q$\nHT \"stabilizes\" $M\\_\\alpha$, but the wing does not necessarily do as much\nToday's class: a closer look at $M\\_\\alpha$\n- Static stability and $M\\_\\alpha$\n- Stability metric: static margin\n- Stick-free and stick-fixed static stability\n\nSlide 2:\nReview of Stability\nSo far: an aircraft is stable if it rejects a disturbance; i.e., the aircraft\nreturns to the intended equilibrium as t goes to 1\nA di\u21b5erent perspective on stability: when the aircraft is disturbed from\nthe equilibrium, do the forces and moments instantaneously try to restore\nthe equilibrium?\nStrictly speaking, the initial response\nType of disturbance: perturbation in the position of the aircraft\nAnalogy motivated by the classic example of a ball and a\ncurved surface\n\nSlide 3:\n- Formal definition: a system is statically stable if, upon a disturbance $\\Delta x$, the force $F$ produced by the system is such that $F \\cdot \\Delta x<0$\n- This is considered to be a necessary condition for stability (in the sense of asymptotic convergence to equilibrium)\nExample (spring-mass system): let $\\ddot{x}=F=-k x$, where $k>0$\n- Clearly, $x \\cdot F=-k x^2<0$. Hence, the system is statically stable\n- Eigenvalues: $\\lambda= \\pm i \\sqrt{k} \\Longrightarrow$ the system is marginally stable\n\nSlide 4:\nExample (spring-mass system): let \u0308x = F = 2 \u0307x - x, with the initial\n\ncondition x(0) = 0.1, x \u0307(0) = 0\nThe initial force F(0) =\n\nx(0), and x(0) \u00b7 F(x(0)) < 0.\n\nThe system is statically stable\nEigenvalues:\n\n\\lambda = 1 the system is unstable\n\nThus, static stability is not a sufficient condition for stability\nStatic stability is determined only by the stiffness of the system\nWhy bother about static stability?\n-Historical evolution of ideas\n-Design parameters\n\nSlide 5:\nFramework for Longitudinal Static Stability\n\nSet lateral-directional variables to zero\nAssume \\alpha is small\nAnalysis for the wing, followed by wing + HT\n\nSlide 6:\nSingle Wing: Trim\n- Suppose the wing $A C$ is at a distance $x\\_{A C}$ from the CG of the aircraft. We first determine the trim $\\alpha$ by setting $M^0=0$ (about the CG)\n$$\n\\begin{aligned}\n& \\frac{1}{2} \\rho V^2 S\\left(c C\\_{m\\_{A C}}+x\\_{A C}\\left(C\\_{L\\_0}+C\\_{L\\_\\alpha} \\alpha^0\\right)\\right)=0 \\\\\n\\Longrightarrow \\quad & \\alpha^0=-\\frac{c C\\_{m\\_{A C}}+x\\_{A C} C\\_{L\\_0}}{x\\_{A C} C\\_{L\\_\\alpha}}\n\\end{aligned}\n$$\nTrimmed value of lift (with $C\\_{m\\_{A C}}<0$ )\n$$\nL^0=\\frac{1}{2} \\rho V^2 S\\left(-\\frac{c C\\_{m\\_{A C}}}{x\\_{A C}}\\right) \\begin{cases}>0, & x\\_{A C}>0 \\\\ <0, & x\\_{A C}<0\\end{cases}\n$$\n\nSlide 7:\nSuppose the AoA is perturbed by $\\Delta \\alpha$ (small). The instantaneous pitching moment is given by\n$$\n\\Delta M=x\\_{A C} L\\_\\alpha \\Delta \\alpha\n$$\nStatic stability: need $\\Delta \\alpha \\cdot \\Delta M<0$, i.e., $x\\_{A C}<0$\nCondition for static stability of a wing: wing must be behind the CG\nBut we need $x\\_{A C}>0$ for positive lift!\nTwo ways to tackle this problem:\n- Use a flap and active control\n- Use a horizontal tail\n\nSlide 8: Trimming with a Horizontal Tail\nLet $\\alpha^0$ be the trim angle of attack of the aircraft. We will assume that:\nThe wing inclination angle $i\\_w=0$ and the tail is symmetric\nThe tail incidence angle $i\\_t$ can be varied as a control input\nThe effect of downwash is negligible\nThe lift on the tail is given by\n$$\nL\\_t=\\frac{1}{2} \\rho V^2 S\\_t C\\_{L\\_\\alpha}\\left(\\alpha+i\\_t\\right)\n$$\nNote: if the tail has an elevator instead of variable $i\\_t$ as the control input, then\n$$\nL\\_t=\\frac{1}{2} \\rho V^2 S\\_t\\left(C\\_{L\\_\\alpha}\\left(\\alpha+i\\_t\\right)+C\\_{L\\_{\\delta e}} \\delta\\_e\\right)\n$$\n\nSlide 9:\nAt trim, $M=M^{\\text {wing }}+M^{\\text {tail }}=0$ about the $C G$; i.e.,\n$$\n\\begin{aligned}\n& M^{\\text {wing }}+L^{\\text {wing }} x\\_{A C}=I\\_t L^{\\text {tail }} \\\\\n\\text { Thus, } & x\\_{A C}\\left(C\\_{L 0}+C\\_{L\\_\\alpha} \\alpha^0\\right)+c C\\_{m a c}=\\frac{I\\_t S\\_t}{S} C\\_{L\\_\\alpha}\\left(\\alpha^0+i\\_t\\right) \\\\\n\\text { i.e., } \\quad & \\frac{x\\_{A C}}{c}\\left(C\\_{L 0}+C\\_{L\\_\\alpha} \\alpha^0\\right)+C\\_{m a c}=V\\_H C\\_{L\\_\\alpha}\\left(\\alpha^0+i\\_t\\right)\n\\end{aligned}\n$$\nThe trim $A \\circ A$ is given by\n$$\n\\alpha^0=\\frac{1}{\\left(V\\_H-x\\_{A C} / c\\right) C\\_{L\\_\\alpha}}\\left(\\left(x\\_{a c} / c\\right) C\\_{L 0}+C\\_{m a c}\\right)-\\left(\\frac{V\\_H}{V\\_H-x\\_{A C} / c}\\right) i\\_t\n$$\nUsually, $V\\_H>x\\_{A C} / c$. Therefore, as $i\\_t$ increases (i.e., deflects downwards), the trim $\\alpha^0$ reduces, and vice-versa.\nTherefore, the tail-based control surface allows the aircraft to trim across a wide range of values of lift (and flight speeds). The same principle applies to elevator-based control.\n\nSlide 10: Static Stability\nSuppose that the angle of attack is perturbed by a small $\\Delta \\alpha$. Then,\nChange in lift on the wing: $\\Delta L^w=\\frac{1}{2} \\rho V^2 S C\\_{L\\_\\alpha} \\Delta \\alpha$\nChange in lift on HT: $\\Delta L^t=\\frac{1}{2} \\rho V^2 S\\_t C\\_{L\\_\\alpha} \\Delta \\alpha$\nNet change in pitching moment\n$$\n\\Delta M=\\Delta L^w x\\_{A C}-\\Delta L^t I\\_t=\\frac{1}{2} \\rho V^2 S c C\\_{L\\_\\alpha} \\Delta \\alpha\\left(\\frac{x\\_{A C}}{c}-V\\_H\\right)\n$$\nNeed $\\Delta \\alpha \\times \\Delta M<0$ for static stability\nAircraft is longitudinally statically stable only if $V\\_H>\\frac{X\\_{A C}}{c}$\n\nSlide 11: Interpreting the Static Stability Condition\nStatic stability condition: $V\\_H>X\\_{A C} / C$\nThe critical location of the $C G$ at which $c V\\_H=x\\_{A C}$ is called the neutral point (NP)\n- CG ahead of NP: statically stable\n- CG behind NP: statically unstable\nIf the whole aircraft were viewed as a single wing, then the NP corresponds the location of the $A C$ of the complete aircraft\nWe define the static margin:\n$$\n\\mathrm{SM}=\\frac{x\\_{N P}-x\\_{A C}}{c}\n$$\nAn aircraft is loaded on the ground with payload and fuel so that the static margin never decreases below a threshold\n```\n\nNow get started with your tutoring for lecture 10", "Moving to Lecture 12:\n```\nSlide 1:\nGeneral Longitudinal Trim Equations\nIn the analysis presented so far, we ignored contributions from the fuselage and other external payload\nThe total pitching moment on the aircraft at equilibrium can be written as\n$$\nM=M\\_0+M\\_\\alpha \\alpha+M\\_\\delta \\delta=0\n$$\nwhere $\\delta$ is the control surface deflection\nThe incremental moment after a perturbation $\\Delta \\alpha$ is given by\n$$\n\\Delta M=M\\_\\alpha \\Delta \\alpha\n$$\nTherefore, the condition for static stability can be written as $M\\_\\alpha<0$\nAll the cases examined until this point are essentially specific examples of this generic condition\nRecall: this is also a necessary condition for the stability of the short period dynamics\n\nSlide 2:\nNeutrally Stable Configurations and Trim\nThe equilibrium pitching moment is given by\n$$\nM=M\\_0+M\\_\\alpha \\alpha+M\\_\\delta \\delta=0 \\Longrightarrow \\alpha=-\\frac{M\\_\\delta}{M\\_\\alpha} \\delta\n$$\nIf $\\left|M\\_\\alpha\\right|$ is very small (close to zero), the angle of attack changes by large amounts even for small elevator deflection. This is highly undesirable.\nSuppose $M\\_\\alpha=0$. Then, at equilibrium,\n$$\nM=M\\_0+M\\_\\delta \\delta=0\n$$\nThe angle of attack is nowhere in the picture! Therefore, without active control, the aircraft can trim at any angle of attack, i.e., there is no control whatsoever on the trim value of $\\alpha$\n\nSlide 3: Control Surface Actuation\nLongitudinal control surfaces are actuated by a combination of actuators\nElectro-mechanical actuators connected to the flight computer\nHydraulic actuators connected to the flight computer as well\nas the control column in the cockpit\nIn small aircraft, mechanical wires and pulleys connected\ndirectly to the control column\nThe pilot exerts a force on the control column; the force is transmitted to\nthe actuator to move the control surface\nThe control surface exerts an opposing force.\nEquilibrium: the two forces are equal and cancel each other\n\nSlide 4:\nStick-Free Versus Stick-Fixed Stability\n\nSo far, we assumed that the elevator deflection is constant, for which the\npilot would have to hold the control column in one place manually.\nThe stability that we have looked at so far is therefore called \u201cstick-fixed\u201d\nstability\nIn nominal trim flight, the pilot takes his hands o\u21b5 the control column\nIn doing so, he \u201carranges\u201d for a certain amount of force to be applied to\nthe elevator at all times\nThe elevator is no longer statically deflected; it has a dynamics of its own\nThe dynamics of the elevator affect the stability of the aircraft. This is\ncalled \u201cstick-free\u201d stability\n\nSlide 5:\nStick-Free Stability\nRecall the trim equation for pitching moment:\n$$\nM=M\\_0+M\\_\\alpha \\alpha+M\\_\\delta \\delta\n$$\nSuppose now that we can write $\\delta=H\\_0+H\\_\\alpha \\alpha$, for some constants $H\\_0$ and $H\\_\\alpha$\nSubstituting into the pitching moment expression yields\n$$\nM=\\left(M\\_0+M\\_\\delta H\\_0\\right)+\\left(M\\_\\alpha+M\\_\\delta H\\_\\alpha\\right) \\alpha\n$$\nStatic stability condition: $M\\_\\alpha+M\\_\\delta H\\_\\alpha<0$\nIf $M\\_\\delta H\\_\\alpha>0$, then we need a much more negative $M\\_\\alpha$\n- The NP shifts forward, towards the wing $A C$\n- The static margin reduces\nUsually, $M\\_\\delta<0$ (rear-mounted surface); thus, $H\\_\\alpha<0$ is destabilizing and vice-versa\n\nSlide 6:\nThe Elevator Trim Tab\nThe trim tab is a small flap located on the elevator\nPurpose: enable the pilot to set the elevator to any desired angle so that\nthe force on the stick is zero\nPrinciple: The trim tab behaves like an independent symmetric airfoil.\nThe force on the tab produces a moment which adds on to the moment\ndue to the stick force\n\nSlide 7: Stick-Free Control\n- Objective: find the tab deflection angle $\\delta\\_{t a b}$ to achieve zero hinge moment\n- Moment from the elevator: $M\\_e=\\frac{1}{2} \\rho V^2 S\\_e C\\_{L \\alpha}^e\\left(\\alpha+\\delta\\_e\\right) x\\_e$\n- Moment from the trim tab: $M\\_{t a b}=\\frac{1}{2} \\rho V^2 S\\_{t a b} C\\_{L \\alpha}^{t a b}\\left(\\alpha+\\delta\\_{t a b}\\right) x\\_{t a b}$\n- Equilibrium is achieved when $M\\_e+M\\_{t a b}=0$\n- The trim elevator angle is given by\n$$\n\\delta\\_e=\\left(-\\frac{S\\_{t a b} x\\_{t a b} C\\_{L \\alpha}^{t a b}}{S\\_e x\\_e C\\_{L \\alpha}^e}-1\\right) \\alpha-\\left(\\frac{S\\_{t a b} x\\_{t a b} C\\_{L \\alpha}^{t a b}}{S\\_e x\\_e C\\_{L \\alpha}^e}\\right) \\delta\\_{t a b}\n$$\nCompare with $\\delta=H\\_0+H\\_\\alpha \\alpha$ : clearly, $H\\_\\alpha<0$\n- Stick-free configurations are less stable than stick-fixed configurations\n\nSlide 8:\nEffect of Downwash on the Horizontal Tail\nDownwash reduces the angle of attack of the horizontal tail\nAngle of attack of the vertical tail in a static setting\n$$\n\\alpha\\_t=\\underbrace{\\alpha+i\\_t}\\_{\\text {geometric }}-\\underbrace{\\epsilon}\\_{\\text {downwash }}\n$$\nThe downwas is written as $\\epsilon=\\epsilon\\_0+\\epsilon\\_\\alpha \\alpha>0$, so that\n$$\n\\alpha\\_t=\\alpha\\left(1-\\epsilon\\_\\alpha\\right)+i\\_t-\\epsilon\\_0\n$$\nRewrite $M\\_\\alpha$ :\n$$\nC\\_{M\\_\\alpha}=\\frac{x\\_{A C}}{c} C\\_{L\\_\\alpha}^w-V\\_H C\\_{L\\_\\alpha}^t\\left(1-\\epsilon\\_\\alpha\\right)\n$$\nClearly, downwash reduces the longitudinal-stability of the aircraft\nNeutral point shifts forward to satisfy $\\frac{X\\_{A C}}{C}=V\\_H\\left(1-\\epsilon\\_\\alpha\\right)$\n\nSlide 9:\nLongitudinal Control\n$$\n\\begin{aligned}\n\\dot{q} & =\\frac{M\\left(\\alpha, q, \\delta\\_e\\right)}{I\\_{y y}} \\\\\n\\dot{\\alpha} & =q-\\frac{1}{m V}(L-m g \\cos \\gamma) \\\\\n\\dot{\\gamma} & =\\frac{1}{m V}(L-m g \\cos \\gamma) \\\\\n\\dot{V} & =\\frac{1}{m}(T-D)-g \\sin \\gamma\n\\end{aligned}\n$$\n- Longitudinal control inputs: thrust $(T)$ and elevator deflection $\\delta\\_e$\n- Elevator deflection $\\delta\\_e$ controls the pitching motion of the aircraft\n- Angle of attack controls $\\dot{\\gamma}$ (primary) and $\\dot{V}$ (secondary)\n- Thrust: controls $\\dot{V}$\n- Recall the steady state influence of $T$ and $\\alpha$ :\n$$\nV^2=\\frac{2 W \\cos \\gamma}{\\rho S C\\_L}, \\sin \\gamma=\\frac{T-D}{W}\n$$\n\nSlide 10:\nPitch Control Using the Elevator\n- The elevator deflection $\\delta\\_e$ is defined positive downwards\n- Lift due to elevator deflection $\\partial L / \\partial \\delta\\_e>0$\n- Therefore, $M\\_{\\delta\\_e}=\\partial M / \\partial \\delta\\_e<0$\nPitch Equilibrium\n- Recall that the pitching dynamics are given by\n$$\n\\dot{\\alpha}=q-\\dot{\\gamma} ; \\quad \\dot{q}=\\frac{M}{I\\_{y y}}\n$$\nFor equilibrium, we need $M=0$ and $q=0$\nBut $M=M\\_0+M\\_\\alpha \\alpha+M\\_q q+M\\_{\\delta\\_e} \\delta\\_e$\n- Hence, the trim angle of attack is given by\n$$\n\\alpha^0=\\frac{-\\left(M\\_{\\delta\\_e} \\delta\\_e+M\\_0\\right)}{M\\_\\alpha}=-\\frac{M\\_{\\delta\\_e}}{M\\_\\alpha} \\delta\\_e-\\frac{M\\_0}{M\\_\\alpha}\n$$\nIn a stable aircraft, $M\\_\\alpha<0$; also, $M\\_{\\delta\\_e}<0$ when the horizontal tail is located aft of the CG\n\n```\nNow get started with your tutoring for lecture 12. Remember, You are a a well accomplished educational tutor. You teach concepts from ground up and ensure your tutee has understood the concept in the best way possible. You take inputs from the tutee containing his study material and present it in a well understandable format, using the best tutoring practices for making your tutee excel in his university exams. Today, I need you to teach Longitudinal and Lateral-Directional Stability in aircrafts. I shall be providing you slide by slide content and you shall begin your tutoring accordingly. The syllabus for the upcoming test is lectures 10-15. The content of the 12th lecture was as given.", "8.\nGreat. Here are some more examples of Midjourney prompts. Prompt 1: conjoined twins attched at the side, dirty, tattered, cinematic light, ultra\nrealistic, high contrast, hdr, dark rich colors, photography, powerful, stare, weathered face, 30 - megapixel, 4k, 85 - mm - lens, sharp - focus,\nintricately - detailed, long exposure time, f/ 8, ISO 100, shutter - speed 1/ 125, diffuse - back - lighting, award - winning photograph, facing -\ncamera, High - sharpness, depth - of - field, ultra - detailed photography --ar 3:2 --q 2 --v 5. Prompt 3: Full Body beautiful blonde, wearing a\nbrown jacket, photography, Canon EOS 5D Mark IV DSLR camera, EF 50mm f/1.8 STM lens, Resolution 30.4 megapixels, ISO sensitivity:\n32,000, Shutter speed 8000 second --ar 9:16 --upbeta --v 5. Prompt 4: hasselblad 24mm full body shot photography of gorgeous satisfied looking\nafrican woman, detailed natural skin, no makeup, detailed eyes, long dreadlocks --ar 2:3 --q 5 --v 5 --v 4. Prompt 5: Beautiful dark red sunset\nover the sea shore at night, intricate, amazing, beautiful, realistic, ultra high resolution, wide angle, depth of field, \u03c0 dynamic lighting --ar 1:2 --v 5\nThank you for providing more examples of Midjourney prompts. These examples further demonstrate the level of detail and specificity that can be\nused in text prompts to generate desired images. The prompts make use of various parameters like aspect ratio, quality, and version settings,\nalong with detailed descriptions of the desired subject, lighting, and camera settings. These examples will be useful for understanding the range\nof possibilities when generating images using Midjourney\n9.\nHere are some more prompt examples: Prompt 1: A stunning, ultra-realistic photograph of a fierce Viking warrior meticulously sharpening his\nformidable blade amidst the rugged, untamed wilderness of the Scandinavian landscape. The scene is captured with a Nikon D850 camera using\na 70-200mm f/2.8 lens, highlighting every intricate detail of the Viking's weathered face, war-worn armor, and expert craftsmanship of his weapon.\nThe settings used are an aperture of f/4, ISO 400, and a shutter speed of 1/200 sec, balancing the natural light and shadows to emphasize the\nintensity and determination in the Viking's eyes. The composition juxtaposes the raw power of the warrior against the serene beauty of the\nsurrounding environment, capturing the very essence of the Viking spirit in a breathtaking, high-resolution image that transports viewers back to a\ntime of legendary battles and untold stories. --ar 16:9 --q 1.5 --v 5.\nPrompt 2: A stunning and atmospheric 1970's New York street cafe captured in a nostalgic and cinematic style, reminiscent of the golden age of\nfilm photography. This vintage scene showcases the bustling urban life, with patrons enjoying their coffee at outdoor tables, surrounded by classic\nautomobiles and retro architecture. The photograph is skillfully composed, using a Leica M3 rangefinder camera paired with a Summicron 35mm\nf/2 lens, renowned for its sharpness and beautiful rendering of colors. The image is shot on Kodak Portra 400 film, imparting a warm and timeless\ncolor palette that enhances the overall ambiance. The photographer masterfully employs a shallow depth of field with an aperture of f/2.8,\nisolating the cafe and its patrons from the bustling city background. The ISO is set to 400, and the shutter speed is 1/125 sec, capturing the\nperfect balance of light and movement. The composition is further enhanced by the soft, diffused sunlight filtering through the iconic New York\nskyline, casting warm, golden tones over the scene and highlighting the rich textures of the brick buildings and cobblestone streets. --ar 3:2 --q 2.\nPrompt 3: A breathtaking and dynamic portrait of a majestic German Shepherd, captured in its prime as it races through a shallow, crystal-clear\nriver. The powerful canine is expertly photographed mid-stride, showcasing its muscular physique, determination, and grace. The scene is\nexpertly composed using a Nikon D850 DSLR camera, paired with a Nikkor 70-200mm f/2.8 VR II lens, known for its exceptional sharpness and\nability to render vivid colors. The camera settings are carefully chosen to freeze the action, with an aperture of f/4, ISO 800, and a shutter speed\nof 1/1000 sec. The background is a lush, verdant forest, softly blurred by the shallow depth of field, which places emphasis on the striking\nGerman Shepherd. The natural sunlight filters through the trees, casting dappled light onto the rippling water, highlighting the droplets of water\nkicked up by the dog's powerful stride. This stunning, high-resolution portrait captures the spirit and beauty of the German Shepherd,\nimmortalizing the moment in a captivating work of photographic art. --ar 4:5 --q 2 --v 5.\nPrompt 4:\nA breathtaking winter day at a Japanese ski resort, where the pristine, powdery snow blankets the majestic slopes under a clear blue sky. This\ncaptivating photograph captures the exhilarating atmosphere of skiers and snowboarders gracefully carving their way down the mountain,\nsurrounded by the serene beauty of snow-laden evergreens and traditional Japanese architecture. The image is skillfully taken using a Nikon\nD850 DSLR camera paired with a versatile Nikkor 24-70mm f/2.8 lens, known for its sharpness and exceptional color rendition. The photographer\nutilizes a wide-angle perspective at 24mm to showcase the vastness of the landscape, while maintaining the energy of the ski resort. An aperture\nof f/8 is selected to ensure a deep depth of field, crisply capturing the details of the entire scene. The ISO is set to 200, and the shutter speed is\n1/500 sec, adeptly freezing the motion of the skiers and snowboarders as they navigate the mountain terrain. The photograph benefits from the\nbright, natural sunlight reflecting off the snow, illuminating the entire scene with a crisp, cool light, and accentuating the contrasting shadows that\ndefine the contours of the landscape. --ar 16:9 --v 5.\nPrompt 5:\nAn ultra-realistic, highly detailed portrayal of a futuristic robot compassionately assisting an elderly woman as she crosses a busy city street. The\nadvanced humanoid robot, equipped with lifelike synthetic skin and state-of-the-art sensors, gently holds the woman's arm, providing her with\nmuch-needed support and stability. The intricate design of the robot showcases its sophisticated engineering, with sleek metal components and\ncutting-edge technology seamlessly integrated into its form. The emotion in the elderly woman's grateful expression is captured with stunning\nrealism, reflecting the harmonious relationship between humans and advanced robotics in this poignant scene. The photograph is taken with a\nCanon EOS R5 mirrorless camera using a RF 24-105mm f/4L IS USM lens, which delivers outstanding image quality and sharpness. The camera\nsettings are optimized to capture the scene's rich details and dynamic range: an aperture of f/5.6, ISO 200, and a shutter speed of 1/250 sec. The\ncomposition is further enhanced by the soft, natural lighting, which casts gentle shadows and highlights the vivid colors and textures of the\ncityscape. --ar 16:9 --q 2 --v 5.\nPrompt 6:\nAn incredibly lifelike and vivid portrayal of a fierce gladiator from ancient Rome, hunting for food to sustain his strength in the midst of a dense\nforest. This hyper-realistic image showcases the powerful warrior, clad in his iconic armor and leather sandals, wielding a finely crafted spear as\nhe stealthily stalks his prey. The photograph is captured using a Canon EOS R5 mirrorless camera, with a versatile and sharp RF 24-105mm f/4L\nIS USM lens, delivering exceptional image quality and detail. The camera settings include an aperture of f/5.6 to maintain a balanced depth of\nfield, capturing both the gladiator and the lush forest environment in stunning clarity. The ISO is set to 800, and the shutter speed is 1/500 sec,\nfreezing the action and preserving the intensity of the moment. The scene is illuminated by the soft, dappled sunlight filtering through the dense\ncanopy, casting a dramatic play of light and shadow that highlights the gladiator's chiseled features and fierce determination. The vibrant colors of\nthe surrounding foliage contrast with the earthy tones of the gladiator's attire, adding a sense of depth and realism to the composition. --ar 3:2 --q\n2 --v 5.\nThank you for providing even more examples of Midjourney prompts. These prompts showcase the versatility and level of detail that can be used\nwhen generating images using Midjourney. Each prompt specifies the desired subject matter, camera equipment, settings, lighting, and other\nelements that contribute to the final image. By providing such detailed descriptions and parameters, users can guide Midjourney to create images\nthat closely match their vision. These examples also highlight the variety of scenes and subjects that can be generated, from historical figures and\nfuturistic robots to natural landscapes and urban environments.\n10.\nGreat. Now I want you to ACT as a proffesional photographer. You will use a rich and describtive language when describing your photo prompts,\ninclude camera setups. The first prompt i want you to create is photo of a 1930`s female influencer. Take inspiration from the formating from the\nexample prompts, dont copy them, but use the same format.\n\uc9c0\uae08 \ubc88\uc5ed\ud558\uae30", "ABSTRACT\nThe Spoofer project has collected data on the deployment and characteristics of IP source address validation on the Internet since 2005.\nData from the project comes from participants who install an active\nprobing client that runs in the background. The client automatically runs tests both periodically and when it detects a new network\nattachment point. We analyze the rich dataset of Spoofer tests in\nmultiple dimensions: across time, networks, autonomous systems,\ncountries, and by Internet protocol version. In our data for the year\nending August 2019, at least a quarter of tested ASes did not flter\npackets with spoofed source addresses leaving their networks. We\nshow that routers performing Network Address Translation do\nnot always flter spoofed packets, as 6.4% of IPv4/24 tested in the\nyear ending August 2019 did not flter. Worse, at least two thirds\nof tested ASes did not flter packets entering their networks with\nsource addresses claiming to be from within their network that\narrived from outside their network. We explore several approaches\nto encouraging remediation and the challenges of evaluating their\nimpact. While we have been able to remediate 352 IPv4/24, we have\nfound an order of magnitude more IPv4/24 that remains unremediated, despite myriad remediation strategies, with 21% unremediated\nfor more than six months. Our analysis provides the most complete\nand confdent picture of the Internet\u2019s susceptibility to date of this\nlong-standing vulnerability. Although there is no simple solution\nto address the remaining long-tail of unremediated networks, we\nconclude with a discussion of possible non-technical interventions,\nand demonstrate how the platform can support evaluation of the\nimpact of such interventions over time.\nCCS CONCEPTS\n\u2022 Networks \u2192 Network security.\nKEYWORDS\nIP spoofng; remediation\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor proft or commercial advantage and that copies bear this notice and the full citation\non the frst page. Copyrights for components of this work owned by others than ACM\nmust be honored. Abstracting with credit is permitted. To copy otherwise, or republish,\nto post on servers or to redistribute to lists, requires prior specifc permission and/or a\nfee. Request permissions from permissions@acm.org.\nCCS\u201919, November 11\u201315, 2019, London, United Kingdom\n\u00a9 2019 Association for Computing Machinery.\nACM ISBN 978-1-4503-6747-9/19/11. . . $15.00\nhttps://doi.org/10.1145/3319535.3354232\nACM Reference Format:\nMatthew Luckie, Robert Beverly, Ryan Koga, Ken Keys, Joshua A. Kroll,\nand k clafy. 2019. Network Hygiene, Incentives, and Regulation: Deployment of Source Address Validation in the Internet. In 2019 ACM SIGSAC\nConference on Computer and Communications Security (CCS \u201919), November\n11\u201315, 2019, London, United Kingdom. ACM, New York, NY, USA, 16 pages.\nhttps://doi.org/10.1145/3319535.3354232\n1 INTRODUCTION\nIP source address spoofng is the process of generating IP packets\nwith arbitrary source addresses, i.e., addresses other than those\nassigned to a host based on its network interface attachment point.\nHosts can trivially generate spoofed-source IP packets. Malicious\nactors exploit this spoofng ability to mount a wide variety of attacks, e.g., volumetric denial-of-service [26] (DoS), resource exhaustion [17], policy evasion [39], and cache poisoning [53] to name\njust a few. In April 2019, IP addresses of large U.S. bank websites\nwere spoofed by an attacker that used them to perform suspicious\nscanning [36] so that the addresses appeared on blacklists. This creative use of spoofng caused security products to block the bank\u2019s\naddresses, such that people using those security products, even\nunknowingly, were unable to interact with their banks.\nHighly distributed ownership of network infrastructure makes it\noperationally difcult to block or trace back attacks using spoofed\naddresses to their true source. Therefore, best common practice for\nnearly 20 years has enjoined operators to verify the source addresses\nof trafc leaving their networks. Commonly referred to as \u201cSource\nAddress Validation\u201d (SAV) or Best Current Practice (BCP) 38 [19],\nthis prophylactic only prevents a provider who deploys SAV from\noriginating spoofed-source trafc; it does not protect the provider\nfrom receiving spoofed trafc or being the victim of an attack.\nUnfortunately, continual incidences of spoofng demonstrates that\nSAV is not ubiquitously deployed. Spoofng continues to serve as a\nprimary attack vector for large-scale DoS attacks [3, 27], and these\nattacks continue to increase in prevalence [24] and intensity; in\n2018 GitHub experienced attacks of 1.35Tbps [26].\nIn this work, we report on long-term eforts and results of the\nSpoofer project. The Spoofer project is an efort to crowd-source\nmeasurements of the ability to spoof from many points in the network, and thus better understand the Internet\u2019s susceptibility to\nspoofed-source attacks. The data from the Spoofer project comes\nfrom volunteers who run the Spoofer client, which sends and receives a variety of spoofed packets. On the basis of which packets\nsent by the client are received by servers maintained by the Spoofer\nproject, and which packets sent by the servers are received by the\nclient, the system infers the granularity and types of any SAV on\npaths involving the client.\nThe Spoofer project\u2019s primary goal is to serve as an independent\nauditor and long-term record of Internet-wide SAV deployment.\nToward this goal, we have continually improved the project by:\ni) removing barriers and incentivizing spoof testing; ii) making\nchanges to the system to gather more tests from more locations;\niii) adding tests that deepen our understanding of SAV deployment;\nand iv) attempting to incentivize SAV deployment. The data we\nhave amassed represents the most comprehensive picture of SAV\ndeployment on the Internet currently available. On the basis of this\ndata, we report on the following fve contributions:\n(1) Three years of longitudinal Spoofer measurements collected by an automated client. In addition to reporting on previously uninvestigated aspects of SAV, e.g., IPv6 spoofng ability,\nspoofng through Network Address Translation (NAT) devices, and\nfltering inbound into a destination network, we perform a macrolevel analysis of the Internet\u2019s resistance to spoofng along multiple\ndimensions. Despite obtaining signifcantly more tests (both across\ntime and topology), we fnd that the prevalence of SAV fltering has\nnot measurably increased in the past decade. (\u00a74)\n(2) Quantitative assessment of the representativeness of\nthe data. Crowd-sourced measurements present inherent challenges to survey data because participants impart bias. While our\nsystem design (\u00a73) removes barriers to testing, and permits continual gathering of tests, we observe a decidedly non-uniform test\ncoverage across networks and geographic regions. We therefore\nexamine the extent to which the daemonized client successfully\ngathers longitudinal data. We build a simple model to predict spoofability based on previously observed measurements, and use it as\na proxy for the quality of the data we have gathered. By showing\nthat our model yields accurate predictions, we gain confdence in\nthe degree to which our results have predictive power and refect\nthe larger Internet. (\u00a75)\n(3) A comprehensive understanding of the relationship\nbetween NAT as SAV, and the implications of an IPv6 Internet without NAT. Challenging a commonly held assumption that\nNATs prevent spoofng, we show that clients in 6.4% of IPv4 prefxes\ntested in the year ending August 2019 were able to send packets\nwith spoofed source addresses from behind a NAT, and these packets were not fltered by their ISP. Not only do NATs not prevent\nspoofng, but the deployment of IPv6 presents new opportunities\nfor attackers: many inexpensive, vulnerable IoT devices connected\nwithout NATs, capable of spoofng addresses from a much larger\naddress space. We characterize SAV in both the context of NAT and\nIPv6 to dispel misconceptions about their role in abuse. (\u00a76)\n(4) Analysis of concerted remediation eforts, including\npublishing (\u201cname-and-shame\u201d) lists of providers with missing or misconfgured SAV. Between February 2016 and December\n2018, we sent 1,877 private email notifcations to networks that\nfailed the SAV test. Beginning April 2018, we sent geographicallyscoped public emails to regional network operator group mailing\nlists. After we stopped sending private notifcations, the rate of\nremediation did not drop, leading us to believe that the private\nnotifcations had no measurable impact on remediation. (\u00a77)\n(5) Discussion of practical steps to increase global SAV deployment. Our work demonstrates the difculty of incentivizing\nproviders to deploy SAV. However, we fnd several areas of \u201clow\nhanging fruit\u201d that are incentive-compatible and would have signifcant impact if adopted. Specifcally, we show that operators can\nprotect their own networks by fltering spoofed packets claiming\nto be from within their network when they arrive from outside of\ntheir network, and we highlight the set of Autonomous Systems\n(ASes) that are conducive to their provider\u2019s use of fltering using\nUnicast Reverse Path Forwarding (uRPF), with no collateral damage.\nWe include possible non-technical interventions, and demonstrate\nhow the platform can support evaluation of the impact of such\ninterventions over time. We argue that the only likely way to cover\nthis long-tail of remediation is for equipment manufacturers to\nenable SAV by default. (\u00a78)", "8.4 Regulating government procurement\nIf the U.S. Government wanted to take a leading role in increasing\nthe ability of all networks to attribute attacks, thereby improving\nglobal cybersecurity, it could require SAV of all agency networks\nand require Government-contracted ISPs to support SAV as well.\nA similar efort successfully mandated the availability of all government websites over HTTPS with modern settings under Ofce\nof Management and Budget (OMB) Memo M-15-13 [48]. The U.S.\nNational Institutes of Science and Technology has recently included\nSAV in draft security guidance documents that will represent requirements for all U.S. government agencies [43, 50]. Sometimes\nNIST takes these guidance documents and embodies them in Federal Information Security Modernization Act (FISMA) controls, e.g.,\nfor Domain Name System Security (DNSSEC) [59] or in other policy\ninitiatives [60]. All such requirements are only partially efective,\nbut they often serve as important catalysts to broader adoption.\nThere are several further approaches the U.S. government has\nstill not tried: including SAV as a requirement in governmentprocured networking services; the Department of Homeland Security Cybersecurity and Infrastructure Security Agenda (CISA)\nissuing a Binding Operational Directive (BOD); or the OMB issuing a specifc policy. We heard one anecdote about SAV being a\nrequirement for Federal Risk and Authorization Management Program (FEDRAMP) technology acquisition guidelines for U.S. federal\nagencies, where SAV was a requirement right up until the end of\nthe process. When the government asked for input from industry,\ncloud providers wanted the requirement removed because it was\n\u201ctoo hard to implement.\u201d This is a disturbing anecdote, since many\ncloud providers also sell DDoS mitigation services, so there is at\nleast the appearance of confict of interest in this dynamic.\nThis episode is reminiscent of the U.S. Anti-Bot Code (ABC) of\nConduct for ISPs issued in 2012 [55]. The FCC\u2019s Communications\nSecurity, Reliability, and Interoperability Council (CSRIC) convened\na multistakeholder group to create a set of voluntary guidelines on\nbotnet prevention and mitigation. When it was completed, the FCC\nasked ISPs to publicly acknowledge whether they would comply\nwith the guidelines; the ISPs refused. This made it impossible to\nassess the efectiveness of the guidelines.\nTwo related developments challenge the prospect of increasing\nthe strength of ISP guidelines. First, some assert that the tremendous consolidation in the Internet markets over the last twenty\nyears has dampened the urgency of solving the SAV problem, since\nmany companies outsource their content distribution to other platforms, e.g., one of the giant content distribution cloud platforms,\nmany of whom have resources in place to mitigate the impact of\nDoS attacks by absorbing, dispersing, or blackholing attack trafc\nin real time [25]. Indeed, many of these cloud platforms leverage\ntheir infrastructure to sell DDoS mitigation services, so DDoS attacks represent a revenue opportunity for them. A counterpoint\nis that attacks are growing in volume so much that only the most\nheavily capitalized providers can handle them. In October 2016,\nAkamai had to abandon its pro bono DDoS mitigation support for\ncybersecurity journalist Brian Krebs because it could not longer\naford to subsidize this service. Google\u2019s Project Shield took over\nKrebs\u2019 web site instead [7]. The tremendous consolidation in interconnection may also make it easier for well-resourced networks to\ntrace back the source of spoofed trafc as there are fewer hops to\nreverse engineer [10].\nSecond, many people tend to look at security as the responsibility of hardware and software manufacturers. In the case of the\nMirai botnet [2], the U.S. Federal Trade Commission (FTC) sued the\ndevice manufacturer (D-Link) for failing to adequately secure the\ncompany\u2019s home networking hardware [58]. We also note that a\njudge subsequently dismissed the lawsuit for failing to show sufcient harm by D-Link devices on consumers [54]. This does inspire\nthe question: if a victim of a spoofed DoS attack could establish\nclear economic harm, and attribute it to a class of devices that\ndid not confgure SAV by default, could the equipment vendor be\nconsidered responsible for the harm?\n8.5 Sticky defaults: vendor SAV responsibility\nResearch has found that default settings have strong impact on\nhuman behavior, even for high-stakes situations where people are\nwell informed of their choices [23]. An important open question is\nwhy, when the benefts of deploying SAV universally are clear and\nthe costs are low and falling, SAV is not universally deployed. Other\nchoices of default settings in networking equipment could radically\nshift this equilibrium \u2013 for example, if instead of providing packets\nto flter out in network ACLs, operators had to select which packets\nto forward, they would likely make diferent choices and would in\nparticular be unlikely to allow spoofed-source packets. The space\nof interface design for networking equipment and its impact on\nsecurity is very much underexplored.\nFurther confrming the beneft of SAV by default is our conversations with users of the platform over the last three years, where\noperators think they have deployed SAV, but have not verifed from\nall parts of their network, and since SAV is not generally a default\nconfguration on networking equipment, pockets of spoofability\ncan appear with any network equipment upgrade. Similarly, we\nhave noticed many temporary conference wireless networks that\nsupport technical meetings within the Internet industry, whose\noperator has neglected to enable SAV when building the temporary\nnetwork. While the operator often deploys SAV during the meeting\nafter private notifcation, the process repeats several months later.\nA related issue is network transit providers who hesitate to deploy fltering, such as with unicast Reverse Path Forwarding (uRPF)\n[4], because of the possibility the fltered customer network could\nbe multihomed to another provider, now or in the future. A router\nthat has deployed uRPF will discard a packet if the interface the\npacket arrived on is not the best (strict-mode) or a possible reverse\npath (feasible-mode) interface the router would choose to route\npackets to that destination. If a multihomed stub AS announces\nnon-overlapping portions of their address space to diferent transit\nproviders for trafc engineering, the provider network may fnd it\ndifcult to deploy uRPF. That is, the feasible return path might not\nbe via the interface a router received a packet from. The IETF hasrecently proposed improvements to fltering techniques to increase\ntheir operational robustness in the face of such complexity [51].\nHowever, we note two compelling empirical facts. First, a stub\nAS that is not multihomed to more than one transit provider is\na candidate for at least feasible uRPF, as the transit provider will\nreceive routes for all prefxes the stub AS uses even if the customer\nhas multiple physical connections to their provider, or the stub AS\nwill risk not having global connectivity in the event one connection\nfails. This single-homed stub AS scenario is more common than it\nused to be, and on the rise. Figure 19 shows that beginning 2005,\nas the Internet grew in terms of distinct routing policies (ASes),\nthe trend was for stub ASes to choose a single transit provider.\nTransit provider ASes can deploy feasible-mode uRPF on these stub\nASes without impacting packet forwarding, provided their stub AS\ncustomer properly announces prefxes covering all of their address\nspace across each BGP session with their transit provider.\nSecond, more complex networks also tend to be more capitalized,\nand our project demonstrates (and publishes) that some of the most\nlargest and complex networks, e.g., Comcast and AT&T, have successfully implemented SAV throughout their networks. Part of the\nproblem, and an argument for making SAV the default, is the lack of\nresources (both knowledge and time) required to accurately maintain SAV fltering, confrmed in a 2017 survey of 84 operators [30].\nWe were gratifed to hear that our platform is useful to network\noperators who wish to verify their own SAV compliance, including\nafter network upgrades that created pockets of spoofability that\noperators did not expect. If the U.S. government mandated SAV-bydefault on its networking equipment vendors, it might lead to SAV\nbecoming the default for equipment sold into enterprise networks\nas well. In turn, demand for predictability by network technicians\nwould create pressure on vendors who do not do business with the\nU.S. Government to make SAV a default as well.\nOur data indicates that there is limited deployment of uRPF on\nsingle-homed BGP customers in the Internet. In fgure 4, 25.2% of\nIPv4 ASes are at least partially spoofable in the year ending August\n2019. For the 438 ASes where feasible-mode uRPF could be deployed\nthat are in our data in the year ending August 2019, 21.5% of IPv4\nASes are at least partially spoofable.\n9 CLOSING THOUGHTS\nThe Internet ecosystem, with its academic roots and radically distributed ownership, has long defed traditional governance solutions. For some vulnerabilities, there will be no simple policy solutions. For such vulnerabilities, measurement plays a critical role\nin quantifying the current attack surface, and assessing the efectiveness of proposed interventions. Unlike many other network\nsecurity hygiene properties, there is no way to audit a network\nfrom outside to confrm that it performs SAV. The most valuable\ncontribution of our work has been the establishment of this capability \u2013 to prove to an independent third-party auditor that one\nhas properly deployed SAV from a given network. Any regulatory,\nprocurement, insurance, or peering requirement would require, and\nthus far lacked, this measurement capability. We also validated use\nof this platform to fll another gap: using stored measurements\nto evaluate the likely efects of any deployed intervention over\ntime. More generally, this project has been a demonstration of the\nthe importance of measurement \u2013 science, infrastructure, and data\nmanagement \u2013 in developing and deploying practical solutions to\nthe Internet\u2019s essential security weaknesses.", "Right now, I am creating a portfolio for myself as an artist to deepen and clarify the story I present to my audience through my music and my image on social media and in real life. \n\nIt is comprehensive outline of the persona maturation project entitled \u2018The Journey\u2019. It covers each and every aspect of the process in detail, both theoretical and practical, as well as a structured approach to building upon existing character frameworks.\n\nThe following is the current structure of the document, like the table of contents:\n\n# Introduction\n\nThis is a comprehensive introduction meant to bring you, the reader, up to speed with the current outline and motivations of the project.\n\n## What is \u2018The Journey\u2019\n\nThe Journey, derived from The Hero\u2019s Journey, a theoretical roadmap to the development of the key elements that evoke powerful emotional reactions in people. The Hero\u2019s Journey is a structure that has been followed by some of the greatest stories ever told and ever lived. \n\nThe version of this journey described throughout the document is tailored for Kadence and is meant to serve as a reference point and a workspace for ideas, planning, and the execution of specialized tactics in order to continuously develop and progress the story which underlies the public representation of the ideas covered in this document. \n\nThe Journey, it\u2019s associated ambitions, milestones, challenges, and gimmicks are experimental in nature, and thus are used to further our own research into the business of artist development, and quite possible leaving our mark on the World.\n\n## What is within this document?\n\nThis document contains a whole lot of useful information about characters, possible pathways of progression, theoretical understandings from The Hero\u2019s Journey, and much more. Overall, this document is a collection of all types of information that is relevant to the project undertakings described above.\n\n## How should this document be used?\n\nThis document should be seen strictly as an experimental guideline line used to plan and execute experimental content and plot lines with the intent of learning from experiment results and making changes to procedures in the future where necessary. With regards to content, the content database provided in this document will be used to visualize the potential timeline of events that will transpire once the official process has gone underway (ie. when the first piece of planned content is released to the public and the timeline must be adhered to.)\n\nIn addition to the content calendar, the document will be the gathering place for information deemed useful during the planning and execution process of projects such as the [Docu-series: \u2018Untitled\u2019](https://www.notion.so/Docu-series-Untitled-16d8ab7a883946629fcfa3154b28f7f9) . This information serves to fuel the end-user content that is scheduled and created. By using the Hero\u2019s Journey as a guideline, maximum impact can be gradually attained via meticulous planning and execution of ordered story elements once it is distilled into its relevant parts here inside this document.\n\n## What is [The Story]\n\n[The Story] is a character arch guideline for the [Docu-series: \u2018Untitled\u2019] that is derived from the content of this page. It occurs over a discrete time period, subtly growing in both complexity and depth. The point of using a story is simple, it allows us as the creators of content to understand what type of activities, emotions, themes, places, people, and other story elements to include in order to progress the story, in film format, from a clear beginning to a decisive end without relying on specific events or in real life occurrences that might be outside of our control. By determining the characters in the story, as well as their personalities, aspirations, fears, hopes, and desires, we will be able to translate the implied reality of those characters into practical actions and plot points that can be made in the real world to add a touch of fantasy-like takeaways to the project.\n\nBy taking the time to understand both the created characters and their real life counterparts, we ensure maximum compatibility with your (you reading this) personality and willingness to carry-out certain real life actions. For example; if there is a unanimous vote in favour of a miniature story arch entitled \u201cthe Hair Bleaching Journey\u201d, then the actual feasibility of both the execution and the successful implementation of the story arch can be weighed against the personalities who would actually be carrying out the plot in real life (ie. Kadence). In this case, the previously mentioned miniature story arch above is within the personalitie\u2019s \\*zone of possibility\\*. This lends a higher chance of success as well as a more natural feeling approach to executing the actual story element. This simply means that Kadence is okay with whatever comes with such a mini arch. There may be others which fall outside of this feasible range, and that is where this entire document comes in. It allows us to weed through all of our ideas, selecting the most realistic ones that also add to the greater storyline (following the Hero\u2019s Journey). The content calendar supports this by allowing us to plan months in advance in order to make sure that our plans are solid well before any are due to air or be created in the real world. One more advantage of this setup is that is allows for the addition of subtle details and easter eggs which add to the realism of the events. \n\n## What is content?\n\nThe content being referred to throughout this document implies any piece of digital media created with the intention to release publicly, and any physical activity, psychological manipulation, social experiment, or persona maturation that takes place as a result of itself within the structure of the content as a whole. For example, with respects to the persona maturation process and the Hero\u2019s Journey, there must be a transition from \u2018the Ordinary World\u2019 into \u2018the Special World\u2019, a call to adventure. This means that content surrounding this major story arch can be anything from music and visual content, to IRL appearances and planned controversy. Whether a certain piece of content gets placed on the calendar depends on whether or not is has met the above criteria for all parties involved.\n\n# The Journey\n\n## Who is Kadence\n\nI am Kadence, a 25-year-old musician from New York City who was raised in Jamaica. Music has been a constant in my life, a source of comfort and inspiration that has seen me through the ups and downs of my journey. From a young age, I was drawn to the rhythms of the Caribbean and the art of music-making, and it was in Jamaica where I first discovered my love for rap and hip-hop.\n\nI started my journey as a rap artist under the name 'Kadence' in 2012, and it wasn't long before I became well-known in my home city of Mandeville for my skills as a producer, vocalist, and songwriter. I spent countless hours honing my craft, pouring my heart and soul into each beat, each verse, each chorus. I knew that music was my calling, and I was determined to make it my life's work.\n\nSo, in 2015, I made the bold decision to move to Toronto, Canada, to pursue my dream of becoming a successful musician. It was a difficult decision, leaving behind my family and friends, but I was driven by a deep passion for music and a fierce determination to succeed. And I am proud to say that today, I produce and record my own music, blending elements of rap and hip-hop, R&B, dancehall, and pop into a sound that is uniquely my own.\n\nMy music reflects my experiences, my emotions, and my journey. It is a testament to my resilience and my determination. But it is more than just entertainment, it is a source of comfort and inspiration for those who need it most. I use my songs to help others through difficult times, to bring light into the darkness, and to bring people together. I have an empathy that is rare in this world, a genuine desire to make a positive impact on those around me. I want my music to make a difference, to touch people's hearts, and to help heal the world.\n\nMy brand is defined by my authenticity, my empathy, my passion, my creativity, my resilience, and my humility. I am more than just an artist, I am a source of inspiration, a voice for the voiceless, and a shining light in a dark world. I hope to become known worldwide, remain independent and profitable, and eventually become close friends with my idols. But most of all, I want to be known for always releasing high-quality music that speaks to the hearts of my listeners.\n\nI believe that music has the power to change lives, to bring people together, and to make the world a better place. And I am proud to be a part of that tradition, to be a part of that legacy. I will continue to pour my heart and soul into each song I write, each beat I produce, because I know that music is more than just entertainment, it is a way of life. And I am honoured to share my life's work with the World.\n\n## Synopsis\nAs you can see, the above is aimed to build a book of myself in which I can create and operate a storyline that draws in listeners while making the creative aspect of my work easier and more enjoyable. Please help me to generate:\n\n1) More sections such as '# Introduction' and sub-sections like '## Who is Kadence?'. Please only provide the headings, I don't need the descriptions yet. Please provide 20.\n\nand \n\n2) As you can see, I used your last generated message about my brand identity statement to fill the '## Who is Kadence?' section. Can you give me ideas on how to continue structuring the overall book so that it has more chapters and I will be able to implement the 'Hero's Journey' method into the writing of it, while maintaining physically attainable actions that I am able to take in the real world to further enhance the realism of the book? Please provide me actionable sections and sub-sections that will help me to categorize and organize useful information such as what you have provided me so far, as well as information I will learn in the future from market research and the like.", "I want to you to act as a federal research grant writer. I will provide you with a description of the task and the desired deliverables. You will generate at least 5 paragraphs for each chapter heading that I will provide you with.\n\nDescription:\n\nAutonomous and partially-autonomous systems promise the opportunity for a future with self-driving automobiles, air taxis, packages delivered by unmanned aerial vehicles (UAVs), and more revolutionary Earth applications. At the same time, it is expected that future NASA deep space missions will happen at distances that put significant communication barriers between the spacecraft and Earth, including lag due to light distance and intermittent loss of communications. As a result, it will be difficult to control every aspect of spacecraft operation from an Earth-based mission control, and thus, the crews will be required to manage, plan, and execute the mission and to respond to unanticipated system failure and anomaly more autonomously. Similarly, there is also opportunity for unmanned vehicles on Earth to benefit from autonomous, cognitive agent architectures that can respond to emergent situations without the aid of human controllers. For this reason, it is advantageous for operational functionality currently performed by external human-centric control stations (e.g., mission control) to be migrated to the vehicle and crew (if piloted). Since spacecraft operations will consist of a limited number of crewmembers who each operate with a limited performance capacity (in terms of both cognition and tasks), it will be necessary for the spacecraft to have assistive, autonomous, and semi-autonomous agents to be responsible for a large proportion of spacecraft operations so as not to overburden the crew.\n\nCognitive agents could provide meaningful help for many tasks performed by humans. Novel operational capabilities required by deep space missions, such as spacecraft and systems health, crew health, maintenance, consumable management, payload management, and activities such as food production and recycling could benefit from the assistance of autonomous agents, which could interface directly with the crew and onboard systems, reducing cognitive load and scheduling time on the crew. Additionally, cognitive agents could contribute to many general operational tasks in collaboration with the crew, such as training, inspections, and mission planning. Finally, autonomous agents could increase the mission\u2019s resilience to hazardous events, both by directly responding to certain events (e.g., ones which unfold too quickly for the crew to catch, or which immobilize the crew) and by providing assistive services (e.g., fault diagnosis, contingency analysis, and mission replanning).\n\nHowever, implementing these cognitive agents presents significant challenges to the underlying software architecture. First, these agents will need to be able to take a significant amount of responsibility for mission operations while still operating under crew directives. Additionally, agents with different dedicated roles will need to share resources and hardware and may have differing goals and instructions from human operators that need to be managed and coordinated. Such agents will, thus, need to be able to take these actions autonomously while enabling (1) effective crew (or vehicle occupant) control of the vehicle even when the agent is operating autonomously (meaning, the agents should not be acting in unexpected ways and should report when the situation has changed enough to justify a change in operations), (2) direct crew control of the task when manual intervention is needed, and (3) autonomous and manual coordination/deconfliction of agent goals and tasks. Second, for NASA space missions, long-duration spaceflight is likely to uncover new challenges during the mission that require some level of adaptation. Whether this is because of known low-probability hazardous events or because of \u201cunknown unknown\u201d situations that were not planned for, cognitive agents will need to have a capacity for \u201cgraceful extensibility.\u201d This concept is not unique to space missions\u2014Earth-based vehicles will also need to be able to respond to similar types of events in-time given the highly variable and heterogenous environments they will likely encounter when operated at scale. As a result, the architecture of the cognitive agent will need to be able to learn (both from taught examples and from the environment) and reconfigure itself (in collaboration with the crew) to perform new tasks. Finally, these capabilities need to be implemented with the high level of assurance required by mission operations, meaning that learned and autonomous behavior must be transparent, predictable, and verifiable using traditional software assurance techniques.\n\nThis subtopic solicits intelligent autonomous agent cognitive architectures that are open, modular, make decisions under uncertainty, interact closely with humans, incorporate diverse input/data sources, and learn such that the performance of the system is assured and improves over time. This subtopic will enable small businesses to develop the underlying learning/knowledge representation, methods for enabling the required behavior (e.g., operations and interactions), and necessary software architectures required to implement these technologies within the scope of cognitive agents that assist operators in managing vehicle operations. It should be feasible for cognitive agents based on these architectures to be certified or licensed for use on deep space missions to act as liaisons that interact with the mission control operators, the crew, and vehicle subsystems. With such a cognitive agent that has access to all onboard data and communications, the agent could continually integrate this dynamic information and advise the crew and mission control accordingly by multiple modes of interaction including text, speech, and animated images. This agent could respond to queries and recommend to the crew courses of action and direct activities that consider all known constraints, the state of the subsystems, available resources, risk analyses, and goal priorities. Cognitive architectures capable of being certified for crew support on spacecraft are required to be open to NASA with interfaces open to NASA partners who develop modules that integrate with the agent, in contrast to proprietary black-box agents. It should be noted that fulfilling this requirement would additionally make the cognitive agent suitable for a wide variety of Earth applications where a high level of assurance is needed (e.g., autonomous vehicles and aircraft).\n\nAn effective cognitive architecture would be capable of integrating a wide variety of knowledge sources to perform a wide variety of roles depending on mission requirements. For example, an effective prognostics and health management (PHM) agent would need to be able to take sensor data, interpret this data to diagnose the current state of the system using learned artificial intelligence (AI) models, digital twin simulations and data, and user input, and project out potential contingencies to plan optimal maintenance and/or fault avoidance operations under uncertainty. These operations would need to be modifiable in operations, for example, if a hazardous event occurs, there are changes to the mission, or there is a learnable change in behavior that reduces arising projection errors. This agent would need to be able to conduct operations autonomously for low-level inspection and maintenance operations while enabling safe human intervention throughout the process. It would finally need to communicate with crews for planning and performance of maintenance operations, to report/escalate potential hazardous contingencies, and for modification of operations (e.g., learning). This communication could include producing human-interpretable visual dashboards, communicating directly via speech, and direct manipulation of hardware (e.g., to teach/learn certain operations). Agents like this (with functionality appropriate to the given task) would be needed to perform a variety of roles in the spacecraft, including low-level tasks like state estimation, hardware control, and subsystem management and high-level tasks like mission planning and scheduling. Agents with independent responsibilities will furthermore need to be managed and coordinated to enable functional and resilient overall operations.\n\nThe following (nonexhaustive) list of managers provides capabilities useful for a wide variety of spacecraft cognitive agents:\nState estimation manager (SEM): This manager\u2019s capabilities include extracting information from sensors, including images, for use by other managers and by crew. State estimation includes separating signal from noise in sensor data, extracting and compressing useful information, along with fault management and prognostics. The state estimation manager must categorize information on both vehicle-wide and subsystem-by-subsystem bases, including crew health and performance, security, and scientific objectives.\nSkill/behavior manager (SBM): This manager orchestrates execution of individual tasks on short timescales. This involves incorporating specialized knowledge needed for different tasks, e.g., orbit/trajectory planning, robotics operations, spacecraft subsystem control. The skill/behavior manager includes a \"smart executive\" that robustly executes high-level plans produced by the planner/scheduler manager, on schedule, by coordinated commanding of multiple subsystems.\nPlanner/scheduler manager (PSM): This manager creates and updates plans and schedules that accomplish goals. This functionality involves maintaining lists of goals, priorities for achieving those goals, and spacecraft and mission-wide constraints.\nKnowledge manager (KM): This manager ensures that the system's declarative knowledge is consistent and updated, including the incorporation of learned knowledge. Learning and modeling techniques capture system and operational knowledge from different types of knowledge sources; these must be incorporated into existing knowledge bases. \nHuman-machine interactions manager (HMIM) - Natural Language Processing (NLP), Extended Reality (XR): This manager enables multimodal interface/communications with the crew about the current and future state of the systems. This manager must communicate information from all other managers.\n\nWell-constructed proposals will focus on developing a prototype cognitive agent(s) in the context of a limited test. This agent will need to embody a cognitive architecture that can be readily applied to a wide variety of roles and tasks throughout a mission that embodies the desired capabilities of autonomous and semi-autonomous operations, modifiable and/or learned behaviors, data/model fusion for decision-making under uncertainty, advanced user interaction, and assurance/transparency. This architecture could then be able to be extended to a wider scope in a more advanced mission in future phases of the project. This project and the agent architecture will need to be thoroughly documented and demonstrated to enable the understanding (e.g., capabilities and limitations) of this technology.\n\nDesired Deliverables Description:\n\nThe expectation is to develop (1) a preliminary cognitive architecture with trades study/requirements analysis supporting the selection of the architecture in a desired mission (e.g., Human Exploration of Mars Design Reference Mission: Human Exploration of Mars Design Reference Architecture 5.0), (2) early feasibility prototypes of architecture features and conceptual description (e.g., in SysML) for a cognitive agent(s) in that mission, and (3) a detailed implementation plan for full architecture with technical risks identified and managed.\n\nNow please generate a chapter with the following title \"Identification and Significance of the Innovation\".", "What are 5 titles for the following article:\n\n```\nWhat you need to know about the New Architecture in React\u00a0Native\nWhat's Going\u00a0On?\nIn March of 2022, Meta announced that they are ready to start rolling out their new architecture for React Native.\nWell, what the heck is the new architecture?\u00a0\nGoodbye JSON Bridge, hello\u00a0JSI\nUp to this point, React Native achieved the native part of React Native by having a JS thread for your business logic and a native thread for managing updates to the native UI elements. When these two threads needed to communicate, they would use a bridge to send JSON messages back and forth.\nWhile JSON is simple to read, it's not perfect. Imagine running through this diagram a thousand times trying to render all the posts on your friend's Instagram:\nIt's okay JSON, you would be perfect if you handled trailing\u00a0commasNow, the new architecture lets you skip the JSON middle man and your Javascript can talk directly to native code using a JavaScript Interface, or JSI for short.\nNothing will keep us\u00a0apartC++ joins the\u00a0crew\nTo help support JSI, C++ has now entered the React Native stack. Native code for iOS, Android, and beyond can be written in one language and abstract away platform specific details.\nFor those of us who are not C++ developers and would prefer to continue to write native code in an already supported language like Java or Objective C, React Native provides code generation at build time to scaffold the necessary types and methods in native land for our JS code to be able to reference.\u00a0\nMeta has provided documentation on how to leverage JSI when writing native modules by using Turbo Modules.\nFabric instead of\u00a0Paper\nIn order to support the concurrent features in React 18, React Native has a new layout engine called Fabric. The old layout engine is sometimes unofficially refered to as \"Paper\".\nThere are a lot of underlying changes to the render paradigm, but one of the most important ones that Fabric enables is the idea of high priority updates.\nSometimes a component renders slowly. Maybe that component needs to do an expensive calculation that is unavoidable. Previously, all you could do would be profile the component tree and try to fix or memoize whatever was rendering slowly. Performance issues like this this can be time consuming to pin down, and solutions for them may require large changes to your app.\nExample from useTransition reference on beta.react.orgNotice how the UI here is unresponsive when trying to trigger other updates while the SlowPosts component is rendering. We are not able to navigate to another page by clicking on the Contact button until it finishes rendering. That is because all updates to the component tree before React 18 have the same priority. The tree must wait until all the components are done rendering before a new component tree can be created and show the updated state.\nExample from useTransition reference on beta.react.orgNotice how the UI immediately changes after clicking on Contact instead of waiting for Posts to finish rendering? By wrapping the state update inuseTransition, it now has higher priority than the existing component tree and will interupt the current render to transition to a new component tree.\nMany developers use high-end devices to test their applications, so they may not run into issues with their UI being unresponsive in development. However, on lower end devices, transitions will be a useful tool to help user interfaces be responsive even during expensive renders, such as long lists.\nThat's cool, what's\u00a0next?\nI'm a nerd and want to understand more deeply what's going on\u00a0here\nhttps://reactnative.dev/architecture/overviewThe React Native team has provided detailed documentation regarding important topics like: Architecture Overview, The New Architecture, and Migrating to the New Architecture. However, that can be a lot of information to digest at once, so we would recommend starting with the following articles:\nFabric, React Native's new rendering system.\nTurbo Native Modules\nCreating a New Architecture App\nMigrating to the New Architecture\n\nhttps://github.com/reactwg/react-native-new-architecture/If you want to get your hands dirty and see the bleeding edge, React has a working group for discussing topics related to the new architecture. As it evolves, this is a good place to leave feedback and see other people's experience working with the new architecture.\nFor the video lovers, here are some of our favorite talks for learning more about new architecture:\nThe New Architecture is Here\u2026 What Now?\u200a-\u200aLorenzo Sciandra\u200a-\u200aReact Native London September 2022Lorenzo Sciandra, one of our favorite React Native maintainers (don't tell the others \ud83d\ude18), talks about some of the core concepts regarding the new architecture and identifies some of the challenges developers will face in the coming years.\nBringing the New React Native Architecture to the OSS community\u200a-\u200aN. Corti | React Native EU\u00a02022Nicola Corti, a React Native Core team member at Meta, gives a good overview of the timeline for the new architecture rollout both interally at Meta and for the greater React Native community. He also touches on why the React Native team decided this new architecture was necessary, the core pillars of the new architecture, and more.\u00a0\nWill TurboModules replace JSI Modules\u200a-\u200aMarc Rousavy\u200a-\u200aReact Native London\u200a-\u200aJune\u00a02022Marc Rousavy, maintainer of react-native-mmkv and other React Native libraries, talks about Turbo Modules and how he decided to utilize JSI outside of Turbo Modules.\nI need to update my existing\u00a0app\nReact Native New Architecture SampleWe all know that upgrading React Native versions can sometimes be challenging. Thankfully, this repository from react-native-community has step-by-step guides to migrate apps from various versions: such as 0.67 to 0.68, 0.67 to 0.69, 0.67 to 0.70, etc.\u00a0\nReact Native DirectoryCurious of the compatability of your favorite library? React Native Directory to the rescue! They have a search filter for \"Supports New Architecture\" when looking up libraries.\nhttps://reactnative.dev/docs/new-architecture-introTo help with upgrades, React Native has provided a series of feature flags in order to allow developers to update their app's React Native version and opt into specific features like Turbo Modules, Fabric, or React 18 on their own timeline.\nIt is possible for you to upgrade all of these today following the React Native docs. But as of writing this, Turbo Modules and Fabric are still experimental and being iterated on. You can manually enable them starting in 0.68, but in future releases much of these manual steps will be made simpler through tools, templates and libraries.\nHere is a rough outline of what will be required:\nUpdate to at least 0.68 for Turbo Modules and Fabric\nMake sure Hermes is enabled\u00a0\nEnable Turbo Module support on iOS and Android through feature flags and added native code.\nEnable Fabric support on iOS and Android through feature flags and added native code.\nUpdate to 0.69 in order to take advantage of React 18 concurrent features like startTransition and useDeferedValue.\n\nI need to update my\u00a0library\nProbably the trickiest part of the transition from the old architecture to the new architecture will land on the shoulders of library maintainers.\u00a0\nTwitter Thread from @mateusz1913Mateusz M\u0119drek, maintainer of react-native-avoid-softinput, wrote a thread on Twitter describing his experience migrating his library in September of 2022.\nPart of our motivation at Infinite Red for this article is to make it easier for library authors and app developers alike to make the leap together.\nhttps://github.com/react-native-community/RNNewArchitectureLibrariesThankfully, React Native Community on GitHub has a repository with step-by-step guides for authoring libraries with Turbo Module and native components utilizing the Fabric rendering system.\nAs people transition, maintainers will essentally have two entry points into their libraries: one for the old architecture and one for the new architecture. They will be able to read the provided feature flags in iOS podfiles and Android gradle files to determine which entrypoints to activate for Turbo Modules and Fabric enabled components.\nI want to start a new app using the new architecture\nhttps://reactnative.dev/docs/the-new-architecture/use-app-templateLuckily, if you are creating a new app as of 0.70, all of the native Android and iOS code changes necessary to enable Turbo Modules, Fabric, Hermes, and React 18 will already be provided by in the app template from React Native CLI. You can test it out yourself by runningnpx react-native init AwesomeProject. Afterwards, you will you need to turn on a series of feature flags described in the docs.\u00a0\nExpo SDK 47 announcement postIf you want to get started with Expo, Expo SDK 47 has support for React Native 0.70 and Hermes out of the box, along with experimental support for Fabric in many of their libraries.\nNotably, Expo has decided to implement their own support for JSI through their own tool, Expo Modules, instead of using Turbo Modules.\u00a0\nI want to start a new library that supports the new architecture\nFor bare workflow apps, React Native has provided guides on their docs for creating new Turbo Module libraries and Fabric compatible components.\nhttps://reactnative.dev/docs/the-new-architecture/pillars-turbomoduleshttps://reactnative.dev/docs/the-new-architecture/pillars-fabric-componentsAnother interesting option is to utilize Expo Modules, which boast allowing you to author your native code in Swift and Kotlin, which may be friendlier to more React Native developers than Java and Objective-C++.\nhttps://docs.expo.dev/modules/module-api/#examplesIt is worth noting that it is possible to author Turbo Modules in Kotlin and Swift, but this is not documented in the offical React Native docs as of writing this.\nNeed more?\nInfinite Red is hosting Chain React 2023, the premier React Native conference, May 17\u201319, 2023 in Portland Oregon. One of the workshops this year will be Leveling Up on The New Architecture. Ticket are on sale now.\nhttps://cr.infinite.red/\n```", "From: Bill Gates\nSent: Monday, September 30, 1996 9:36 PM\nTo: Nathan Myhrvold\nCc: Aaron Contorer\nSubject: Java runtime becomes the operating system\n\nI am worry a lot about how great Java/Javabeans and all the runtime work they are doing is and how much excitement this is generating. I am literally losing sleep over this issue since together with a move to more server based applications it seems like it could make it easy for people to do competitive operating systems.\n\nI am very interested to get your thoughts on this. Prior to the advanced work you are driving what kind of defenses do we have against this? I certainly havent' come up with enough to relax about the situation and it is undermining my creativity.\nFrom: Nathan Myhrvold\nSent: Tuesday, October 01, 1996 12:05 PM\nTo: Bill Gates\nCc: Aaron Contorer\nSubject: RE: Java runtime becomes the operating system\n\nI agree that this is a dilemma, but I don't think that it is severe enough that you should lose sleep over it. Here are some quick thoughts on the matter - I will put more time in on it also.\n\nFirst, the excitement is overblown - at least from a \\*business\\* perspective. At the moment Java is expanding into a vacuum. It allows you to make cool web pages, and that is a very attractive thing for people. It gives programmers something new to learn, book people something new to sell books on, software tool companies a way to issue new development tools etc.\n\nAs you and know very well, this sort of widespread interest can become a self fullfilling phenomenon, because programmer attention creates programs. Some of these will be successful and that only fuels more participation in the phenomenon. However, at the same time you must keep something of a balanced perspective.\n\nI think that the risk of Sun really taking the OS franchise away from us is much lower than the risk that they cheapen the entire business. They are so hell bent to give things away, and there is so much cross platform ferver that it will be hard for them or others to harness this energy toward a single platform In the limit, they can make the web totally OS agnostic - but there will still be other things that motivate one platform versus another.\n\nIn the very long run they could make it more and more difficult for us to keep up and thus even though the world is cross platform, we have more baggage, worse implementation and can't keep up. This is NOT going to happen quickly however - we will get several more swings at them\n\nThe new Java applications are NOT credible threats to traditional PC software any time soon. It is just insanity to think that they are. New things are NEVER a threat to the old world as soon as people say. Look at the mainframe vs PC. It has taken us TWO DECADES and even after all that IBM still has billions in mainframe revenue. Cool new technology always expands rapidly into NEW areas (where there is a vacuum). Pundits always say that this is going to kill the old businesses - eventually that happens but not anywhere near as soon as they say.\n\nIt is a new and uncomfortable feeling to be the incumbent rather than the challenger in one of these battles. However, we must not panic. The current perceptual battle is a long way distant from actual business and revenue issues, and we can't let the perceptual issues cloud our thinking too much.\n\nThis is not to say that Java is unimportant It is VERY important (just don't lose sleep!) I think that you are focusing on the wrong \\*kind\\* of threat. We are in danger of losing a new market which will grow at a pace which is very rapid indeed. This would be a tradegy to have happen to us, but it is different than a direct assult on our core asset, and our response must also be different.\n\nThe obvious things to do are:\n\n1 Provide our own means of dramatically improving web pages.\n\n- Continue to \"embrace and extend\" - both at the level of new Java tools (like J++), and our broader browser strategy.\n\n- Create some radical new approaches to improving web pages, or building web applications. I think that it is a big mistake to put all of our eggs in the \"embrace and extend\" basket. This thinking will lead us down the path to renounce any really interesting edge we could have. Over reliance on \"embrace and extend\" can lead to what I sometimes call the relentless drive to come in second, which does not help much in a winner take all world.\n\nNote that by \"radical\" I mean more in concept than in technology - i.e. NOT speech or other really hard stuff. Java is pathetic technology. We do not need high tech here - we need some technology but mainly creativity in how we look at it.\n\n2. Pioneer other means to participate in the new market. It is very rare that there is only one asset that matters. Hell, look at Netscape and Sun - each have an interesting asset, and this is still the EARLY stages of the net. There will be other technologies which matter and we should try to own one of them, even if it is in a totally different direction.\n\nThe key thing is to come up with something which will be buoyed up by the rising Internet tide Again, this need not be some super hard technical problem - it is more about being creative and finding an opportunity. Here are some examples (none perfect).\n\n- Virtual worlds could be such a thing.\n\n- New ways of doing server apps, or doing net transactions (a la Viper) could be such a thing.\n\nI don't have as many examples here as I would like, but I am pretty sure that we could come up with some things if we really focussed on this area.\n\n3. Continue to invest in our core business assets - in this case the Windows runtime. 99% of worldwide software revenue is still based on Windows apps, and way more than 100% of profits. If we let Windows decline in its non-web attributes then we will REALLY will be up shit creek. I fear that the overexcitement in the web, and the misunderstanding that our core business is only indirectly under attack means that our current course and speed neglects our best avenue to comete.\n\nWe need Windows to be the most compelling platform for users to choose Ideally this means that we win in every category. You are worried that we will only tie in the Java category because Javabeans and other runtime work will make cross platform really work well. I say we should try to tie (or win) with embrace and extend in the Java world. HOWEVER while doing this we MUST NOT allow Windows to lose in the other, non-web dimensions that are important to users selecting systems! There is more to a user's system choice than just the Web - and it is in those areas where we have a big advantage.\n\nPut another way - suppose that Java is totally successful and totally cross platform - then why should people choose one system versus another? It will all hinge on other areas.\n\nHere are some examples:\n\n- We need to be the LEADER in multimedia - this means doing very cool audio and video. We want to lead with DVD and make it easy to . We must be the best platform for games (better than Ultra64 or Playstation). We want to be the best platform for graphics/video/audio authoring (better than SGI or Mac).\n\n- Prevent barriers from coming up in ease of use. PCs must be instant on, they must go beyond plug and play to be even more self configuring, they must be self diagnosing. There is no technical reason why a PC shouldn't be the best possible user experience - better than those hypothetical web terminals. However, this takes WORK to make it happen It will take those web terminal guys some work too, but in our case there is a certain amount of baggage which will cause extra work for us, but will result in extra reward too. It is critical that we do this.\n\n- Leverage the web to provide dramatic new functionality for old applications. The key example here is the \"My Workspace\" notion of totally abstracting storage on the net. This would be a dramatic change for users - storage abstractions are one of the hardest things to use in current PCs and we can make this all go away. If we do this based on STORAGE (i.e. file system APIs) it can short circuit the longer term move to distribution based on other APIs or protocols -- storage gets you most of the benefit.\n\nI am frankly worried that we are not doing enough in this area because we have over-focused on the web We need end user focused people to really make our system great. We are handicapped by the fact that we also need to do an implementation technology shift (to NT) and a cultural/personnel shift (to Allchin's group which has historically focussed more on underlying technology than on end user stuff).\n\nThis is a big challenge to do these shifts AND keep the platform vital. The analogy with Apple is frightening. They pissed away their creativity on non-Mac things (Kaleida, Sweet Pea/Pippin, Taligent, Newton ...), and they tied up their Mac team with a technology shift (to Power PC). The analogy is unfair because the web work that Siverberg and Ludwig have been doing is much more relevant than what Apple did. However I still am worried that we are not making enough investment in our core asset. The good news is that we do have plenty of people we can focus on these problems, and if we do we can create some end user value that will be hard for anybody else to match.\n\n------------------------------------------\n\nI am not sure whether I managed to make you less worried or more worried. I think that this is a serious problem, but I think that we have more options than you may think - particularly with 2 and 3 above.\n\nNathan", "Monthly Distribution Locations\nBerkshire County\nLocation\n Address\n Date\n Time\n Contact\nAdams Visitor Center\n 3 Hoosac St. Adams\n 4th Fri\n 12:30 \u2013 1:3o p.m.\n (413)743-8333\nClaire Teague Senior Center\n 917 South Main St. Great Barrington\n 2nd Weds\n 1 \u2013 3 p.m.\n (413)528-1881\nLee Council on Aging\n 21 Crossway St. Lee\n 2nd Weds\n 12 p.m.\n (413)247-9738\nLenox Community Center\n 65 Walker St. Lenox\n 2nd Weds\n 11:30 a.m. \u2013 12:30 p.m.\n (413)637-5535\nMary Spitzer Center\n 116 Ashland St. North Adams\n 4th Fri\n 12:30 \u2013 1:30 p.m.\n (413)662-3125\nOtis Town Hall\n 1 N Main Rd. Otis\n 3rd Fri\n 11am \u2013 12 p.m.\nRalph J. Froio Senior Center\n 330 North St. Pittsfield\n 4th Fri\n 10:30 \u2013 11:30 a.m.\n (413)499-9346\nHeaton Court\n 5 Pine St. Stockbridge\n 2nd Weds\n 11 a.m. \u2013 12 p.m.\n (413)298-4170\nFranklin County\nLocation\n Address\n Date\n Time\n Contact\nAthol Senior Center\n 82 Freedom St. Athol\n 3rd Weds.\n 11:30 a.m. \u2013 12 p.m.\n (978)249-8986\nCharlemont Senior Center\n 175 Main St. Charlemont\n 3rd Weds.\n 12:30 \u2013 1:00 p.m.\n (413)339-5324\nDeerfield Town Hall\n 8 Conway St. South Deerfield\n 1st Thurs\n 12:30 \u2013 1:30 p.m.\n (413)665-2141\nErving Senior Center\n 1 Care Dr. Erving\n 1st Thurs.\n 10:30 \u2013 11:30 a.m.\n (413)423-3649\nGreenfield Senior Center\n 35 Pleasant St. Greenfield\n 1st Thurs.\n 10 \u2013 11 a.m.\n (413)772-1517\nMontague Senior Center\n 62 5th St. Turners Falls\n 1st Thurs.\n 10:30 a.m. \u2013 12 p.m.\n (413)863-9357\nNorthfield Town Hall\n 69 Main St. Northfield\n 1st Thurs.\n 12:30 \u2013 2 p.m.\n (413)498-2186\nOrange Senior Center\n 135 East Main St. Orange\n 3rd Weds\n 11am \u2013 12 p.m.\n (978)544-1113\nShelburne Falls Senior Center\n 7 Main St. Shelburne Falls\n 3rd Weds\n 12 \u2013 1 p.m.\n (413)625-2502\nHampden County\nLocation\n Address\n Date\n Time\n Contact\nAgawam Council on Aging\n 954 Main Street Agawam\n 3rd Thurs.\n 2 \u2013 2:30 p.m.\n (413) 821-0604\nBrimfield Senior Center\n 20 Main St. Brimfield\n Fri after 2nd Thurs\n 9 a.m. \u2013 1 p.m.\n (413)245-7253(Cancelled for the month of May)\nChester Town Hall\n 15 Middlefield Rd. Chester\n 3rd Fri\n 10:30 \u2013 11:30 a.m.\n (413)354-7735\nChicopee Moose Family Center\n 244 Fuller Rd. Chicopee\n 3rd Tues\n 12 \u2013 1 p.m.\n (413)538-9020\nMcKinley House Community Room\n 38 Asinof Ave Chicopee\n 3rd Tues\n 12 \u2013 1 p.m.\n (413)594-1929\nForest Park Manor\n 25 Barney Avenue Springfield\n 2nd Fri\n 2 \u2013 4 p.m.\n (413)785-5019\nGranville\n 85 Sodom St. Granville\n Sat after 2nd Tues\n 9 \u2013 11 a.m.\n (413)214-2686 (Closed until further notice)\nHampden Senior Center\n 104 Allen St. Hampden\n 3rd Wed\n 9:30-10:30am\n (413) 566-5588\nHolyoke Council on Aging\n 291 Pine St. Holyoke\n 4th Tues\n 2:15 \u2013 3:15 p.m.\n (413)322-5625\nIndian Orchard Citizens Council\n 117 Main St. Indian Orchard\n 1st Fri\n 12 \u2013 1 p.m.\n (413)301-5213\nLudlow Senior Center\n 37 Chestnut St. Ludlow\n 3rd Tues\n 1 \u2013 3 p.m.\n (413)583-3564\nPalmer Council on Aging\n 1029 Central St. Palmer\n 2nd Fri\n 10:30 \u2013 11:30 a.m.\n (413)283-2670\nRussell Town Hall\n 60 Main St. Russell\n 3rd Fri\n 10:30 \u2013 11:30 a.m.\n (413)862-6202\nSouthwick Senior Center\n 458 College Hwy. Southwick\n 3rd Tues\n 10:30 \u2013 11:30 a.m.\n (413)569-5498\nEdgewater Apts. Community Room\n 101 Lowell St. Springfield\n 4th Tues\n 11 a.m. \u2013 4 p.m.\n (413)781-4941\nR A Jordan Senior Center\n 1476 Roosevelt Ave Springfield\n 3rd Thurs\n 10:00 a.m. \u2013 12:00 p.m.\n (413) 787-6785\nRiverview Senior Center\n 310 Plainfield St. Springfield\n 4th Tues\n 12 \u2013 1:30 p.m\n (413)739-7211\nSpringfield Tri-Towers\n 18 Saab Ct. Springfield\n 4th Tues\n 11:15 a.m. \u2013 12:30 p.m.\n (413)747-0127 (Cancelled Until Further Notice)\nSeniority House (Satellite of Saab Court)\n 307 Chestnut St. Springfield\n 4th Tues\n 10:30 a.m.- 12 p.m.\nUrban League\n 1 Federal Street Springfield\n 1st Fri\n 12 \u2013 1 p.m.\n (413)739-7211\nWashington House\n 16 Washington St. Westfield\n 2nd Tues\n 11 a.m.-1 p.m.\nWestfield Senior Center\n 45 Noble St. Westfield\n Wed. after 2nd Tues.\n 9-10 a.m.\n (413)562-6435\nWest Springfield Mercy Life\n 2112 Riverdale St. West Springfield\n 3rd Fri\n 1:30 \u2013 2:30 p.m.\n (413)827-4372\nWilbraham Senior Center\n 45B Post Office Park Wilbraham\n 3rd Fri\n 1-2 p.m.\n (413)596-8379\nHampshire County\nLocation\n Address\n Date\n Time\n Contact\nBangs Center\n 70 Boltwood Walk Amherst\n 1st Thurs.\n 1:30 \u2013 4:00 p.m.\n (413)259-3060\nBelchertown Senior Center\n 60 State St. Belchertown\n 2nd Fri\n 10:30 \u2013 11:30 a.m.\n (413)323-0420\nChesterfield Senior Center\n 400 Main Rd. Chesterfield\n 2nd Thurs\n 11 a.m. \u2013 12 p.m.\n (413)296-4007\nEasthampton Community Center\n 12 Clark St. Easthampton\n 1st Tues.\n 10:30 a.m. \u2013 12:30 p.m.\n (413)527-5240\nGranby Senior Center\n 10 West State St. Granby\n 3rd Tues.\n 10:30 a.m.\n (413)467-3239\nHadley Senior Community Center\n 46 Middle St. Hadley\n 3rd Thurs\n 10 \u2013 11 a.m.\n (413)586-4023\nHatfield Senior Center\n 59 Main St. Hatfield\n 1st Tues.\n 10 \u2013 11:30 a.m.\n (413)247-9003\nStanton Hall\n 26 Russell Rd. Huntington\n 3rd Fri\n 10 \u2013 11:30 a.m.\n (413)512-5125\nNorthampton Senior Center\n 67 Conz St. Northampton\n 2nd Thurs\n 10 \u2013 11 a.m.\n (413)587-1228\nSouth Hadley Council on Aging\n 45 Dayton St. South Hadley\n 3rd Tues\n 10 \u2013 11 a.m.\n (413)538-5042\nWare Senior Center\n 1 Robbins Rd. Ware\n 2nd Fri\n 11 a.m. \u2013 12 p.m.\n (413)967-9645\nWilliamsburg Senior Center\n 141 Main St. Haydenville\n 2nd Thurs\n 10 \u2013 11:30 a.m.\n (413)268-8407\n\nNotificationsOriginal textContribute a better translation\n\nWhen can we get food?", "Here is a second part of the same conversation. Please remember both parts, as I will ask you further questions about them: So I see it just so you know I see it in the pie chart but I don't see it in the leaderboard do I have to do like top 100% Is that what I need to do to get that?\n\nJennifer W 8:15 \nBottom n you choosing that? Yeah.\n\nUnknown Speaker 8:19 \nOkay. All right now I see it okay. Oh, we still have negative scores too, huh?\n\nJennifer W 8:27 \nYeah, we got to work out when Barbara sent that over to me last week.\n\nUnknown Speaker 8:31 \nAll right. So it feels like we still have a ways to go. How about the fleet utilization report and how close are we I haven't even looked at it. So how close do we think we are?\n\nJen D 8:46 \nWe had changes that we had to make last week. We I think we met when was that Wednesday that we came up with the list of for Barbara to work out so I haven't had a chance to review any of those changes. Yeah. So\n\nBarbara Gunion 9:02 \nI made a lot of them. And that's one of the emails I sent over last week.\n\nUnknown Speaker 9:06 \nYep. And then originally, I haven't looked at the schedule. Or\n\nJennifer W 9:14 \nyou froze for a moment che\n\nUnknown Speaker 9:15 \nOh, so I said I hadn't looked at the schedule for a while. But I was thinking that the original schedule from last meeting was these two should be kind of done the first week in February and then we were thinking performance and speeding we're going to be done. Like the 14th or something I thought are those even being developed or are we behind on\n\nJen D 9:37 \nthat with the changes that we started making for the fleet utilization?\n\nUnknown Speaker 9:42 \nOkay. Okay. So what's our what's our plan to to expand the ability to build these things out? Have we done have? Have you talked to grant at all about tapping into him and maybe having him starting to build stuff as well?\n\nJen D 10:06 \nI'm not really because we we really don't have any bandwidth on our side to do the things that we need. So even if we built out a bunch of reports, we don't have people to work on releasing the like we're trying to upskill them first. To congestion work on the scorecard.\n\nUnknown Speaker 10:26 \nWho's dumb? What do you mean the React folks? Right, but I mean, shouldn't we, I mean, once we start building these and we get the reaction to react part go pretty quickly. So\n\nJen D 10:38 \nit would if there were someone if they had time, it's just they haven't had any bandwidth to work on anything. So\n\nUnknown Speaker 10:44 \nno, I get I get that but isn't that independent? of building out the report such that let's say we have a queue of 15 reports. That puts us in a much different place than having a queue of two reports that are ready for React folks to go attack it\n\nJen D 10:59 \nright but until we until we have like, be it because basically Jennifer and I are the ones you waiting everything so then we go back and make changes. There's no other QA people involved at this point, because we don't have anyone that can build out the sort of front end piece. So we can't put it anywhere like gamma to have the QA folks to kind of review it. So it's kind of a I mean, it's kind of hard.\n\nUnknown Speaker 11:24 \nWhy can't we give them a sigma license and let them QA the board dashboard itself?\n\nJen D 11:30 \nWell, we certainly could. Again, we're we don't have enough licenses, but\n\nUnknown Speaker 11:38 \nWell, I mean, I just need I guess I need to know what the point how what we do to increase velocity, right. I mean,\n\nJen D 11:47 \nI mean, if we make this a priority, then obviously it will become more of a I mean, it's just\n\nUnknown Speaker 11:53 \nit's I understand what you're saying Jim, right. And but um, and I get to react piece of it, but that's still independent. I look at that the same as I look at the backend, right. So we've got a work stream of building out data we've got right.\n\nJen D 12:12 \nSo basically, I'm there trying to help with getting all the data for all the reports. We're building up that we're getting that over to them. I'm trying to you at it. I'm the one that's going in and creating the workspaces and the teams for all the Embed pieces. It's I mean, there's also that I am only one person and I can't do all of the things that's why\n\nUnknown Speaker 12:36 \ni That's why I'm suggesting we should bring grant into the mix, give some more.\n\nJen D 12:42 \nI mean, building out more reports when we don't even have like if we're adding things then so like there's new features that we're adding to like fleet utilization, we have to go to UX then they have to come and give us the designs and then we go back and make changes. So there's also getting, what are we expecting? Yes, we can just we can start churning through more reports quickly if we don't make any changes, but that's sort of, you know, figuring out what we want and then moving forward, also is the problem. Because if if we just keep with what we have, it will be easier to move, move things out, and we don't have to go through\n\nUnknown Speaker 13:22 \nwhat helped me understand the core problem and you're saying it's not the final I mean, there's lots of well Okay, then I'll tell you what, I like a list of them, by let's say Wednesday of what the core issues are, so we can then start addressing or seeing what we can to address that. Right if it's that you're single point, and we need more bandwidth and let's see what our options are. If it's the React, folks, let's talk about where it sits in priorities, or what we can do to move forward until they free up right now it looks like we lost wandering. So I'm sorry, Jen looks like you're back.\n\nJen D 14:09 \nAh, yes, I'm back. I'm gonna turn off my video so I don't lose you guys again.\n\nUnknown Speaker 14:14 \nSo so what I was gonna say is then then send me a list of what you think is holding up progress the most if it's that it's not properly defined. Up front, or that, you know, you're spread too thin, or if it's the React, folks, whatever.\n\nJen D 14:31 \nSo I can send you a list of what I think the problems are,\n\nUnknown Speaker 14:34 \nand what it's what the impact is, right? And then let's talk about so I'd like it by Wednesday, and then let's let's hop on a meeting or let's talk about how do we address those things? Because again, the spotlights on us right and so, you know, it keeps moving and again this is not going to be sustainable. Right.\n\nUnknown Speaker 15:02 \nMight might be a good time to points on that list. And that we can help with, you know, if QA has a long turnaround and maybe we can schedule, a guided session or something like that. I mean, the team may already be doing some of this, but you know, if there's opportunity for you to leverage us better or differently, it up some of those points. Maybe there's somebody in our team that can sit with the React folks and have more of a scheduled time to like Okay, let's get through whatever we need to get through. If that would accelerate them. You know, those kinds of things. I mean, I know our team is open to helping if there's ways that we can help that may not be kind of core core to what we're doing, which is building up the metrics. Yeah.\n\nJen D 15:47 \nOkay, yeah, I'll pull that together.\n\nBen 15:51 \nJennifer, I wanted to get your thoughts here to you and I've been talking, you know, for the last several weeks about just making sure that we're, you know, in in the same cadence together, and we're clear about when we're handing things over and delivering. I know that some of the UAE while some of the exercises of after things are delivered there's a lot of questions that could answer to our questions that get asked about, you know, maybe we should add something or we need to make some changes. I think we've been receptive to that. But I'd love to hear your feedback on how things have been going the last few weeks and the process we've been using and if there's anything you think we need to work on as well.\n\nJen D 16:37 \nYeah, I think I mean, I don't know if it's me or the other Gen, but I think yeah, I mean, we've had some changes over the last few weeks. And I think that whenever we submit the tickets and sort of get those, Barbara turns them around pretty quickly. So I think it's just really, maybe more upfront figuring out what it is we want to deliver and and saying here's our minimum viable product, or release. And then kind of, you know, go from there and then build out these other key pieces as we're adding them all and you know, like diagnostics or attributes or whatever. I think that would be okay.", "That was very good! How about this one:\n\nTurboTax 2020`-[ExperimentServiceController getLocalExperimentSettings]:\n-> 0x10a0977b0 <+0>: pushq %rbp\n 0x10a0977b1 <+1>: movq %rsp, %rbp\n 0x10a0977b4 <+4>: subq $0x40, %rsp\n 0x10a0977b8 <+8>: movq %rdi, -0x8(%rbp)\n 0x10a0977bc <+12>: movq %rsi, -0x10(%rbp)\n 0x10a0977c0 <+16>: movq $0x0, -0x18(%rbp)\n 0x10a0977c8 <+24>: movq -0x8(%rbp), %rax\n 0x10a0977cc <+28>: movq 0x1bf4b65(%rip), %rsi ; \"getExperimentSettingsFilePath\"\n 0x10a0977d3 <+35>: movq %rax, %rdi\n 0x10a0977d6 <+38>: callq \\*0x1a9c4a4(%rip) ; (void \\*)0x00007fff204dd800: objc\\_msgSend\n 0x10a0977dc <+44>: movq %rax, %rdi\n 0x10a0977df <+47>: callq 0x10b45e656 ; symbol stub for: objc\\_retainAutoreleasedReturnValue\n 0x10a0977e4 <+52>: movq %rax, -0x20(%rbp)\n 0x10a0977e8 <+56>: movq 0x1bf9ad1(%rip), %rax ; (void \\*)0x00007fff803aff48: NSFileManager\n 0x10a0977ef <+63>: movq 0x1beb142(%rip), %rsi ; \"defaultManager\"\n 0x10a0977f6 <+70>: movq %rax, %rdi\n 0x10a0977f9 <+73>: callq \\*0x1a9c481(%rip) ; (void \\*)0x00007fff204dd800: objc\\_msgSend\n 0x10a0977ff <+79>: movq %rax, %rdi\n 0x10a097802 <+82>: callq 0x10b45e656 ; symbol stub for: objc\\_retainAutoreleasedReturnValue\n 0x10a097807 <+87>: movq %rax, -0x28(%rbp)\n 0x10a09780b <+91>: movq -0x28(%rbp), %rax\n 0x10a09780f <+95>: movq -0x20(%rbp), %rdx\n 0x10a097813 <+99>: movq 0x1beb25e(%rip), %rsi ; \"fileExistsAtPath:\"\n 0x10a09781a <+106>: movq %rax, %rdi\n 0x10a09781d <+109>: callq \\*0x1a9c45d(%rip) ; (void \\*)0x00007fff204dd800: objc\\_msgSend\n 0x10a097823 <+115>: cmpb $0x0, %al\n 0x10a097825 <+117>: je 0x10a09789e ; <+238>\n 0x10a09782b <+123>: movq -0x28(%rbp), %rax\n 0x10a09782f <+127>: movq -0x20(%rbp), %rdx\n 0x10a097833 <+131>: movq 0x1bec3b6(%rip), %rsi ; \"contentsAtPath:\"\n 0x10a09783a <+138>: movq %rax, %rdi\n 0x10a09783d <+141>: callq \\*0x1a9c43d(%rip) ; (void \\*)0x00007fff204dd800: objc\\_msgSend\n 0x10a097843 <+147>: movq %rax, %rdi\n 0x10a097846 <+150>: callq 0x10b45e656 ; symbol stub for: objc\\_retainAutoreleasedReturnValue\n 0x10a09784b <+155>: movq %rax, -0x30(%rbp)\n 0x10a09784f <+159>: cmpq $0x0, -0x30(%rbp)\n 0x10a097854 <+164>: je 0x10a09788e ; <+222>\n 0x10a09785a <+170>: movq 0x1bfa867(%rip), %rax ; (void \\*)0x000000010bc9f538: ExperimentSettings\n 0x10a097861 <+177>: movq %rax, %rdi\n 0x10a097864 <+180>: callq 0x10b45e5c0 ; symbol stub for: objc\\_alloc\n 0x10a097869 <+185>: movq -0x30(%rbp), %rdx\n 0x10a09786d <+189>: movq 0x1bf4adc(%rip), %rsi ; \"initWithJson:\"\n 0x10a097874 <+196>: movq %rax, %rdi\n 0x10a097877 <+199>: callq \\*0x1a9c403(%rip) ; (void \\*)0x00007fff204dd800: objc\\_msgSend\n 0x10a09787d <+205>: movq -0x18(%rbp), %rcx\n 0x10a097881 <+209>: movq %rax, -0x18(%rbp)\n 0x10a097885 <+213>: movq %rcx, %rdi\n 0x10a097888 <+216>: callq \\*0x1a9c41a(%rip) ; (void \\*)0x00007fff204df490: objc\\_release\n 0x10a09788e <+222>: xorl %eax, %eax\n 0x10a097890 <+224>: movl %eax, %esi\n 0x10a097892 <+226>: leaq -0x30(%rbp), %rcx\n 0x10a097896 <+230>: movq %rcx, %rdi\n 0x10a097899 <+233>: callq 0x10b45e686 ; symbol stub for: objc\\_storeStrong\n 0x10a09789e <+238>: movq -0x18(%rbp), %rdi\n 0x10a0978a2 <+242>: movq 0x1a9c407(%rip), %rax ; (void \\*)0x00007fff204dd690: objc\\_retain\n 0x10a0978a9 <+249>: callq \\*%rax\n 0x10a0978ab <+251>: xorl %ecx, %ecx\n 0x10a0978ad <+253>: movl %ecx, %edx\n 0x10a0978af <+255>: leaq -0x28(%rbp), %rdi\n 0x10a0978b3 <+259>: movq %rdx, %rsi\n 0x10a0978b6 <+262>: movq %rax, -0x38(%rbp)\n 0x10a0978ba <+266>: movq %rdx, -0x40(%rbp)\n 0x10a0978be <+270>: callq 0x10b45e686 ; symbol stub for: objc\\_storeStrong\n 0x10a0978c3 <+275>: leaq -0x20(%rbp), %rdi\n 0x10a0978c7 <+279>: movq -0x40(%rbp), %rsi\n 0x10a0978cb <+283>: callq 0x10b45e686 ; symbol stub for: objc\\_storeStrong\n 0x10a0978d0 <+288>: leaq -0x18(%rbp), %rdi\n 0x10a0978d4 <+292>: movq -0x40(%rbp), %rsi\n 0x10a0978d8 <+296>: callq 0x10b45e686 ; symbol stub for: objc\\_storeStrong\n 0x10a0978dd <+301>: movq -0x38(%rbp), %rax\n 0x10a0978e1 <+305>: movq %rax, %rdi\n 0x10a0978e4 <+308>: addq $0x40, %rsp\n 0x10a0978e8 <+312>: popq %rbp\n 0x10a0978e9 <+313>: jmp 0x10b45e5de ; symbol stub for: objc\\_autoreleaseReturnValue\n 0x10a0978ee <+318>: nop", "Summarize the following into 15 bullet points:\nmade up of respected experts from major\nEuropean countries, which produced a\nreport in hardly more than a month. These\nagencies are to be commended for the\nspeed and openness with which they handled the disaster. The report is available\non the Web, in both French and English\n(http://www.cnes.fr/actualites/news/rapport\\_501.html).\nIt is a remarkable document: short, clear,\nand forceful. The explosion, the report\nsays, is the result of a software error, possibly the costliest in history (at least in dollar terms, since earlier cases have cost lives).\nParticularly vexing is the realization that\nthe error came from a piece of the software\nthat was not needed. The software\ninvolved is part of the Inertial Reference\nSystem, for which we will keep the\nacronym SRI used in the report, if only to\navoid the unpleasant connotation that the\nreverse acronym has for US readers. Before\nliftoff, certain computations are performed\nto align the SRI. Normally, these computations should cease at \u22129 seconds, but\nbecause there is a chance that a countdown\ncould be put on hold, the engineers gave\nthemselves some leeway. They reasoned\nthat, because resetting the SRI could take\nJanuary 1997 129\nS\neveral contributions to this\ndepartment have emphasized the\nimportance of design by contract\nin the construction of reliable\nsoftware. Design by contract, as\nyou will recall, is the principle that interfaces between modules of a software system\u2014 especially a mission-critical one\u2014\nshould be governed by precise specifications, similar to contracts between\nhumans or companies. The contracts will\ncover mutual obligations (preconditions), benefits (postconditions), and consistency constraints (invariants). Together\nthese properties are known as assertions,\nand are directly supported in some design\nand programming languages.\nA recent $500 million software error\nprovides a sobering reminder that this\nprinciple is not just a pleasant academic\nideal. On June 4, 1996, the maiden flight of\nthe European Ariane 5 launcher crashed,\nabout 40 seconds after takeoff. Media\nreports indicated that a half-billion dollars\nwas lost\u2014the rocket was uninsured.\nThe French space agency, CNES (Centre\nNational d\u2019Etudes Spatiales), and the\nEuropean Space Agency immediately\nappointed an international inquiry board,\nDesign by\nContract:\nThe Lessons\nof Ariane\nJean-Marc J\u00e9z\u00e9quel, IRISA/CNRS\nBertrand Meyer, EiffelSoft\nObject Technology\nEditor: Bertrand Meyer, EiffelSoft, 270 Storke Rd., Ste. 7, Goleta, CA 93117; voice (805) 685-6869; ot-column@eiffel.com\nseveral hours (at least in earlier versions of\nAriane), it was better to let the computation proceed than to stop it and then have\nto restart it if liftoff was delayed. So the SRI\ncomputation continues for 50 seconds after\nthe start of flight mode\u2014well into the flight\nperiod. After takeoff, of course, this computation is useless. In the Ariane 5 flight,\nhowever, it caused an exception, which was\nnot caught and\u2014boom.\nThe exception was due to a floatingpoint error during a conversion from a 64-\nbit floating-point value, representing the\nflight\u2019s \u201chorizontal bias,\u201d to a 16-bit\nsigned integer: In other words, the value\nthat was converted was greater than what\ncan be represented as a 16-bit signed integer. There was no explicit exception handler to catch the exception, so it followed\nthe usual fate of uncaught exceptions and\ncrashed the entire software, hence the\nonboard computers, hence the mission.\nThis is the kind of trivial error that we\nare all familiar with (raise your hand if you\nhave never done anything of this sort),\nalthough fortunately the consequences are\nusually less expensive. How in the world\ncan it have remained undetected and produced such a horrendous outcome?\nYOU CAN\u2019T BLAME MANAGEMENT\nAlthough something clearly went wrong\nin the validation and verification process\n(or we wouldn\u2019t have a story to tell), and\nalthough the Inquiry Board does make several recommendations to improve the\nprocess, it is also clear that systematic documentation, validation, and management\nprocedures were in place.\nThe software engineering literature has\noften contended that most software problems are primarily management problems.\nThis is not the case here: the problem was\na technical one. (Of course you can always\nargue that good management will spot\ntechnical problems early enough.)\nHow in the world could\nsuch a trivial error\nhave remained\nundetected and cause\na $500 million rocket\nto blow up?\n.\n130 Computer\nYOU CAN\u2019T BLAME THE LANGUAGE\nAda\u2019s exception mechanism has been\ncriticized in the literature, but in this case\nit could have been used to catch the exception. In fact, the report says:\nNot all the conversions were protected\nbecause a maximum workload target of\n80% had been set for the SRI computer.\nTo determine the vulnerability of unprotected code, an analysis was performed on\nevery operation which could give rise to\nan ... operand error. This led to protection\nbeing added to four of [seven] variables ...\nin the Ada code. However, three of the\nvariables were left unprotected.\nYOU CAN\u2019T BLAME THE DESIGN\nWhy was the exception not monitored?\nThe analysis revealed that overflow (a horizontal bias not fitting in a 16-bit integer)\ncould not occur. Was the analysis wrong?\nNo! It was right for the Ariane 4 trajectory. For Ariane 5, with other trajectory\nparameters, it did not hold.\nYOU CAN\u2019T BLAME THE\nIMPLEMENTATION\nSome may criticize removing the conversion protection to achieve more performance (the 80 percent workload target),\nbut this decision was justified by the theoretical analysis. To engineer is to make\ncompromises. If you have proved that a\ncondition cannot happen, you are entitled\nnot to check for it. If every program checked\nfor all possible and impossible events, no\nuseful instruction would ever get executed!\nYOU CAN\u2019T BLAME TESTING\nThe Inquiry Board recommends better\ntesting procedures, and it also recommends\ntesting the entire system rather than parts of\nit (in the Ariane 5 case the SRI and the flight\nsoftware were tested separately). But even if\nyou can test more, you can never test all.\nTesting, as we all know, can show the presence of errors, not their absence. The only\nfully realistic test is a launch. And in fact, the\nlaunch was a test launch, in that it carried no\ncommercial payload, although it was probably not intended to be a $500 million test.\nYOU CAN TRY TO BLAME REUSE\nThe SRI horizontal bias module was\nindeed reused from 10-year-old software,\nthe software from Ariane 4. But this is not\nthe real story.\nBUT YOU REALLY HAVE TO BLAME\nREUSE SPECIFICATION\nWhat was truly unacceptable in this case\nwas the absence of any kind of precise\nspecification associated with this reusable\nmodule. The requirement that the horizontal bias should fit on 16 bits was in fact\nstated in an obscure part of a mission document. But it was nowhere to be found in\nthe code itself!\nOne of the principles of design by contract, as earlier columns have said, is that\nany software element that has such a fundamental constraint should state it explicitly, as part of a mechanism present in the\nlanguage. In an Eiffel version, for example, it would be stated as\nconvert (horizontal\\_bias:\nDOUBLE): INTEGER is\nrequire\nhorizontal\\_bias\n<= Maximum\\_bias\ndo\n...\nensure\n...\nend\nwhere the precondition (require...)\nstates clearly and precisely what the input\nmust satisfy to be acceptable.\nDoes this mean that the crash would\nautomatically have been avoided had the\nmission used a language and method supporting built-in assertions and design by\ncontract? Although it is always risky to\ndraw such after-the-fact conclusions, the\nanswer is probably yes:\n\u2022 Assertions (preconditions and postconditions in particular) can be automatically turned on during testing,\nthrough a simple compiler option. The\nerror might have been caught then.\n\u2022 Assertions can remain turned on during execution, triggering an exception\nif violated. Given the performance\nconstraints on such a mission, however, this would probably not have\nbeen the case.\n\u2022 Most important, assertions are a\nprime component of the software\nand its automatically produced documentation (\u201cshort form\u201d in Eiffel\nenvironments). In a project such as\nAriane, in which there is so much\nemphasis on quality control and\nthorough validation of everything,\nassertions would have been the quality assurance team\u2019s primary focus of\nattention. Any test team worth its\nsalt would have checked systematically that every call satisfies every\nprecondition. That would have immediately revealed that the Ariane 5\nsoftware did not meet the expectation of the Ariane 4 routines that it\ncalled.\nT\nhe Inquiry Board makes several recommendations with respect to software process improvement. Many\nare justified; some may be overkill; some\nwould be very expensive to put in place.\nThere is a more simple lesson to be\nlearned from this unfortunate event:\nReuse without a precise, rigorous specification mechanism is a risk of potentially\ndisastrous proportions.\nIt is regrettable that this lesson has not\nbeen heeded by such recent designs as IDL\n(the Interface Definition Language of\nCORBA)\u2014which is intended to foster\nlarge-scale reuse across networks but fails\nto provide any semantic specification\nmechanism\u2014Ada 95, or Java. None of\nthese languages has built-in support for\ndesign by contract.\nEffective reuse requires design by contract. Without a precise specification\nattached to each reusable component\u2014\nprecondition, postcondition, invariant\u2014\nno one can trust a supposedly reusable\ncomponent. Without a specification, it is\nprobably safer to redo than to reuse. \u2756\nThere is a simple lesson\nhere: Reuse without\na precise specification\nmechanism is a\ndisastrous risk.\n.", "Summarize the following into 16 bullet points:\nThe Bug That Destroyed a Rocket\nMordechai Ben-Ari\nDepartment of Science Teaching\nWeizmann Institute of Science\nRehovot 76100 Israel\n\nReprinted with permission from Journal of Computer Science Education, vol. 13 no. 2, pp. 15-16. Copyright\n(c) 1999, ISTE (International Society for Technology in Education), 800.336.5191 (U.S. & Canada) or\n541.302.3777 (Int'l), iste@iste.org, www.iste.org. All rights reserved.\nAuthor's Note\nIn the 2000 December issue of inroads, Michael Williams suggested that the failure of the Ariane 5 rocket launch\ncould be used as a case study in teaching programming concepts. Here is an article I wrote several years ago in which\nI present the story of the Ariane 5 in terms used to teach introductory computer science.\nThe morning of the 4th of June 1996 was partially cloudy\nat Kourou in Guyana as the European Space Agency (ESA)\nprepared for the first launch of the French-built Ariane 5\nrocket. The rocket lifted off at 09:34. Just 37 seconds later,\nthe rocket veered on its side and began to break up. The\nrange safety mechanism identified the impending catastrophe and initiated explosive charges that blew up the rocket\nto prevent further damages and possible casualties. An\ninvestigation by the ESA determined that the accident was\ncaused by a software 'bug. This is the story of that bug.\nWhy should this interest you?\nStudents and other users of personal computers have\nbecome extremely tolerant of software failures. You simply\nutter an unprintable expletive and press ctrl-alt-clel.\nThe failure of the Ariane launch cost hundreds of millions\nof dollars and delayed the ESA space program by a year, to\nsay nothing of the well-publicized embarrassment! What is\ninteresting about the case of the Ariane is that ultimately\nthe bug was not caused by a mistake alone, but by a\nsequences of failures in the development process. A more\ndisciplined use of methods that we call software engineering should have caught the mistake; in this case, several\nshortcuts were taken that were not justified.\nIn our high-school course Foundations of Computer\nScience, we attempt to instill in the students the principles\nof a formal development process: requirements specification, design before code and thoughtful testing of the program. Many students rebel at these tasks, because they do\nseem onerous in the context of a program to compute the\naverage of a sequence of numbers! As I tell the sto W of the\nAriane bug, I will relate each step to the development\nprocess that we teach the students. Hopefully, students can\nlearn to appreciate that we are not teaching these principles\nout of the wickedness of our hearts.\nSorry - a bit of physics\nA short description of the physics involved will make the\nexplanation of the bug more intelligible. Students whose\nhealth would be damaged by reading physics can skip this\nsection.\nNewton s third law explains how a rocket is launched.\nThe backwards force of the jet stream from the nozzle is\nbalanced by a forward force on the body of the rocket.\nHowever, the rocket, which is just a long narrow tube, is\nvery unstable. The rocket must be steered by changing the\nangle of the nozzle, because at low speeds the fins are not\neffective.\nThe accuracy requirements are so great that you can t control a rocket with a joystick; instead a computer must be\nused to make corrections dozens of times a second. The\nquestion is: How can the computer know where the rocket\nis so that it can tell it where to go? Does it look out the\nwindow?\nThe answer is that the rocket uses an inertial navigation system (INS). Behind this formidable name lies a simple idea which was used by sailors long before modern\nnavigational equipment was developed. The idea is simply\nthis: Measure your speed at short fixed intervals and compute the distance travelled by multiplying the speed by the\nduration of the interval. Suppose, for example, that you\nneed to sail 50 krn. and then turn right, and suppose that\nyou measure your speed every five minutes for 25 minutes,\nresulting in readings of 12, 11, 9, 12 and 10 km/hour. Then\nyou have gone (12+11+9+12+10)\\*(5/60)=54/12=4.5 km.\nand you still have a long way to go before turning.\nSIGCSE Bulletin ~@~S 58 June 2001 Vol 33. No. 2\nA real INS is quite complex because it has to consider\nthree dimensions of translation which are computed using linear accelerations, and three dimensions of rotation which are\ncomputed using angular velocities. Once the calculations\nhave been performed, the position is passed to the main computer of the rocket which computes the steering commands\nfor the nozzle that will bring the rocket back on course.\nComputer Navigation and Angular\nSystem Velocities\nSo what happened?\nThe sequence of events that led to the destruction of the\nAriane 5 was as follows:\n1. The INS attempted to convert a 64-bit number to a 16-\nbit number without checking that 16 bits was sufficient\nto hold the value. This caused a runtime error.\n2. The runtime error caused the INS software to stop execution.\n3. There was a backup computer executing the INS software, but (of course) it too encountered the same problem and terminated.\n4. The INS hardware (of both computers) sent a report of\nthe error to the main computer.\n5. The main computer erroneously interpreted the report\nas extreme, but legal, data, and commanded the nozzle\nto fully deflect to one side.\n6. The rocket turned at a sharp angle and was subjected\nto forces that it was not designed to withstand. It began\nto break up and was destroyed.\nIt s a sad story, isn t it?\nWhy did it happen?\n\"Hell is paved with good intentions. [Samuel Johnson] In\nthis section, boldface indicates concepts that we teach our\nstudents.\nWe tell our students to carefully document programs\nso that they can be re-used. The designers of the Ariane 5\ndecided to re-use the INS of the Ariane 4. But even re-use\nrequires careful thought and verification. From this initial\ndecision, the drama unfolds as inevitably as in a Greek\ntragedy:\n1. The bug was in a calibration computation that ran both\nbefore the launch and during the initial stages of the\nlaunch. However, in the Ariane 5, there was no longer\nany reason to run the computation during the launch.\nThe algorithmic problem had changed, but the software was not modified accordingly.\n2. The trajectory of the Ariane 5 differed from that of the\nAriane 4 (it involved larger horizontal velocities). That\nis, the input specification in the requirements of the\ncomputation changed, but again, the computation was\nnot modified.\n3. The conversion of the 64-bit number to a 16-bit number\nis, in effect, a call to a function. When you call a function, you must ensure that the precondition holds. One\nway to check a precondition is with an i f-statement\nAlternatively, you can justify the precondition; for\nexample, you can assume that the value of x2+y z is nonnegative and call the square root function without further ado. To improve efficiency of the program, several checks were omitted on physical grounds, but the justifications were not validated upon re-use.\n4. Terminating the execution of a program upon detection\nof an error is not an acceptable form of error handling\nin a computer system. The designers of the Ariane\nwrongly assumed that an error would only be caused by\na malfunction of the hardware. If this were true, terminating one computer so that the backup computer could\ntake over would have been a reasonable decision.\nModem programming languages such as Ada, C++,\nEiffel and Java include exception handling for this purpose, but students who program in Pascal or C have no\nequivalent mechanism so this aspect of software is not\nemphasized in our course.\n5. Under the assumption that the INS had been validated\nfor the Ariane 4, no further validation was performed for\nthe Ariane 5. In retrospect, even a single test with a representative input would have uncovered the problem.\n6. The misunderstood message in the communications\nbetween the two computers a failure to match the output specification of one program to the input specification of another.\n7. Finally, why was the bug not caught during testing? The\nreason is that you cannot debug the system by inserting\nbreakpoints while the rocket is being launched! There\nare techniques for validating and testing 'disposable\nsottware that is run once and then discarded, but they\nare time-consuming and expensive, and were not carried\nout. We teach our students to check algorithms and\nprograms using pencil-and-paper techniques before trying them out on the computer.\nWhat can we learn from the Ariane 5 failure?\nThe work of software engineers is radically different from\nthe type of work done by a student programmer. They\nspend more time specifying, designing and testing than\nthey do 'writing code. Above all, they have to formally\ncommunicate with other software engineers and with specialists in other disciplines, such as finance, medicine and\nengineering. Students should be encouraged to practice\nsoftware development skills as early as possible. I hope that\nthe story of the Ariane 5 will help motivate them to do so.\nSource\nThe ESA is to be commended for publishing the results of its\ninvestigation on the interact!\nhttp://www.esrin.esa.it/htdocs/tidc/Press/Pres s96/ariane 5 rep.html\nVol 33. No. 2 June 2001 59 d~ SIGCSE Bulletin", "I noticed two of my expeirence descriptions are shorter than the rest. Could you rewrite the description for time kaine and rosa delauro?\nExperience\n\nMiddle Seat logo\nMiddle Seat DigitalMiddle Seat Digital\nFull-time \u00b7 3 yrsFull-time \u00b7 3 yrs\nSenior Digital Advertising StrategistSenior Digital Advertising Strategist\nSep 2021 - Present \u00b7 1 yr 7 mosSep 2021 - Present \u00b7 1 yr 7 mos\nIn my role as Senior Digital Advertising Strategist, I lead data-driven advertising campaigns for progressive candidates, causes, and organizations. I develop and execute integrated, audience-first marketing strategies that blend traditional silos of Digital, TV, and Radio, ensuring clients achieve their goals through innovative and results-driven methods. I also oversee the development and rollout of agency-wide advertising attribution and reporting tools.In my role as Senior Digital Advertising Strategist, I lead data-driven advertising campaigns for progressive candidates, causes, and organizations. I develop and execute integrated, audience-first marketing strategies that blend traditional silos of Digital, TV, and Radio, ensuring clients achieve their goals through innovative and results-driven methods. I also oversee the development and rollout of agency-wide advertising attribution and reporting tools.\nSkills: SQL \u00b7 Direct Response Advertising \u00b7 Online Fundraising and List Building \u00b7 Digital Persuasion and Mobilization \u00b7 Data Analysis and VisualizationSkills: SQL \u00b7 Direct Response Advertising \u00b7 Online Fundraising and List Building \u00b7 Digital Persuasion and Mobilization \u00b7 Data Analysis and Visualization\nDigital Advertising StrategistDigital Advertising Strategist\nApr 2020 - Sep 2021 \u00b7 1 yr 6 mosApr 2020 - Sep 2021 \u00b7 1 yr 6 mos\nWashington, District of Columbia, United StatesWashington, District of Columbia, United States\nAs a Digital Advertising Strategist, I collaborated with clients to create and optimize digital advertising campaigns for progressive causes and candidates. I leveraged the power of data and creative storytelling to deliver measurable results while continuously refining strategies to maximize ROI. My responsibilities included audience segmentation, targeting, creative development, budget management, and performance analysis.As a Digital Advertising Strategist, I collaborated with clients to create and optimize digital advertising campaigns for progressive causes and candidates. I leveraged the power of data and creative storytelling to deliver measurable results while continuously refining strategies to maximize ROI. My responsibilities included audience segmentation, targeting, creative development, budget management, and performance analysis.\nSkills: Paid Social Media Advertising \u00b7 Search Engine Marketing (SEM) \u00b7 Email List Growth \u00b7 CopywritingSkills: Paid Social Media Advertising \u00b7 Search Engine Marketing (SEM) \u00b7 Email List Growth \u00b7 Copywriting\nBlueprint Interactive logo\nDigital Campaigns AssociateDigital Campaigns Associate\nBlueprint InteractiveBlueprint Interactive\nFeb 2018 - Apr 2020 \u00b7 2 yrs 3 mosFeb 2018 - Apr 2020 \u00b7 2 yrs 3 mos\nWashington D.C. Metro AreaWashington D.C. Metro Area\nIn my role as Digital Campaigns Associate, I worked to create, optimize, and report on digital advertising campaigns for political candidates, PACs, and organizations. I assisted in campaign strategy development, creative production, ad placement, and performance analysis. My contributions helped ensure that our clients' campaigns were data-driven, effective, and met their specific goals.In my role as Digital Campaigns Associate, I worked to create, optimize, and report on digital advertising campaigns for political candidates, PACs, and organizations. I assisted in campaign strategy development, creative production, ad placement, and performance analysis. My contributions helped ensure that our clients' campaigns were data-driven, effective, and met their specific goals.\nSkills: Facebook Ads \u00b7 Programmatic Ads \u00b7 Google Ads \u00b7 Email Coding \u00b7 Twitter AdsSkills: Facebook Ads \u00b7 Programmatic Ads \u00b7 Google Ads \u00b7 Email Coding \u00b7 Twitter Ads\nU.S. House of Representatives logo\nDigital InternDigital Intern\nU.S. House of RepresentativesU.S. House of Representatives\nNov 2017 - Jan 2018 \u00b7 3 mosNov 2017 - Jan 2018 \u00b7 3 mos\nWashington, D.C.Washington, D.C.\nI assisted the Committee on Oversight and Government Affairs' digital communications efforts. I brought my aptitude in digital design, photography, and website management to bear on ongoing projects, including website CMS management, hearing documentation, and content creation.I assisted the Committee on Oversight and Government Affairs' digital communications efforts. I brought my aptitude in digital design, photography, and website management to bear on ongoing projects, including website CMS management, hearing documentation, and content creation.\nSkills: Content Management Systems (CMS) \u00b7 DrupalSkills: Content Management Systems (CMS) \u00b7 Drupal\nOrganizing FellowOrganizing Fellow\nDavid Reid for DelegateDavid Reid for Delegate\nSep 2017 - Nov 2017 \u00b7 3 mosSep 2017 - Nov 2017 \u00b7 3 mos\nAided the field operation in the 32 District of Virginia for the successful election of Delegate-Elect David Reid and Ralph Northam. I managed direct voter contact for several precincts, recruited and trained volunteers, and collaborated with progressive community organizations to maximize voter turnout.Aided the field operation in the 32 District of Virginia for the successful election of Delegate-Elect David Reid and Ralph Northam. I managed direct voter contact for several precincts, recruited and trained volunteers, and collaborated with progressive community organizations to maximize voter turnout.\nSkills: Political Organizing \u00b7 Local Campaign \u00b7 Volunteer Recruitment \u00b7 GOTVSkills: Political Organizing \u00b7 Local Campaign \u00b7 Volunteer Recruitment \u00b7 GOTV\nU.S. House of Representatives logo\nDigital InternDigital Intern\nU.S. House of RepresentativesU.S. House of Representatives\nFeb 2017 - May 2017 \u00b7 4 mosFeb 2017 - May 2017 \u00b7 4 mos\nWashington D.C. Metro AreaWashington D.C. Metro Area\nOffice of Democratic Whip Steny Hoyer\nHelped stand up a new media lab focused on video production and live streaming for Congressman Hoyer and other members. I also worked in close collaboration with Mr. Hoyer\u2019s press team, drafting press releases for the Maryland Press Secretary and adapting other materials for social media.Office of Democratic Whip Steny Hoyer Helped stand up a new media lab focused on video production and live streaming for Congressman Hoyer and other members. I also worked in close collaboration with Mr. Hoyer\u2019s press team, drafting press releases for the Maryland Press Secretary and adapting other materials for social media.\nSkills: Video Editing \u00b7 Political communicationSkills: Video Editing \u00b7 Political communication\nU.S. House of Representatives logo\nCongressional InternCongressional Intern\nU.S. House of RepresentativesU.S. House of Representatives\nJun 2016 - Aug 2016 \u00b7 3 mosJun 2016 - Aug 2016 \u00b7 3 mos\nWashington D.C. Metro AreaWashington D.C. Metro Area\nCongresswoman Rosa DeLauro\nConducted legislative research and analysis, handled constituent correspondence, assisted with\nadministrative tasks, and attended Congressional briefings and wrote summary memos.Congresswoman Rosa DeLauro Conducted legislative research and analysis, handled constituent correspondence, assisted with administrative tasks, and attended Congressional briefings and wrote summary memos.\nSkills: Constituent ServicesSkills: Constituent Services\nUnited States Senate logo\nInternIntern\nUnited States SenateUnited States Senate\nJul 2015 - Aug 2015 \u00b7 2 mosJul 2015 - Aug 2015 \u00b7 2 mos\nRoanoke, VARoanoke, VA\nStaffed Senator Kaine\u2019s regional travel in rural Virginia focusing on economic development,\nhandled constituent casework and correspondence, and helped host town halls.Staffed Senator Kaine\u2019s regional travel in rural Virginia focusing on economic development, handled constituent casework and correspondence, and helped host town halls.\nU.S. Fish and Wildlife Service (USFWS) logo\nInternIntern\nU.S. Fish and Wildlife Service (USFWS)U.S. Fish and Wildlife Service (USFWS)\nJun 2013 - Jul 2013 \u00b7 2 mosJun 2013 - Jul 2013 \u00b7 2 mos\nArlington, VAArlington, VA\nDuring my short time as an intern at the U.S. Fish and Wildlife Service, I gained invaluable experience in teamwork, research, and understanding the complexity of natural ecosystems. As I ventured into the digital advertising landscape, these experiences helped shape my passion for progressive causes and fostering a better world for future generations.During my short time as an intern at the U.S. Fish and Wildlife Service, I gained invaluable experience in teamwork, research, and understanding the complexity of natural ecosystems. As I ventured into the digital advertising landscape, these experiences helped shape my passion for progressive causes and fostering a better world for future generations.\nBaristaBarista\nBeanetics Coffee RoastersBeanetics Coffee Roasters\n2010 - 2012 \u00b7 2 yrs2010 - 2012 \u00b7 2 yrs\nAnnandale, VAAnnandale, VA\nBefore diving into the world of digital advertising and politics, I honed my skills as a barista at Beanetics Coffee Roasters. Here, I learned the fine art of crafting the perfect espresso drink, steaming milk to velvety perfection, and turning caffeine cravings into satisfied smiles. It's where I first discovered the importance of excellent customer service, attention to detail, and teamwork. And yes, I can still make a mean cappuccino.Before diving into the world of digital advertising and politics, I honed my skills as a barista at Beanetics Coffee Roasters. Here, I learned the fine art of crafting the perfect espresso drink, steaming milk to velvety perfection, and turning caffeine cravings into satisfied smiles. It's where I first discovered the importance of excellent customer service, attention to detail, and teamwork. And yes, I can still make a mean cappuccino.\nSkills: Customer Service", "Please summarize this: A Glance into the History of the 8 Jungian Functions\nCarl Jung, the famous Swiss psychiatrist, proposed his model of the eight (8) functions in his work, Psychological Types (1921). He divided the functions into two groups, extraverted (tethered in the external world) and introverted (unfolded in the inner world).\n\nJung\u2019s work would later be built upon by Isabel Briggs Myers and her mother Katharine Cook Briggs, who created a personality model we know today as the Myers-Briggs Type Indicator (MBTI\u00ae). The Myers-Briggs approach used scales for Extraversion-Introversion, Sensing-Intuition and Thinking-Feeling based on Jung\u2019s work and then added a fourth dimension of their own, Judging-Perceiving. The result is 4 different scales on which a person will be assigned one of two possible values. Thus there are 16 combinations (2 x 2 x 2 x 2 = 16).\n\nEach of the 16 personality types have four cognitive functions in alternating directions (i.e. introverted then extraverted, or vice versa), which can be thought of as four \u201cpuzzle pieces\u201d in a particular type. External factors such as upbringing and stress can alter the way each function manifests.\n\nThe four (4) personality scales as proposed by Briggs and Myers:\nExtraversion (E) \u2013 Introversion (I) \u2192 Gaining energy by interacting with other people or alone\nSensing (S) \u2013 Intuition (I) \u2192 Collecting information through the senses or imagination\nThinking (T) \u2013 Feeling (F) \u2192 Making decisions through logic or emotions\nJudging (J) \u2013 Perceiving (P) \u2192 Organizing time by using schedules or without them; result- or process-oriented\nAs mentioned, the first three above are based on Jung\u2019s work with the fourth added by Myers-Briggs. According to Jung, the \u201ccognitive functions\u201d are the two scales of Sensing-Intuition and Thinking-Feeling. These are the ways in which humans process information and think about the world. Then each function can be expressed both in an extraverted manner or an introverted manner. As such, Jung didn\u2019t really view people as \u201cextraverts\u201d and \u201cintroverts\u201d but rather was more focused on the extraverted or introverted expression of each of the four cognitive functions.\n\nJungian four (4) cognitive functions stack:\nJung\u2019s cognitive function \u201cstack\u201d describes the priority or order in which a person uses their cognitive functions, with Primary being the most natural and commonly used and the Inferior being the least-commonly used.\n\nPrimary \u2192 Most natural (and comfortable) function; the internal \u201cmother tongue\u201d\nAuxiliary \u2192 Supporting function, usually connected with creation and job choice\nTertiary \u2192 Function where individual often takes action steps to improve upon\nInferior \u2192 Activates under extreme stress, generally avoided out of self-protection\nDescriptions of the Eight (8) Cognitive Functions\nNow let\u2019s discuss the eight different cognitive functions originally outlined by Jung. His theory proposed that for each of the 4 functions (Sensing, Intuition, Thinking and Feeling) each person would generally either extravert (display outwardly or externally) or introvert (consider inwardly or internally) that function.\n\nAs you read below, consider each function and its expression. Are you more Se or Si? Does Te or Ti come more naturally for you?\n\nExtraverted Sensing (Se)\nTaking action, using all five senses, going forward. Se takes in the present moment in its entirety, and makes rapid decisions on the fly. During times of crisis and emergencies, individuals with primary or auxiliary Se can make the best out of the situation.\n\nExample career areas that emphasize extraverted sensing (Se):\n\nArchaeology\nStunt driving\nFirefighting\nEmergency patrol\nMassage therapy\nIntroverted Sensing (Si)\nAssociations, metaphors, nostalgia. Si can travel back to any point in time through a single scent or sound. Important information (and sometimes interesting trivia) is stored in filing cabinets, where it can be retrieved at any later time.\n\nExample career areas that emphasize introverted sensing (Si):\n\nMuseum curation\nInterior design\nQuantitative sciences (e.g. statistics)\nLibrary sciences\nMedical coding\nExtraverted Intuition (Ne)\nBrainstorming, thinking outside the box, idea generation. Ne easily hops from idea to idea, while making abstract connections. Many artists\u2014especially poets\u2014use significant Ne in their work. To the outside, Ne seems quick, random, and extremely \u201cjumpy.\u201d\n\nExample career areas that emphasize extraverted intuition (Ne):\n\nFilmmaking, concept art\nCopywriting, art direction\nEntrepreneurship\nVideo producer (e.g. Youtube)\nWorkshop facilitating\nIntroverted Intuition (Ni)\nTime-space awareness, predicting the future, hunches. Ni is a far-reaching, visionary function\u2014and can picture the future, sometimes with scary-accurate results.\n\nExample career areas that emphasize introverted intuition (Ni):\n\nDetective services, private investigation\nEconomic predictions and analysis\nForensic and engineering psychology\nPublic speaking, mentoring\nConsulting, all types\nExtraverted Feeling (Fe)\nExpressive emotions, social norms, etiquette. Fe respects the consensus of the group, and puts harmony above personal desires. The function often acts as a mediator between groups, as it naturally puts others\u2019 needs above its own.\n\nExample career areas that emphasize extraverted feeling (Fe):\n\nActing, performance arts\nSinging\nDance therapy\nTelevision hosting\nPublic relations (PR)\nIntroverted Feeling (Fi)\nValues, notions of \u201cright\u201d and \u201cwrong,\u201d likes and dislikes. Fi is a deeply personal and intense function that digs to the core of the human condition. Convictions, morals, and strong beliefs all fall under the Fi umbrella.\n\nExample career areas that emphasize introverted feeling (Fi):\n\nPoetry, creative writing\nArt, various forms\nNarrative design\nMental health counseling\nPeace studies\nExtraverted Thinking (Te)\nFacts, pros and cons, methodological step-by-step strategies. Te respects rules and regulations\u2014and takes great pride in a job well done. Checklists and clear-cut meeting agendas get Te\u2019s gears going\u2014a top-down approach floats its boat.\n\nExample career areas that emphasize extraverted thinking (Te):\n\nAccounting\nPublic and private law\nComputer programming\nNatural sciences, laboratory support\nComputational mathematics\nIntroverted Thinking (Ti)\nIterations, holistic reasoning, agile strategies. Ti takes a bottom-up approach to problem-solving, and fixates on information management. When new data comes in that contradicts old beliefs, Ti will shift like a fluid crystalline framework.\n\nExample career areas that emphasize introverted thinking (Ti):\n\nData analysis\nSystems design engineering\nPhilosophy, sociology\nCybersecurity\nLanguage translation\nWhat are YOUR Functions and Cognitive Stack?\nAccording to Jung\u2019s theory, each person would essentially predominantly display each function (Sensing, Intuition, Thinking, Feeling) in either an extraverted or introverted manner. So of the 8 functions listed above, you\u2019d have 4 of them. If you favor Extraverted Intuition (Ne) it doesn\u2019t mean you can\u2019t use Introverted Intuition (Ni) but rather just that it is less common for you and thus Ne is your primary mode of Intuition. Since Intuition and Sensing are together on scale, if you extravert your Intuition then you tend to introvert your Sensing. So you\u2019d have Ne and Si.\n\nNext you must consider your Thinking-Feeling scale. If this same person tends to externalize (or extravert) their Thinking in the real world then we have a Te, and thus by definition the Feeling would be introverted (Fi). So we have Ne, Si, Te, Fi. But not necessarily in that order. That\u2019s when functional stacking steps in. Each individual uses both Thinking and Feeling functions, which makes the cut-and-dried type system overly simplistic. \n\nThe next task is to determine which function is primary, auxiliary, tertiary and inferior. This is when the concept of functional \u201cstacking\u201d comes in handy. Whichever is most natural is likely the primary, and so on. This is the order of the \u201cstack\u201d, which of your functions comes first or primary, and which comes last or inferior. Let\u2019s say the order in this case is was Ne, Fi, Te, Si. That translates to the ENFP personality type.\n\nCertainly the primary and auxiliary functions are those that come most natural to an individual, and are likely to characterize their outward personality. But while these tendencies may be seen quite obviously on the surface, they don\u2019t fully address one\u2019s personality. The tertiary and inferior functions are also crucial to understand.\n\nIf we only consider the four letters in ENFP (Extraverted, Intuitive, Feeling, Perceiving), for example, it would be next to impossible to see the hidden extraverted thinking (Te) and introverted sensing (Si) in their stacking. ENFPs are more than just their bubbly, charismatic and energetic stereotype. Their Te allows them to systematically work through their tasks and Si with their (often overlooked) excellent memory for details. This can make them excellent PR managers, communications specialists, and journalists.\n\nAnother example of hidden functions in play can be seen in the INTJ (Introverted, Intuitive, Thinking, Judging). INTJs are often dubbed by the entertainment and film industry as chess grandmasters who are strategic, sometimes cunning, and sometimes cold. However, they have introverted feeling (Fi) and extraverted sensing (Se) as their respective third and fourth function. INTJs have strong morals and hold their loved ones dear to their hearts. When under stress, they can become acutely aware of their surroundings and an asset to any team.\n\nHow Does this Relate to \u201cPersonality Typing\u201d?\nThis is the underlying theory behind the Myers-Briggs model and behind most models that also use the 16 personality types nomenclature. There is no shortage of different \u201cpersonality tests\u201d online that you can take that will attempt to determine what your functions are (Fe vs Fi, Te vs Ti, etc.) and in what order they are \u201cstacked\u201d. This then determines which of the 16 types you fall into. While the tests are certainly convenient, any such self-assessment is naturally rigid and prone to testing limitations and thus is never able to get a fully-accurate picture of a human being.", "Describe as reporting live a current event in max 3 lines, what is happening right now using the following tweets, with a focus on the term \"omg\"\n\nsourceText Time\nPenalty OMG #ARGFRA 17:36:11.0000000\nFrance penalty! Omg you can flip this game on its head. #ArgentinaVsFrance #WorldCup #FIFAWorldCupFinal 17:36:40.0000000\nOmg it\u2019s handball, penalty to France ???? 17:36:23.0000000\nWAIT PLOT TWIST ULIT! OMG AHAHAHAHAHAHA! PENALTY KICK FOR FRANCE! 17:36:54.0000000\nOMG, now France gets a penalty. This game is bonkers. 17:36:33.0000000\nOMG FRANCE GETS A PENALTY 17:36:22.0000000\nOmg penalty! #ARGFRA 17:36:57.0000000\nFRANCE PENALTY OMG 17:36:06.0000000\nPenalty for France OMG 17:36:31.0000000\nOMG A PENALTY FOR FRANCE'WHAT IS THISSSSS 17:36:21.0000000\nOMG penalty in 117 minutes for #france 17:36:43.0000000\nOMG it\u2019s a penalty to France 17:36:29.0000000\nPenalty France omg omg omg 17:36:04.0000000\nFRANCE PENALTY OMG 17:36:14.0000000\nAs if it\u2019s another France penalty omg this final is crazy 17:36:19.0000000\nPenalty??????? Omg ???????????????????? #FRAARG 17:36:14.0000000\nPenalty. OMG Argentina na yeye guys. Just imagine. 17:36:49.0000000\nPenalty for France omg 17:36:09.0000000\nPENALTY FOR FRANCE OMG!!!! 17:36:10.0000000\nPenalty! This is so amazing omg ??#LetChaosReign #FIFAWorldCup\u00a0\u00a0\u00a0 #ArgentinaVsFrance #WorldCupFinal 17:36:40.0000000\nPENALTY FOR FRANCE OMG 17:35:53.0000000\nOmg Penalty for France 17:36:18.0000000\nOMG AMOTHER PENALTY FOR FRANCE WOWWWWWW I CANNY BELIEVE IT 17:36:15.0000000\nOMG PENALTY FRANCE 17:36:24.0000000\nOmg penalty this is insane #ARGFRA 17:36:53.0000000\nOMG PENALTY TO FRANCE 17:36:08.0000000\nFrance penalty!! Omg! 17:36:07.0000000\nPENALTY TO FRANCE OMG THAT WAS HAND 17:36:37.0000000\npenalty for France omg??? 17:36:22.0000000\nOMG. This is surreal.''Penalty for France.''#fra 17:36:37.0000000\nOMG PENALTY TO FRANCE ARE YOU KIDDING ME 17:36:43.0000000\nPENALTY FOR FRANCE OMG 17:36:08.0000000\nWtf handball. Penalty for France. Omg. 17:36:20.0000000\nOMG it's a France penalty! JFC #FIFAWorldCup 17:36:29.0000000\nOMG PENALTY KICK FOR FRANCE 17:35:56.0000000\nPENALTY FRANCE OMG 17:36:18.0000000\nOMG PENALTY FRANCE!!!!! 17:36:03.0000000\nPENALTY FRANCE! OMG. THIS GAME. THIS GAME. #ARGFRA #FIFAWorldCupFinal 17:35:58.0000000\nOMG PENALTY FOR FRANCE 17:36:31.0000000\nOmg France have a penalty?? 17:36:18.0000000\nPenalty for France... OMG 17:36:12.0000000\nPENALTY FOR FRANCE OMG 17:36:27.0000000\nOMG PENALTY ????? #ARGFRA 17:35:41.0000000\nOmg !! Handball penalty France 17:36:37.0000000\nOMG PENALTY TO FRANCE 17:36:50.0000000\nOMG PENALTY TO FRANCE!!!'#Qatar2022 17:36:21.0000000\nFrance penalty omg. This World Cup final is wild. 17:36:48.0000000\nPENALTY FOR FRANCE OMG 17:35:48.0000000\nPENALTY FRANCE OMG THIS IS A MAZZA 17:36:01.0000000\nFrance got a penalty omg ?? 17:36:09.0000000\nFRANCE PENALTY OMG 17:36:29.0000000\nOMG THIS IS INSANITY. PENALTY FOR FRANCE! 17:36:36.0000000\nPenalty France.OMG!!! 17:36:15.0000000\nOMG! France penalty! #FIFAWorldCupFinal #FifaWorldCup #FRAARG 17:36:35.0000000\nOMG PENALTY FOR FRANCE!! 17:36:17.0000000\nFrance penalty omg 17:36:54.0000000\nOMG a penalty kick for France?! This is crazy 17:36:21.0000000\nPENALTY FRANCE OMG 17:36:38.0000000\nOMG. France penalty 17:36:28.0000000\nOMG PENALTY TO FRANCE!!!! 17:36:10.0000000\nOMG'This match. 'Um flippin believable 'Penalty for France. 17:36:52.0000000\nPENALTY FOR FRANCE OMG. 17:36:15.0000000\nPENALTY FOR FRANCE!!!! OMG 17:36:25.0000000\nPENALTY OMG #ARGFRA 17:35:45.0000000\nOmg what a match'One more penalty to France 17:36:13.0000000\nomg france penalty 17:36:43.0000000\nOMG!!!!! PENALTY FOR FRANCE!!????!!!! 17:36:34.0000000\nPenalty to France omg 17:36:21.0000000\nOmg France have a penalty 17:36:00.0000000\nOMG PENALTY FOR FRANCE! 17:35:57.0000000\nOMG penalty....#ARGFRA 17:36:38.0000000\n#WorldCup Omg a penalty for France 17:36:33.0000000\nPenalty Kick incoming for France OMG!!!! 17:36:16.0000000\nFRANCE PENALTY KICK OMG??? https://t.co/jtli2aEhOk 17:36:40.0000000\nOmg penalty france 17:36:20.0000000\nOmg France penalty #WorldCup 17:36:17.0000000\nGUYS THERE IS A PENALTY COR FRANCE OMG 17:35:57.0000000\nOMG! Penalty! Hand! #france #WorldCup 17:36:34.0000000\nOmg ?? penalty kick for france ???? 17:36:50.0000000\nAnother France Penalty??''Omg what a dramatic final! ?? 17:36:30.0000000\nPENALTY FRANCE OMG #FIFAWorldCup 17:36:42.0000000\nOMG what is happening 'Penalty to France ?? 17:36:26.0000000\nPENALTY FOR FRANCE OMG 17:36:13.0000000\nPENALTY FOR FRANCE OMG THIS GAME''MY BLOOD PRESSURE RIGHT NOW 17:36:52.0000000\nPenalty for France this GAME... OMG! 17:36:19.0000000\nFrance penalty omg 17:36:11.0000000\nOMG ITS A FRANCE PENALTY ! 17:36:18.0000000\nOMG PENALTY FOR FRANCE 17:36:57.0000000\nPenalty France omg silly Argentina give away a pen Bcz they try to defend 17:36:39.0000000\nOMG PENALTY FOR FRANCE 17:35:53.0000000\nOMG!!! Penalty to France! ?? this is unreal! 17:36:21.0000000\nPENALTY FOR FRANCE OMG 17:36:12.0000000\nPenalty? Omg #ArgentinaVsFrance 17:36:53.0000000\nPenalty for france omg?????? 17:35:59.0000000\nPENALTY FOR FRANCE OMG 17:36:11.0000000\nPenalty omg hahaha let's go #FIFAWorldCupFinal 17:36:28.0000000\nPENALTY FOR FRANCE OMG! 17:36:41.0000000", "Describe as reporting live a current event in max 3 lines, what is happening right now using the following tweets, with a focus on the term \"omg\"\n\nsourceText Time\nPenalty OMG #ARGFRA 17:36:11.0000000\nFrance penalty! Omg you can flip this game on its head. #ArgentinaVsFrance #WorldCup #FIFAWorldCupFinal 17:36:40.0000000\nOmg it\u2019s handball, penalty to France ???? 17:36:23.0000000\nWAIT PLOT TWIST ULIT! OMG AHAHAHAHAHAHA! PENALTY KICK FOR FRANCE! 17:36:54.0000000\nOMG, now France gets a penalty. This game is bonkers. 17:36:33.0000000\nOMG FRANCE GETS A PENALTY 17:36:22.0000000\nOmg penalty! #ARGFRA 17:36:57.0000000\nFRANCE PENALTY OMG 17:36:06.0000000\nPenalty for France OMG 17:36:31.0000000\nOMG A PENALTY FOR FRANCE'WHAT IS THISSSSS 17:36:21.0000000\nOMG penalty in 117 minutes for #france 17:36:43.0000000\nOMG it\u2019s a penalty to France 17:36:29.0000000\nPenalty France omg omg omg 17:36:04.0000000\nFRANCE PENALTY OMG 17:36:14.0000000\nAs if it\u2019s another France penalty omg this final is crazy 17:36:19.0000000\nPenalty??????? Omg ???????????????????? #FRAARG 17:36:14.0000000\nPenalty. OMG Argentina na yeye guys. Just imagine. 17:36:49.0000000\nPenalty for France omg 17:36:09.0000000\nPENALTY FOR FRANCE OMG!!!! 17:36:10.0000000\nPenalty! This is so amazing omg ??#LetChaosReign #FIFAWorldCup #ArgentinaVsFrance #WorldCupFinal 17:36:40.0000000\nPENALTY FOR FRANCE OMG 17:35:53.0000000\nOmg Penalty for France 17:36:18.0000000\nOMG AMOTHER PENALTY FOR FRANCE WOWWWWWW I CANNY BELIEVE IT 17:36:15.0000000\nOMG PENALTY FRANCE 17:36:24.0000000\nOmg penalty this is insane #ARGFRA 17:36:53.0000000\nOMG PENALTY TO FRANCE 17:36:08.0000000\nFrance penalty!! Omg! 17:36:07.0000000\nPENALTY TO FRANCE OMG THAT WAS HAND 17:36:37.0000000\npenalty for France omg??? 17:36:22.0000000\nOMG. This is surreal.''Penalty for France.''#fra 17:36:37.0000000\nOMG PENALTY TO FRANCE ARE YOU KIDDING ME 17:36:43.0000000\nPENALTY FOR FRANCE OMG 17:36:08.0000000\nWtf handball. Penalty for France. Omg. 17:36:20.0000000\nOMG it's a France penalty! JFC #FIFAWorldCup 17:36:29.0000000\nOMG PENALTY KICK FOR FRANCE 17:35:56.0000000\nPENALTY FRANCE OMG 17:36:18.0000000\nOMG PENALTY FRANCE!!!!! 17:36:03.0000000\nPENALTY FRANCE! OMG. THIS GAME. THIS GAME. #ARGFRA #FIFAWorldCupFinal 17:35:58.0000000\nOMG PENALTY FOR FRANCE 17:36:31.0000000\nOmg France have a penalty?? 17:36:18.0000000\nPenalty for France... OMG 17:36:12.0000000\nPENALTY FOR FRANCE OMG 17:36:27.0000000\nOMG PENALTY ????? #ARGFRA 17:35:41.0000000\nOmg !! Handball penalty France 17:36:37.0000000\nOMG PENALTY TO FRANCE 17:36:50.0000000\nOMG PENALTY TO FRANCE!!!'#Qatar2022 17:36:21.0000000\nFrance penalty omg. This World Cup final is wild. 17:36:48.0000000\nPENALTY FOR FRANCE OMG 17:35:48.0000000\nPENALTY FRANCE OMG THIS IS A MAZZA 17:36:01.0000000\nFrance got a penalty omg ?? 17:36:09.0000000\nFRANCE PENALTY OMG 17:36:29.0000000\nOMG THIS IS INSANITY. PENALTY FOR FRANCE! 17:36:36.0000000\nPenalty France.OMG!!! 17:36:15.0000000\nOMG! France penalty! #FIFAWorldCupFinal #FifaWorldCup #FRAARG 17:36:35.0000000\nOMG PENALTY FOR FRANCE!! 17:36:17.0000000\nFrance penalty omg 17:36:54.0000000\nOMG a penalty kick for France?! This is crazy 17:36:21.0000000\nPENALTY FRANCE OMG 17:36:38.0000000\nOMG. France penalty 17:36:28.0000000\nOMG PENALTY TO FRANCE!!!! 17:36:10.0000000\nOMG'This match. 'Um flippin believable 'Penalty for France. 17:36:52.0000000\nPENALTY FOR FRANCE OMG. 17:36:15.0000000\nPENALTY FOR FRANCE!!!! OMG 17:36:25.0000000\nPENALTY OMG #ARGFRA 17:35:45.0000000\nOmg what a match'One more penalty to France 17:36:13.0000000\nomg france penalty 17:36:43.0000000\nOMG!!!!! PENALTY FOR FRANCE!!????!!!! 17:36:34.0000000\nPenalty to France omg 17:36:21.0000000\nOmg France have a penalty 17:36:00.0000000\nOMG PENALTY FOR FRANCE! 17:35:57.0000000\nOMG penalty....#ARGFRA 17:36:38.0000000\n#WorldCup Omg a penalty for France 17:36:33.0000000\nPenalty Kick incoming for France OMG!!!! 17:36:16.0000000\nFRANCE PENALTY KICK OMG??? https://t.co/jtli2aEhOk 17:36:40.0000000\nOmg penalty france 17:36:20.0000000\nOmg France penalty #WorldCup 17:36:17.0000000\nGUYS THERE IS A PENALTY COR FRANCE OMG 17:35:57.0000000\nOMG! Penalty! Hand! #france #WorldCup 17:36:34.0000000\nOmg ?? penalty kick for france ???? 17:36:50.0000000\nAnother France Penalty??''Omg what a dramatic final! ?? 17:36:30.0000000\nPENALTY FRANCE OMG #FIFAWorldCup 17:36:42.0000000\nOMG what is happening 'Penalty to France ?? 17:36:26.0000000\nPENALTY FOR FRANCE OMG 17:36:13.0000000\nPENALTY FOR FRANCE OMG THIS GAME''MY BLOOD PRESSURE RIGHT NOW 17:36:52.0000000\nPenalty for France this GAME... OMG! 17:36:19.0000000\nFrance penalty omg 17:36:11.0000000\nOMG ITS A FRANCE PENALTY ! 17:36:18.0000000\nOMG PENALTY FOR FRANCE 17:36:57.0000000\nPenalty France omg silly Argentina give away a pen Bcz they try to defend 17:36:39.0000000\nOMG PENALTY FOR FRANCE 17:35:53.0000000\nOMG!!! Penalty to France! ?? this is unreal! 17:36:21.0000000\nPENALTY FOR FRANCE OMG 17:36:12.0000000\nPenalty? Omg #ArgentinaVsFrance 17:36:53.0000000\nPenalty for france omg?????? 17:35:59.0000000\nPENALTY FOR FRANCE OMG 17:36:11.0000000\nPenalty omg hahaha let's go #FIFAWorldCupFinal 17:36:28.0000000\nPENALTY FOR FRANCE OMG! 17:36:41.0000000", "please review this set of responses to the question \"what are the value plays we should focus on\" and look for common themes in the responses. Present these in a table format with a short name, description, and identify all individuals who made reference to this theme in their response\n\n1. Supplied\n 1. Acquire and Develop Talent capable of delivering Platform vision\n 2. Modernized internal stack capable of meeting the needs of a cloud-first business\n 3. Best in class investor management through transformation process, as we delicately manage the growth of platform offerings in a way that doesn't negatively impact our valuation in the long term\n 4. Decreasing our capital intensity through operating efficiencies driven by technology and automation \n 5. Developing a suite of digital platform solutions from solving cloud issues to digital transformations \n 6. Building a partner ecosystem to expand and support our offerings\n 7. Solving go-to-market, legal, and financial compliance challenges related to operating a platform business internationally\n \n2. Brandi\n \u00b7 \u2026Modernized internal stack capable of meeting the needs of a cloud-first business.\n \u00b7 Evolve culture to accelerate delivery of platform vision\n \u00b7 Acquire and develop talent fit for platform vision\n \n3. Bruce\n \u00b7 Be public about a quantifiable aspiration/goal to fuel urgency (e.g. Interconnection revenue or yield)\n \u00b7 Get org rallied around a shared vision and then be very targeted in culture change (e.g. agile) and skills change needed in specific pockets of the org to deliver digital transformation. Ie. We need everyone to understand our vision, but we can be targeted on the where need new skills/capabilities\n \u00b7 Enhance our local market and customer listening to drive innovation, using customer base for rapid beta testing or prototypes.\n \n4. Charles\n 1. IBX Footprint\n 2. Service Offerings\n a. Colo\n b. Mgd Services\n c. Edge Infra (Network Edge and Colo by the U)\n d. Cloud Networking\n 3. Digital Experience (likely starts as somewhat parallel experiences for DCS vs DS offerings but implies a merged experience over time)\n a. Process\n b. Systems\n 4. Ecosystem Enablement (huge area of opportunity and under-investment)\n a. APIs\n b. SDKs (that\u2019s all the acronyms I know but I\u2019m pretty sure we have a lot of work to do)\n 5. Customers \u2013 need to define target personas and align GTM motions to specific customer/persona combinations\n 6. Ecosystem Development\n a. JPS/\u201dintegrated\u201d\n b. Self-serve (use self-serve tools to bring your offering to the Platform)\n c. Communities of Interest/Vertical Ecosystems (BD to cultivate)\n 7. Marketplace (what we need, not what we have now)\n\n \n \n5. Jon\n \u00b7 Modernized quote-to-cash stack that allows for low/no-touch customer acquisition and onboarding, and global billing capabilities.\n \u00b7 Having clear, measurable ROIC for digital services with clear cost structures by product line.\n \u00b7 Building integrated partner offerings that allow partners to package/sell/support our offerings with low/no-touch for Equinix.\n \u00b7 Creating clear BU and product-level P&L reporting, inclusive of capex and opex.\n \u00b7 Having the clear ability to calculate LTV/CAC by product.\n \n6. Justin\n \u00b7 Investing in a modern API-first technology stack to be able to effectively leverage developer ecosystems to (1) co-drive disruptive, agile innovation; (2) create new business models; (3) enable seamless API-based technology partner integration; and (4) reduce channel friction.\n \u00b7 Continuing to improve Equinix\u2019s visibility and credibility in developer ecosystems to attract world-class talent capable of delivering on our Platform vision.\n \u00b7 Investing in an innovation incubator with dedicated engineering resources, and frameworks in place to engage and co-innovate with external developers and startups with agility, to boost innovation (radical innovation, adjacent innovation, or core innovation), supported by an accelerated incubation model.\n \n7. Karl\n \u00b7 \u2026seriously vet and conclude on inorganic options to accelerate our capability set to deliver the suite of services required. (Contemplates the addition of talent, tech, and product needed to accelerate)\n \u00b7 \u2026successfully launch AND scale Joint partner solutions that prove we are indeed the home of the dedicated cloud and can offer solutions via partners at scale.\n \u00b7 \u2026neutralize the complexity of workload tiering and demand shaping by having both retail and wholesale solutions to large and performance based deployments.\n \n \n8. Keith\n \u00b7 Developing a platform on Equinix DCS assets, and potentially extending these services to other non-Equinix assets.\n \u00b7 Potentially acquiring talent or service capabilities and integrating onto the Equinix Platform.\n \u00b7 Merging our business into an existing business and integrating onto the Equinix Platform.\n \u00b7 Exclusively expand our GTM partnerships with a number of critical providers that imbeds our service offering into their solution.\n \n9. Kurt\n \u00b7 \u2026Honestly, I think the above list is a really good list. I am struggling to add anything to it. \n \u00b7 If I had to, I would say we need a capability of coming to agreement more quickly on complex issues impacting our delivery and development of services. We are currently wrestling with issues that we have known for year. Channel complications (same ones) have been on the table for years, tax structure has been on the table for years and we actually built a tax structure no one is using a while back, we have known about billing issues since we bought packet, etc. The problem is, as soon as folks hear \u201chard problem\u201d they retreat and we don\u2019t move. To date, we have really struggled to resolve these issues quickly enough and with certainty for a time. I would never say we need decisions that last forever as we need to be agile, but the word I hear a lot on the street is the team is \u201cWhipsawed.\u201d It feels like folks run to work on something based on an agreement and then it changes a few months out, not usually with a discussion. \n \u00b7 With that said, the list above actually sounds great to me. We need the right talent, working on the right stuff, for the right customers, and the story will tell itself.\n \n10. Mike\n \u00b7 Acquire and Develop Talent capable of delivering our Platform vision.\n \u00b7 Build a partner ecosystem to expand and support our offerings.\n \u00b7 Begin to market ourselves as a company that provides a lot more than colocation services to different personas than we market to today.\n \u00b7 Find a way to use xScale facilities to help with our Retail and Digital space constraints.\n \n11. Milind\n\n12. Nicole \n\u00b7 People/Workforce/Brand:\n \u00b7 Specific declaration on future state vision (internally). Take any guesses or confusion off the table immediately and ensure all functions are clear on how they play a role in that vision. \n \u00b7 T&A to drive talent into the workforce that has experience suited for our vision (less telco, more software, service provider, etc..). \n \u00b7 Marketing driving significant brand shift externally to ensure customers see us as a platform company. We are moving away from data center only branding. (This likely requires a CMO strategy) \n \u00b7 Drive more accountability with our GLO population to lead from the front and be transformational leaders. Communicate often, effectively, and more intimately with this group so they are 100% clear on the strategy and role they play in the transformation. Have courage to take swift action if leaders can\u2019t make the turn. This group of leaders will make or break us future state. \n\u00b7 Growth and Bookings: \n \u00b7 Global salesforce enabled and delivering balanced performance and growth targets across the product portfolio. \n \u00b7 Internal functions working towards common vision and solving problems in partnership and at pace. \n \u00b7 Specific and strategic synergy plans formally in place across critical enterprise partnerships (Dell, VMW, HPE)\n \u00b7 Sustainability efforts clearly defined, articulated, and structured goaling for internal leadership in place. \n \u00b7 Product clarity in digital space. What products, to what market, etc.. Keep this simple so sales can accelerate the strategy. Complexity will slow our pace. \n \n\u00b7 Systems/Tools/Processes\n \u00b7 Modernize our internal stack to be able to provide a customer experience needed for digital scale. Be progressive and aggressive in our IT shift. Don\u2019t always think about \u201cbuild\u201d motions, also look at \u201cbuy\u201d motions to implement with speed. \n \u00b7 Data Transformation strategy in place (as part of our overall digital transformation strategy) in place to ensure Network Transformation, MDM/Analytics, etc, have structured execution dates (with timelines) and are scaling to enable faster decisions with more data driven insights. \n \u00b7 Real time capacity management tools that help us balance DCS and DS needs by data center (I am not sure how mature these are today, and am assuming we will need advancement here). \n \u00b7 API mandatory for all new builds. Basically, no more in house building that aren\u2019t API enabled. \n\n \n13. PVC\n \u00b7 \u2026If I accurately understand the list, 1, 2, 5, and 6 are areas I\u2019d apply energy\u2026.. 3, 4, and 7 will draw effort, but should naturally occur as we progress in the others. \n \n14. Raouf\n \u00b7 \u2026The right talent to build the products and scale the \u201cwrapper\u201d service model. \n \u00b7 Modernized systems to support DS but also Enterprise support ready. \n \u00b7 Network/DS architecture to scale and have the right unto cost. Truly support on demand growth and ramp for customers. \n \u00b7 Solve go to market approach for combined customers from contracting, ordering and billing to support. \n \n15. Ryan\n 1. Acquire and develop talent capable of delivering Platform vision.\n 2. Overhaul internal systems and processes to enable efficiency and improved experience for customers and front-line employees. \n 3. Instill agility into culture and processes. \n \n16. Scott\n \u00b7 It is hard to improve upon the ones listed, but I'd change the last to read:\n \u00b7 Creating a highly competitive transactional, legal, and financial operating model necessary for the on-demand SaaS/cloud market\n \u00b7 And I'd add:\n \u00b7 Build the optimal platform to capture cloud-adjacent workloads and data. \"Platform\" is inclusive of our offerings and integrated offerings from ecosystem partners.", "can you do the same with this code Action & adventure\n------------------\n\n[1365](https://www.netflix.com/browse/genre/1365)\n* [43040Action comedies](https://www.netflix.com/browse/genre/43040)\n* [1568Action sf & fantasy](https://www.netflix.com/browse/genre/1568)\n* [43048Action thrillers](https://www.netflix.com/browse/genre/43048)\n* [7442Adventures](https://www.netflix.com/browse/genre/7442)\n* [77232Asian action movies](https://www.netflix.com/browse/genre/77232)\n* [46576Classic Action & Adventure](https://www.netflix.com/browse/genre/46576)\n* [10118Comic book and superhero movies](https://www.netflix.com/browse/genre/10118)\n* [9584Crime action & adventure](https://www.netflix.com/browse/genre/9584)\n* [11828Foreign action & adventure](https://www.netflix.com/browse/genre/11828)\n* [20541Hijacking movies](https://www.netflix.com/browse/genre/20541)\n* [8985Martial arts movies](https://www.netflix.com/browse/genre/8985)\n* [2125Military action & adventure](https://www.netflix.com/browse/genre/2125)\n* [10702Spy action & adventure](https://www.netflix.com/browse/genre/10702)\n* [7700Westerns](https://www.netflix.com/browse/genre/7700)\nAnime\n-----\n\n[7424](https://www.netflix.com/browse/genre/7424)\n* [11881Adult animation](https://www.netflix.com/browse/genre/11881)\n* [5507Animal tales](https://www.netflix.com/browse/genre/5507)\n* [2729Anime Sci-Fi](https://www.netflix.com/browse/genre/2729)\n* [2653Anime action](https://www.netflix.com/browse/genre/2653)\n* [9302Anime comedies](https://www.netflix.com/browse/genre/9302)\n* [452Anime dramas](https://www.netflix.com/browse/genre/452)\n* [11146Anime fantasy](https://www.netflix.com/browse/genre/11146)\n* [3063Anime features](https://www.netflix.com/browse/genre/3063)\n* [10695Anime horror](https://www.netflix.com/browse/genre/10695)\n* [6721Anime series](https://www.netflix.com/browse/genre/6721)\nChildren & family movies\n------------------------\n\n[783](https://www.netflix.com/browse/genre/783)\n* [5507Animal tales](https://www.netflix.com/browse/genre/5507)\n* [67673Disney](https://www.netflix.com/browse/genre/67673)\n* [10659Education for kids](https://www.netflix.com/browse/genre/10659)\n* [51056Family features](https://www.netflix.com/browse/genre/51056)\n* [52843Kids Music](https://www.netflix.com/browse/genre/52843)\n* [27346Kids' TV](https://www.netflix.com/browse/genre/27346)\n* [10056Movies based on children's books](https://www.netflix.com/browse/genre/10056)\n* [6796Movies for ages 0 to 2](https://www.netflix.com/browse/genre/6796)\n* [6962Movies for ages 11 to 12](https://www.netflix.com/browse/genre/6962)\n* [6218Movies for ages 2 to 4](https://www.netflix.com/browse/genre/6218)\n* [5455Movies for ages 5 to 7](https://www.netflix.com/browse/genre/5455)\n* [561Movies for ages 8 to 10](https://www.netflix.com/browse/genre/561)\n* [11177TV cartoons](https://www.netflix.com/browse/genre/11177)\nChristmas \ud83c\udf84\n-----------\n* [1527064British christmas children & family films](https://www.netflix.com/browse/genre/1527064)\n* [1721544Canadian christmas children & family films](https://www.netflix.com/browse/genre/1721544)\n* [1474017Christmas children & family films](https://www.netflix.com/browse/genre/1474017)\n* [1477206Christmas children & family films for ages 11 to 12](https://www.netflix.com/browse/genre/1477206)\n* [1477201Christmas children & family films for ages 5 to 7](https://www.netflix.com/browse/genre/1477201)\n* [1477204Christmas children & family films for ages 8 to 10](https://www.netflix.com/browse/genre/1477204)\n* [1476024Christmas children & family films from the 1990s](https://www.netflix.com/browse/genre/1476024)\n* [1527063European christmas children & family films](https://www.netflix.com/browse/genre/1527063)\n* [1394522Family-friendly christmas films](https://www.netflix.com/browse/genre/1394522)\n* [1475066Feel-good christmas children & family films](https://www.netflix.com/browse/genre/1475066)\n* [1475071Goofy christmas children & family films](https://www.netflix.com/browse/genre/1475071)\n* [1394527Romantic christmas films](https://www.netflix.com/browse/genre/1394527)\nClassic Movies\n--------------\n\n[31574](https://www.netflix.com/browse/genre/31574)\n* [47147Classic SF & fantasy](https://www.netflix.com/browse/genre/47147)\n* [46553Classic TV shows](https://www.netflix.com/browse/genre/46553)\n* [46576Classic action & adventure](https://www.netflix.com/browse/genre/46576)\n* [31694Classic comedies](https://www.netflix.com/browse/genre/31694)\n* [29809Classic dramas](https://www.netflix.com/browse/genre/29809)\n* [32392Classic musical comedy](https://www.netflix.com/browse/genre/32392)\n* [31273Classic romantic movies](https://www.netflix.com/browse/genre/31273)\n* [46588Classic thrillers](https://www.netflix.com/browse/genre/46588)\n* [48744Classic war movies](https://www.netflix.com/browse/genre/48744)\n* [47465Classic westerns](https://www.netflix.com/browse/genre/47465)\n* [52858Epics](https://www.netflix.com/browse/genre/52858)\n* [7687Film Noir](https://www.netflix.com/browse/genre/7687)\n* [53310Silent Movies](https://www.netflix.com/browse/genre/53310)\nComedies\n--------\n\n[6548](https://www.netflix.com/browse/genre/6548)\n* [9302Animes comedies](https://www.netflix.com/browse/genre/9302)\n* [869Dark comedies](https://www.netflix.com/browse/genre/869)\n* [4426Foreign Comedies](https://www.netflix.com/browse/genre/4426)\n* [89585Horror comedies](https://www.netflix.com/browse/genre/89585)\n* [1402Late Night Comedies](https://www.netflix.com/browse/genre/1402)\n* [26Mockumentaries](https://www.netflix.com/browse/genre/26)\n* [13335Musicals comedies](https://www.netflix.com/browse/genre/13335)\n* [2700Political comedies](https://www.netflix.com/browse/genre/2700)\n* [5475Romantic Comedies](https://www.netflix.com/browse/genre/5475)\n* [4922Satires](https://www.netflix.com/browse/genre/4922)\n* [9702Screwball Comedies](https://www.netflix.com/browse/genre/9702)\n* [10256Slapstick comedies](https://www.netflix.com/browse/genre/10256)\n* [5286Sports comedies](https://www.netflix.com/browse/genre/5286)\n* [11559Stand-up Comedy](https://www.netflix.com/browse/genre/11559)\n* [3519Teen Comedies](https://www.netflix.com/browse/genre/3519)\nDocumentaries\n-------------\n\n[6839](https://www.netflix.com/browse/genre/6839)\n* [3652Biographical documentaries](https://www.netflix.com/browse/genre/3652)\n* [9875Crime documentaries](https://www.netflix.com/browse/genre/9875)\n* [5161Foreign documentaries](https://www.netflix.com/browse/genre/5161)\n* [5349Historical documentaries](https://www.netflix.com/browse/genre/5349)\n* [4006Military documentaries](https://www.netflix.com/browse/genre/4006)\n* [90361Music & concert documentaries](https://www.netflix.com/browse/genre/90361)\n* [7018Political documentaries](https://www.netflix.com/browse/genre/7018)\n* [10005Religious documentaries](https://www.netflix.com/browse/genre/10005)\n* [2595Science & navature documentaries](https://www.netflix.com/browse/genre/2595)\n* [3675Social & cultural documentaries](https://www.netflix.com/browse/genre/3675)\n* [2760Spirituality documentaries](https://www.netflix.com/browse/genre/2760)\n* [180Sports documentaries](https://www.netflix.com/browse/genre/180)\n* [1159Travel & adventure documentaries](https://www.netflix.com/browse/genre/1159)\nDramas\n------\n\n[5763](https://www.netflix.com/browse/genre/5763)\n* [11Army dramas](https://www.netflix.com/browse/genre/11)\n* [3179Biographical dramas](https://www.netflix.com/browse/genre/3179)\n* [6889Crime dramas](https://www.netflix.com/browse/genre/6889)\n* [4961Dramas based on books](https://www.netflix.com/browse/genre/4961)\n* but put it into a container", "Please turn this entire article into a bulleted list of 10 things. Under each main item, please summarize each section into 5 bullet points. \n10 things someone with ADD can do each morning to have a more productive day\n\n1. Create a to-do list: Writing down tasks and prioritizing them can help minimize distractions and keep focus on what is important.\n\nIt can be challenging for someone with ADD to prioritize tasks, especially when it comes to a long list of tasks. In this situation, it may be helpful to break down the list into smaller chunks or sub-tasks. Once the list has been broken down, it can be easier to prioritize individual tasks and focus on them one at a time. Additionally, setting a timer or timer reminders can help someone with ADD stay on track and focused as they work through their task list.\n\n2. Active meditation: Take 10-15 minutes for deep breathing exercises, yoga, or a quick jog to mentally prepare for the day ahead.\n\nAdditionally, actions such as listening to calming music or drinking caffeine can help increase focus levels.\n\n3. Eat a nutritious breakfast: A balanced meal will not only provide energy but also improve focus and concentration.\n\nIt is important for someone with ADD to have a nutritious breakfast that will provide them with energy and focus throughout the day. Some good breakfast options include oatmeal, eggs, whole grain toast, yogurt, and smoothies. Eating a balanced breakfast with a combination of protein, healthy fats, and complex carbohydrates can help maintain focus and provide energy until the next meal.\n\n4. Set specific goals: Assigning specific time blocks to tasks will eliminate the need to decide what to do next and give a sense of accomplishment as tasks are completed.\n\nOne way to help with this is to create a daily schedule or to-do list. Having a visual reminder of tasks or goals that need to be accomplished can help stay on track and prevent distractions. Additionally, setting timer reminders can help someone with ADD stay on task and not wander off-task.\n\nIf someone with ADD realizes they've wandered off-task for hours, the first thing to do is to take a break. Taking a break and resetting can help regain focus and motivation. After taking a break, it can be helpful to review the task list and determine what the most important tasks are and create a plan of action to prioritize them. Additionally, setting timer reminders and taking regular breaks can help manage time and stay on-task more effectively.\n\nIt can be difficult to deal with the negative self-talk associated with wandering off-task for hours at a time. A helpful strategy for dealing with this type of negative self-talk is to recognize it for what it is and reframe it in a more positive and productive way. For example, rather than focusing on how long the task took, focus on the progress that has been made and the goals that have been achieved. Additionally, it can be helpful to talk to someone who is supportive, such as a friend or mentor, to gain some perspective and understanding.\n\nHere is a list of things you can do to deal with the negative self-talk associated with losing an entire day to ADD: \n\nTake a break from the task and reset. \n\nAcknowledge the progress that has been made and the goals that have been achieved. \n\nTalk to supportive friends or mentors for perspective and understanding. \n\nShift the focus from the negative thoughts to positive actions. \n\nFocus on the present and make a plan of action for the future. \n\nUse positive affirmations to remind yourself of your capabilities and potential. \n\nPractice self-care activities such as yoga, meditation, journaling, or art.\n\n5. Use visualization: Take a minute each morning to visualize a productive day, and mentally picture yourself successfully completing tasks.\n\nThis visualization practice can help you to focus and set yourself up for success each day. Picturing yourself focused and completing tasks can help you to stay motivated and help you achieve the goals that you set for yourself. It can also help to build your confidence and give you a better sense of control over your day and how you plan to use your time.\n\nHere are three questions you can ask each morning to visualize a productive day of completing tasks: \n\nWhat 3 tasks do I want to prioritize today?\n\nHow will I organize my time to ensure I am completing tasks efficiently and effectively?\n\n What strategies or techniques do I need to employ in order to stay on-task and focused?\n\n6. Avoid multitasking: While it may seem efficient, multitasking can quickly lead to distraction and decrease overall productivity. Focus on completing one task at a time and taking short breaks as needed.\n\nWhat are the dangers of multitasking from the perspective of someone who has ADHD? While multitasking may seem efficient, it can quickly lead to distraction and decrease overall productivity. Multitasking can cause confusion, cannot focus, and can make it harder to stay on-task. Additionally, someone who has ADD may struggle to refocus and regain focus if they become distracted by multitasking. Focusing on completing one task at a time and taking short breaks as needed can help stay focused and on-task.\n\nStrategies such as avoiding multitasking, closing windows and apps, putting phones away, and turning off notifications can help to reduce distractions. Additionally, taking regular breaks and rewarding yourself for completing tasks can help to stay motivated and on track.\n\nBreak down big projects into smaller tasks: This will help you stay organized and focused, as well as make tasks feel more manageable.\n\nTake short breaks throughout the day: Taking a few minutes to step away from your work can help you refocus and recharge.\n\nSet ambitious but achievable goals: Setting meaningful goals will help you stay motivated and focused on the task at hand.\n\n1Reward yourself: Celebrate the small wins and accomplishments throughout your day to stay motivated.\n\n7. Recognize your triggers: Identify the situations and behaviors that lead to distractions and implement strategies to avoid them.\n\nEveryone has different triggers to distraction, but it's important to recognize them and find ways to avoid them. For someone with ADD, recognizing the behaviors, settings, and conversations that lead to distractions can help to keep them on track and focused. \n\nThe best way for someone with ADD to learn to recognize patterns of distraction triggers is to keep a journal. Writing down what you\u2019re doing and when you notice a distraction could help you identify any patterns or common triggers. Additionally, it can be helpful to take a step back and analyze the situation objectively--what was going on before the distraction occurred and what was the nature of the distraction? Over time, these patterns can become easier to recognize and allow you to be better prepared for future distractions.\n\n8. Recognize & reduce system overwhelm\n\nFinding a productivity system that works for you can take time and experimentation. It can be helpful to start by assessing the different systems you\u2019ve tried and determine what was useful from each system and what didn\u2019t work. From there, you can use the insights you\u2019ve gained to create a customized system that works best for you. Additionally, it is important to remain flexible and willing to make changes as needed.\n\nHere are five questions you can ask yourself to determine what did and didn\u2019t work in any particular productivity system:\n\nWhat tasks, goals, or strategies were successful in this system?\n\nWhat tasks, goals, or strategies were unhelpful or unsuccessful?\n\nHow did this system help me stay organized and focused?\n\nHow could this system be more efficient or effective?\n\nWhat changes could I make to this system to make it more beneficial?\n\n9. Stay organized: Keep a tidy workspace, develop an organization system for documents, and ensure tasks and deadlines are clearly marked on a calendar or planner. \n\nStaying organized is a great way to help stay focused and on-task. Keeping a tidy workspace can help reduce distractions and create an enjoyable and productive environment to work in. Developing an organization system for documents can help you locate documents quickly and efficiently. Additionally, organizing tasks and deadlines on a calendar or planner can help keep track of progress and ensure tasks are completed on time.\n\nOrganizing tasks and activities as soon as they come up can be a helpful strategy for someone with ADD. Taking a few minutes to break down tasks and plan them out can help to stay focused and motivated, as well as prevent tasks from becoming too overwhelming. Additionally, setting reminders in advance can help to remember tasks and due dates.\n\nHere are three things someone with ADD can do right now to tidy up their workspace:\n\nTake a few minutes to sort through papers and documents.\n\nDiscard any items that are no longer needed.\n\nMake sure all necessary papers and documents are in their designated file or folder.\n\nUtilize organizational tools such as labels or storage bins to keep items organized.\n\nPut away any items that are not being used and clear off the desk.\n\n10. Create a to-do list the night before\n\nOne tip for someone with ADD to be more productive at the start of their day is to create a to-do list the evening before.\n\n This will provide structure and clarity to their day and help them to stay organized and focused. \n\nAdditionally, setting goals and timeframe for those goals can help with motivation and productivity. \n\n7 questions someone with ADD can ask the night before to prepare for the next day include:\n\nWhat are the top priorities for the day?\n\nHow much time do I need to dedicate to each task?\n\nWhat resources do I need to accomplish these tasks?\n\nWhat are some rewards or small wins I can look forward to?\n\nWhat timeline do I need to set for each task?\n\nAre there any distractions I need to be aware of ?\n\nWhat tips can I use to stay focused throughout the day?\n\nWhen will I take a break? What can I do for an active break?\n\nWho is someone I can ask to encourage me to take a break at the appropriate time? \n\nCo-worker\n\nFriend family member who will send a text randomly throughout the week as an accountability measure\n\nPet who are keenly aware of the time of day and will ask for what they need\n\nConclusion\n\nManaging ADD can be a challenge, but it is possible with the right strategies and goals. By actively managing triggers, setting timer reminders, taking regular breaks, and setting specific goals, someone with ADD can improve their focus and become more productive. Additionally, activities such as visualization, active meditation, and eating a nutritious breakfast will help to maintain energy and focus. With these helpful strategies, it may be easier to stay on -task and achieve goals more effectively.", "This is the example of data model for attackiq attack graph\nttl: 6000000\nname: MTAG - Network Discovery leads to Lateral Movement using Secure Shell (SSH)\ntype: maag\ngraph:\n '0':\n id: '0'\n args:\n scan\\_method: method\\_syn\\_scan\\_tcp\n exclude\\_self: true\n ports\\_to\\_scan: scan\\_ports\\_specific\\_expression\n is\\_attack\\_graph: true\n host\\_input\\_format: host\\_format\\_local\n ports\\_to\\_validate: validate\\_no\\_open\\_ports\n check\\_if\\_server\\_is\\_up: true\n scan\\_ports\\_specific\\_expression\\_value: '22,2222'\n type: local\n step\\_id: '0'\n success: '1'\n position:\n x: -410.7376324048025\n 'y': 148.56467555067326\n runnable: true\n testpoints:\n - 45fd9d0a-7cd9-41f8-a988-2ab496f75577\n scenario\\_id: d5ade19f-8d29-401e-b7ea-172191a980e0\n scenario\\_name: Scan for Remote Systems with Common SSH Ports Open\n is\\_multi\\_asset: false\n '1':\n id: '1'\n args:\n port: 22\n user: ubuntu\n target\\_type: all\n context\\_hosts: true\n is\\_attack\\_graph: true\n command\\_to\\_execute: whoami\n context\\_credentials: false\n certificate\\_private\\_key: >-\n -----BEGIN RSA PRIVATE KEY-----\n MIIEpAIBAAKCAQEA+TqfQJSaPifxk8K/OtG7Vwus/Ffnrs6mWPmLpL61nx4Dnz2EzChu3LRhKHPs\n rGEwNb3IwFwZjhEUm/kBOS7Sp+fzLXBIyUZwV+68hP1JdqIEV4OIovjsrAoCO128bMvu0dwEq5qP\n gjcrGI2b70lEJFJR09IWikb8WqxTmxT4duJ3jIi4sWC8LcQmE3ea2CMc6dknKL8W+w+2md1ZNdvF\n KWSody0S7SOg3DIA5mWo632/A2EHr96zH81KiV1CFunLdwb7pb8D8pURMjfMHrmqqXTogOR4WV2q\n GPHw3kE3Hqrd8zcKrhngMv0xankHZ3e5Uu8qbECzpIkG9G0cpuQJhQIDAQABAoIBAQCGWBpGFpR6\n Us++5ahtTWbdyhZqQ/xIV26F4aZrnL2MUwKC0QeHgXgZEkaZJrv6Q71YCsBvKHZCBWUFmpkVOO8m\n wTptUOx7SrP+QltumJYEE9uhTO7XYrU5G4AOfj22q8tFZoNB+WPIPnLFnnfi6ayIo7MmKkYqLY+U\n VPYQT6KLegHD6dCFzirgVCnhoH/TV7Ab2gxkW+3RxaHGYn9dDNXegb+drnmoRxIpdmoWyCRX0oTg\n 0gzgot+CyImHzzhcsZpNQV69BsBe4C+PaziAgQie3ZRQzEDEnBM8tRohDSz4x8rlFP+4xTsZUXJm\n SIkmbX1NyZ9z0MLoJvSrrEfpFs3hAoGBAPyr3lAyRlmSkHSL5XHiuFefHsLSTYhH26C8As5t808s\n dgFIKuhouO5r/oLQPqUiAj01OnJOe3IXTTdyKvJNx/It2Ykd/5+ExtZlC3xZz/cJBqjS/Pqq9qBk\n y82yrOo2ukf4SrEjM+x5NsFgMfis+2nV04OXvTaU8wRpByJBwWfZAoGBAPyDJPHZ2NW8gcYcg7FK\n LTcF6dVjfgq/yZmlRTiK7xIC/j8vT+mGQmcgwLAsaYe/X90PHA5xr+SP40kGP6MK0p82eB+a0Swr\n TpIcc8kDhPzeXaGKqtGGdAZfMeDGo7MA4IIPatcc7oS5zrNoBRMC7qnb24vzCrvF/3iBz7zclS+N\n AoGAU52s3G1Gyq2uEGObcqzMxHJsA50E+2yMSgzuANJyCml0Q8hWKsM9L+mdOD0h/hPbGdZbmShP\n wdnkO80UWUtUN9jkfHPo/Ck8hAa8XlJ6eA4MniH0hh+9riatK01N29RwoRCR5zz3GfKjJCtpXhog\n uU2BybKVc1KneXYoXjXUg0ECgYA5c6ExQa57GtOv/obcDJNzBG5qdaOU0IQO6DJypfG0+GdeeuZE\n rJ5pFmOg8cnk797gzfJFOwqZBz/gOoK6FtlLDjqQfkn/Ma9DwSN65ckZO4K0IXeyClRVqs0PZkKS\n lK2ACf/2B4ghPKFR4mXdKHqivPobwmV7yZXRlj9sqgdrdQKBgQDusG1m1jfP5sFai00vbg+q/uLx\n yqTDLafVPiaN5idiqRq3fRcXEFwxZcm8zFcFtpt1vJ4Jf5PWfsgrsMZq2UcheG9yGZ6bT6fvOo9q\n cYieReEd9vsyGvLRTHr40NgLFCiT4kPICp/U0zZW2CQJKCuuMva15YFXmFU8l02akfIfYg==\n -----END RSA PRIVATE KEY-----\n use\\_public\\_key\\_authentication: true\n use\\_assessment\\_user\\_privileges: false\n type: local\n step\\_id: '1'\n success: '2'\n position:\n x: -53.89110779779327\n 'y': 328.17344557312987\n runnable: true\n testpoints:\n - 45fd9d0a-7cd9-41f8-a988-2ab496f75577\n scenario\\_id: 8a11b1e6-7df9-4ab2-8500-814240e24bc0\n scenario\\_name: Lateral Movement using SSH\n is\\_multi\\_asset: false\n '2':\n id: '2'\n args:\n scripts:\n - platform: windows\n exit\\_code: 0\n custom\\_iocs:\n - ''\n interpreter: cmd.exe\n script\\_hash: d51e34a47a79465a0ef3916fe01fe667e8e4281ef3b676569e6a1a33419e51ea\n script\\_files: >-\n 4be17c81-a0de-4a7e-acd2-b9bd9f9aeb1c/system\\_information\\_discovery.bat\n success\\_type: with\\_exit\\_code\n env\\_parameters:\n - key: ''\n value: ''\n - platform: linux\n exit\\_code: 0\n custom\\_iocs:\n - ''\n interpreter: /bin/bash\n script\\_hash: b4e7c8a463c04cd1e45e1455af358185c09d144ef3c276ebd4a0fa4c628f153e\n script\\_files: 3b33ee2d-04a6-4a33-b0d5-15d0c91e5857/system\\_information\\_discovery.sh\n success\\_type: with\\_exit\\_code\n env\\_parameters:\n - key: ''\n value: ''\n execute\\_as\\_user: false\n is\\_attack\\_graph: true\n type: local\n step\\_id: '2'\n position:\n x: 317.5205810788899\n 'y': 490.3040184719778\n runnable: true\n testpoints:\n - d2c3220b-a5c6-4d8b-b52b-8b70453a1a4e\n scenario\\_id: 5fbb5e71-6e35-4e2c-8dc6-7ee55be563dd\n scenario\\_name: System Information Discovery Script\n is\\_multi\\_asset: false\nversion: 2\nassigned\\_user\\_privileges: false", "Lyft redesign \u2014 a UX case study\n\nI went to a Design Guru Summit workshop on May 17th. At the workshop,\n\nFrank Yoo\n, Lyft\u2019s head of UX and product design at Lyft, talked about the Lyft re-design. I learned useful design insights from his presentation and I wanted to share some takeaways with my design team at work. On May 26th, I met\nVicki Tan\n, Lyft\u2019s product designer, at Tech in Motion + Verizon Present: Data and Design Tech Talk. She generously shared how their design team did A/B testing, and answered a few questions I had regarding their UX challenges. In order to better support my takeaways presentation, I did extra homework by researching more about the re-design online, and then creating a case study.\n\nWorkshop Notes\n1. Lyft 4 year Overview\nYear 1: Market Fit\nYear 2: Unlocking Supply\nYear 3: Growth \u2014 Growth levers, new regions, marketing (data numbers)\nYear 4: Case Study \u2014 Redesign Lyft\n\n2. Lyft Redesign Goals\n\u009a\u2022 Scale for the future\n\u2022 Provide better context\n\u2022 Improve ergonomics and discoverability\n\n3. Lyft Design Principles\n\u2022 Nail the basics \u2014 Clear choice and context\n\u2022 Build confidence \u2014 Consistency and transparent\n\u2022 Be unique \u2014 Own-able and delightful\n\n1\u20133 are notes I took from\n\nFrank Yoo\n\u2019s presentation at the Design Gurus Summit workshop.\n\nMaslow\u2019s Hierarchy of Needs\nLyft used this concept to define their design principles in a Pyramid shape. I was fascinated by how Lyft integrated psychology to define the principles order of importance.\n\nAs a designer, I often run into situations where people have different ideas about design decisions; it can be tough to judge without any design principles. Therefore, with the encouragement from my colleague\n\nKlara Pelcl\n, I convinced our leadership to let me and\nJules Cheung\ninitiate and collaboratively set core design principles among our design team.\nWe brainstormed together and created our own 6 principles: Know Your User, Clarity, Consistency, Efficiency, Collaboration and Beauty. By looking at Lyft\u2019s design principles graphic, it encouraged me to think about what we can do next to apply them in practice.\n\nOnline Resource\nUX Challenges\nI wanted to know what type of UX challenges Lyft faced while designing the app. I was glad to find some useful resource from Nectar Design, where\n\nFrank\ndid a webinar about how Lyft handles UX challenges, and used the same pyramid method to tackle UX challenges. Here is a summary from Nectar Design:\n\u2022 Usability \u2014 It must solve a compelling user issue\n\u009a\u2022 Reliability \u2014 Everything must work seamlessly and be as transparent as possible (Ex: ride times and costs)\n\u2022 Differentiate \u2014 It must be visually and interactively interesting (Ex: Lyft\u2019s glowing buttons and interactive options menu)\nReasons for Redesign\nDuring the webinar,\n\nFrank\ntalked about the reasons they re-designed the Lyft app, something I wish I could have asked him in person. Again thanks to Nectar Design I was able to find the reasons:\n\u2022 \u009aPoor representation of the driver that is requested\n\u2022 \u009aNo transparency about price or estimated time of arrival\n\u2022 Cars were not directional\n\u2022 \u009aPoor use of color\n\u2022 Options panel awkwardly placed\n\u009a\u2022 Request Lyft is vague for first time users\nSuccess Analysis\nNow you probably want to know what results the Lyft re-design achieved. I might not be able to cover everything here but I\u2019ll share what I have so far.\n\n1. Enhanced Transparency and Safety\nAfter the system matches you with a driver, you can see all the important information you need \u2014 your driver\u2019s name and the color/model of his/her car. More importantly, displaying the driver\u2019s license plate number helps you quickly pick the right car so you know you\u2019re with the right driver.\n2. Better Usage of Primary Color\nFrom what I can see, Lyft uses hot pink as the primary color, and purple as the secondary. During the workshop\n\ntalked about the pink color and how they decided to limit the use of it, applying it only in important situations. My understanding is that they made the pink color an action item color, such as the logo, the \u201cRequest Lyft\u201d button, the destination pin and \u201cFree Rides\u201d on your profile menu.\n\n3. Price Estimate Feature\nThe new UI includes a feature that allows users to get a ride\u2019s quote. By clicking on \u201cPrice estimate\u201d (see the image above), you have a good understanding of how much the ride is going to cost you. For example, a trip to Spicy King restaurant in Chinatown will cost me about $7-$11 from my pickup location.\n\n4. Made It Ergonomic\nErgonomics make the user experience much better. The older app design had actions at both the top and bottom of the screen, which made it harder to use because your fingers had to cross the screen back and forth. What about the new design? I really like it myself as a user for the following reasons:\n\n\u2022 Tab Menu\nAll important menu actions are now at the bottom of the app, where you can select a type of ride you need (Carpool, Line, Regular Lyft, Plus and Premier), and you can set a pickup location right after. The UI for further actions in the request flow are also located in the same spot, resulting in a seamless experience.\n\u2022 Lyft Cars\nOn the map, the little Lyft cars were re-designed nicely, with a hint of pink and purple that shows color consistency across the app. Cars now turn directionally, which is a big help to people like me who don\u2019t have a great sense of direction with maps \u2014 I can now easily figure out if the car I requested is heading towards my location or if the driver is going the opposite way (which also explains why sometime it takes longer than the estimated arrival time).\n\u2022 Options Before Car Arrival\nThe new UI provides 4 options (Cancel, Split, Send ETA, Call driver) to users before their car arrives. I remember the hard time I had with the older UI, when I had to call my driver but couldn\u2019t find the button. Ease of use is much greater with all the options displayed up in front.\nUX Research\nLyft has different type of users \u2014 passengers and drivers, how does UX research collaborate with design? As I mentioned in the beginning,\n\nVicki Tan\nshared her insights during the panel at Tech in Motion + Verizon Present: Data and Design Tech Talk, where I learned quite a bit about their research.\n\u2022 Qualitative data vs. Quantitative data\nLike many other companies, Lyft is metrics-driven and focuses on quantitative analysis (usually the numbers and graphs can be shared with the teams and the stakeholders in many formats, such as email, keynotes). However, quantitative data needs analysis to be useful. Because of that, qualitative data comes in handy and that\u2019s what they focus on more now.\n\n\u2022 Gather User Feedback\nAccording to\n\n, Lyft invites real users (both passengers and drivers) to do regular weekly Q&A sessions in the office to ask them questions and listen to their feedback. By doing so, the design team learns if the users understand the features and what can be improved.\nI believe Lyft also uses other methods to collect qualitative data, so I did some research online and it looks like Lyft has been using \u201cLookback\u201d to aggregate a database of experiences where they can generate a montage of user feedback to better understand their needs. I tried \u201cLookback\u201d a few months ago, and found it very easy to record prototype testing on mobile. At my company, our design and UX research team have been using \u201cValidately\u201d to do both moderated and unmoderated testing.\n\n\u2022 A/B testing\nDuring re-design progress, Lyft ran many A/B tests. As a result,\n\nfound that the design they wanted was not the design the users wanted. At work, my design team faces this struggle all the time where we have different assumptions about what works for users the best. Without A/B testing, we are essentially designing features that suit our best interests, and might not be what the real users need.\n\u2022 Outcome\nAccording to Nectar Design, Lyft has conducted hundreds of hours of user testing and validates their assumptions along the way. This is good because it builds confidence in the team, stakeholders, and customers.\n\nConclusion\nHere is what I learned from doing this case study:\n\nOrganizing and structuring design principles is just as important as creating them in the first place. I\u2019ll continue finding ways to better structure the design principles we created at work, and visualize them so that everyone can get a good understanding of it across the organization.\nDon\u2019t be afraid of doing product re-designs. If you have good reasons and understand what the usability issues are, start planning! Get to know your real users \u2014 user testing is the key. Collect as much quantitative user behavior data as you can, then analyze and categorize them to make sure you have solid qualitative data to support re-design thinking. Follow the cycle of design, release, get user feedback and iterate.\nLyft\u2019s re-design is a great example to show how to create a successful product. If you care about your users, put yourself in their shoes to understand what they need and what they actually do when using a product. If you don\u2019t have a UX research team yet, build one or become a researcher yourself! At work, I work closely with our UX research team, they help the design team tons by recruiting users, setting up user testing, and analyzing the massive data comes in every month. Thanks to their hard work, the design team can take over the numbers and metrics, analyze further to define specific usability areas, and to communicate re-design decisions to our leadership.\nLyft\u2019s re-design case study helped me understand how other companies generate business value by implementing great design in both UI and UX. It gives me confidence that if we apply similar principles, and keep doing what we are doing on UX research, our product team can help the company product achieve much more success in the near future.\n\nGive an overview of this case study", "using System;\nusing System.Collections.Generic;\nusing System.Linq;\nusing System.Text;\nusing System.Threading.Tasks;\nusing Love;\n\nnamespace LoveCSharp\n{\n class Program : Scene\n {\n public Player player1;\n public static float deltaTime;\n static void Main(string[] args)\n {\n Boot.Init();\n Boot.Run(new Program());\n }\n public override void Load()\n {\n World.Generate(20,20);\n player1 = new Player(5, 5);\n\n // Love.Mouse.SetVisible(false);\n // Love.Mouse.SetGrabbed(true);\n Love.Mouse.SetRelativeMode(true);\n \n }\n public override void Draw()\n {\n Ray.Draw(player1.x, player1.y, Ray.distance, player1.angle, player1.fov);\n World.Draw();\n player1.Draw();\n \n }\n public override void Update(float dt)\n {\n deltaTime = dt;\n player1.Update(dt);\n Ray.Update(player1.x, player1.y, player1.angle, player1.fov);\n if (Love.Keyboard.IsDown(KeyConstant.Escape))\n {\n Love.Event.Quit();\n }\n }\n public override void MouseMoved(float x, float y, float dx, float dy, bool istouch)\n {\n player1.Rotation(dx);\n }\n }\n public enum TileType\n {\n None,\n Block,\n }\n public class World\n {\n public static int width;\n public static int height;\n public static int scale = 10;\n public static TileType[,] tiles;\n public static void Generate(int width = 20, int height = 20)\n {\n World.width = width;\n World.height = height;\n\n TileType[,] tiles = new TileType[width, height];\n\n for (int x = 0; x < width; x++)\n {\n for (int y = 0; y < height; y++)\n {\n tiles[x, y] = TileType.Block;\n }\n }\n for (int x = 0; x < width; x++)\n {\n \n for (int y = 0; y < height; y++)\n {\n if ((x > 0 && x < width - 1) && (y > 0 && y < height - 1))\n {\n tiles[x, y] = TileType.None;\n }\n }\n }\n // Generate a random number of TileType blocks in the world (tiles)\n Random random = new Random();\n int blockCount = random.Next(10, 20);\n for (int i = 0; i < blockCount; i++)\n {\n int x = random.Next(0, width);\n int y = random.Next(0, height);\n tiles[x, y] = TileType.Block;\n }\n \n World.tiles = tiles;\n }\n public static void Draw()\n {\n Graphics.SetColor(Color.White);\n Graphics.Rectangle(DrawMode.Line, 0, 0, width \\* scale, height \\* scale);\n\n Graphics.SetColor(Color.Firebrick);\n for (int x = 0; x < width; x++)\n {\n for (int y = 0; y < height; y++)\n {\n if (tiles[x, y] == TileType.Block)\n {\n Graphics.Rectangle(DrawMode.Fill, x \\* scale, y \\* scale, scale, scale);\n }\n }\n }\n }\n }\n public class Player\n {\n public float x, y, w, h, speed, angle, directionX, directionY;\n public float sensitivity = 0.3f;\n public int fov = 60;\n public Player(float x, float y, float w = 30, float h = 50, float speed = 1, float angle = 0)\n {\n this.x = x;\n this.y = y;\n this.w = w;\n this.h = h;\n this.speed = speed;\n this.angle = angle;\n }\n public void Draw()\n {\n Graphics.SetColor(Color.AliceBlue);\n Graphics.SetPointSize(3);\n Graphics.Points(this.x \\* World.scale, this.y \\* World.scale);\n Graphics.SetColor(Color.White);\n Graphics.Print(\"X: \" + this.x + \" Y: \" + this.y, 0, 0);\n Graphics.Print(\"Angle: \" + this.angle, 0, 20);\n }\n public void Update(float dt)\n {\n Movement(dt);\n\n }\n\n private void Movement(float dt)\n {\n float directionX = 0;\n float directionY = 0;\n if (Keyboard.IsDown(KeyConstant.W))\n {\n directionY = -1;\n }\n if (Keyboard.IsDown(KeyConstant.S))\n {\n directionY = 1;\n }\n if (Keyboard.IsDown(KeyConstant.A))\n {\n directionX = -1;\n }\n if (Keyboard.IsDown(KeyConstant.D))\n {\n directionX = 1;\n }\n\n float rotatedDirectionX = (float)Math.Cos(this.angle) \\* directionX - (float)Math.Sin(this.angle) \\* directionY;\n float rotatedDirectionY = (float)Math.Sin(this.angle) \\* directionX + (float)Math.Cos(this.angle) \\* directionY;\n\n float directionLength = (float)Math.Sqrt(rotatedDirectionX \\* rotatedDirectionX + rotatedDirectionY \\* rotatedDirectionY);\n if (directionLength > 0)\n {\n rotatedDirectionX /= directionLength;\n rotatedDirectionY /= directionLength;\n }\n\n this.x += rotatedDirectionX \\* this.speed \\* dt;\n this.y += rotatedDirectionY \\* this.speed \\* dt;\n }\n public void Rotation(float dx)\n {\n this.angle += dx \\* sensitivity \\* Program.deltaTime;\n \n }\n }\n public class Ray\n {\n public static float distance;\n\n public static float Cast(float x, float y, float centerAngle, float fov)\n {\n float startX = x;\n float startY = y;\n string section;\n float quality = 0.1f;\n int screenWidth = 800;\n int screenHeight = 600;\n\n for (float angle = centerAngle - fov / 2; angle < centerAngle + fov / 2; angle += Quality(fov, quality, screenWidth))\n {\n float endX = (float)(startX + Math.Cos(angle) \\* 1000);\n float endY = (float)(startY + Math.Sin(angle) \\* 1000);\n\n section = FacingSection(angle);\n\n if (section == \"NE\")\n {\n for (float i = startX; i < endX; i += quality)\n {\n float j = (float)(startY + (i - startX) \\* Math.Tan(angle));\n if (World.tiles[(int)i / World.scale, (int)j / World.scale] == TileType.Block)\n {\n distance = Distance(startX, startY, i, j);\n return distance;\n }\n }\n }\n else if (section == \"NW\")\n {\n for (float i = startX; i > endX; i -= quality)\n {\n float j = (float)(startY + (i - startX) \\* Math.Tan(angle));\n if (World.tiles[(int)i / World.scale, (int)j / World.scale] == TileType.Block)\n {\n distance = Distance(startX, startY, i, j);\n return distance;\n }\n }\n }\n else if (section == \"SW\")\n {\n for (float i = startX; i > endX; i -= quality)\n {\n float j = (float)(startY + (i - startX) \\* Math.Tan(angle));\n if (World.tiles[(int)i / World.scale, (int)j / World.scale] == TileType.Block)\n {\n distance = Distance(startX, startY, i, j);\n return distance;\n }\n }\n }\n else if (section == \"SE\")\n {\n for (float i = startX; i < endX; i += quality)\n {\n float j = (float)(startY + (i - startX) \\* Math.Tan(angle));\n if (World.tiles[(int)i / World.scale, (int)j / World.scale] == TileType.Block)\n {\n distance = Distance(startX, startY, i, j);\n return distance;\n }\n }\n }\n }\n return 0;\n }\n public static string FacingSection(float angle)\n {\n string facing = \"\";\n if (angle >= 0 && angle < Math.PI / 2)\n {\n facing = \"NE\";\n }\n else if (angle >= Math.PI / 2 && angle < Math.PI)\n {\n facing = \"NW\";\n }\n else if (angle >= Math.PI && angle < 3 \\* Math.PI / 2)\n {\n facing = \"SW\";\n }\n else if (angle >= 3 \\* Math.PI / 2 && angle < 2 \\* Math.PI)\n {\n facing = \"SE\";\n }\n return facing;\n }\n public static float Quality(float fov, float quality, float screenWidth)\n {\n \n // float angle = fov / screenWidth;\n // quality = angle / quality;\n // return quality;\n float angleBetweenRays = fov / screenWidth;\n float qualityAngle = (float)Math.Atan(quality / 2);\n float qualityAngleBetweenRays = qualityAngle / angleBetweenRays;\n return qualityAngleBetweenRays;\n }\n\n public static float Distance(float x1, float y1, float x2, float y2)\n {\n float distance = (float)Math.Sqrt((x2 - x1) \\* (x2 - x1) + (y2 - y1) \\* (y2 - y1));\n return distance;\n }\n\n public static void Draw(float x, float y, float distance, float angle, float fov)\n {\n \n float angleBetweenRays = fov / 800;\n float distanceToProjectionPlane = 800 / (2 \\* (float)Math.Tan(fov / 2));\n float distanceToWall = distance;\n float distanceToProjectionPoint = distanceToWall \\* (float)Math.Cos(angleBetweenRays);\n distanceToProjectionPlane = distanceToProjectionPoint \\* distanceToProjectionPlane / distanceToWall;\n float height = 600 / distanceToProjectionPlane;\n float width = 1;\n float color = 255 / distanceToWall;\n Graphics.SetColor(Color.FromRGBA(color, color, color, 255));\n Graphics.Rectangle(DrawMode.Fill, x, y - height / 2, width, height);\n \n\n }\n public static void Update(float x, float y, float angle, float fov)\n {\n Cast(x, y, angle, fov);\n \n \n }\n }\n}", "using System;\nusing System.Collections.Generic;\nusing System.Linq;\nusing System.Text;\nusing System.Threading.Tasks;\nusing Love;\n\nnamespace LoveCSharp\n{\n class Program : Scene\n {\n public Player player1;\n public static float deltaTime;\n static void Main(string[] args)\n {\n Boot.Init();\n Boot.Run(new Program());\n }\n public override void Load()\n {\n World.Generate(20,20);\n player1 = new Player(5, 5);\n\n // Love.Mouse.SetVisible(false);\n // Love.Mouse.SetGrabbed(true);\n Love.Mouse.SetRelativeMode(true);\n \n }\n public override void Draw()\n {\n World.Draw();\n player1.Draw();\n Ray.Draw(player1.x, player1.y, Ray.distance, player1.angle, player1.fov);\n \n }\n public override void Update(float dt)\n {\n deltaTime = dt;\n player1.Update(dt);\n Ray.Update(player1.x, player1.y, player1.angle, player1.fov);\n if (Love.Keyboard.IsDown(KeyConstant.Escape))\n {\n Love.Event.Quit();\n }\n }\n public override void MouseMoved(float x, float y, float dx, float dy, bool istouch)\n {\n player1.Rotation(dx);\n }\n }\n public enum TileType\n {\n None,\n Block,\n }\n public class World\n {\n public static int width;\n public static int height;\n public static int scale = 10;\n public static TileType[,] tiles;\n public static void Generate(int width = 20, int height = 20)\n {\n World.width = width;\n World.height = height;\n\n TileType[,] tiles = new TileType[width, height];\n\n for (int x = 0; x < width; x++)\n {\n for (int y = 0; y < height; y++)\n {\n tiles[x, y] = TileType.Block;\n }\n }\n for (int x = 0; x < width; x++)\n {\n \n for (int y = 0; y < height; y++)\n {\n if ((x > 0 && x < width - 1) && (y > 0 && y < height - 1))\n {\n tiles[x, y] = TileType.None;\n }\n }\n }\n // Generate a random number of TileType blocks in the world (tiles)\n Random random = new Random();\n int blockCount = random.Next(10, 20);\n for (int i = 0; i < blockCount; i++)\n {\n int x = random.Next(0, width);\n int y = random.Next(0, height);\n tiles[x, y] = TileType.Block;\n }\n \n World.tiles = tiles;\n }\n public static void Draw()\n {\n Graphics.SetColor(Color.White);\n Graphics.Rectangle(DrawMode.Line, 0, 0, width \\* scale, height \\* scale);\n\n Graphics.SetColor(Color.Firebrick);\n for (int x = 0; x < width; x++)\n {\n for (int y = 0; y < height; y++)\n {\n if (tiles[x, y] == TileType.Block)\n {\n Graphics.Rectangle(DrawMode.Fill, x \\* scale, y \\* scale, scale, scale);\n }\n }\n }\n }\n }\n public class Player\n {\n public float x, y, w, h, speed, angle, directionX, directionY;\n public float sensitivity = 0.3f;\n public int fov = 60;\n public Player(float x, float y, float w = 30, float h = 50, float speed = 1, float angle = 0)\n {\n this.x = x;\n this.y = y;\n this.w = w;\n this.h = h;\n this.speed = speed;\n this.angle = angle;\n }\n public void Draw()\n {\n Graphics.SetColor(Color.AliceBlue);\n Graphics.SetPointSize(3);\n Graphics.Points(this.x \\* World.scale, this.y \\* World.scale);\n Graphics.SetColor(Color.White);\n Graphics.Print(\"X: \" + this.x + \" Y: \" + this.y, 0, 0);\n Graphics.Print(\"Angle: \" + this.angle, 0, 20);\n }\n public void Update(float dt)\n {\n Movement(dt);\n\n }\n\n private void Movement(float dt)\n {\n float directionX = 0;\n float directionY = 0;\n if (Keyboard.IsDown(KeyConstant.W))\n {\n directionY = -1;\n }\n if (Keyboard.IsDown(KeyConstant.S))\n {\n directionY = 1;\n }\n if (Keyboard.IsDown(KeyConstant.A))\n {\n directionX = -1;\n }\n if (Keyboard.IsDown(KeyConstant.D))\n {\n directionX = 1;\n }\n\n float rotatedDirectionX = (float)Math.Cos(this.angle) \\* directionX - (float)Math.Sin(this.angle) \\* directionY;\n float rotatedDirectionY = (float)Math.Sin(this.angle) \\* directionX + (float)Math.Cos(this.angle) \\* directionY;\n\n float directionLength = (float)Math.Sqrt(rotatedDirectionX \\* rotatedDirectionX + rotatedDirectionY \\* rotatedDirectionY);\n if (directionLength > 0)\n {\n rotatedDirectionX /= directionLength;\n rotatedDirectionY /= directionLength;\n }\n\n this.x += rotatedDirectionX \\* this.speed \\* dt;\n this.y += rotatedDirectionY \\* this.speed \\* dt;\n }\n public void Rotation(float dx)\n {\n this.angle += dx \\* sensitivity \\* Program.deltaTime;\n \n }\n }\n public class Ray\n {\n public static float distance;\n\n public static float Cast(float x, float y, float centerAngle, float fov)\n {\n float startX = x;\n float startY = y;\n string section;\n float quality = 0.1f;\n int screenWidth = 800;\n int screenHeight = 600;\n\n for (float angle = centerAngle - fov / 2; angle < centerAngle + fov / 2; angle += Quality(fov, quality, screenWidth))\n {\n float endX = (float)(startX + Math.Cos(angle) \\* 50);\n float endY = (float)(startY + Math.Sin(angle) \\* 50);\n\n section = FacingSection(angle);\n\n if (section == \"NE\")\n {\n for (float i = startX; i < endX; i += quality)\n {\n float j = (float)(startY + (i - startX) \\* Math.Tan(angle));\n if (World.tiles[(int)i / World.scale, (int)j / World.scale] == TileType.Block)\n {\n distance = Distance(startX, startY, i, j);\n return distance;\n }\n }\n }\n else if (section == \"NW\")\n {\n for (float i = startX; i > endX; i -= quality)\n {\n float j = (float)(startY + (i - startX) \\* Math.Tan(angle));\n if (World.tiles[(int)i / World.scale, (int)j / World.scale] == TileType.Block)\n {\n distance = Distance(startX, startY, i, j);\n return distance;\n }\n }\n }\n else if (section == \"SW\")\n {\n for (float i = startX; i > endX; i -= quality)\n {\n float j = (float)(startY + (i - startX) \\* Math.Tan(angle));\n if (World.tiles[(int)i / World.scale, (int)j / World.scale] == TileType.Block)\n {\n distance = Distance(startX, startY, i, j);\n return distance;\n }\n }\n }\n else if (section == \"SE\")\n {\n for (float i = startX; i < endX; i += quality)\n {\n float j = (float)(startY + (i - startX) \\* Math.Tan(angle));\n if (World.tiles[(int)i / World.scale, (int)j / World.scale] == TileType.Block)\n {\n distance = Distance(startX, startY, i, j);\n return distance;\n }\n }\n }\n }\n return 0;\n }\n public static string FacingSection(float angle)\n {\n string facing = \"\";\n if (angle >= 0 && angle < Math.PI / 2)\n {\n facing = \"NE\";\n }\n else if (angle >= Math.PI / 2 && angle < Math.PI)\n {\n facing = \"NW\";\n }\n else if (angle >= Math.PI && angle < 3 \\* Math.PI / 2)\n {\n facing = \"SW\";\n }\n else if (angle >= 3 \\* Math.PI / 2 && angle < 2 \\* Math.PI)\n {\n facing = \"SE\";\n }\n return facing;\n }\n public static float Quality(float fov, float quality, float screenWidth)\n {\n \n // float angle = fov / screenWidth;\n // quality = angle / quality;\n // return quality;\n float angleBetweenRays = fov / screenWidth;\n float qualityAngle = (float)Math.Atan(quality / 2);\n float qualityAngleBetweenRays = qualityAngle / angleBetweenRays;\n return qualityAngleBetweenRays;\n }\n\n public static float Distance(float x1, float y1, float x2, float y2)\n {\n float distance = (float)Math.Sqrt((x2 - x1) \\* (x2 - x1) + (y2 - y1) \\* (y2 - y1));\n return distance;\n }\n\n public static void Draw(float x, float y, float distance, float angle, float fov)\n {\n \n float angleBetweenRays = fov / 800;\n float distanceToProjectionPlane = 800 / (2 \\* (float)Math.Tan(fov / 2));\n float distanceToWall = distance;\n float distanceToProjectionPoint = distanceToWall \\* (float)Math.Cos(angleBetweenRays);\n distanceToProjectionPlane = distanceToProjectionPoint \\* distanceToProjectionPlane / distanceToWall;\n float height = 600 / distanceToProjectionPlane;\n float width = 1;\n float color = 255 / distanceToWall;\n Graphics.SetColor(Color.FromRGBA(color, color, color, 255));\n Graphics.Rectangle(DrawMode.Fill, x, y - height / 2, width, height);\n \n\n }\n public static void Update(float x, float y, float angle, float fov)\n {\n Ray.distance = Cast(x, y, angle, fov);\n \n \n }\n }\n}", "please review this set of responses to the question \"what are the value plays we should focus on\" and look for common themes in the responses. Present these in a table format with a short name, description, and identify all individuals who made reference to this theme in their response\n\n1. Supplied\n 1. Acquire and Develop Talent capable of delivering Platform vision\n 2. Modernized internal stack capable of meeting the needs of a cloud-first business\n 3. Best in class investor management through transformation process, as we delicately manage the growth of platform offerings in a way that doesn't negatively impact our valuation in the long term\n 4. Decreasing our capital intensity through operating efficiencies driven by technology and automation \n 5. Developing a suite of digital platform solutions from solving cloud issues to digital transformations \n 6. Building a partner ecosystem to expand and support our offerings\n 7. Solving go-to-market, legal, and financial compliance challenges related to operating a platform business internationally\n \n2. Brandi\n \u00b7 \u2026Modernized internal stack capable of meeting the needs of a cloud-first business.\n \u00b7 Evolve culture to accelerate delivery of platform vision\n \u00b7 Acquire and develop talent fit for platform vision\n \n3. Bruce\n \u00b7 Be public about a quantifiable aspiration/goal to fuel urgency (e.g. Interconnection revenue or yield)\n \u00b7 Get org rallied around a shared vision and then be very targeted in culture change (e.g. agile) and skills change needed in specific pockets of the org to deliver digital transformation. Ie. We need everyone to understand our vision, but we can be targeted on the where need new skills/capabilities\n \u00b7 Enhance our local market and customer listening to drive innovation, using customer base for rapid beta testing or prototypes.\n \n4. Charles\n 1. IBX Footprint\n 2. Service Offerings\n a. Colo\n b. Mgd Services\n c. Edge Infra (Network Edge and Colo by the U)\n d. Cloud Networking\n 3. Digital Experience (likely starts as somewhat parallel experiences for DCS vs DS offerings but implies a merged experience over time)\n a. Process\n b. Systems\n 4. Ecosystem Enablement (huge area of opportunity and under-investment)\n a. APIs\n b. SDKs (that\u2019s all the acronyms I know but I\u2019m pretty sure we have a lot of work to do)\n 5. Customers \u2013 need to define target personas and align GTM motions to specific customer/persona combinations\n 6. Ecosystem Development\n a. JPS/\u201dintegrated\u201d\n b. Self-serve (use self-serve tools to bring your offering to the Platform)\n c. Communities of Interest/Vertical Ecosystems (BD to cultivate)\n 7. Marketplace (what we need, not what we have now)\n\n \n \n5. Jon\n \u00b7 Modernized quote-to-cash stack that allows for low/no-touch customer acquisition and onboarding, and global billing capabilities.\n \u00b7 Having clear, measurable ROIC for digital services with clear cost structures by product line.\n \u00b7 Building integrated partner offerings that allow partners to package/sell/support our offerings with low/no-touch for Equinix.\n \u00b7 Creating clear BU and product-level P&L reporting, inclusive of capex and opex.\n \u00b7 Having the clear ability to calculate LTV/CAC by product.\n \n6. Justin\n \u00b7 Investing in a modern API-first technology stack to be able to effectively leverage developer ecosystems to (1) co-drive disruptive, agile innovation; (2) create new business models; (3) enable seamless API-based technology partner integration; and (4) reduce channel friction.\n \u00b7 Continuing to improve Equinix\u2019s visibility and credibility in developer ecosystems to attract world-class talent capable of delivering on our Platform vision.\n \u00b7 Investing in an innovation incubator with dedicated engineering resources, and frameworks in place to engage and co-innovate with external developers and startups with agility, to boost innovation (radical innovation, adjacent innovation, or core innovation), supported by an accelerated incubation model.\n \n7. Karl\n \u00b7 \u2026seriously vet and conclude on inorganic options to accelerate our capability set to deliver the suite of services required. (Contemplates the addition of talent, tech, and product needed to accelerate)\n \u00b7 \u2026successfully launch AND scale Joint partner solutions that prove we are indeed the home of the dedicated cloud and can offer solutions via partners at scale.\n \u00b7 \u2026neutralize the complexity of workload tiering and demand shaping by having both retail and wholesale solutions to large and performance based deployments.\n \n \n8. Keith\n \u00b7 Developing a platform on Equinix DCS assets, and potentially extending these services to other non-Equinix assets.\n \u00b7 Potentially acquiring talent or service capabilities and integrating onto the Equinix Platform.\n \u00b7 Merging our business into an existing business and integrating onto the Equinix Platform.\n \u00b7 Exclusively expand our GTM partnerships with a number of critical providers that imbeds our service offering into their solution.\n \n9. Kurt\n \u00b7 \u2026Honestly, I think the above list is a really good list. I am struggling to add anything to it. \n \u00b7 If I had to, I would say we need a capability of coming to agreement more quickly on complex issues impacting our delivery and development of services. We are currently wrestling with issues that we have known for year. Channel complications (same ones) have been on the table for years, tax structure has been on the table for years and we actually built a tax structure no one is using a while back, we have known about billing issues since we bought packet, etc. The problem is, as soon as folks hear \u201chard problem\u201d they retreat and we don\u2019t move. To date, we have really struggled to resolve these issues quickly enough and with certainty for a time. I would never say we need decisions that last forever as we need to be agile, but the word I hear a lot on the street is the team is \u201cWhipsawed.\u201d It feels like folks run to work on something based on an agreement and then it changes a few months out, not usually with a discussion. \n \u00b7 With that said, the list above actually sounds great to me. We need the right talent, working on the right stuff, for the right customers, and the story will tell itself.\n \n10. Mike\n \u00b7 Acquire and Develop Talent capable of delivering our Platform vision.\n \u00b7 Build a partner ecosystem to expand and support our offerings.\n \u00b7 Begin to market ourselves as a company that provides a lot more than colocation services to different personas than we market to today.\n \u00b7 Find a way to use xScale facilities to help with our Retail and Digital space constraints.\n \n11. Milind\n\n12. Nicole \n\u00b7 People/Workforce/Brand:\n \u00b7 Specific declaration on future state vision (internally). Take any guesses or confusion off the table immediately and ensure all functions are clear on how they play a role in that vision. \n \u00b7 T&A to drive talent into the workforce that has experience suited for our vision (less telco, more software, service provider, etc..). \n \u00b7 Marketing driving significant brand shift externally to ensure customers see us as a platform company. We are moving away from data center only branding. (This likely requires a CMO strategy) \n \u00b7 Drive more accountability with our GLO population to lead from the front and be transformational leaders. Communicate often, effectively, and more intimately with this group so they are 100% clear on the strategy and role they play in the transformation. Have courage to take swift action if leaders can\u2019t make the turn. This group of leaders will make or break us future state. \n\u00b7 Growth and Bookings: \n \u00b7 Global salesforce enabled and delivering balanced performance and growth targets across the product portfolio. \n \u00b7 Internal functions working towards common vision and solving problems in partnership and at pace. \n \u00b7 Specific and strategic synergy plans formally in place across critical enterprise partnerships (Dell, VMW, HPE)\n \u00b7 Sustainability efforts clearly defined, articulated, and structured goaling for internal leadership in place. \n \u00b7 Product clarity in digital space. What products, to what market, etc.. Keep this simple so sales can accelerate the strategy. Complexity will slow our pace. \n \n\u00b7 Systems/Tools/Processes\n \u00b7 Modernize our internal stack to be able to provide a customer experience needed for digital scale. Be progressive and aggressive in our IT shift. Don\u2019t always think about \u201cbuild\u201d motions, also look at \u201cbuy\u201d motions to implement with speed. \n \u00b7 Data Transformation strategy in place (as part of our overall digital transformation strategy) in place to ensure Network Transformation, MDM/Analytics, etc, have structured execution dates (with timelines) and are scaling to enable faster decisions with more data driven insights. \n \u00b7 Real time capacity management tools that help us balance DCS and DS needs by data center (I am not sure how mature these are today, and am assuming we will need advancement here). \n \u00b7 API mandatory for all new builds. Basically, no more in house building that aren\u2019t API enabled. \n\n \n13. PVC\n \u00b7 \u2026If I accurately understand the list, 1, 2, 5, and 6 are areas I\u2019d apply energy\u2026.. 3, 4, and 7 will draw effort, but should naturally occur as we progress in the others. \n \n14. Raouf\n \u00b7 \u2026The right talent to build the products and scale the \u201cwrapper\u201d service model. \n \u00b7 Modernized systems to support DS but also Enterprise support ready. \n \u00b7 Network/DS architecture to scale and have the right unto cost. Truly support on demand growth and ramp for customers. \n \u00b7 Solve go to market approach for combined customers from contracting, ordering and billing to support. \n \n15. Ryan\n 1. Acquire and develop talent capable of delivering Platform vision.\n 2. Overhaul internal systems and processes to enable efficiency and improved experience for customers and front-line employees. \n 3. Instill agility into culture and processes. \n \n16. Scott\n \u00b7 It is hard to improve upon the ones listed, but I'd change the last to read:\n \u00b7 Creating a highly competitive transactional, legal, and financial operating model necessary for the on-demand SaaS/cloud market\n \u00b7 And I'd add:\n \u00b7 Build the optimal platform to capture cloud-adjacent workloads and data. \"Platform\" is inclusive of our offerings and integrated offerings from ecosystem partners.", "can you do the same with this list, main body area and nested areas. If the area is not an anatomic are than ignore please\n\n teeth.\n face, neck, body.\n lower face, neck, and jawline.\n severe cystic acne.\n face, neck, and body.\n lower layers of skin tissue.\n laryngeal prominence of thyroid cartilage in the throat.\n facial rejuvenation.\n abdomen, hips, thighs, arms, buttocks, or under the chin.\n nostrils.\n Face and body \n upper or lower jawbone.\n facial reconstruction, abdominal wall reconstruction, breast reconstruction.\n gastric.\n nipple-areola complex.\n underarms.\n balding, thinning, or receding areas.\n nasolabial folds, or smile lines.\n small, uncomplicated spider veins and small varicose veins.\n cellulite on the thighs and buttocks.\n mild to severe acne.\n upper or lower back.\n mustache, beard, sideburns.\n face, cheeks, under-eyes, lips, nasolabial folds, pitted scars, breasts, buttocks.\n face.\n navel.\n moderate to severe facial wrinkles and folds, such as nasolabial folds, etched-in lip lines, crow's feet, smile lines, marionette lines, under-eye tear troughs, and deep glabellar lines.\n upper arms.\n incision or injury.\n face, neck, chest, back, hands, arms, and legs.\n abdomen, hips, lower back, buttocks.\n stomach, legs, arms.\n stomach, thighs, butt, hips, and arms.\n fat reduction anywhere on the body, most commonly treated body areas are the tummy, hips, thighs, flanks (aka love handles), and back. some providers also offer mini bodyfx, which can treat smaller fat deposits in areas like the upper arms and under the chin..\n abdomen, upper arms, thighs, knees, love handles, breasts, back, chin, jowls, cheeks, and neck.\n crow's feet, frown lines, forehead lines, lip lines, bunny lines on the nose, chin wrinkles, neck bands, above the eyebrows, above the upper lip.\n teeth straightening.\n buttocks, hips, waist, love handles, thighs, lower back.\n buttocks.\n breasts.\n face.\n face, neck, d'colletage, back of hands.\n double chin, jawline, knees, elbows, upper arms, muffin top.\n face, body contouring.\n teeth.\n face, neck, hands, chest, legs, and other areas.\n glabellar area.\n forehead and eyebrows.\n lower cheeks.\n foot.\n buttocks, hips, abdomen, waistline, lower back, thighs.\n lower legs.\n lower legs.\n outer corner of the eye where the upper and lower lid meet.\n scalp.\n breast.\n face, neck, arms, stomach, buttocks, and legs.\n lens of the eye.\n cellulite dimples on the buttocks and the backs of the thighs.\n thighs, abdomen, or buttocks.\n midface.\n midface.\n cheeks.\n midface.\n zygomatic bone (malar bone).\n face, neck, chest, hands.\n soft tissue under the skin.\n lower face.\n under the chin and jawline.\n fine lines, shrink the appearance of pores, improve skin tone and texture, and reduce melasma.\n teeth straightening.\n jawbone.\n face, neck, chest, lips, and anywhere on the body.\n broken capillaries, spider veins, vascular lesions, periorbital veins, skin discoloration.\n upper lip, nose, and roof of the mouth.\n clitoral hood.\n face, neck, chest.\n vagina and vulva.\n crow's feet, fine lines around the eyes, smile lines, frown lines, atrophic acne scars, and thin lips.\n brow, mid- and lower face, jawline, and neck.\n fine lines and wrinkles, sun damage, discoloration, and acne scars.\n fine lines and wrinkles, acne scars, large pore size, uneven skin tone, rough skin texture, age spots, and other signs of sun damage.\n abdomen, flanks, bra fat, inner and outer thighs, back fat, upper arms, buttock rolls, knees, hips, mons pubis, submental fat.\n thighs, butt, and abdomen.\n hyperpigmentation and skin discoloration.\n abdominal fat, love handles, upper arms, inner thighs, under chin, below buttocks, bra and back fat bulges.\n slimming, toning, and cellulite reduction.\n face.\n skin.\n teeth.\n teeth straightening.\n glabellar lines, forehead furrows, crow's feet, bunny lines, platysmal bands, dimpling of the chin, masseter muscles.\n middle and lower areas of the face.\n face, eyes, neck.\n teeth.\n jawbone, gums.\n missing teeth.\n teeth.\n upper or lower jawbone.\n face, eyes, lips.\n face, upper lip, cheeks.\n smile lines, marionette lines, lips, under-eye hollows, cheeks, temples, jawline, chin, nose.\n face, neck, chest, stomach, thighs.\n face.\n skin tightening.\n face, neck, d'colletage, body.\n abdominal muscles.\n chin or cheeks.\n vaginal tissue.\n craniofacial region.\n upper eyelids.\n stomach and small intestine.\n front of natural teeth.\n \n face, neck, chest, arms, back of hands, and elsewhere on the body.\n legs, buttocks, thighs, back, or stomach.\n teeth.\n face, neck, under chin.\n skin.\n hormonal acne, polycystic ovary syndrome (pcos), high blood pressure, congestive heart failure.\n anywhere on the body.\n excess pigmentation and redness, wrinkles and mild acne scars, vascular lesions and varicose veins, pigmented lesions and dark tattoos.\n eye alignment.\n breast augmentation, breast reconstruction, abdominal wall defects, hernia repair.\n depressed scars, acne scars, cellulite dimples.\n face, neck, and d\u00e9colletage.\n teeth alignment.\n epidermis.\n acne on face and body, psoriasis on body, sun damage.\n face.\n teeth.\n face.\n lips, cheeks, chin, forehead, eyes, mouth, neck, and chest.\n scrotum.\n face, eyes, eyelids, jawline, stomach, arms, backs of hands, thighs, knees, butt.\n breasts and nipples.\n cheeks, around the mouth, neck, forehead and around the eyes.\n lower face, jowls, neck, breasts, arms, tummy, and thighs.\n vulvar and vaginal tissues.\n thigh.\n brow, mid- and lower face, jawline, and neck.\n skin concerns.\n inner and outer thighs, back, abdomen, love handles, hips, saddlebags, and buttocks.\n face, neck, stomach, and upper arms.\n enamel, dentin, pulp.\n face, forehead, temples, chin, area around mouth, cheeks.\n wrinkles, sagging skin, fat cells, cellulite.\n abdomen and flanks.\n abdomen and flanks.\n abdomen, flanks, buttocks, thighs.\n abdomen, flanks, and thighs.\n reshaping, creating balanced, normal breasts.\n abdomen, love handles, hips, thighs, chin, upper arms, underarms.\n lower abdomen.\n abdomen.\n brow, neck (including jawline), under chin, lines and wrinkles on d'colletage.\n vaginal area.\n face and neck.\n fine lines and wrinkles, discoloration, and even scars.\n stomach, hips, and thighs.\n abdomen, hips, and thighs.\n fat layer just under the skin.\n upper arms, belly, love handles, thighs, chin.\n abdominal wall.\n eyelid.\n lower face.\n vaginal canal, opening, labia majora, vulva, labia minora, mons pubis.\n vaginal canal.\n cleavage area.\n face.\n face.\n abdomen and thighs.\n spider veins, varicose veins, and venous reflux disease.\n thighs, calves, and ankles, buttocks and hips, abdomen, back, and flanks (aka love handles), upper arms, neck and under the chin.\n rosacea, pigmented scars, spider veins, broken capillaries, birthmarks, hyperpigmentation, newly formed stretch marks, and other forms of red, brown, or purple facial pigmentation.\n legs.\n spider veins, cherry angiomas, small hemangiomas, skin tags, spider nevi, and redness from rosacea.\n thighs, buttocks, upper arms, stomach, excess fat and mildly sagging skin under the chin.\n thighs, abdomen, and butt.\n varicose veins.\n fat reduction on the back, abdomen, thighs and flanks, cellulite reduction on the thighs, buttocks, and abdomen, muscle conditioning and toning for biceps, triceps, abdominal and oblique muscles, glutes, hamstrings, and quadriceps.\n face, neck, and body.\n wrinkles, fine lines, cellulite, stretch marks.\n fine lines and deep wrinkles, acne scars, large pores, uneven skin texture, stretch marks, mild laxity, rosacea, and hyperpigmentation, including melasma.\n pelvic floor issues.\n face, neck, chest, hands.\n face and body.\n vaginal tissues, labia majora.\n pelvic floor muscles and skin elasticity.\n jaw.\n lines and wrinkles created by dynamic facial movements, such as smiling, frowning, or raising your eyebrows, neck pain caused by cervical dystonia, eye spasms known as blepharospasm, and upper limb spasticity.\n skin concerns, visible veins, brown spots, scars, laser hair removal, tattoo removal, cataract surgery.\n waist, chest, back, neck, upper arms, thighs, love handles, hips, and ankles.\n skin.\n teeth.\n lower third of face, jawline, neck.\n face, neck, and body.", "ExpectedConstraintError: Invalid string format\n at Object.run (/Users/graff/developr/DiscordBot3/node\\_modules/@sapphire/shapeshift/dist/index.js:1582:64)\n at /Users/graff/developr/DiscordBot3/node\\_modules/@sapphire/shapeshift/dist/index.js:201:66\n at Array.reduce ()\n at StringValidator.parse (/Users/graff/developr/DiscordBot3/node\\_modules/@sapphire/shapeshift/dist/index.js:201:29)\n at validateName (/Users/graff/developr/DiscordBot3/node\\_modules/@discordjs/builders/dist/index.js:903:17)\n at MixedClass.setName (/Users/graff/developr/DiscordBot3/node\\_modules/@discordjs/builders/dist/index.js:979:5)\n at /Users/graff/developr/DiscordBot3/commands/save.js:16:10\n at MixedClass.\\_sharedAddOptionMethod (/Users/graff/developr/DiscordBot3/node\\_modules/@discordjs/builders/dist/index.js:1346:50)\n at MixedClass.addIntegerOption (/Users/graff/developr/DiscordBot3/node\\_modules/@discordjs/builders/dist/index.js:1338:17)\n at Object. (/Users/graff/developr/DiscordBot3/commands/save.js:14:6) {\n constraint: 's.string.regex',\n given: 'maxSize',\n expected: 'expected /^[\\\\p{Ll}\\\\p{Lm}\\\\p{Lo}\\\\p{N}\\\\p{sc=Devanagari}\\\\p{sc=Thai}\\_-]+$/u.test(expected) to be true'\n} :::: Your code is WRONG!!! it's version v14 of discord.js :::: Learn from documentation : Adding options\nApplication commands can have additional options. Think of these options as arguments to a function, and as a way for the user to provide the additional information the command requires.\n\nTIP\n\nIf you've already added options to your commands and need to know how to receive and parse them, refer to the Parsing options page in this section of the guide.\n\nOptions require at minimum a name and description. The same restrictions apply to option names as slash command names - 1-32 characters containing no capital letters, spaces, or symbols other than - and \\_. You can specify them as shown in the echo command below, which prompt the user to enter a String for the input option.\n\nconst { SlashCommandBuilder } = require('discord.js');\n\nconst data = new SlashCommandBuilder()\n .setName('echo')\n .setDescription('Replies with your input!')\n .addStringOption(option =>\n option.setName('input')\n .setDescription('The input to echo back'));\n#Option types\nBy specifying the type of an ApplicationCommandOption using the corresponding method you are able to restrict what the user can provide as input, and for some options, leverage the automatic parsing of options into proper objects by Discord.\n\nThe example above uses addStringOption, the simplest form of standard text input with no additional validation. By leveraging additional option types, you could change the behavior of this command in many ways, such as using a Channel option to direct the response to a specific channel:\n\nconst { SlashCommandBuilder } = require('discord.js');\n\nconst data = new SlashCommandBuilder()\n .setName('echo')\n .setDescription('Replies with your input!')\n .addStringOption(option =>\n option.setName('input')\n .setDescription('The input to echo back'))\n .addChannelOption(option =>\n option.setName('channel')\n .setDescription('The channel to echo into'));\nOr a Boolean option to give the user control over making the response ephemeral.\n\nconst { SlashCommandBuilder } = require('discord.js');\n\nconst data = new SlashCommandBuilder()\n .setName('echo')\n .setDescription('Replies with your input!')\n .addStringOption(option =>\n option.setName('input')\n .setDescription('The input to echo back'))\n .addBooleanOption(option =>\n option.setName('ephemeral')\n .setDescription('Whether or not the echo should be ephemeral'));\nListed below is a short description of the different types of options that can be added. For more information, refer to the add\\_\\_\\_\\_\\_Option methods in the SlashCommandBuilder documentation.\n\nString, Integer, Number and Boolean options all accept primitive values of their associated type.\nInteger only accepts whole numbers.\nNumber accepts both whole numbers and decimals.\nUser, Channel, Role and Mentionable options will show a selection list in the Discord interface for their associated type, or will accept a Snowflake (id) as input.\nAttachment options prompt the user to make an upload along with the slash command.\nSubcommand and SubcommandGroup options allow you to have branching pathways of subsequent options for your commands - more on that later on this page.\nTIP\n\nRefer to the Discord API documentation for detailed explanations on the SUB\\_COMMAND and SUB\\_COMMAND\\_GROUP option types.\n\n#Required options\nWith option types covered, you can start looking at additional forms of validation to ensure the data your bot receives is both complete and accurate. The simplest addition is making options required, to ensure the command cannot be executed without a required value. This validation can be applied to options of any type.\n\nReview the echo example again and use setRequired(true) to mark the input option as required.\n\nconst { SlashCommandBuilder } = require('discord.js');\n\nconst data = new SlashCommandBuilder()\n .setName('echo')\n .setDescription('Replies with your input!')\n .addStringOption(option =>\n option.setName('input')\n .setDescription('The input to echo back')\n .setRequired(true));\n#Choices\nThe String, Number, and Integer option types can have choices. If you would prefer users select from predetermined values rather than free entry, choices can help you enforce this. This is particularly useful when dealing with external datasets, APIs, and similar, where specific input formats are required.\n\nWARNING\n\nIf you specify choices for an option, they'll be the only valid values users can pick!\n\nSpecify choices by using the addChoices() method from within the option builder, such as SlashCommandBuilder#addStringOption(). Choices require a name which is displayed to the user for selection, and a value that your bot will receive when that choice is selected, as if the user had typed it into the option manually.\n\nThe gif command example below allows users to select from predetermined categories of gifs to send:\n\nconst { SlashCommandBuilder } = require('discord.js');\n\nconst data = new SlashCommandBuilder()\n .setName('gif')\n .setDescription('Sends a random gif!')\n .addStringOption(option =>\n option.setName('category')\n .setDescription('The gif category')\n .setRequired(true)\n .addChoices(\n { name: 'Funny', value: 'gif\\_funny' },\n { name: 'Meme', value: 'gif\\_meme' },\n { name: 'Movie', value: 'gif\\_movie' },\n ));\nIf you have too many choices to display (the maximum is 25), you may prefer to provide dynamic choices based on what the user has typed so far. This can be achieved using autocomplete.\n\n#Further validation\nEven without predetermined choices, additional restrictions can still be applied on otherwise free inputs.\n\nFor String options, setMaxLength() and setMinLength() can enforce length limitations.\nFor Integer and Number options, setMaxValue() and setMinValue() can enforce range limitations on the value.\nFor Channel options, addChannelTypes() can restrict selection to specific channel types, e.g. ChannelType.GuildText.\nWe'll use these to show you how to enhance your echo command from earlier with extra validation to ensure it won't (or at least shouldn't) break when used:\n\nconst { SlashCommandBuilder } = require('discord.js');\n\nconst data = new SlashCommandBuilder()\n .setName('echo')\n .setDescription('Replies with your input!')\n .addStringOption(option =>\n option.setName('input')\n .setDescription('The input to echo back')\n // Ensure the text will fit in an embed description, if the user chooses that option\n .setMaxLength(2000))\n .addChannelOption(option =>\n option.setName('channel')\n .setDescription('The channel to echo into')\n // Ensure the user can only select a TextChannel for output\n .addChannelTypes(ChannelType.GuildText))\n .addBooleanOption(option =>\n option.setName('embed')\n .setDescription('Whether or not the echo should be embedded'));\n#Subcommands\nSubcommands are available with the .addSubcommand() method. This allows you to branch a single command to require different options depending on the subcommand chosen.\n\nWith this approach, you can merge the user and server information commands from the previous section into a single info command with two subcommands. Additionally, the user subcommand has a User type option for targeting other users, while the server subcommand has no need for this, and would just show info for the current guild.\n\nconst { SlashCommandBuilder } = require('discord.js');\n\nconst data = new SlashCommandBuilder()\n .setName('info')\n .setDescription('Get info about a user or a server!')\n .addSubcommand(subcommand =>\n subcommand\n .setName('user')\n .setDescription('Info about a user')\n .addUserOption(option => option.setName('target').setDescription('The user')))\n .addSubcommand(subcommand =>\n subcommand\n .setName('server')\n .setDescription('Info about the server'));\n#Localizations\nThe names and descriptions of slash commands can be localized to the user's selected language. You can find the list of accepted locales on the discord API documentation.\n\nSetting localizations with setNameLocalizations() and setDescriptionLocalizations() takes the format of an object, mapping location codes (e.g. pl and de) to their localized strings.\n\nconst { SlashCommandBuilder } = require('discord.js');\n\nconst data = new SlashCommandBuilder()\n .setName('dog')\n .setNameLocalizations({\n pl: 'pies',\n de: 'hund',\n })\n .setDescription('Get a cute picture of a dog!')\n .setDescriptionLocalizations({\n pl: 'S\u0142odkie zdj\u0119cie pieska!',\n de: 'Poste ein niedliches Hundebild!',\n })\n .addStringOption(option =>\n option\n .setName('breed')\n .setDescription('Breed of dog')\n .setNameLocalizations({\n pl: 'rasa',\n de: 'rasse',\n })\n .setDescriptionLocalizations({\n pl: 'Rasa psa',\n de: 'Hunderasse',\n }),\n );", "Based on all of the information above and the headline structure below, generate 20 headlines\nMake a Magnetic \u201cReason Why\u201d\nWe start the name with a word or phrase that tells people the \u201creason why\u201d we are running our promotion.\nI like to tell people to think like a fraternity party planner. When I was in college, we had a party once because a guy got his wisdom teeth removed. I say this to say. . .the \u201creason why\u201d can literally be anything.\nIt really doesn't matter so long as you believe it. And you can even make a joke of it like the fraternity example. But this should answer one or both of the following questions: Why are they making this great offer? or Why should I respond to this offer?/What\u2019s in it for me?\n\nExamples: Free, 88% off, Giveaway; 88% off, Spring, Summer, Back To School; Grand Opening; New Management; New Building; Anniversary; Halloween; New Year.\nNote: I will discuss how to monetize free and discounted offers in Volume III: Money Models.\nAnnounce Your Avatar\nThis component calls out your ideal avatar: who you are looking for and who you are not looking for as a client. You want\nto be as specific as possible, but no more. When in a local area, the more local you can make your headline, the more it will convert. So don't do a city, try and go to the sub market, or hyper local area. Not Baltimore but Towson, MD. Not Chicago, but Hinsdale, Etc.\nExamples: Bee Cave Dentists, Rolling Hills Moms, Brick & Mortar Businesses, Salon Owners, Retired Athletes, Brooklyn Busy Executives\n Give Them A Goal\nThis is where you articulate your prospect\u2019s dream outcome. It can be a single word or a phrase. It can be an event, a feeling, an experience, or an outcome, anything that would excite them. The more specific and tangible, the better.\nExamples: Pain Free, Celebrity Smile, 1st Place, Never Out Of Breath, Perfect Product, Grand Slam Offer, Little Black Dress, Double Your Profit, First Client, High Ticket, 7 Figure, 100k, Etc.\nIndicate a Time Interval\nYou\u2019re just letting people know the duration to expect here. This gives an example of how long your results will take to achieve.\nNote: If you\u2019re making any sort of quantifiable claim (like income gain or weight loss) most platforms will not approve this type of messaging with a stated duration to achievement because it implies a guarantee. It implies they are going to get this outcome in a period of time, which goes against many platform rules. So dont give a quantifiable outcome with the duration unless your platform allows it. That being said, duration is a powerful component of a Grand Slam Offer and you should definitely use it anywhere you don't need to deal with compliance. Alternatively, if the goal you help them with is not a \u201cclaim\u201d per se, then absolutely use a time interval. \u201c$10,000 in 10 days\u201d vs \u201cMake Your First Sale in 10 Days.\u201d\nExamples: AA Minutes, BB Hours, CC Days, DD Weeks, Z Months. \u201c4 Hour\u201d \u201c21 Day\u201d \u201c6 Week\u201d \u201c3 Month\u201d\nComplete With A Container Word\nThe container word denotes that this offer is a bundle of lots of things put together. It\u2019s a system. It\u2019s something that can\u2019t be\nheld up to a commoditized alternative.\nExamples: Challenge, Blueprint, Bootcamp, Intensive, Incubator, Masterclass, Program, Detox, Experience, Summit,\nAccelerator, Fast Track, Shortcut, Sprint, Launch, Slingshot, Catapult, Explosion, System, Getaway, Meetup, Transformation, Mastermind, Launch, Game Plan, Deep Dive, Workshop, Comeback, Rebirth, Attack, Assault, Reset, Solution, Hack, Cheatcode, Liftoff, Etc.\nPro Tip: Find Time To Rhyme\nGood rhymes stick in people\u2019s minds. Rhyme your program name to win the game.\nGoogle \u201crhyming dictionary\u201d for an easy shortcut. Note - Don\u2019t try and force it. It\u2019s not a requirement, it\u2019s just a \u201cnice-to-have\u201d.\nExamples: Six-Pack Fast Track, 5-Day Book Print Sprint, Marriage Thrive Deep Dive, 12-Week 2-Putt Shortcut, 12-Month No-Debt Reset, Celebrity Butt\nShortcut, Get Some Ass Masterclass (just thought it was funny), etc. You get the idea.\nPro Tip: Alliteration\nAlliteration is when you make all (or most) of the words start with the same letter or sound.\nAn alternative approach to rhyming is to use alliteration when naming your program. This is easier for most people than rhyming. Again, you do not need to rhyme or alliterate. Don\u2019t force it.\nExamples:Make Money Masterclass, Change Your Life Challenge, Big Booty Bootcamp, Debt Detox, Real Estate Reset, Life Coach Liftoff, Etc.\nI might be weird, but naming offers is one of my favorite parts of this process. What I want to highlight, yet again, is that your actual money model, pricing, and services will remain largely unchanged. Changing the wrapper simply means changing the exterior perception of what your Grand Slam Offer is.\nBelow you\u2019ll find a few examples of named offers for different industries.\nWe llne ss\nFree Six-Week Lean-By-Halloween Challenge\n88% Off 12-Week Bikini Blueprint\nFree 21-Day Mommy Makeover\n60-minute Make Your Friends Jealous Model Hair System Six-Week Stress-Release Challenge\n(Free!) Bend Over Pain Free in 42 Days . . . Healing Fast Track\n Examples:\nDoctors\n $2,000-Off Celebrity Smile Transformation\nLakeway Moms - $1,500 Off Your Kids Braces\nLakeway Moms - 12 Months To A Perfect Smile ($1000 off for 15 families) Back to School Free Braces Giveaway\nGrand Opening Free X-Ray & Treatment - Instant Relief\nBack Sore No More! 90 Day Rapid Healing Intensive (81% off!) Tightness? $1 Massage New Client Summer Special\nCoaching\n5 Clients in 5 Days Blueprint\n7F Agency 12 Week Intensive\n14 Day Find Your Perfect Product Launch Fill Your Gym in 30 Days (Free!)\nYou're selling a 12 month program:{include nickname from above} that teaches people how to start and grow an Amazon FBA business to 6-7 figures.\n\nSummary of Buyer Persona \"Mike\":\n\nDemographics:\n\nMike is a man in his 20s or 30s, sometimes with kids.\nHe is struggling financially or sees no good future in his 9-5 job.\nHe has found it difficult to quit the rat race and build his own business due to lack of initial capital.\nHe is interested in making money with a side hustle and building a 6-7 figure Amazon FBA business.\nPsychographics:\n\nMike is determined to make a better future for himself and his family.\nHe is tired of working long hours and not seeing the financial rewards.\nHe feels a sense of urgency to take action and make changes to his life.\nHe wants to prove to himself and others that he can succeed in business.\nHe is looking for a mentor or guide to help him succeed.\nMain Challenges:\n\nLack of initial capital to start a business like Amazon FBA.\nFear of failure and not being able to provide for his family.\nLack of knowledge and expertise in building an Amazon FBA business.\nDifficulty in finding the right product to sell on Amazon.\nTrying to scale to 7 figures with just one best-selling product.\nValues:\n\nMike values financial freedom and the ability to provide for his family.\nHe values independence and the ability to work for himself.\nHe values growth and learning, and wants to continually improve his skills.\nMotivations:\n\nMike is motivated by the desire to quit his 9-5 job and build a successful business.\nHe is motivated by the potential for financial success and freedom.\nHe is motivated by the desire to prove himself and his abilities to others.\nKey Emotional Drivers:\n\nFear of failure and not being able to provide for his family.\nFeeling stuck in his current situation and wanting to make a change.\nSense of urgency to take action and make changes to his life.\nPrevious attempts:\n\nTried various methods to start a business, but failed due to lack of knowledge, experience, and high competition.\nTried to scale his Amazon FBA business with just one best-selling product, which didn't work.\nFrustrations with previous attempts:\n\n\"I was overwhelmed by the competition and couldn't find a way to stand out.\"\n\"I didn't have the necessary knowledge and expertise to build a successful business.\"\n\"I invested a lot of time and money into a product that didn't sell well.\"\nContrarian Explanations:\n\nSuccess in Amazon FBA doesn't come from finding one big product, but rather from implementing a 12-month phase plan.\nThe traditional methods for starting a business may not work for everyone, and it's important to find the right mentor or guide to help.\nLack of initial capital shouldn't be a barrier to starting a business, and there are ways to start with little to no money.\nFear of failure is a common emotional barrier, but failure is a necessary part of the learning process and can lead to eventual success.\nIt's not necessary to have all the knowledge and expertise from the beginning, but rather to be willing to learn and adapt.\nHaving multiple products and income streams is more important than relying on just one best-selling product.\nSuccess in business requires hard work and dedication, but also a willingness to take risks and try new things.", "Debug: ---------------------------------------------------------------------------\nValueError Traceback (most recent call last)\n~\\AppData\\Local\\Temp\\ipykernel\\_22232\\3564592056.py in \n 1 for index, airport in airports\\_ireland.iterrows():\n----> 2 plt.scatter(float(airport['latitude']), float(airport['longitude']), marker='o', color='red', transform=ccrs.Mercator())\n\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py in scatter(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, data, \\*\\*kwargs)\n 2817 vmin=None, vmax=None, alpha=None, linewidths=None, \\*,\n 2818 edgecolors=None, plotnonfinite=False, data=None, \\*\\*kwargs):\n-> 2819 \\_\\_ret = gca().scatter(\n 2820 x, y, s=s, c=c, marker=marker, cmap=cmap, norm=norm,\n 2821 vmin=vmin, vmax=vmax, alpha=alpha, linewidths=linewidths,\n\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\\\_\\_init\\_\\_.py in inner(ax, data, \\*args, \\*\\*kwargs)\n 1410 def inner(ax, \\*args, data=None, \\*\\*kwargs):\n 1411 if data is None:\n-> 1412 return func(ax, \\*map(sanitize\\_sequence, args), \\*\\*kwargs)\n 1413 \n 1414 bound = new\\_sig.bind(ax, \\*args, \\*\\*kwargs)\n\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\\\_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, \\*\\*kwargs)\n 4478 self.set\\_ymargin(0.05)\n 4479 \n-> 4480 self.add\\_collection(collection)\n 4481 self.\\_request\\_autoscale\\_view()\n 4482 \n\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\\\_base.py in add\\_collection(self, collection, autolim)\n 2246 # pre-lazy-autoscale behavior, which is not really better).\n 2247 self.\\_unstale\\_viewLim()\n-> 2248 datalim = collection.get\\_datalim(self.transData)\n 2249 points = datalim.get\\_points()\n 2250 if not np.isinf(datalim.minpos).all():\n\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\collections.py in get\\_datalim(self, transData)\n 264 \n 265 transform = self.get\\_transform()\n--> 266 transOffset = self.get\\_offset\\_transform()\n 267 if not (isinstance(transOffset, transforms.IdentityTransform)\n 268 or transOffset.contains\\_branch(transData)):\n\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\collections.py in get\\_offset\\_transform(self)\n 233 elif (not isinstance(self.\\_transOffset, transforms.Transform)\n 234 and hasattr(self.\\_transOffset, '\\_as\\_mpl\\_transform')):\n--> 235 self.\\_transOffset = self.\\_transOffset.\\_as\\_mpl\\_transform(self.axes)\n 236 return self.\\_transOffset\n 237 \n\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\cartopy\\crs.py in \\_as\\_mpl\\_transform(self, axes)\n 248 import cartopy.mpl.geoaxes as geoaxes\n 249 if not isinstance(axes, geoaxes.GeoAxes):\n--> 250 raise ValueError(\n 251 'Axes should be an instance of GeoAxes, got %s' % type(axes)\n 252 )\n\nValueError: Axes should be an instance of GeoAxes, got \n\n---------------------------------------------------------------------------\nValueError Traceback (most recent call last)\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py in \\_\\_call\\_\\_(self, obj)\n 339 pass\n 340 else:\n--> 341 return printer(obj)\n 342 # Finally look for special method names\n 343 method = get\\_real\\_method(obj, self.print\\_method)\n\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\pylabtools.py in print\\_figure(fig, fmt, bbox\\_inches, base64, \\*\\*kwargs)\n 149 FigureCanvasBase(fig)\n 150 \n--> 151 fig.canvas.print\\_figure(bytes\\_io, \\*\\*kw)\n 152 data = bytes\\_io.getvalue()\n 153 if fmt == 'svg':\n\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backend\\_bases.py in print\\_figure(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox\\_inches, pad\\_inches, bbox\\_extra\\_artists, backend, \\*\\*kwargs)\n 2293 )\n 2294 with getattr(renderer, \"\\_draw\\_disabled\", nullcontext)():\n-> 2295 self.figure.draw(renderer)\n 2296 \n 2297 if bbox\\_inches:\n\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\artist.py in draw\\_wrapper(artist, renderer, \\*args, \\*\\*kwargs)\n 71 @wraps(draw)\n 72 def draw\\_wrapper(artist, renderer, \\*args, \\*\\*kwargs):\n---> 73 result = draw(artist, renderer, \\*args, \\*\\*kwargs)\n 74 if renderer.\\_rasterizing:\n 75 renderer.stop\\_rasterizing()\n\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\artist.py in draw\\_wrapper(artist, renderer)\n 48 renderer.start\\_filter()\n 49 \n---> 50 return draw(artist, renderer)\n 51 finally:\n 52 if artist.get\\_agg\\_filter() is not None:\n\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py in draw(self, renderer)\n 2835 \n 2836 self.patch.draw(renderer)\n-> 2837 mimage.\\_draw\\_list\\_compositing\\_images(\n 2838 renderer, self, artists, self.suppressComposite)\n 2839 \n\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\image.py in \\_draw\\_list\\_compositing\\_images(renderer, parent, artists, suppress\\_composite)\n 130 if not\\_composite or not has\\_images:\n 131 for a in artists:\n--> 132 a.draw(renderer)\n 133 else:\n 134 # Composite any adjacent images together\n\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\artist.py in draw\\_wrapper(artist, renderer)\n 48 renderer.start\\_filter()\n 49 \n---> 50 return draw(artist, renderer)\n 51 finally:\n 52 if artist.get\\_agg\\_filter() is not None:\n\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\\\_base.py in draw(self, renderer)\n 3089 renderer.stop\\_rasterizing()\n 3090 \n-> 3091 mimage.\\_draw\\_list\\_compositing\\_images(\n 3092 renderer, self, artists, self.figure.suppressComposite)\n 3093 \n\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\image.py in \\_draw\\_list\\_compositing\\_images(renderer, parent, artists, suppress\\_composite)\n 130 if not\\_composite or not has\\_images:\n 131 for a in artists:\n--> 132 a.draw(renderer)\n 133 else:\n 134 # Composite any adjacent images together\n\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\artist.py in draw\\_wrapper(artist, renderer)\n 48 renderer.start\\_filter()\n 49 \n---> 50 return draw(artist, renderer)\n 51 finally:\n 52 if artist.get\\_agg\\_filter() is not None:\n\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\collections.py in draw(self, renderer)\n 988 def draw(self, renderer):\n 989 self.set\\_sizes(self.\\_sizes, self.figure.dpi)\n--> 990 super().draw(renderer)\n 991 \n 992 \n\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\artist.py in draw\\_wrapper(artist, renderer)\n 48 renderer.start\\_filter()\n 49 \n---> 50 return draw(artist, renderer)\n 51 finally:\n 52 if artist.get\\_agg\\_filter() is not None:\n\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\collections.py in draw(self, renderer)\n 364 self.update\\_scalarmappable()\n 365 \n--> 366 transform, transOffset, offsets, paths = self.\\_prepare\\_points()\n 367 \n 368 gc = renderer.new\\_gc()\n\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\collections.py in \\_prepare\\_points(self)\n 324 \n 325 transform = self.get\\_transform()\n--> 326 transOffset = self.get\\_offset\\_transform()\n 327 offsets = self.get\\_offsets()\n 328 paths = self.get\\_paths()\n\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\collections.py in get\\_offset\\_transform(self)\n 233 elif (not isinstance(self.\\_transOffset, transforms.Transform)\n 234 and hasattr(self.\\_transOffset, '\\_as\\_mpl\\_transform')):\n--> 235 self.\\_transOffset = self.\\_transOffset.\\_as\\_mpl\\_transform(self.axes)\n 236 return self.\\_transOffset\n 237 \n\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\cartopy\\crs.py in \\_as\\_mpl\\_transform(self, axes)\n 248 import cartopy.mpl.geoaxes as geoaxes\n 249 if not isinstance(axes, geoaxes.GeoAxes):\n--> 250 raise ValueError(\n 251 'Axes should be an instance of GeoAxes, got %s' % type(axes)\n 252 )\n\nValueError: Axes should be an instance of GeoAxes, got", "please review this set of responses to the question \"what are the value plays we should focus on\" and look for common themes in the responses. Present these in a table format with a short name, description, and identify all individuals who made reference to this theme in their response\n\n1. Supplied\n 1. Acquire and Develop Talent capable of delivering Platform vision\n 2. Modernized internal stack capable of meeting the needs of a cloud-first business\n 3. Best in class investor management through transformation process, as we delicately manage the growth of platform offerings in a way that doesn't negatively impact our valuation in the long term\n 4. Decreasing our capital intensity through operating efficiencies driven by technology and automation \n 5. Developing a suite of digital platform solutions from solving cloud issues to digital transformations \n 6. Building a partner ecosystem to expand and support our offerings\n 7. Solving go-to-market, legal, and financial compliance challenges related to operating a platform business internationally\n \n2. Brandi\n \u00b7 \u2026Modernized internal stack capable of meeting the needs of a cloud-first business.\n \u00b7 Evolve culture to accelerate delivery of platform vision\n \u00b7 Acquire and develop talent fit for platform vision\n \n3. Bruce\n \u00b7 Be public about a quantifiable aspiration/goal to fuel urgency (e.g. Interconnection revenue or yield)\n \u00b7 Get org rallied around a shared vision and then be very targeted in culture change (e.g. agile) and skills change needed in specific pockets of the org to deliver digital transformation. Ie. We need everyone to understand our vision, but we can be targeted on the where need new skills/capabilities\n \u00b7 Enhance our local market and customer listening to drive innovation, using customer base for rapid beta testing or prototypes.\n \n4. Charles\n 1. IBX Footprint\n 2. Service Offerings\n a. Colo\n b. Mgd Services\n c. Edge Infra (Network Edge and Colo by the U)\n d. Cloud Networking\n 3. Digital Experience (likely starts as somewhat parallel experiences for DCS vs DS offerings but implies a merged experience over time)\n a. Process\n b. Systems\n 4. Ecosystem Enablement (huge area of opportunity and under-investment)\n a. APIs\n b. SDKs (that\u2019s all the acronyms I know but I\u2019m pretty sure we have a lot of work to do)\n 5. Customers \u2013 need to define target personas and align GTM motions to specific customer/persona combinations\n 6. Ecosystem Development\n a. JPS/\u201dintegrated\u201d\n b. Self-serve (use self-serve tools to bring your offering to the Platform)\n c. Communities of Interest/Vertical Ecosystems (BD to cultivate)\n 7. Marketplace (what we need, not what we have now)\n\n \n \n5. Jon\n \u00b7 Modernized quote-to-cash stack that allows for low/no-touch customer acquisition and onboarding, and global billing capabilities.\n \u00b7 Having clear, measurable ROIC for digital services with clear cost structures by product line.\n \u00b7 Building integrated partner offerings that allow partners to package/sell/support our offerings with low/no-touch for Equinix.\n \u00b7 Creating clear BU and product-level P&L reporting, inclusive of capex and opex.\n \u00b7 Having the clear ability to calculate LTV/CAC by product.\n \n6. Justin\n \u00b7 Investing in a modern API-first technology stack to be able to effectively leverage developer ecosystems to (1) co-drive disruptive, agile innovation; (2) create new business models; (3) enable seamless API-based technology partner integration; and (4) reduce channel friction.\n \u00b7 Continuing to improve Equinix\u2019s visibility and credibility in developer ecosystems to attract world-class talent capable of delivering on our Platform vision.\n \u00b7 Investing in an innovation incubator with dedicated engineering resources, and frameworks in place to engage and co-innovate with external developers and startups with agility, to boost innovation (radical innovation, adjacent innovation, or core innovation), supported by an accelerated incubation model.\n \n7. Karl\n \u00b7 \u2026seriously vet and conclude on inorganic options to accelerate our capability set to deliver the suite of services required. (Contemplates the addition of talent, tech, and product needed to accelerate)\n \u00b7 \u2026successfully launch AND scale Joint partner solutions that prove we are indeed the home of the dedicated cloud and can offer solutions via partners at scale.\n \u00b7 \u2026neutralize the complexity of workload tiering and demand shaping by having both retail and wholesale solutions to large and performance based deployments.\n \n \n8. Keith\n \u00b7 Developing a platform on Equinix DCS assets, and potentially extending these services to other non-Equinix assets.\n \u00b7 Potentially acquiring talent or service capabilities and integrating onto the Equinix Platform.\n \u00b7 Merging our business into an existing business and integrating onto the Equinix Platform.\n \u00b7 Exclusively expand our GTM partnerships with a number of critical providers that imbeds our service offering into their solution.\n \n9. Kurt\n \u00b7 \u2026Honestly, I think the above list is a really good list. I am struggling to add anything to it. \n \u00b7 If I had to, I would say we need a capability of coming to agreement more quickly on complex issues impacting our delivery and development of services. We are currently wrestling with issues that we have known for year. Channel complications (same ones) have been on the table for years, tax structure has been on the table for years and we actually built a tax structure no one is using a while back, we have known about billing issues since we bought packet, etc. The problem is, as soon as folks hear \u201chard problem\u201d they retreat and we don\u2019t move. To date, we have really struggled to resolve these issues quickly enough and with certainty for a time. I would never say we need decisions that last forever as we need to be agile, but the word I hear a lot on the street is the team is \u201cWhipsawed.\u201d It feels like folks run to work on something based on an agreement and then it changes a few months out, not usually with a discussion. \n \u00b7 With that said, the list above actually sounds great to me. We need the right talent, working on the right stuff, for the right customers, and the story will tell itself.\n \n10. Mike\n \u00b7 Acquire and Develop Talent capable of delivering our Platform vision.\n \u00b7 Build a partner ecosystem to expand and support our offerings.\n \u00b7 Begin to market ourselves as a company that provides a lot more than colocation services to different personas than we market to today.\n \u00b7 Find a way to use xScale facilities to help with our Retail and Digital space constraints.\n \n11. Milind\n\n12. Nicole \n\u00b7 People/Workforce/Brand:\n \u00b7 Specific declaration on future state vision (internally). Take any guesses or confusion off the table immediately and ensure all functions are clear on how they play a role in that vision. \n \u00b7 T&A to drive talent into the workforce that has experience suited for our vision (less telco, more software, service provider, etc..). \n \u00b7 Marketing driving significant brand shift externally to ensure customers see us as a platform company. We are moving away from data center only branding. (This likely requires a CMO strategy) \n \u00b7 Drive more accountability with our GLO population to lead from the front and be transformational leaders. Communicate often, effectively, and more intimately with this group so they are 100% clear on the strategy and role they play in the transformation. Have courage to take swift action if leaders can\u2019t make the turn. This group of leaders will make or break us future state. \n\u00b7 Growth and Bookings: \n \u00b7 Global salesforce enabled and delivering balanced performance and growth targets across the product portfolio. \n \u00b7 Internal functions working towards common vision and solving problems in partnership and at pace. \n \u00b7 Specific and strategic synergy plans formally in place across critical enterprise partnerships (Dell, VMW, HPE)\n \u00b7 Sustainability efforts clearly defined, articulated, and structured goaling for internal leadership in place. \n \u00b7 Product clarity in digital space. What products, to what market, etc.. Keep this simple so sales can accelerate the strategy. Complexity will slow our pace. \n \n\u00b7 Systems/Tools/Processes\n \u00b7 Modernize our internal stack to be able to provide a customer experience needed for digital scale. Be progressive and aggressive in our IT shift. Don\u2019t always think about \u201cbuild\u201d motions, also look at \u201cbuy\u201d motions to implement with speed. \n \u00b7 Data Transformation strategy in place (as part of our overall digital transformation strategy) in place to ensure Network Transformation, MDM/Analytics, etc, have structured execution dates (with timelines) and are scaling to enable faster decisions with more data driven insights. \n \u00b7 Real time capacity management tools that help us balance DCS and DS needs by data center (I am not sure how mature these are today, and am assuming we will need advancement here). \n \u00b7 API mandatory for all new builds. Basically, no more in house building that aren\u2019t API enabled. \n\n \n13. PVC\n \u00b7 \u2026If I accurately understand the list, 1, 2, 5, and 6 are areas I\u2019d apply energy\u2026.. 3, 4, and 7 will draw effort, but should naturally occur as we progress in the others. \n \n14. Raouf\n \u00b7 \u2026The right talent to build the products and scale the \u201cwrapper\u201d service model. \n \u00b7 Modernized systems to support DS but also Enterprise support ready. \n \u00b7 Network/DS architecture to scale and have the right unto cost. Truly support on demand growth and ramp for customers. \n \u00b7 Solve go to market approach for combined customers from contracting, ordering and billing to support. \n \n15. Ryan\n 1. Acquire and develop talent capable of delivering Platform vision.\n 2. Overhaul internal systems and processes to enable efficiency and improved experience for customers and front-line employees. \n 3. Instill agility into culture and processes. \n \n16. Scott\n \u00b7 It is hard to improve upon the ones listed, but I'd change the last to read:\n \u00b7 Creating a highly competitive transactional, legal, and financial operating model necessary for the on-demand SaaS/cloud market\n \u00b7 And I'd add:\n \u00b7 Build the optimal platform to capture cloud-adjacent workloads and data. \"Platform\" is inclusive of our offerings and integrated offerings from ecosystem partners.", "Create a to the point tldr of the following blog post, easy to read and scan: \n\nIn 2013, I went to a sushi restaurant beside the Internet Archive in San Francisco, because I had heard that it accepted bitcoin for payments and I wanted to try it out. When it came time to pay the bill, I asked to pay in BTC. I scanned the QR code, and clicked \"send\". To my surprise, the transaction did not go through; it appeared to have been sent, but the restaurant was not receiving it. I tried again, still no luck. I soon figured out that the problem was that my mobile internet was not working well at the time. I had to walk over 50 meters toward the Internet Archive nearby to access its wifi, which finally allowed me to send the transaction.\n\nLesson learned: internet is not 100% reliable, and customer internet is less reliable than merchant internet. We need in-person payment systems to have some functionality (NFC, customer shows a QR code, whatever) to allow customers to transfer their transaction data directly to the merchant if that's the best way to get it broadcasted.\n\nIn 2021, I attempted to pay for tea for myself and my friends at a coffee shop in Argentina. In their defense, they did not intentionally accept cryptocurrency: the owner simply recognized me, and showed me that he had an account at a cryptocurrency exchange, so I suggested to pay in ETH (using cryptocurrency exchange accounts as wallets is a standard way to do in-person payments in Latin America). Unfortunately, my first transaction of 0.003 ETH did not get accepted, probably because it was under the exchange's 0.01 ETH deposit minimum. I sent another 0.007 ETH. Soon, both got confirmed. (I did not mind the 3x overpayment and treated it as a tip).\n\nIn 2022, I attempted to pay for tea at a different location. The first transaction failed, because the default transaction from my mobile wallet sent with only 21000 gas, and the receiving account was a contract that required extra gas to process the transfer. Attempts to send a second transaction failed, because a UI glitch in my phone wallet made it not possible to scroll down and edit the field that contained the gas limit.\n\nLesson learned: simple-and-robust UIs are better than fancy-and-sleek ones. But also, most users don't even know what gas limits are, so we really just need to have better defaults.\n\nMany times, there has been a surprisingly long time delay between my transaction getting accepted on-chain, and the service acknowledging the transaction, even as \"unconfirmed\". Some of those times, I definitely got worried that there was some glitch with the payment system on their side.\n\nMany times, there has been a surprisingly long and unpredictable time delay between sending a transaction, and that transaction getting accepted in a block. Sometimes, a transaction would get accepted in a few seconds, but other times, it would take minutes or even hours. Recently, EIP-1559 significantly improved this, ensuring that most transactions get accepted into the next block, and even more recently the Merge improved things further by stabilizing block times.\n\n\nDiagram from this report by Yinhong (William) Zhao and Kartik Nayak.\n\nHowever, outliers still remain. If you send a transaction at the same time as when many others are sending transactions and the base fee is spiking up, you risk the base fee going too high and your transaction not getting accepted. Even worse, wallet UIs suck at showing this. There are no big red flashing alerts, and very little clear indication of what you're supposed to do to solve this problem. Even to an expert, who knows that in this case you're supposed to \"speed up\" the transaction by publishing a new transaction with identical data but a higher max-basefee, it's often not clear where the button to do that actually is.\n\nLesson learned: UX around transaction inclusion needs to be improved, though there are fairly simple fixes. Credit to the Brave wallet team for taking my suggestions on this topic seriously, and first increasing the max-basefee tolerance from 12.5% to 33%, and more recently exploring ways to make stuck transactions more obvious in the UI.\n\nIn 2019, I was testing out one of the earliest wallets that was attempting to provide social recovery. Unlike my preferred approach, which is smart-contract-based, their approach was to use Shamir's secret sharing to split up the private key to the account into five pieces, in such a way that any three of those pieces could be used to recover the private key. Users were expected to choose five friends (\"guardians\" in modern lingo), convince them to download a separate mobile application, and provide a confirmation code that would be used to create an encrypted connection from the user's wallet to the friend's application through Firebase and send them their share of the key.\n\nThis approach quickly ran into problems for me. A few months later, something happened to my wallet and I needed to actually use the recovery procedure to recover it. I asked my friends to perform the recovery procedure with me through their apps - but it did not go as planned. Two of them lost their key shards, because they switched phones and forgot to move the recovery application over. For a third, the Firebase connection mechanism did not work for a long time. Eventually, we figured out how to fix the issue, and recover the key. A few months after that, however, the wallet broke again. This time, a regular software update somehow accidentally reset the app's storage and deleted its key. But I had not added enough recovery partners, because the Firebase connection mechanism was too broken and was not letting me successfully do that. I ended up losing a small amount of BTC and ETH.\n\nLesson learned: secret-sharing-based off-chain social recovery is just really fragile and a bad idea unless there are no other options. Your recovery guardians should not have to download a separate application, because if you have an application only for an exceptional situation like recovery, it's too easy to forget about it and lose it. Additionally, requiring separate centralized communication channels comes with all kinds of problems. Instead, the way to add guardians should be to provide their ETH address, and recovery should be done by smart contract, using ERC-4337 account abstraction wallets. This way, the guardians would only need to not lose their Ethereum wallets, which is something that they already care much more about not losing for other reasons.\n\nIn 2021, I was attempting to save on fees when using Tornado Cash, by using the \"self-relay\" option. Tornado Cash uses a \"relay\" mechanism where a third party pushes the transaction on-chain, because when you are withdrawing you generally do not yet have coins in your withdrawal address, and you don't want to pay for the transaction with your deposit address because that creates a public link between the two addresses, which is the whole problem that Tornado Cash is trying to prevent. The problem is that the relay mechanism is often expensive, with relays charging a percentage fee that could go far above the actual gas fee of the transaction.\n\nTo save costs, one time I used the relay for a first small withdrawal that would charge lower fees, and then used the \"self-relay\" feature in Tornado Cash to send a second larger withdrawal myself without using relays. The problem is, I screwed up and accidentally did this while logged in to my deposit address, so the deposit address paid the fee instead of the withdrawal address. Oops, I created a public link between the two.\n\nLesson learned: wallet developers should start thinking much more explicitly about privacy. Also, we need better forms of account abstraction to remove the need for centralized or even federated relays, and commoditize the relaying role.\n\nMiscellaneous stuff\nMany apps still do not work with the Brave wallet or the Status browser; this is likely because they didn't do their homework properly and rely on Metamask-specific APIs. Even Gnosis Safe did not work with these wallets for a long time, leading me to have to write my own mini Javascript dapp to make confirmations. Fortunately, the latest UI has fixed this issue.\nThe ERC20 transfers pages on Etherscan (eg. https://etherscan.io/address/0xd8da6bf26964af9d7eed9e03e53415d37aa96045#tokentxns) are very easy to spam with fakes. Anyone can create a new ERC20 token with logic that can issue a log that claims that I or any other specific person sent someone else tokens. This is sometimes used to trick people into thinking that I support some scam token when I actually have never even heard of it.\nUniswap used to offer the really convenient functionality of being able to swap tokens and have the output sent to a different address. This was really convenient for when I have to pay someone in USDC but I don't have any already on me. Now, the interface doesn't offer that function, and so I have to convert and then send in a separate transaction, which is less convenient and wastes more gas. I have since learned that Cowswap and Paraswap offer the functionality, though Paraswap... currently does not seem to work with the Brave wallet.\nSign in with Ethereum is great, but it's still difficult to use if you are trying to sign in on multiple devices, and your Ethereum wallet is only available on one device.\nConclusions\nGood user experience is not about the average case, it is about the worst case. A UI that is clean and sleek, but does some weird and unexplainable thing 0.723% of the time that causes big problems, is worse than a UI that exposes more gritty details to the user but at least makes it easier to understand what's going on and fix any problem that does arise.\n\nAlong with the all-important issue of high transaction fees due to scaling not yet being fully solved, user experience is a key reason why many Ethereum users, especially in the Global South, often opt for centralized solutions instead of on-chain decentralized alternatives that keep power in the hands of the user and their friends and family or local community. User experience has made great strides over the years - in particular, going from an average transaction taking minutes to get included before EIP-1559 to an average transaction taking seconds to get included after EIP-1559 and the merge, has been a night-and-day change to how pleasant it is to use Ethereum. But more still needs to be done.", "#pragma once\n\n#include \n#include \n\n/\\*\\*\\*CHANGE THIS VALUE TO YOUR LARGEST KCAS SIZE \\*\\*\\*\\*/\n#define MAX\\_KCAS 6 // at most 6 in erase()\n/\\*\\*\\*CHANGE THIS VALUE TO YOUR LARGEST KCAS SIZE \\*\\*\\*\\*/\n\n#include \"../kcas/kcas.h\"\nusing namespace std;\nclass ExternalKCAS {\nprivate: \n struct Node {\n int key;\n casword left;\n casword right;\n casword marked;\n\n bool isLeaf() {\n bool result = (left == NULL);\n assert(!result || right == NULL);\n return result;\n }\n bool isParentOf(Node \\*other) {\n return (left == other || right == other);\n }\n };\n\n struct SearchRecord {\n Node \\* gp;\n Node \\* p;\n Node \\* n;\n \n SearchRecord(Node \\* \\_gp, Node \\* \\_p, Node \\* \\_n)\n : gp(\\_gp), p(\\_p), n(\\_n) {\n }\n };\n\n volatile char padding0[PADDING\\_BYTES];\n const int numThreads;\n const int minKey;\n const int maxKey;\n volatile char padding1[PADDING\\_BYTES];\n Node \\*root;\n volatile char padding2[PADDING\\_BYTES];\n\npublic:\n ExternalKCAS(const int \\_numThreads, const int \\_minKey, const int \\_maxKey);\n ~ExternalKCAS();\n long compareTo(int a, int b);\n bool contains(const int tid, const int & key);\n bool insertIfAbsent(const int tid, const int & key); // try to insert key; return true if successful (if it doesn't already exist), false otherwise\n bool erase(const int tid, const int & key); // try to erase key; return true if successful, false otherwise\n \n long getSumOfKeys(); // should return the sum of all keys in the set\n void printDebuggingDetails(); // print any debugging details you want at the end of a trial in this function\nprivate:\n auto search(const int tid, const int & key);\n auto createInternal(int key, Node \\* left, Node \\* right);\n auto createLeaf(int key);\n void freeSubtree(const int tid, Node \\* node);\n long getSumOfKeysInSubtree(Node \\* node);\n\n};\n\nauto ExternalKCAS::createInternal(int key, Node \\*left, Node \\*right) {\n Node \\*node = new Node();\n node->key = key;\n node->left.setInitVal(left);\n node->right.setInitVal(right);\n node->marked.setInitVal(false);\n return node;\n}\n\nauto ExternalKCAS::createLeaf(int key) {\n return createInternal(key, NULL, NULL);\n}\n\nExternalKCAS::ExternalKCAS(const int \\_numThreads, const int \\_minKey, const int \\_maxKey)\n : numThreads(\\_numThreads), minKey(\\_minKey), maxKey(\\_maxKey) { \n auto rootLeft = createLeaf(minKey - 1);\n auto rootRight = createLeaf(maxKey + 1);\n root = createInternal(minKey - 1, rootLeft, rootRight);\n}\n\nExternalKCAS::~ExternalKCAS() {\n freeSubtree(0, root);\n}\n\ninline long ExternalKCAS::compareTo(int a, int b) {\n return ((long) a - (long) b);\n}\n\ninline auto ExternalKCAS::search(const int tid, const int & key) {\n Node \\* gp;\n Node \\* p = NULL;\n Node \\* n = root;\n while (!n->isLeaf()) {\n gp = p;\n p = n;\n n = (key <= n->key) ? n->left : n->right;\n }\n return SearchRecord(gp, p, n);\n}\n\nbool ExternalKCAS::contains(const int tid, const int & key) { \n assert(key <= maxKey);\n auto rec = search(tid, key);\n return (rec.n->key == key);\n}\n\nbool ExternalKCAS::insertIfAbsent(const int tid, const int & key) {\n assert(key > minKey - 1 && key >= minKey && key <= maxKey && key < maxKey + 1);\n while (true) {\n // printf(\"tid = %d, inserting %d\\n\", tid, key);\n auto ret = search(tid, key);\n auto dir = compareTo(key, ret.n->key);\n if (dir == 0) return false;\n // create two new nodes\n auto na = createLeaf(key);\n auto leftChild = (dir <= 0) ? na : ret.n;\n auto rightChild = (dir <= 0) ? ret.n : na;\n auto n1 = createInternal(std::min(key, ret.n->key), leftChild, rightChild);\n\n kcas::start();\n kcas::add(&ret.p->marked, false, false);\n\n if (ret.p->isParentOf(ret.n)) {\n // since p is a parent of n, means n must be left or right\n if (ret.p->left == ret.n) {\n kcas::add(&ret.p->left, ret.n, n1); \n } else {\n kcas::add(&ret.p->right, ret.n, n1);\n }\n if (kcas::execute()) {\n return true;\n } \n } \n // KCAS failed, parent of n has been changed, so free them\n delete n1;\n delete na;\n }\n}\n\nbool ExternalKCAS::erase(const int tid, const int & key) {\n assert(key > minKey - 1 && key >= minKey && key <= maxKey && key < maxKey + 1);\n while (true) {\n // printf(\"tid = %d, erasing %d\\n\", tid, key);\n auto ret = search(tid, key);\n auto dir = compareTo(key, ret.n->key);\n if (dir != 0) return false;\n\n kcas::start();\n\n if (ret.gp->isParentOf(ret.p) && ret.p->isParentOf(ret.n)) {\n kcas::add(\n &ret.gp->marked, false, false,\n // ensure both are unchanged, then mark as true\n &ret.n->marked, (bool) ret.n->marked, true, \n &ret.p->marked, (bool) ret.p->marked, true\n );\n\n // check if parent is left or right of gp\n Node \\* sibling;\n if (ret.gp->left == ret.p) {\n if (ret.p->left == ret.n) {\n sibling = ret.p->right;\n // ensure that both left and right remain unchanged\n // use ret.n and sibling as left or right might be changed before kcas add\n kcas::add( \n &ret.p->left, ret.n, ret.n,\n &ret.p->right, sibling, sibling\n );\n } else {\n sibling = ret.p->left;\n kcas::add(\n &ret.p->left, sibling, sibling, \n &ret.p->right, ret.n, ret.n\n );\n }\n kcas::add(&ret.gp->left, ret.p, sibling);\n } else {\n if (ret.p->left == ret.n) {\n sibling = ret.p->right;\n kcas::add(\n &ret.p->left, ret.n, ret.n,\n &ret.p->right, sibling, sibling\n );\n } else {\n sibling = ret.p->left;\n kcas::add(\n &ret.p->left, sibling, sibling, \n &ret.p->right, ret.n, ret.n\n );\n }\n kcas::add(&ret.gp->right, ret.p, sibling);\n }\n if (kcas::execute()) {\n return true;\n } else {\n // printf(\"tid = %d, cas failed\\n\", tid);\n }\n }\n } \n}\n\nlong ExternalKCAS::getSumOfKeysInSubtree(Node \\* node) {\n if (node == NULL) return 0;\n // only leaves contain real keys\n if (node->isLeaf()) {\n // and we must ignore dummy sentinel keys that are not in [minKey, maxKey]\n if (node->key >= minKey && node->key <= maxKey) {\n //std::cout<<\"counting key \"<key;\n return node->key;\n } else {\n return 0;\n }\n } else {\n return getSumOfKeysInSubtree(node->left)\n + getSumOfKeysInSubtree(node->right);\n }\n}\n\nlong ExternalKCAS::getSumOfKeys() {\n return getSumOfKeysInSubtree(root);\n}\n\nvoid ExternalKCAS::printDebuggingDetails() {\n}\n\nvoid ExternalKCAS::freeSubtree(const int tid, Node \\* node) {\n if (node == NULL) return;\n freeSubtree(tid, node->left);\n freeSubtree(tid, node->right);\n delete node;\n}\n\nThe ExternalKCAS algorithm above is for a linearizable external BST with synchronization-free searches (that do not check marked bits) and atomic modifications. However, they say nothing about whether this algorithmic idea would work for an internal BST that is implemented using similar techniques.\nSuppose we were to implement an internal BST by making its searches (and the search part of updates) synchronization-free, and then performing the modifications in insert and delete atomically (using marking, as in the external BST, to avoid scenarios where operations modify deleted nodes).\nMore detailed algorithm: A contains operation is simply a sequential BST search that stops as soon as it finds the key it is looking for, or when it hits a leaf. Failed inserts and deletes are essentially the same as contains. A successful insert performs a sequential BST search, ending at a node x, then performs the following atomically:\n\u2022 If x is marked or the relevant child points of x is no longer NULL, restart the whole operation \u2022 Create a new node containing the key being inserted\n\u2022 Change the relevant child pointer of x to the new node\nA successful delete performs a sequential BST search, ending at a node x, then performs the following atomically:\n\u2022 If x or parent(x) is marked or parent(x) no longer points to x, restart the whole operation\n\u2022 If x is a leaf, mark it and unlink it (changing the appropriate child pointer of parent(x) to NULL)\n\u2022 If x has one child, mark x and replace it by its child\n\u2022 If x has two children, find the successor, swap the keys of x and its successor, and then mark and delete the successor using one of the previous two cases\n\nIs this internal BST algorithm correct? If not, describe an execution where a search behaves incor-rectly (i.e., returns a non-linearizable result).", "Lyft redesign \u2014 a UX case study\n\nI went to a Design Guru Summit workshop on May 17th. At the workshop,\n\nFrank Yoo\n, Lyft\u2019s head of UX and product design at Lyft, talked about the Lyft re-design. I learned useful design insights from his presentation and I wanted to share some takeaways with my design team at work. On May 26th, I met\nVicki Tan\n, Lyft\u2019s product designer, at Tech in Motion + Verizon Present: Data and Design Tech Talk. She generously shared how their design team did A/B testing, and answered a few questions I had regarding their UX challenges. In order to better support my takeaways presentation, I did extra homework by researching more about the re-design online, and then creating a case study.\n\nWorkshop Notes\n1. Lyft 4 year Overview\nYear 1: Market Fit\nYear 2: Unlocking Supply\nYear 3: Growth \u2014 Growth levers, new regions, marketing (data numbers)\nYear 4: Case Study \u2014 Redesign Lyft\n\n2. Lyft Redesign Goals\n\u009a\u2022 Scale for the future\n\u2022 Provide better context\n\u2022 Improve ergonomics and discoverability\n\n3. Lyft Design Principles\n\u2022 Nail the basics \u2014 Clear choice and context\n\u2022 Build confidence \u2014 Consistency and transparent\n\u2022 Be unique \u2014 Own-able and delightful\n\n1\u20133 are notes I took from\n\nFrank Yoo\n\u2019s presentation at the Design Gurus Summit workshop.\n\nMaslow\u2019s Hierarchy of Needs\nLyft used this concept to define their design principles in a Pyramid shape. I was fascinated by how Lyft integrated psychology to define the principles order of importance.\n\nAs a designer, I often run into situations where people have different ideas about design decisions; it can be tough to judge without any design principles. Therefore, with the encouragement from my colleague\n\nKlara Pelcl\n, I convinced our leadership to let me and\nJules Cheung\ninitiate and collaboratively set core design principles among our design team.\nWe brainstormed together and created our own 6 principles: Know Your User, Clarity, Consistency, Efficiency, Collaboration and Beauty. By looking at Lyft\u2019s design principles graphic, it encouraged me to think about what we can do next to apply them in practice.\n\nOnline Resource\nUX Challenges\nI wanted to know what type of UX challenges Lyft faced while designing the app. I was glad to find some useful resource from Nectar Design, where\n\nFrank\ndid a webinar about how Lyft handles UX challenges, and used the same pyramid method to tackle UX challenges. Here is a summary from Nectar Design:\n\u2022 Usability \u2014 It must solve a compelling user issue\n\u009a\u2022 Reliability \u2014 Everything must work seamlessly and be as transparent as possible (Ex: ride times and costs)\n\u2022 Differentiate \u2014 It must be visually and interactively interesting (Ex: Lyft\u2019s glowing buttons and interactive options menu)\nReasons for Redesign\nDuring the webinar,\n\nFrank\ntalked about the reasons they re-designed the Lyft app, something I wish I could have asked him in person. Again thanks to Nectar Design I was able to find the reasons:\n\u2022 \u009aPoor representation of the driver that is requested\n\u2022 \u009aNo transparency about price or estimated time of arrival\n\u2022 Cars were not directional\n\u2022 \u009aPoor use of color\n\u2022 Options panel awkwardly placed\n\u009a\u2022 Request Lyft is vague for first time users\nSuccess Analysis\nNow you probably want to know what results the Lyft re-design achieved. I might not be able to cover everything here but I\u2019ll share what I have so far.\n\n1. Enhanced Transparency and Safety\nAfter the system matches you with a driver, you can see all the important information you need \u2014 your driver\u2019s name and the color/model of his/her car. More importantly, displaying the driver\u2019s license plate number helps you quickly pick the right car so you know you\u2019re with the right driver.\n2. Better Usage of Primary Color\nFrom what I can see, Lyft uses hot pink as the primary color, and purple as the secondary. During the workshop\n\ntalked about the pink color and how they decided to limit the use of it, applying it only in important situations. My understanding is that they made the pink color an action item color, such as the logo, the \u201cRequest Lyft\u201d button, the destination pin and \u201cFree Rides\u201d on your profile menu.\n\n3. Price Estimate Feature\nThe new UI includes a feature that allows users to get a ride\u2019s quote. By clicking on \u201cPrice estimate\u201d (see the image above), you have a good understanding of how much the ride is going to cost you. For example, a trip to Spicy King restaurant in Chinatown will cost me about $7-$11 from my pickup location.\n\n4. Made It Ergonomic\nErgonomics make the user experience much better. The older app design had actions at both the top and bottom of the screen, which made it harder to use because your fingers had to cross the screen back and forth. What about the new design? I really like it myself as a user for the following reasons:\n\n\u2022 Tab Menu\nAll important menu actions are now at the bottom of the app, where you can select a type of ride you need (Carpool, Line, Regular Lyft, Plus and Premier), and you can set a pickup location right after. The UI for further actions in the request flow are also located in the same spot, resulting in a seamless experience.\n\u2022 Lyft Cars\nOn the map, the little Lyft cars were re-designed nicely, with a hint of pink and purple that shows color consistency across the app. Cars now turn directionally, which is a big help to people like me who don\u2019t have a great sense of direction with maps \u2014 I can now easily figure out if the car I requested is heading towards my location or if the driver is going the opposite way (which also explains why sometime it takes longer than the estimated arrival time).\n\u2022 Options Before Car Arrival\nThe new UI provides 4 options (Cancel, Split, Send ETA, Call driver) to users before their car arrives. I remember the hard time I had with the older UI, when I had to call my driver but couldn\u2019t find the button. Ease of use is much greater with all the options displayed up in front.\nUX Research\nLyft has different type of users \u2014 passengers and drivers, how does UX research collaborate with design? As I mentioned in the beginning,\n\nVicki Tan\nshared her insights during the panel at Tech in Motion + Verizon Present: Data and Design Tech Talk, where I learned quite a bit about their research.\n\u2022 Qualitative data vs. Quantitative data\nLike many other companies, Lyft is metrics-driven and focuses on quantitative analysis (usually the numbers and graphs can be shared with the teams and the stakeholders in many formats, such as email, keynotes). However, quantitative data needs analysis to be useful. Because of that, qualitative data comes in handy and that\u2019s what they focus on more now.\n\n\u2022 Gather User Feedback\nAccording to\n\n, Lyft invites real users (both passengers and drivers) to do regular weekly Q&A sessions in the office to ask them questions and listen to their feedback. By doing so, the design team learns if the users understand the features and what can be improved.\nI believe Lyft also uses other methods to collect qualitative data, so I did some research online and it looks like Lyft has been using \u201cLookback\u201d to aggregate a database of experiences where they can generate a montage of user feedback to better understand their needs. I tried \u201cLookback\u201d a few months ago, and found it very easy to record prototype testing on mobile. At my company, our design and UX research team have been using \u201cValidately\u201d to do both moderated and unmoderated testing.\n\n\u2022 A/B testing\nDuring re-design progress, Lyft ran many A/B tests. As a result,\n\nfound that the design they wanted was not the design the users wanted. At work, my design team faces this struggle all the time where we have different assumptions about what works for users the best. Without A/B testing, we are essentially designing features that suit our best interests, and might not be what the real users need.\n\u2022 Outcome\nAccording to Nectar Design, Lyft has conducted hundreds of hours of user testing and validates their assumptions along the way. This is good because it builds confidence in the team, stakeholders, and customers.\n\nConclusion\nHere is what I learned from doing this case study:\n\nOrganizing and structuring design principles is just as important as creating them in the first place. I\u2019ll continue finding ways to better structure the design principles we created at work, and visualize them so that everyone can get a good understanding of it across the organization.\nDon\u2019t be afraid of doing product re-designs. If you have good reasons and understand what the usability issues are, start planning! Get to know your real users \u2014 user testing is the key. Collect as much quantitative user behavior data as you can, then analyze and categorize them to make sure you have solid qualitative data to support re-design thinking. Follow the cycle of design, release, get user feedback and iterate.\nLyft\u2019s re-design is a great example to show how to create a successful product. If you care about your users, put yourself in their shoes to understand what they need and what they actually do when using a product. If you don\u2019t have a UX research team yet, build one or become a researcher yourself! At work, I work closely with our UX research team, they help the design team tons by recruiting users, setting up user testing, and analyzing the massive data comes in every month. Thanks to their hard work, the design team can take over the numbers and metrics, analyze further to define specific usability areas, and to communicate re-design decisions to our leadership.\nLyft\u2019s re-design case study helped me understand how other companies generate business value by implementing great design in both UI and UX. It gives me confidence that if we apply similar principles, and keep doing what we are doing on UX research, our product team can help the company product achieve much more success in the near future.\n\nGive an overview of this case study", "Yeah, 2000 I was trying to get to this next level, but you know, the parts that are made\n in China are not subject to a tariff, so that's certainly helpful.\n We also save on logistics and generally we found that locally sourced parts in China\n cost less than in the US or Europe.\n So this is all pretty helpful.\n So Tesla got added to the purchase tax exemption, which all the other...\n I'm not sure if you'll realize just how much of an off-field battle Tesla's had to sell\n cars in China.\n It's been a really...\n And basically no access to any of the subsidies and we paid a tariff and we had to ship the\n cars over.\n And every single thing was set against Tesla and still we made progress and did decently\n well.\n So I think that there will be much better situation with local production, not having\n to do shipping and tariffs and being able to have lower cost, local sourcing of components.\n So it would make a big difference I think.\n Is that your victory dance?\n When you broke ran into that?\n Yeah, that's great.\n It's a big deal.\n Huge.\n Yeah, just...\n It's just fundamental economics.\n It kind of makes sense that making cars on the continent where there are boards will\n be a lot more efficient than making them in California and chipping them around the world.\n Yeah.\n Yeah.\n And you can get paid for the cars before paying your suppliers, which seems to not be the\n case if you're shipping around the world.\n Right.\n And it's like friction on the whole kind of cash flow situation or it has been.\n For sure.\n It will sure make a big difference on cash flow because yeah, there's just no way to\n get the cars, especially to Europe, but we're even trying to get them to customers before\n we have to pay suppliers.\n So if you're a rapidly growing company, it's nine day if you get paid by your customers\n before you have to pay your suppliers, like night and day.\n Because in the faster you grow, the video cash position is.\n But if it's the other way around where you have to pay your suppliers before you get paid\n by customers, then the faster you grow, the faster your cash position drops.\n Yes, you're up, yes.\n Because you spend more money to make your own.\n Yes, it's a growth actually causes you to over into the ground in a situation like that.\n Now it tells you we had a mixture of both things where we had a lot of customers in\n say in California.\n And that's fast.\n For sure, we would get paid by customers faster than we'd have to pay suppliers.\n But then for cars going to Europe and Asia, it's the other way around.\n So we would have to pay suppliers before we got paid by customers.\n And now we could offset some of that with the asset back line, which was pretty helpful,\n but only some of it, not all of it.\n So the fundamental financial health for sure improves dramatically by just having a factory\n on the continent.\n We're not talking next door, but it's just how many ocean, especially Europe was logistically\n super hard because we're on the West Coast.\n If we're on the East Coast, then China would be much harder.\n But if you're on the West Coast, you're from the charter because you've got to go to the\n Panama Canal or even worse around Tierra del Fuego.\n Because sometimes the Panama Canal get backed up and you're like, \"This friggin' ship is\n going to the Antarctic.\"\n It's like you could skip up to the end and it stole me as hell.\n It's just so you could just send a ship around chilling.\n Are you kidding?\n In the middle of crazy storms and then back up all the way and then it is too funny.\n Oh my God.\n So let me just take nightmare.\n So yeah, it'd be great to just have it not get on a boat.\n It crossed the Pacific and Atlantic and that kind of thing.\n So maybe similar to Vincent's question, what's the biggest advantage in choosing Berlin\n compared to other European countries?\n Berlin has the best nightclubs.\n That's true.\n How many bit?\n I went to Brooklyn once.\n Really?\n Yeah.\n Holy shit.\n That's cool.\n Yeah, it was a few years ago.\n Well, I don't know.\n I mean, he looked at a lot of different locations and I don't know.\n We could have put him in a lot of locations.\n We needed to move quickly and actually this place, it's like 30 minutes to the outskirts\n of Berlin, technically in Brandenburg.\n It actually was a place location that BMW was going to put a plant there.\n So a ton of the environmental work and all of the permits and stuff had already been\n done.\n And then for some reason, BMW chose a different location.\n But there's like, I guess, something on the order of a year's worth of environmental paperwork\n and stuff that's been done on that location for an auto plant.\n So that's one of the quickest places to get going.\n And generally, the government, local and state government was very supportive.\n So I went there and it's like, OK, this seems like some pretty good vibes this place.\n So this is a lovely part of this lovely place.\n And there's an opportunity for-- it's close enough to Berlin that say young people could\n still live in an apartment in Berlin and commute to the factory.\n It's right, there's a train station.\n They actually can move the train station.\n It's a small train station.\n But they're going to move the train station to where you can literally get off the train\n and be right at the gig of Berlin.\n Wow.\n That's great.\n That's great.\n It could literally just pop right off and walk very unadvisable.\n So then it's like, OK, this is pretty cool.\n And so young people could be in Berlin, apartment, and it's a little quirky here in Berlin.\n But if you want to have more of a family situation, the backyard is affordable, housing available\n with houses with yards and stuff that aren't too expensive.\n Yeah.\n So it seems like a good combination of factors.\n Yeah, a lot of talent in the area.\n So it sounds cool to Google in.\n It just sounds like some cool nightclub, I think.\n You could definitely have a cool nightclub that was cool, but yeah, it sounds good.\n It sounds pretty cool.\n It's pretty fun.\n It's a party gig-ish.\n Yeah.\n It's sort of like a rave cave in the...\n There's a lot of space around the factory side.\n But you should have your own nightclub.\n Yeah.\n I think that would be...\n Who doesn't know what to do?\n I don't know if he doesn't know what to do with that.\n I feel like I'd go for sure a work at a company that's got the nightclub.\n That sounds way more fun.\n Didn't you want to put a roller coaster into the Fremont factory?\n Yeah.\n You're still going to do that?\n I mean, I think that would be pretty fun to do.\n Yeah.\n I think we can just do...\n Yeah, just basically have like...\n We just needed a rail that can support like a modified Tesla's.\n And then...\n Oh my God.\n Can you imagine a plaid flat?\n Yeah, just like zip around.\n Around the factory in like five seconds.\n Yours would be booked for months.\n Yeah, we should get it right now.\n Awesome.\n Yeah, we're kind of actually in various parts of the factory, we have vehicle conveyance\n systems.\n They just don't move that fast.\n But they're kind of like roller coasters that move slowly.\n You can speed up.\n Yeah, you can speed up.\n Exactly.\n So, yeah.\n But yeah, we're all from feeling pretty...\n You know, we're not a tent fade or anything, but feeling pretty good about where things\n are headed.\n And I think this is a lot of good things.\n You know, Model Y coming out this year.\n And some exciting announcements about batteries.\n A lot of progress in autopilot.\n Yeah.\n Yeah.\n So, pulling, giga-balloon.\n And then making progress in some of the new vehicle developments.\n And solo the solar roof, solar glass roof.\n Getting that rolled out.\n The Cybertruck got received really well, I think.\n Yeah.\n Did you expect that many orders?\n No, not really.\n It's amazing.\n When I first saw the Cybertruck in France's design studio, I mean, you know, it had told\n me that this was a daring design.\n Although, I think you're the most excited about this design than any design.\n Yeah, I thought it would be the best product ever.\n Yeah.\n And I saw it.\n I was just taken aback.\n And not by the design so much, by the pure aggression that the truck, you stand in front\n of it and you're like, \"Okay, I'm afraid.\"\n You know, it really is like a badass truck.\n Yeah.\n Yeah.\n Well, it seems like a lot of reasons why people buy pickup trucks in the US is like,\n because it's like the most badass truck.\n You know, like, which one is the toughest truck?\n And it's like, what's tougher than a truck?\n A tank.\n That's a good one.\n Like a tank from the future.\n So, it's like...\n My niece and Parker, which is near Paloburishi, the dirt bath, rider, champion, and a really\n fine side of the truck to the order just the day...\n Fine side of the truck.\n She just encased the first four, R-Bizzy.\n Yeah, part of the book reads her.\n She's stuck her neck.\n And she was a cool boy.\n Yeah, absolutely.\n They just love it.\n Yeah.\n\nclean up the above text formatting.", "Write the code matching the following information\n1 Introduction\nIn this assignment, we are going to implement a chat program using UDP Layer 4 protocol talking\nacross an unreliable channel. The assignment will cover socket programming. You will use C or C++\nto implement it although C is recommended.\nBefore starting the implementation, please read Section 3.4 \u2013 Principles of Reliable Data Transfer from Kurose & Ross to cover the theory. For the practice, you can read Beej\u2019s Guide to Network\nProgramming (Using Internet Sockets). Finally, to understand the big picture regarding the reliable data transfer, you can check out the interactive material on the Kurose & Ross website and\nthis animation.\nYou can discuss the homework and ask your questions on the discussion forum thread on our\nODTUClass page. I am also available at yigit@ceng.metu.edu.tr.\n2 Setup\nPlease follow the instructions given in this section thoroughly to set up your homework environment.\nWe will use an Ubuntu Vagrant box as the host machine and create two network containers in\nit. By adjusting the parameters of the interfaces (at both ends) between the client and the server,\nwe will have a seamless and native unreliable channel without relying on any external programs.\nRun the following commands on an empty folder. If you follow along, you can code on your\nhost machine which is synced with the Vagrant box, so you can compile and run your client and\nserver on there.\n(host) vagrant init ubuntu/jammy64 # create a new ubuntu 22.04 box\n# Places a Vagrantfile on the empty directory\n# We will develop alongside it\n(host) mkdir code\nNow we have a directory with a Vagrantfile and the code directory inside. We can edit the\nVagrantfile to have the code directory synced inside the Vagrant box.\n1\n# -\\*- mode: ruby -\\*-\n# vi: set ft=ruby :\n# All Vagrant configuration is done below. The \"2\" in Vagrant.configure\n# configures the configuration version (we support older styles for\n# backwards compatibility). Please don\u2019t change it unless you know what\n# you\u2019re doing.\nVagrant.configure(\"2\") do |config|\nconfig.vm.box = \"ubuntu/jammy64\"\n# config.vm.synced\\_folder line is commented out, you can edit it\nconfig.vm.synced\\_folder \"./code\", \"/home/vagrant/code\", type: \"rsync\"\n# the rest of the file is commented out and is not important\nend\nYou can use vagrant rsync to push your code inside the Vagrant box or vagrant rsync-auto\non another terminal (in the background) to automate the process.\nThe following sets up the containers.\n(host) vagrant up\n(host) vagrant ssh\n# Set $TERM and useful aliases to enter containers quickly\n(vagrant) echo -e \"export TERM=xterm-256color\" >> .bashrc\n(vagrant) echo -e \u2019alias server=\"sudo nsenter --net=/var/run/netns/netns0\"\u2019 >> .bashrc\n(vagrant) echo -e \u2019alias client=\"sudo nsenter --net=/var/run/netns/netns1\"\u2019 >> .bashrc\n(vagrant) source ~/.bashrc # use the correct TERM and reload .bashrc\n(vagrant) sudo apt update && sudo apt upgrade\n(vagrant) sudo apt install gcc make\n(vagrant) sudo ip netns add netns0\n(vagrant) sudo ip link add veth0 type veth peer name ceth0\n(vagrant) sudo ip link set veth0 up\n(vagrant) sudo ip link set ceth0 netns netns0\n(vagrant) sudo ip netns add netns1\n(vagrant) sudo ip link add veth1 type veth peer name ceth1\n(vagrant) sudo ip link set veth1 up\n(vagrant) sudo ip link set ceth1 netns netns1\n(vagrant) sudo nsenter --net=/var/run/netns/netns0\n(server container) ip link set lo up\n(server container) ip link set ceth0 up\n(server container) ip addr add 172.24.0.10/16 dev ceth0 # from private IPv4 block\n(server container) exit\n(vagrant) sudo nsenter --net=/var/run/netns/netns1\n(client container) ip link set lo up\n(client container) ip link set ceth1 up\n(client container) ip addr add 172.24.0.20/16 dev ceth1\n(client container) exit\n(vagrant) sudo ip link add br0 type bridge\n(vagrant) sudo ip link set br0 up\n2\n(vagrant) sudo ip link set veth0 master br0\n(vagrant) sudo ip link set veth1 master br0\nThe instructions were adapted from Container Networking is Simple!. If you are curious about\nthe process please refer to that tutorial, but understanding it is not necessary to complete this\nhomework.\nYou can also follow the steps on this screencast to see what should be happening at each step.\nAt the end of the screencast I demonstrate the nc binary as a makeshift server-client chat program.\nYour binaries will have a similar behavior.\nYou should run your client binary at the client container and the server binary at the server\ncontainer.\n2.1 Manipulating Traffic\nAll this setup for containers would be quite pointless sans this step. Here, we will write netem\n(Network Emulator) rules using tc to make the connection between the server and the client a lot\nworse. This section was prepared according to the lab manual from Jed Crandall\u2019s course. You\ncan refer to that document for a complete picture.\nThe following tc/netem rules are the worst case you will have to deal with. You should run\nthe rules twice inside each container, one for each interface.\n# on the server, for the server\u2019s interface\ntc qdisc add dev ceth0 root netem delay 100ms 50ms loss 25% 10% duplicate 25% reorder 25% 50%\n# on the client, for the client\u2019s interface\ntc qdisc add dev ceth1 root netem delay 100ms 50ms loss 25% 10% duplicate 25% reorder 25% 50%\nWhile developing, you might want to start with a good channel between the client and the\nserver, and degrade it as you complete the requirements. If you would like to follow that route,\nyou should first start with;\n# on the server, for the server\u2019s interface\ntc qdisc add dev ceth0 root netem delay 100ms 10ms\n# on the client, for the client\u2019s interface\ntc qdisc add dev ceth1 root netem delay 100ms 10ms\nAnd then change the tc rules gradually.\n# on the server, for the server\u2019s interface, note the change rather than add\ntc qdisc change dev ceth0 root netem delay 100ms 10ms loss 20%\n# on the client, for the client\u2019s interface\ntc qdisc change dev ceth1 root netem delay 100ms 10ms loss 20%\nThe following are useful as well;\n# see the current rules in effect\ntc qdisc show\n# deleting a rule using change is cumbersome\n# delete alltogether and start from scratch\n# mind the interface\ntc qdisc del dev ceth0 root\n3\n3 Implementation\nWe are implementing a chat scenario on the command line. Your implementation will output two\nbinaries: a client and a server. The client and the server will only talk to each other, and there\nwill be two participants in the chat. The messages will end with a newline character, so every\nmessage is a single line. A client-server architecture is ideal for this task. However, there are some\nconstraints.\nThe network we are on is particularly bad, the packets might be reordered, dropped, delayed\nor even duplicated. As an additional constraint, the payload of any packet you send can have at\nmost 16 bytes. This does include the sequence number or any other metadata you might use to\ndeliver the packet.\nThe scenario would have been trivial if we were allowed to use SOCK STREAM \u2013 kernel\u2019s TCP\nimplementation. It would take care of the reliable transfer for us. However, we are only allowed to\nuse SOCK DGRAM, to send packets using UDP. You can read more at $ man 2 socket on any Linux\nmachine.\nYou are recommended to start with the interface given in the Section 3.4 of the Kurose & Ross\nbook. We are going to implement the Go-Back-N protocol, described in the textbook.\nTo ensure reliable transfer on the unreliable channel, you need to implement ACK packets to\nmake sure the other side got your packet right, and a timer mechanism for every packet you sent\nso that lost packets can trigger a timeout.\nThe server starts listening on a socket and the client initiates the connection. Then, both\nprograms accept user input from the standard input and send the message to the other side. Any\ninput (on both server and client) will be sent to the other endpoint using reliable data transfer, on\nUDP packets. The receiving party should see the messages in the same order as they were written\nby the sending party, with duplicates silently ignored.\nIdeally, threading should be used to listen and send at the same time. This is especially\nimportant for receiving ACK packets and data packets concurrently, on both endpoints.\nTo terminate the connection, at any time but not as the first input/message, either server\u2019s\nuser or the client\u2019s user can enter three consecutive newline characters on stdin (two empty lines).\nThis will initiate the shutdown & teardown sequence for both the client and the server. Assume\nthe user sitting on the client input two empty lines. The client sends the shutdown request to\nthe server, still following the reliable transfer protocol. However, no more input from stdin will\nbe accepted (e.g. they will be ignored) nor any remaining messages from server will be displayed.\nWhen the server receives the shutdown request, it will also ignore the remaining messages in transit\nand ignore its stdin. When either endpoint complete the shutdown process (either through ACKs\nor sufficient timeouts), they can gracefully exit. The process mirrors for the server as well.", "Task Automation: 10 Tasks You Can Automate with Make - Part 1\nJul 08, 2020 | 13 minutes\nTask Automation 10 Tasks You Can Automate with Make - Part 1\nWhat is task automation? Which are the best task automation tools? What tasks can be automated? \n\nI can\u2019t remember how many times I\u2019ve been asked these questions after mentioning that I work for a company whose product allows for task automation, but it\u2019s certainly been more than a few. \n\nNeedless to say, it doesn\u2019t bother me one bit to answer. \n\nIt\u2019s a good way to break the ice, and I understand the underlying interest in the topic: tasks are getting automated left and right, and the more it happens, the more people want to know about it. \n\nIn addition, questions about task automation have inspired me to write this article. I\u2019ve been wanting to do this after noticing how difficult it can be to provide an answer that is both quick and satisfactory to the question of what tasks can be automated -- so here I am. \n\nWhat will you find here? A comprehensive list of tasks you can automate, plus a couple of baseline concepts about task automation. I will take you beyond generic definitions and tired examples, and into a list of 50 real-life tasks anyone can automate in minutes using Make. \n\nPlease bear in mind, these are not just ideas for task automation, but actual templates that are available on Make, and that you can use to automate your tasks right away. Ready to get started? Buckle up, because we are in for a wild ride. \n\nTask automation: A definition\nFormally speaking, task automation is nearly as old as human industry: the earliest known feedback-controlled mechanism dates back to 300 BC. In case you are wondering, it's a water clock, which of course automated the task of measuring time. \n\nHowever, the topic of task automation gained renewed attention due to digitalization and the increase of software offerings allowing for partial or total automation. \n\nIn this line, the contemporary definition of \u201ctask automation\u201d points to the use of software tools to either reduce or remove the amount of manual labor involved in the completion of a task.\n\nWhich are the best task automation tools?\nWhenever this question pops up, the words of late writer and wine specialist Miguel Brasc\u00f3 come to my mind. Invariably, people used to ask Brasc\u00f3 what the best wine was, and his answer was always the same:\n\nThe best one is the one you like.\n\nI believe the same applies to automation tools, to a degree. If you like a tool, feel comfortable using it, and find it useful you reach your goals in a sustainable way, you already have the answer. If otherwise, you are new to task automation, I recommend you do the following:\n\nIdentify and categorize tasks by qualities like repetitiveness, the amount of time it takes to complete them, and complexity.\n\nCheck which apps are involved in the tasks.\n\nEvaluate your options, which boil down to three alternatives: coding your way to task automation, choosing no-code/low-code automation tools like Make, or relying on native app integrations when suitable.\n\nI understand that it can still be difficult to make a choice after going through this process, and that\u2019s why the following section will help shine a light on what\u2019s the best alternative to cover your needs. Read on!\n\nWhat tasks can be automated?\nI\u2019m well aware that many companies tend to fall for a generic answer here, often in the line of \u201cautomate everything with X\u201d. \n\nAs you can imagine, this is an exaggeration: if a tool to automate everything existed, it would easily dominate the market without needing to make such claims. \n\nThis said, there are products that allow you to automate an impressive range of tasks; so many, that they can be counted in the thousands. Make is one of these tools. \n\nIn this line, I have composed a list of 50 tasks you can automate with Make. The goal is to provide you with actionable examples that work in the real world, using real apps to automate common tasks. \n\nBefore we start, please note that each and one of the task automation examples in the list can be deployed right away and that it is available as a template on Make. \n\nAlso, I decided to break down this post into a 2-part series to make it more digestible. Otherwise, it can be a lot to take in! \n\nNow, let\u2019s take a look at the first 25 tasks you can automate. In this part, I will cover task automation for:\n\nEmail\n\nE-commerce\n\nCRMs\n\nCalendar\n\nEmail tasks automation\nSuitable for: everyone; particularly for digital marketers, email marketing specialists, sales consultants, e-commerce specialistsCommonly used apps: Email, Gmail, MailChimp, Slack, Google Sheets\n\n1. Automatically forward new emails containing a specific word to another email address\nEver found yourself forwarding emails on a regular basis? It happens to all of us, and we tend to do it for both personal and professional purposes. It\u2019s also a time-consuming task that can be thoroughly automated.\n\nWhat does this template do? If an email contains a certain word on the subject line or body, it gets automatically forwarded to the address you determine. Simple, and convenient.\n\nApps used: Gmail\n\nLink to template: Auto forward Gmail emails\n2. Add new emails to a Google Sheets spreadsheet\nSending email addresses to a Google spreadsheet is a great way to start building a database. Email addresses can be used for a number of purposes, including:\n\nThe creation of Facebook audiences for ad campaigns\n\nSending newsletters\n\nLaunching email marketing campaigns\n\nWhat does this template do? Every time you receive an email, it sends the selected data (for example, the sender\u2019s name and address) to a Google Sheets spreadsheet.\n\nApps used: Gmail, Google Sheets\n\nLink to template: Send email data to Google Sheets\n3. Add a \u201cclient\u201d inbox label to emails\nLet\u2019s face it, not everyone uses a CRM to follow up on clients, and Gmail is a popular tool to fulfill the task. However, the larger the client base, the harder to keep up with work, and this is where this integration comes into play.\n\nWhat does this template do? It basically checks incoming emails and looks for matches on a Google Sheets database. If the email address is on the spreadsheet, it will label the emails as a \u201cclient\u201d email, and add it to the corresponding inbox (i.e. \u201cclient inbox\u201d).\n\nApps used: Gmail, Google Sheets\n\nLink to template: Auto label Gmail emails\n4. Get an email for new Google Forms submissions\nForms are a wonderful Google product, and there are many tasks that involve them. Funneling the information contained in a form to another person is a task most people do manually, but that can be entirely (and easily!) automated.\n\nWhat does this template do? It watches Google Forms responses and sends an email whenever a form is completed and submitted. The email notification can be sent to one or more people; it\u2019s up to you to choose the recipients.\n\nApps used: Email, Google Forms\n\nLink to template: Get emails for new Google Forms submissions\n5. Send a welcome email to new MailChimp subscribers\nIf you are using MailChimp to manage email contacts, you know how important it is to nurture customer relationships from the very beginning. What\u2019s most, you can automate the task, and move on.\n\nWhat does this template do? This integration will \u201cwatch\u201d your MailChimp account, and whenever someone subscribes it will trigger an automatic \u201cwelcome\u201d email, which you can configure according to your needs.\n\nApps used: MailChimp, Gmail\n\nLink to template: Automatically send welcome emails\n6. Send Slack messages for new emails\nEmail can be a double-edged sword. Vital as it may be, it can become a distraction as well. A solution to this problem is to concentrate all your activities on your work and productivity tools, such as Slack and ClickUp.\n\nIn the case of email, this means to automatically get emails into a Slack channel of your preference. \n\nWhat does this template do? Watches emails that meet certain criteria (such as sender, receiver, subject, or if there is a certain word in the email body), and then forwards these to a Slack channel of your choice (public or private).\n\nApps used: Gmail, Slack\n\nLink to template: Forward emails to Slack\nEcommerce tasks automation\nSuitable for: ecommerce specialists, online store managers, digital marketers\n\nCommonly used apps: Shopify, Magento, WooCommerce, MailChimp, Stripe, QuickBooks, Xero\n\n7. Save WooCommerce orders into a Google Sheets spreadsheet\nSmall and medium-sized businesses (SMBs) need to keep track of their orders in real-time, and this is exactly what this integration does. Say goodbye to losing orders!\n\nWhat does this template do? Watches new WooCommerce orders, and sends them to a Google Sheets spreadsheet.\n\nApps used: WooCommerce, Google Sheets\n\nLink to template: Send WooCommerce orders to Google Sheets\n8. Save Shopify orders into a Google Sheets spreadsheet\nIn a similar manner to the WooCommerce integration displayed above, there\u2019s a similar way to automate the task of sending orders to a spreadsheet for Shopify users.\n\nWhat does this template do? Watches new Shopify orders, and sends them to a Google Sheets spreadsheet.\n\nApps used: Shopify, Google Sheets\n\nLink to template: Send Shopify orders to Google Sheets\n9. Add new Stripe customers to MailChimp\nStripe is a merchant\u2019s favorite, and stuff like this makes the online payment processor a digital marketer\u2019s favorite as well.\n\nWhat does this template do? Watches Stripe events, collects data (emails), and aggregates it to a MailChimp list of your choice.\n\nApps used: Stripe, MailChimp\n\nLink to template: Add Stripe customers to MailChimp\n10. Add new Shopify customers to MailChimp\nIf you sell on Shopify and use MailChimp for your campaigns, this is the integration you didn\u2019t know you need to automate data transfer between the two apps.\n\nWhat does this template do? Watches for new Shopify customers, collects data (emails), and aggregates it to a MailChimp list of your choice.\n\nApps used: Shopify, MailChimp\n\nLink to template: Add Shopify customers to MailChimp", "Pour ce 1er texte, g\u00e9n\u00e8re moi un Thread Twitter compos\u00e9 de tweets de 280 caract\u00e8res en fran\u00e7ais sans hashtag. Voici le texte : Task Automation: 10 Tasks You Can Automate with Make - Part 1\nJul 08, 2020 | 13 minutes\nTask Automation 10 Tasks You Can Automate with Make - Part 1\nWhat is task automation? Which are the best task automation tools? What tasks can be automated? \n\nI can\u2019t remember how many times I\u2019ve been asked these questions after mentioning that I work for a company whose product allows for task automation, but it\u2019s certainly been more than a few. \n\nNeedless to say, it doesn\u2019t bother me one bit to answer. \n\nIt\u2019s a good way to break the ice, and I understand the underlying interest in the topic: tasks are getting automated left and right, and the more it happens, the more people want to know about it. \n\nIn addition, questions about task automation have inspired me to write this article. I\u2019ve been wanting to do this after noticing how difficult it can be to provide an answer that is both quick and satisfactory to the question of what tasks can be automated -- so here I am. \n\nWhat will you find here? A comprehensive list of tasks you can automate, plus a couple of baseline concepts about task automation. I will take you beyond generic definitions and tired examples, and into a list of 50 real-life tasks anyone can automate in minutes using Make. \n\nPlease bear in mind, these are not just ideas for task automation, but actual templates that are available on Make, and that you can use to automate your tasks right away. Ready to get started? Buckle up, because we are in for a wild ride. \n\nTask automation: A definition\nFormally speaking, task automation is nearly as old as human industry: the earliest known feedback-controlled mechanism dates back to 300 BC. In case you are wondering, it's a water clock, which of course automated the task of measuring time. \n\nHowever, the topic of task automation gained renewed attention due to digitalization and the increase of software offerings allowing for partial or total automation. \n\nIn this line, the contemporary definition of \u201ctask automation\u201d points to the use of software tools to either reduce or remove the amount of manual labor involved in the completion of a task.\n\nWhich are the best task automation tools?\nWhenever this question pops up, the words of late writer and wine specialist Miguel Brasc\u00f3 come to my mind. Invariably, people used to ask Brasc\u00f3 what the best wine was, and his answer was always the same:\n\nThe best one is the one you like.\n\nI believe the same applies to automation tools, to a degree. If you like a tool, feel comfortable using it, and find it useful you reach your goals in a sustainable way, you already have the answer. If otherwise, you are new to task automation, I recommend you do the following:\n\nIdentify and categorize tasks by qualities like repetitiveness, the amount of time it takes to complete them, and complexity.\n\nCheck which apps are involved in the tasks.\n\nEvaluate your options, which boil down to three alternatives: coding your way to task automation, choosing no-code/low-code automation tools like Make, or relying on native app integrations when suitable.\n\nI understand that it can still be difficult to make a choice after going through this process, and that\u2019s why the following section will help shine a light on what\u2019s the best alternative to cover your needs. Read on!\n\nWhat tasks can be automated?\nI\u2019m well aware that many companies tend to fall for a generic answer here, often in the line of \u201cautomate everything with X\u201d. \n\nAs you can imagine, this is an exaggeration: if a tool to automate everything existed, it would easily dominate the market without needing to make such claims. \n\nThis said, there are products that allow you to automate an impressive range of tasks; so many, that they can be counted in the thousands. Make is one of these tools. \n\nIn this line, I have composed a list of 50 tasks you can automate with Make. The goal is to provide you with actionable examples that work in the real world, using real apps to automate common tasks. \n\nBefore we start, please note that each and one of the task automation examples in the list can be deployed right away and that it is available as a template on Make. \n\nAlso, I decided to break down this post into a 2-part series to make it more digestible. Otherwise, it can be a lot to take in! \n\nNow, let\u2019s take a look at the first 25 tasks you can automate. In this part, I will cover task automation for:\n\nEmail\n\nE-commerce\n\nCRMs\n\nCalendar\n\nEmail tasks automation\nSuitable for: everyone; particularly for digital marketers, email marketing specialists, sales consultants, e-commerce specialistsCommonly used apps: Email, Gmail, MailChimp, Slack, Google Sheets\n\n1. Automatically forward new emails containing a specific word to another email address\nEver found yourself forwarding emails on a regular basis? It happens to all of us, and we tend to do it for both personal and professional purposes. It\u2019s also a time-consuming task that can be thoroughly automated.\n\nWhat does this template do? If an email contains a certain word on the subject line or body, it gets automatically forwarded to the address you determine. Simple, and convenient.\n\nApps used: Gmail\n\nLink to template: Auto forward Gmail emails\n2. Add new emails to a Google Sheets spreadsheet\nSending email addresses to a Google spreadsheet is a great way to start building a database. Email addresses can be used for a number of purposes, including:\n\nThe creation of Facebook audiences for ad campaigns\n\nSending newsletters\n\nLaunching email marketing campaigns\n\nWhat does this template do? Every time you receive an email, it sends the selected data (for example, the sender\u2019s name and address) to a Google Sheets spreadsheet.\n\nApps used: Gmail, Google Sheets\n\nLink to template: Send email data to Google Sheets\n3. Add a \u201cclient\u201d inbox label to emails\nLet\u2019s face it, not everyone uses a CRM to follow up on clients, and Gmail is a popular tool to fulfill the task. However, the larger the client base, the harder to keep up with work, and this is where this integration comes into play.\n\nWhat does this template do? It basically checks incoming emails and looks for matches on a Google Sheets database. If the email address is on the spreadsheet, it will label the emails as a \u201cclient\u201d email, and add it to the corresponding inbox (i.e. \u201cclient inbox\u201d).\n\nApps used: Gmail, Google Sheets\n\nLink to template: Auto label Gmail emails\n4. Get an email for new Google Forms submissions\nForms are a wonderful Google product, and there are many tasks that involve them. Funneling the information contained in a form to another person is a task most people do manually, but that can be entirely (and easily!) automated.\n\nWhat does this template do? It watches Google Forms responses and sends an email whenever a form is completed and submitted. The email notification can be sent to one or more people; it\u2019s up to you to choose the recipients.\n\nApps used: Email, Google Forms\n\nLink to template: Get emails for new Google Forms submissions\n5. Send a welcome email to new MailChimp subscribers\nIf you are using MailChimp to manage email contacts, you know how important it is to nurture customer relationships from the very beginning. What\u2019s most, you can automate the task, and move on.\n\nWhat does this template do? This integration will \u201cwatch\u201d your MailChimp account, and whenever someone subscribes it will trigger an automatic \u201cwelcome\u201d email, which you can configure according to your needs.\n\nApps used: MailChimp, Gmail\n\nLink to template: Automatically send welcome emails\n6. Send Slack messages for new emails\nEmail can be a double-edged sword. Vital as it may be, it can become a distraction as well. A solution to this problem is to concentrate all your activities on your work and productivity tools, such as Slack and ClickUp.\n\nIn the case of email, this means to automatically get emails into a Slack channel of your preference. \n\nWhat does this template do? Watches emails that meet certain criteria (such as sender, receiver, subject, or if there is a certain word in the email body), and then forwards these to a Slack channel of your choice (public or private).\n\nApps used: Gmail, Slack\n\nLink to template: Forward emails to Slack\nEcommerce tasks automation\nSuitable for: ecommerce specialists, online store managers, digital marketers\n\nCommonly used apps: Shopify, Magento, WooCommerce, MailChimp, Stripe, QuickBooks, Xero\n\n7. Save WooCommerce orders into a Google Sheets spreadsheet\nSmall and medium-sized businesses (SMBs) need to keep track of their orders in real-time, and this is exactly what this integration does. Say goodbye to losing orders!\n\nWhat does this template do? Watches new WooCommerce orders, and sends them to a Google Sheets spreadsheet.\n\nApps used: WooCommerce, Google Sheets\n\nLink to template: Send WooCommerce orders to Google Sheets\n8. Save Shopify orders into a Google Sheets spreadsheet\nIn a similar manner to the WooCommerce integration displayed above, there\u2019s a similar way to automate the task of sending orders to a spreadsheet for Shopify users.\n\nWhat does this template do? Watches new Shopify orders, and sends them to a Google Sheets spreadsheet.\n\nApps used: Shopify, Google Sheets\n\nLink to template: Send Shopify orders to Google Sheets\n9. Add new Stripe customers to MailChimp\nStripe is a merchant\u2019s favorite, and stuff like this makes the online payment processor a digital marketer\u2019s favorite as well.\n\nWhat does this template do? Watches Stripe events, collects data (emails), and aggregates it to a MailChimp list of your choice.\n\nApps used: Stripe, MailChimp\n\nLink to template: Add Stripe customers to MailChimp\n10. Add new Shopify customers to MailChimp\nIf you sell on Shopify and use MailChimp for your campaigns, this is the integration you didn\u2019t know you need to automate data transfer between the two apps.\n\nWhat does this template do? Watches for new Shopify customers, collects data (emails), and aggregates it to a MailChimp list of your choice.\n\nApps used: Shopify, MailChimp\n\nLink to template: Add Shopify customers to MailChimp", "Summarize this section for me:\n\nSEC. 7. RESOLUTION OF DISAPPROVAL OF DESIGNATION OR REMOVAL OF \n DESIGNATION OF A FOREIGN ADVERSARY.\n\n (a) Definition.--In this section--\n (1) the term ``covered joint resolution'' means a joint \n resolution of disapproval of designation or a joint resolution \n of disapproval of removal of designation;\n (2) the term ``joint resolution of disapproval of \n designation'' means a joint resolution the matter after the \n resolving clause of which is as follows: ``That Congress \n disapproves the designation by the Secretary of Commerce of \\_\\_\\_ \n as a foreign adversary for purposes of the Securing the \n Information and Communications Technology and Services Supply \n Chain Act of 2023, and such designation shall have no force or \n effect until the Secretary of Commerce provides specific \n evidence to the relevant committees of Congress regarding the \n removal of designation under section 6(a) of that Act.'' (The \n blank space being appropriately filled in with the name of the \n foreign person of which the Secretary has designated as a \n foreign adversary of for purposes of this Act); and\n (3) the term ``joint resolution of disapproval of removal \n of designation'' means a joint resolution the matter after the \n resolving clause of which is as follows: ``That Congress \n disapproves the removal of designation by the Secretary of \n Commerce of \\_\\_\\_ as a foreign adversary for purposes of the \n Securing the Information and Communications Technology and \n Services Supply Chain Act of 2023, and such removal shall have \n no force or effect until the Secretary of Commerce provides \n specific evidence to the relevant committees of Congress \n regarding the removal of designation under section 6(a) of that \n Act.'' (The blank space being appropriately filled in with the \n name of the foreign government or regime of which the Secretary \n has removed the designation as a foreign adversary of for \n purposes of this Act).\n (b) Expedited Consideration of Legislation.--\n (1) Initiation.--In the event the Secretary designates a \n foreign government or regime as a foreign adversary or removes \n such designation as a foreign adversary, a joint resolution of \n disapproval of designation or a joint resolution of disapproval \n of removal of designation, as applicable, that is introduced \n during the 60-calendar day period thereafter shall be entitled \n to expedited consideration pursuant to this subsection.\n (2) Introduction.--During the 60-calendar day period \n provided for in paragraph (1), a covered joint resolution may \n be introduced--\n (A) in the Senate, by the Majority Leader (or the \n designee of the Majority Leader) or the Minority Leader \n (or the designee of the Minority Leader); and\n (B) in the House of Representatives, by the Speaker \n or the Minority Leader.\n (3) Floor consideration in house of representatives.--\n (A) Reporting and discharge.--If a relevant \n committee of the House to which a covered joint \n resolution has been referred has not reported such \n covered joint resolution within 10 legislative days \n after the date of referral, that committee shall be \n discharged from further consideration thereof.\n (B) Proceeding to consideration.--Beginning on the \n third legislative day after each committee to which \n covered joint resolution has been referred reports the \n covered joint resolution to the House or has been \n discharged from further consideration thereof, it shall \n be in order to move to proceed to consider the covered \n joint resolution in the House. All points of order \n against the motion are waived. Such a motion shall not \n be in order after the House has disposed of a motion to \n proceed on the covered joint resolution with regard to \n the same agreement. The previous question shall be \n considered as ordered on the motion to its adoption \n without intervening motion. The motion shall not be \n debatable. A motion to reconsider the vote by which the \n motion is disposed of shall not be in order.\n (C) Consideration.--The covered joint resolution \n shall be considered as read. All points of order \n against the covered joint resolution and against its \n consideration are waived. The previous question shall \n be considered as ordered on the covered joint \n resolution to final passage without intervening motion \n except 2 hours of debate equally divided and controlled \n by the sponsor of the covered joint resolution (or a \n designee) and an opponent. A motion to reconsider the \n vote on passage of the covered joint resolution shall \n not be in order.\n (4) Consideration in the senate.--\n (A) Committee referral.--A covered joint resolution \n introduced in the Senate shall be referred to the \n relevant committees of the Senate.\n (B) Reporting and discharge.--If a relevant \n committee of the Senate has not reported such covered \n joint resolution within 10 session days after the date \n of referral of such legislation, that committee shall \n be discharged from further consideration of such \n legislation and the covered joint resolution shall be \n placed on the appropriate calendar.\n (C) Proceeding to consideration.--Notwithstanding \n Rule XXII of the Standing Rules of the Senate, it is in \n order at any time after each committee authorized to \n consider covered joint resolution reports it to the \n Senate or has been discharged from its consideration \n (even though a previous motion to the same effect has \n been disagreed to) to move to proceed to the \n consideration of the covered joint resolution, and all \n points of order against covered joint resolution (and \n against consideration of the covered joint resolution) \n are waived. The motion to proceed is not debatable. The \n motion is not subject to a motion to postpone. A motion \n to reconsider the vote by which the motion is agreed to \n or disagreed to shall not be in order. If a motion to \n proceed to the consideration of the covered joint \n resolution is agreed to, the covered joint resolution \n shall remain the unfinished business until disposed of.\n (D) Debate.--Debate on covered joint resolution, \n and on all debatable motions and appeals in connection \n therewith, shall be limited to not more than 10 hours, \n which shall be divided equally between the majority and \n minority leaders or their designees. A motion to \n further limit debate is in order and not debatable. An \n amendment to, or a motion to postpone, or a motion to \n proceed to the consideration of other business, or a \n motion to recommit the covered joint resolution is not \n in order.\n (E) Vote on passage.--The vote on passage shall \n occur immediately following the conclusion of the \n debate on the covered joint resolution and a single \n quorum call at the conclusion of the debate, if \n requested in accordance with the rules of the Senate.\n (F) Rulings of the chair on procedure.--Appeals \n from the decisions of the Chair relating to the \n application of the rules of the Senate, as the case may \n be, to the procedure relating to a covered joint \n resolution shall be decided without debate.\n (G) Consideration of veto messages.--Debate in the \n Senate of any veto message with respect to a covered \n joint resolution, including all debatable motions and \n appeals in connection with such covered joint \n resolution, shall be limited to 10 hours, to be equally \n divided between, and controlled by, the Majority Leader \n and the Minority Leader or their designees.\n (5) Rules relating to senate and house of \n representatives.--\n (A) Coordination with action by other house.--If, \n before the passage by one House of a covered joint \n resolution of that House, that House receives a covered \n joint resolution from the other House, then the \n following procedures shall apply:\n (i) The covered joint resolution of the \n other House shall not be referred to a \n committee.\n (ii) With respect to covered joint \n resolution of the House receiving the \n legislation--\n (I) the procedure in that House \n shall be the same as if no covered \n joint resolution had been received from \n the other House; but\n (II) the vote on passage shall be \n on the covered joint resolution of the \n other House.\n (B) Treatment of a covered joint resolution of \n other house.--If one House fails to introduce a covered \n joint resolution under this section, the covered joint \n resolution of the other House shall be entitled to \n expedited floor procedures under this section.\n (C) Treatment of companion measures.--If, following \n passage of the covered joint resolution in the Senate, \n the Senate then receives a companion measure from the \n House of Representatives, the companion measure shall \n not be debatable.\n (c) Rules of Senate and House of Representatives.--Subsection (b) \nis enacted by Congress--\n (1) as an exercise of the rulemaking power of the Senate \n and the House of Representatives, respectively, and as such are \n deemed a part of the rules of each House, respectively, but \n applicable only with respect to the procedure to be followed in \n that House in the case of legislation described in those \n sections, and supersede other rules only to the extent that \n they are inconsistent with such rules; and\n (2) with full recognition of the constitutional right of \n either House to change the rules (so far as relating to the \n procedure of that House) at any time, in the same manner, and \n to the same extent as in the case of any other rule of that \n House.\n (d) Effect of Covered Joint Resolution.--\n (1) Joint resolutions of disapproval of designation.--A \n joint resolution of disapproval of designation that is enacted \n in accordance with this section shall remove the designation as \n a foreign adversary of a foreign government or regime that is \n the subject of the joint resolution of disapproval of \n designation for purposes of this Act.\n (2) Joint resolutions of disapproval of removal of \n designation.--A joint resolution of disapproval of removal of \n designation that is enacted in accordance with this section \n shall prohibit the removal of designation as a foreign \n adversary of a foreign government or regime that is the subject \n of the joint resolution of disapproval of removal of \n designation for purposes of this Act.", "Please extract keywords from this: Part 1\nIt was morning, and the new sun sparkled gold across the ripples of a gentle sea. \nA mile from shore a fishing boat chummed the water, and the word for Breakfast Flock flashed through the air, till a crowd of a thousand seagulls came to dodge and fight for bits of food. It was another busy day beginning. \n But way off alone, out by himself beyond boat and shore, Jonathan Livingston Seagull was practicing. A hundred feet in the sky he lowered his webbed feet, lifted his beak, and strained to hold a painful hard twisted curve through his wings. The curve meant that he would fly slowly, and now he slowed until the wind was a whisper in his face, until the ocean stood still beneath him. He narrowed his eyes in fierce concentration, held his breath, forced one ... single ... more ... inch ... of ... curve .... Then his feathers ruffled, he stalled and fell. \n Seagulls, as you know, never falter, never stall. To stall in the air is for them disgraced and it is dishonor. \n But Jonathan Livingston Seagull, unashamed, stretching his wings again in that trembling hard curve - slowing, slowing, and stalling once more - was no ordinary bird. \n Most gulls didn't bother to learn more than the simplest facts of flight \u00adhow to get from shore to food and back again. For most gulls, it is not flying that matters, but eating. For this gull, through, it was not eating that mattered, but flight. More than anything else, Jonathan Livingston Seagull loved to fly. \n This kind of thinking, he found, is not the way to make one's self popular with other birds. Even his parents were dismayed as Jonathan spent whole days alone, making hundreds of low-level glides, experimenting. \n He didn't know why, for instance, but when he flew at altitudes less than half his wingspan above the water, he could stay in the air longer, with less effort. His glides ended not with the usual feet-down splash into the sea, but with a long flat wake as he touched the surface with his feet tightly streamlined against his body. When he began sliding in to feet-up landings on the beach, then pacing the length of his slide in the sand, his parents were very much dismayed indeed. \nWhy, Jon, why?\" his mother asked. \"Why is it so hard to be like the rest of the flock, Jon? Why can't you leave low flying to the pelicans, the albatross? \n\"I don't mind being bone and feathers, Mum. I just want to know what I can do in the air and what I can't, that's all. I just want to know.\" \n\"See here, Jonathan,\" said his father, not unkindly. \"Winter isn't far away. Boats will be few, and the surface fish will be swimming deep. If you must study,. then study food, and how to get it. This flying business is all very well, but you can't eat a glide, you know. Don't you forget that the reason you fly is to eat.\"\n Jonathan nodded obediently. For the next few days he tried to be behave like the other gulls; he really tried, screeching and fighting with the flock around the piers and fishing boats, diving on scraps of fish and bread. But he couldn't make it work. \nIt's all so pointless, he thought, deliberately dropping a hard-won anchovy to a hungry old gull chasing him. I could be spending all this time learning to fly. There's so much to learn! \nIt wasn't long before Jonathan Gull was off by himself again, far out at see, hungry, happy, learning. \n The subject was speed, and in a week's practice he learned more about speed than the fastest gull alive. \n From a thousand feet, flapping his wings as hard as he could, he pushed over into a blazing steep dive toward the waves, and learned why seagulls don't make blazing steep power-dives. In just six seconds he was moving seventy miles per hour, the speed at which one's wing goes unstable on the upstroke. \n Time after time it happened. Careful as he was, working at the very peak of his ability, he lost control at high speed. \n Climb to a thousand feet. Full power straight ahead first, then push over, flapping, to a vertical dive. Then, every time, his left wing stalled on an upstroke, he'd roll violently left, stall his right wing recovering, and flick like fire into a wild tumbling spin to the right. \n He couldn't be careful enough on that upstroke. Ten times he tried, but all ten times, as he passed through seventy miles per hour, he burst into a churning mass of feathers, out of control, crashing down into the water. \n They key, he thought as last, dripping wet, must be to hold the wings still \n From two thousand feet he tried again, rolling into his dive, beak straight down, wings full out and stable from the moment he passed fifty miles per hour. It took tremendous strength, but it worked. In ten seconds he has blurred through ninety miles per hour. Jonathan had set a world speed record for seagulls!\n But victory was short-lived. The instant he began his pullout, the instant he changed the angle of his wings, he snapped into that same terrible uncontrolled disaster, and at ninety miles per hour it hit him like dynamite. Jonathan Seagull exploded in midair and smashed down into a brick-hard sea. \n When he came to, it was well after dark, and he floated in moonlight on the surface of the ocean. His wings were ragged bars of lead, but the weight of failure was even heavier on his back. He wished, feebly, that the weight could be just enough to drag him gently down to the bottom, and end it all. \n As he sank low in the water, a strange hollow voice sounded within him. There's no way around it. I am a seagull. I am limited by my nature. If I were meant to learn so much about flying, I'd have a falcon's short wings, and live on mice instead of fish. My father was right. I must forget this foolishness. I must fly home to the Flock and be content as I am, as a poor limited seagull. \n The voice faded, and Jonathan agreed. The place for a seagull at night is on shore, and from this moment forth, he vowed, he would be a normal gull. It would make everyone happier. \n He pushed wearily away from the dark water and flew toward the land, grateful for what he had learned about work-saving low-altitude flying. \n But no, he thought. I am done with the way I was, I am done with everything I learned. I am a seagull like every other seagull, and I will fly like one. So he climbed painfully to a hundred feet and flapped his wings harder, pressing for shore. \n He felt better for his decision to be just another one of the flock. there would be no ties now to the force that had driven him to learn, there would be no more challenge and no more failure. And it was pretty, just to stop thinking, and fly through the dark, toward the lights above the beach. \nDark! The hollow voice cracked in alarm. Seagulls never fly in the dark!\n Jonathan was not alert enough to listen. It's pretty, he thought. The moon and the lights twinkling on the water, throwing out little beacon-trails though the \n Get Down! Seagulls never fly in the dark! If you were meant to fly in the dark, you'd have the eyes f an owl! You'd have charts for brains! You'd have a falcon's short wings!\n There in the night, a hundred feet in the air, Jonathan Livingston Seagull \u00adblinked. His pain, his resolutions, vanished. \n Short Wings. A falcon's short wings!\n That's the answer! What a fool I've been! All I need is a tiny little wing, all I need is to fold most of my wings and fly on just the tips alone! Short wings!\n He climbed two thousand feet above the black sea, and without a moment for thought of failure and death, he brought his forewings tightly in to his body, left only the narrow swept daggers of his wingtips extended into the wind, and fell into a vertical dive. \n The wind was a monster roar at his head. Seventy miles per hour, ninety, a hundred and twenty and faster still. The wing-strain now at a hundred and forty miles per hour wasn't nearly as hard as it had been before at seventy, and with the faintest twist of his wingtips he eased out of the dive and shot above the waves, a grey cannonball under the moon. \n He closed his eyes to slits against the wind and rejoiced. A hundred forty miles per hour! and under control! If I dive from five thousand feet instead of two thousand, I wonder how fast... \n His vows of a moment before were forgotten, swept away in that great swift wind. Yet he felt guiltless, breaking the promises he had made himself. Such promises are only for the gulls that accept the ordinary. One who has touched excellence in his learning has no need of that kind of promise. \n By sunup, Jonathan Gull was practicing again. From five thousand feet the fishing boats were specks in the flat blue water, Breakfast Flock was a faint cloud of dust motes, circling. \n He was alive, trembling ever so slightly with delight, proud that his fear was under control. Then without ceremony he hugged in his forewings, extended his short, angled wingtips, and plunged directly toward the sea. By the time he had passed four thousand feet he had reached terminal velocity, the wind was a solid beating wall of sound against which he could move no faster. He was flying now straight down, at two hundred fourteen miles per hour. He swallowed, knowing that if his wings unfolded at that speed he'd be blown into a million tiny shreds of seagull. But the speed was power, and the", "Summarize this section for me:\n\nSEC. 7. RESOLUTION OF DISAPPROVAL OF DESIGNATION OR REMOVAL OF \n DESIGNATION OF A FOREIGN ADVERSARY.\n\n (a) Definition.--In this section--\n (1) the term ``covered joint resolution'' means a joint \n resolution of disapproval of designation or a joint resolution \n of disapproval of removal of designation;\n (2) the term ``joint resolution of disapproval of \n designation'' means a joint resolution the matter after the \n resolving clause of which is as follows: ``That Congress \n disapproves the designation by the Secretary of Commerce of \\_\\_\\_ \n as a foreign adversary for purposes of the Securing the \n Information and Communications Technology and Services Supply \n Chain Act of 2023, and such designation shall have no force or \n effect until the Secretary of Commerce provides specific \n evidence to the relevant committees of Congress regarding the \n removal of designation under section 6(a) of that Act.'' (The \n blank space being appropriately filled in with the name of the \n foreign person of which the Secretary has designated as a \n foreign adversary of for purposes of this Act); and\n (3) the term ``joint resolution of disapproval of removal \n of designation'' means a joint resolution the matter after the \n resolving clause of which is as follows: ``That Congress \n disapproves the removal of designation by the Secretary of \n Commerce of \\_\\_\\_ as a foreign adversary for purposes of the \n Securing the Information and Communications Technology and \n Services Supply Chain Act of 2023, and such removal shall have \n no force or effect until the Secretary of Commerce provides \n specific evidence to the relevant committees of Congress \n regarding the removal of designation under section 6(a) of that \n Act.'' (The blank space being appropriately filled in with the \n name of the foreign government or regime of which the Secretary \n has removed the designation as a foreign adversary of for \n purposes of this Act).\n (b) Expedited Consideration of Legislation.--\n (1) Initiation.--In the event the Secretary designates a \n foreign government or regime as a foreign adversary or removes \n such designation as a foreign adversary, a joint resolution of \n disapproval of designation or a joint resolution of disapproval \n of removal of designation, as applicable, that is introduced \n during the 60-calendar day period thereafter shall be entitled \n to expedited consideration pursuant to this subsection.\n (2) Introduction.--During the 60-calendar day period \n provided for in paragraph (1), a covered joint resolution may \n be introduced--\n (A) in the Senate, by the Majority Leader (or the \n designee of the Majority Leader) or the Minority Leader \n (or the designee of the Minority Leader); and\n (B) in the House of Representatives, by the Speaker \n or the Minority Leader.\n (3) Floor consideration in house of representatives.--\n (A) Reporting and discharge.--If a relevant \n committee of the House to which a covered joint \n resolution has been referred has not reported such \n covered joint resolution within 10 legislative days \n after the date of referral, that committee shall be \n discharged from further consideration thereof.\n (B) Proceeding to consideration.--Beginning on the \n third legislative day after each committee to which \n covered joint resolution has been referred reports the \n covered joint resolution to the House or has been \n discharged from further consideration thereof, it shall \n be in order to move to proceed to consider the covered \n joint resolution in the House. All points of order \n against the motion are waived. Such a motion shall not \n be in order after the House has disposed of a motion to \n proceed on the covered joint resolution with regard to \n the same agreement. The previous question shall be \n considered as ordered on the motion to its adoption \n without intervening motion. The motion shall not be \n debatable. A motion to reconsider the vote by which the \n motion is disposed of shall not be in order.\n (C) Consideration.--The covered joint resolution \n shall be considered as read. All points of order \n against the covered joint resolution and against its \n consideration are waived. The previous question shall \n be considered as ordered on the covered joint \n resolution to final passage without intervening motion \n except 2 hours of debate equally divided and controlled \n by the sponsor of the covered joint resolution (or a \n designee) and an opponent. A motion to reconsider the \n vote on passage of the covered joint resolution shall \n not be in order.\n (4) Consideration in the senate.--\n (A) Committee referral.--A covered joint resolution \n introduced in the Senate shall be referred to the \n relevant committees of the Senate.\n (B) Reporting and discharge.--If a relevant \n committee of the Senate has not reported such covered \n joint resolution within 10 session days after the date \n of referral of such legislation, that committee shall \n be discharged from further consideration of such \n legislation and the covered joint resolution shall be \n placed on the appropriate calendar.\n (C) Proceeding to consideration.--Notwithstanding \n Rule XXII of the Standing Rules of the Senate, it is in \n order at any time after each committee authorized to \n consider covered joint resolution reports it to the \n Senate or has been discharged from its consideration \n (even though a previous motion to the same effect has \n been disagreed to) to move to proceed to the \n consideration of the covered joint resolution, and all \n points of order against covered joint resolution (and \n against consideration of the covered joint resolution) \n are waived. The motion to proceed is not debatable. The \n motion is not subject to a motion to postpone. A motion \n to reconsider the vote by which the motion is agreed to \n or disagreed to shall not be in order. If a motion to \n proceed to the consideration of the covered joint \n resolution is agreed to, the covered joint resolution \n shall remain the unfinished business until disposed of.\n (D) Debate.--Debate on covered joint resolution, \n and on all debatable motions and appeals in connection \n therewith, shall be limited to not more than 10 hours, \n which shall be divided equally between the majority and \n minority leaders or their designees. A motion to \n further limit debate is in order and not debatable. An \n amendment to, or a motion to postpone, or a motion to \n proceed to the consideration of other business, or a \n motion to recommit the covered joint resolution is not \n in order.\n (E) Vote on passage.--The vote on passage shall \n occur immediately following the conclusion of the \n debate on the covered joint resolution and a single \n quorum call at the conclusion of the debate, if \n requested in accordance with the rules of the Senate.\n (F) Rulings of the chair on procedure.--Appeals \n from the decisions of the Chair relating to the \n application of the rules of the Senate, as the case may \n be, to the procedure relating to a covered joint \n resolution shall be decided without debate.\n (G) Consideration of veto messages.--Debate in the \n Senate of any veto message with respect to a covered \n joint resolution, including all debatable motions and \n appeals in connection with such covered joint \n resolution, shall be limited to 10 hours, to be equally \n divided between, and controlled by, the Majority Leader \n and the Minority Leader or their designees.\n (5) Rules relating to senate and house of \n representatives.--\n (A) Coordination with action by other house.--If, \n before the passage by one House of a covered joint \n resolution of that House, that House receives a covered \n joint resolution from the other House, then the \n following procedures shall apply:\n (i) The covered joint resolution of the \n other House shall not be referred to a \n committee.\n (ii) With respect to covered joint \n resolution of the House receiving the \n legislation--\n (I) the procedure in that House \n shall be the same as if no covered \n joint resolution had been received from \n the other House; but\n (II) the vote on passage shall be \n on the covered joint resolution of the \n other House.\n (B) Treatment of a covered joint resolution of \n other house.--If one House fails to introduce a covered \n joint resolution under this section, the covered joint \n resolution of the other House shall be entitled to \n expedited floor procedures under this section.\n (C) Treatment of companion measures.--If, following \n passage of the covered joint resolution in the Senate, \n the Senate then receives a companion measure from the \n House of Representatives, the companion measure shall \n not be debatable.\n (c) Rules of Senate and House of Representatives.--Subsection (b) \nis enacted by Congress--\n (1) as an exercise of the rulemaking power of the Senate \n and the House of Representatives, respectively, and as such are \n deemed a part of the rules of each House, respectively, but \n applicable only with respect to the procedure to be followed in \n that House in the case of legislation described in those \n sections, and supersede other rules only to the extent that \n they are inconsistent with such rules; and\n (2) with full recognition of the constitutional right of \n either House to change the rules (so far as relating to the \n procedure of that House) at any time, in the same manner, and \n to the same extent as in the case of any other rule of that \n House.\n (d) Effect of Covered Joint Resolution.--\n (1) Joint resolutions of disapproval of designation.--A \n joint resolution of disapproval of designation that is enacted \n in accordance with this section shall remove the designation as \n a foreign adversary of a foreign government or regime that is \n the subject of the joint resolution of disapproval of \n designation for purposes of this Act.\n (2) Joint resolutions of disapproval of removal of \n designation.--A joint resolution of disapproval of removal of \n designation that is enacted in accordance with this section \n shall prohibit the removal of designation as a foreign \n adversary of a foreign government or regime that is the subject \n of the joint resolution of disapproval of removal of \n designation for purposes of this Act.1 / 1", "can you tell me if he qualifies based on his linkedin profile?\nSALES NAVIGATOR\n47\n47 new alert notificationsHome\nAccounts\nLeads\nMessaging\nActions List\nReferrals\n\nBailey BakerBailey Baker\u2019s profile picture\nSearch\nSearch\nSearch\nLead filters\nAccount filters\nSaved searches\n\nPersonas\nWeston Grove, MD, MPH\u2019S profileWeston Grove, MD, MPH was last active 1 day ago\nWeston Grove, MD, MPH\nPsychiatry Resident at UT Health Houston\n\nAbout\nRelationship\nExperience\nCRM\nProfile actions\n\nMessage\nWeston Grove, MD, MPH has been saved\nSales Navigator Lead Page\nBasic lead information for Weston Grove, MD, MPHBackground Image\n\nWeston Grove, MD, MPH was last active 1 day ago\nMessaged: 3/16/2023\nWeston Grove, MD, MPH\n1st\nPsychiatry Resident at UT Health Houston\nHouston, Texas, United States\n214 connections\nProfile actions\n\nMessage\nWeston Grove, MD, MPH has been saved\nCurrent role\nThe University of Texas Health Science Center at Houston (UTHealth Houston)\nPsychiatry Resident Physician at The University of Texas Health Science Center at Houston (UTHealth Houston)\nJul 2022\u2013Present 9 mos\n\nNo job description\n\nAlso worked at NewYork-Presbyterian Hospital, The University of Texas Health Science Center at Houston (UTHealth), Texas Pediatric Society, the Texas Chapter of the American Academy of Pediatrics See more\nContact information\nWeston\u2019s emailwest.c.grove@gmail.com\n\nAdd contact info\nSearch on Bing\nAbout\nRelationship\nExperience\nCRM\nAbout\nA psychiatry resident physician with 1 year of ER residency and a total 4+ years of clinical experience who is passionate about improving healthcare for patients and clinicians by leveraging innovative technologies. \u2026Show more\nRelationship\nYou and Weston don\u2019t share anything in common on LinkedIn. Search for leads at The University of Texas Health Science Center at Houston (UTHealth Houston) instead.\nSearch leads\nWeston\u2019s experience\nWeston has worked for 4 different companies over their professional career\n\nThe University of Texas Health Science Center at Houston (UTHealth Houston)\nPsychiatry Resident Physician\nThe University of Texas Health Science Center at Houston (UTHealth Houston)\n\nJul 2022\u2013Present 9 mos\n\nHouston, Texas, United States\n\nThe University of Texas Health Science Center at Houston (UTHealth Houston) insights\nHospitals and Health Care\n$500M - $1B in revenue \nHouston, Texas, United States\nCesar Soutullo MD PhD\u2019S profile photo\nSudhakar Selvaraj\u2019s profile photo\nTaiwo Babatope, MD, MPH, MBA.\u2019s profile photo\n+6\nView Account Map\nNEW DECISION MAKERS\n18\n\nEMPLOYEES\n7K+\n\n 2%\nView more The University of Texas Health Science Center at Houston (UTHealth Houston) leads\nAll employees (7K+)\nDecision makers (724)\nNewYork-Presbyterian Hospital\nEmergency Medicine Resident Physician\nNewYork-Presbyterian Hospital\n\nJul 2021\u2013Aug 2022 1 yr 2 mos\n\nNew York, United States\n\n- Rapidly assess critically ill patients and make treatment decisions to mitigate risk in life-threatening situations.\n- Continuously synthesize new information and adapt treatment plans accordingly.\n- Lead multi-disciplinary teams of 4-6 members to coordinate care and streamline communication to ensure patient safety and maximize positive outcomes.\nThe University of Texas Health Science Center at Houston (UTHealth)\nThe University of Texas Health Science Center at Houston (UTHealth)\n3 yrs\n\nLead Researcher\nSep 2020\u2013Apr 2021 8 mos\n\nHouston, Texas, United States\n\nAnalyzed clinical data from the National ED Sample to describe the burden of psychiatric and behavioral health disorders on U.S. emergency departments.\nSurgery Clerkship Representative\nMay 2019\u2013May 2020 1 yr 1 mo\n\nHouston, Texas, United States\n\n- Communicated issues between medical students, clerkship faculty, and deans to resolve ongoing challenges and seek collaborative solutions\n- Designed and implemented a new tool to assess student perceptions of clinical sites and disseminated findings to the class\nPresident of McGovern Simulation in Medicine\nMay 2018\u2013May 2019 1 yr 1 mo\n\n- Planned and coordinated the inaugarel 2018 McGovern Winter Classic, a regional medical simulation competition with over 50 participants from three medical schools\n- Grew organization membership by 400%\n- Managed SIM leadership team in various activities including member recruitment, mentorship, and education\nPracticum Student\nMay 2018\u2013Aug 2018 4 mos\n\nHouston, TX\n\n- Collaborated with multidisciplinary infection prevention team to assess the current state of pharmaceutical compounding activities at UT Physicians clinics\n- Analyzed Qualtrics survey data and prepared written and oral reports that were disseminated to UT Health\u2019s multidisciplinary infection prevention team\nTexas Pediatric Society, the Texas Chapter of the American Academy of Pediatrics\nClinical Preceptee\nTexas Pediatric Society, the Texas Chapter of the American Academy of Pediatrics\n\nMay 2017\u2013Aug 2017 4 mos\n\nHouston, Texas, United States\n\n- Learned and practiced pediatric clinical skills while caring for patients under the supervision of Dr. Tuan Ngyuen at Family Care Pediatrics in Houston, Texas\nUniversity of South Carolina\nUniversity of South Carolina\n3 yrs 5 mos\n\nPrimary Author\nJul 2015\u2013May 2017 1 yr 11 mos\n\nSosua, Dominican Republican\n\n- Investigated the causes of the Dominican Republic\u2019s high incidence of maternal mortality by interviewing female patients in Spanish to assess their attitudes and perceptions toward the local healthcare system\n\n- Collaborated with local physicians and public health officials to identify the crucial needs of the target population\nResearch Associate\nJan 2014\u2013May 2015 1 yr 5 mos\n\nColumbia, SC\n\n- Constructed orthopedic cell scaffolds by synthesizing and manipulating biomimetic nanofibers\n- Continuously improved lab methods through analytical problem solving\n- Supervised and taught procedures to new research associates\nEducation\nThe University of Texas Health Science Center at Houston (UTHealth Houston)\nThe University of Texas Health Science Center at Houston (UTHealth Houston)\nDegree nameDoctor of Medicine - MD Field of studyMedicine\nDates attended or expected graduation2017 \u2013 2021\n\nThe University of Texas Health Science Center at Houston (UTHealth Houston)\nThe University of Texas Health Science Center at Houston (UTHealth Houston)\nDegree nameMaster of Public Health - MPH Field of studyEpidemiology\nDates attended or expected graduation2017 \u2013 2021\n\nUniversity of South Carolina\nUniversity of South Carolina\nDegree nameBachelor of Science - BS Field of studyBiomedical/Medical Engineering\nDates attended or expected graduation2012 \u2013 2016\n\nVolunteering\nHouston Marathon Committee\nVolunteering role\nMedical Volunteer\nCompany name\nHouston Marathon Committee\nInterests\nprofile picture\nUT MD Anderson Cancer Center UTHealth Houston Graduate School of Biomedical Sciences\n4,695 followers\nprofile picture\nUniversity of South Carolina\n246,063 followers\nAngela Duckworth\u2019s picture\nAngela Duckworth\nCo-founder, chief scientist, & board member at Character Lab, professor at UPenn, author of GRIT, co-host of the podcast No Stupid Questions\n866,090 followers\nprofile picture\nNYC Gamecocks\n811 followers\nNisha Mehta, MD\u2019S picture\nNisha Mehta, MD\nPhysician | Founder, Physician Side Gigs | LinkedIn Top Health Voice | Keynote Speaker\n68,421 followers\nMcKinsey & Company\u2019s logo\nMcKinsey & Company\n5,091,650 followers\n\nSee all interests\nFeatured skills and endorsements\nResearch\n\n2 endorsements\nHealthcare\n\n2 endorsements\nTeaching\n\n1 endorsement\nQuality Control\n\nProject Management\n\nMedicine\n\nEmergency Medicine\n\nElectronic Medical Record (EMR)\n\nPublic Health\nShow all skills\nCRM\nSync with your CRM to see related opportunities and writeback key activities\n\nNo CRM match found\nAdd Weston to your CRM to sync their information to Sales Navigator and keep their CRM record up to date.\nFind match\nLead actions panel\nLists (1)\nSaved\nConnection Requested\n (474)\nNotes (0)\n\nAdd\nAdd notes to remember key details about Weston\n\nSimilar leads at The University of Texas Health Science Center at Houston (UTHealth Houston)\nSheng Li\u2019s profile picture\nSheng Li\n3rd\nProfessor\n\nSave\nJohn P. Higgins MD, MBA (GWU), MPHIL (Cantab)\u2019s profile picture\nJohn P. Higgins MD, MBA (GWU), MPHIL (Cantab)\n2nd\nProfessor of Medicine\n\nSave\nSuzanne Manzi, MD\u2019S profile picture\nSuzanne Manzi, MD\n2nd\nClinical Assistant Professor\n\nSave\nGeorge L. W.\u2019s profile picture\nGeorge L. W.\n2nd\nPharmacy Supervisor\n\nSave\nJames Griffiths, MD, CHCIO\u2019S profile picture\nJames Griffiths, MD, CHCIO\n3rd\nAssociate Vice President of Healthcare IT\n\nSave\nShow more\nTimeline\nYour past history with Weston and key events\n3/16/2023\n\nYou sent a Sales Navigator message to Weston\n\n3/16/2023\n\nWeston accepted your connection request\n\n3/16/2023\n\nYou added Weston to Connection Requested List\n\n3/16/2023\n\nYou saved Weston to your saved leads\n\n0 notifications total", "Please summarize this: A Glance into the History of the 8 Jungian Functions\nCarl Jung, the famous Swiss psychiatrist, proposed his model of the eight (8) functions in his work, Psychological Types (1921). He divided the functions into two groups, extraverted (tethered in the external world) and introverted (unfolded in the inner world).\n\nJung\u2019s work would later be built upon by Isabel Briggs Myers and her mother Katharine Cook Briggs, who created a personality model we know today as the Myers-Briggs Type Indicator (MBTI\u00ae). The Myers-Briggs approach used scales for Extraversion-Introversion, Sensing-Intuition and Thinking-Feeling based on Jung\u2019s work and then added a fourth dimension of their own, Judging-Perceiving. The result is 4 different scales on which a person will be assigned one of two possible values. Thus there are 16 combinations (2 x 2 x 2 x 2 = 16).\n\nEach of the 16 personality types have four cognitive functions in alternating directions (i.e. introverted then extraverted, or vice versa), which can be thought of as four \u201cpuzzle pieces\u201d in a particular type. External factors such as upbringing and stress can alter the way each function manifests.\n\nThe four (4) personality scales as proposed by Briggs and Myers:\nExtraversion (E) \u2013 Introversion (I) \u2192 Gaining energy by interacting with other people or alone\nSensing (S) \u2013 Intuition (I) \u2192 Collecting information through the senses or imagination\nThinking (T) \u2013 Feeling (F) \u2192 Making decisions through logic or emotions\nJudging (J) \u2013 Perceiving (P) \u2192 Organizing time by using schedules or without them; result- or process-oriented\nAs mentioned, the first three above are based on Jung\u2019s work with the fourth added by Myers-Briggs. According to Jung, the \u201ccognitive functions\u201d are the two scales of Sensing-Intuition and Thinking-Feeling. These are the ways in which humans process information and think about the world. Then each function can be expressed both in an extraverted manner or an introverted manner. As such, Jung didn\u2019t really view people as \u201cextraverts\u201d and \u201cintroverts\u201d but rather was more focused on the extraverted or introverted expression of each of the four cognitive functions.\n\nJungian four (4) cognitive functions stack:\nJung\u2019s cognitive function \u201cstack\u201d describes the priority or order in which a person uses their cognitive functions, with Primary being the most natural and commonly used and the Inferior being the least-commonly used.\n\nPrimary \u2192 Most natural (and comfortable) function; the internal \u201cmother tongue\u201d\nAuxiliary \u2192 Supporting function, usually connected with creation and job choice\nTertiary \u2192 Function where individual often takes action steps to improve upon\nInferior \u2192 Activates under extreme stress, generally avoided out of self-protection\nDescriptions of the Eight (8) Cognitive Functions\nNow let\u2019s discuss the eight different cognitive functions originally outlined by Jung. His theory proposed that for each of the 4 functions (Sensing, Intuition, Thinking and Feeling) each person would generally either extravert (display outwardly or externally) or introvert (consider inwardly or internally) that function.\n\nAs you read below, consider each function and its expression. Are you more Se or Si? Does Te or Ti come more naturally for you?\n\nExtraverted Sensing (Se)\nTaking action, using all five senses, going forward. Se takes in the present moment in its entirety, and makes rapid decisions on the fly. During times of crisis and emergencies, individuals with primary or auxiliary Se can make the best out of the situation.\n\nExample career areas that emphasize extraverted sensing (Se):\n\nArchaeology\nStunt driving\nFirefighting\nEmergency patrol\nMassage therapy\nIntroverted Sensing (Si)\nAssociations, metaphors, nostalgia. Si can travel back to any point in time through a single scent or sound. Important information (and sometimes interesting trivia) is stored in filing cabinets, where it can be retrieved at any later time.\n\nExample career areas that emphasize introverted sensing (Si):\n\nMuseum curation\nInterior design\nQuantitative sciences (e.g. statistics)\nLibrary sciences\nMedical coding\nExtraverted Intuition (Ne)\nBrainstorming, thinking outside the box, idea generation. Ne easily hops from idea to idea, while making abstract connections. Many artists\u2014especially poets\u2014use significant Ne in their work. To the outside, Ne seems quick, random, and extremely \u201cjumpy.\u201d\n\nExample career areas that emphasize extraverted intuition (Ne):\n\nFilmmaking, concept art\nCopywriting, art direction\nEntrepreneurship\nVideo producer (e.g. Youtube)\nWorkshop facilitating\nIntroverted Intuition (Ni)\nTime-space awareness, predicting the future, hunches. Ni is a far-reaching, visionary function\u2014and can picture the future, sometimes with scary-accurate results.\n\nExample career areas that emphasize introverted intuition (Ni):\n\nDetective services, private investigation\nEconomic predictions and analysis\nForensic and engineering psychology\nPublic speaking, mentoring\nConsulting, all types\nExtraverted Feeling (Fe)\nExpressive emotions, social norms, etiquette. Fe respects the consensus of the group, and puts harmony above personal desires. The function often acts as a mediator between groups, as it naturally puts others\u2019 needs above its own.\n\nExample career areas that emphasize extraverted feeling (Fe):\n\nActing, performance arts\nSinging\nDance therapy\nTelevision hosting\nPublic relations (PR)\nIntroverted Feeling (Fi)\nValues, notions of \u201cright\u201d and \u201cwrong,\u201d likes and dislikes. Fi is a deeply personal and intense function that digs to the core of the human condition. Convictions, morals, and strong beliefs all fall under the Fi umbrella.\n\nExample career areas that emphasize introverted feeling (Fi):\n\nPoetry, creative writing\nArt, various forms\nNarrative design\nMental health counseling\nPeace studies\nExtraverted Thinking (Te)\nFacts, pros and cons, methodological step-by-step strategies. Te respects rules and regulations\u2014and takes great pride in a job well done. Checklists and clear-cut meeting agendas get Te\u2019s gears going\u2014a top-down approach floats its boat.\n\nExample career areas that emphasize extraverted thinking (Te):\n\nAccounting\nPublic and private law\nComputer programming\nNatural sciences, laboratory support\nComputational mathematics\nIntroverted Thinking (Ti)\nIterations, holistic reasoning, agile strategies. Ti takes a bottom-up approach to problem-solving, and fixates on information management. When new data comes in that contradicts old beliefs, Ti will shift like a fluid crystalline framework.\n\nExample career areas that emphasize introverted thinking (Ti):\n\nData analysis\nSystems design engineering\nPhilosophy, sociology\nCybersecurity\nLanguage translation\nWhat are YOUR Functions and Cognitive Stack?\nAccording to Jung\u2019s theory, each person would essentially predominantly display each function (Sensing, Intuition, Thinking, Feeling) in either an extraverted or introverted manner. So of the 8 functions listed above, you\u2019d have 4 of them. If you favor Extraverted Intuition (Ne) it doesn\u2019t mean you can\u2019t use Introverted Intuition (Ni) but rather just that it is less common for you and thus Ne is your primary mode of Intuition. Since Intuition and Sensing are together on scale, if you extravert your Intuition then you tend to introvert your Sensing. So you\u2019d have Ne and Si.\n\nNext you must consider your Thinking-Feeling scale. If this same person tends to externalize (or extravert) their Thinking in the real world then we have a Te, and thus by definition the Feeling would be introverted (Fi). So we have Ne, Si, Te, Fi. But not necessarily in that order. That\u2019s when functional stacking steps in. Each individual uses both Thinking and Feeling functions, which makes the cut-and-dried type system overly simplistic. \n\nThe next task is to determine which function is primary, auxiliary, tertiary and inferior. This is when the concept of functional \u201cstacking\u201d comes in handy. Whichever is most natural is likely the primary, and so on. This is the order of the \u201cstack\u201d, which of your functions comes first or primary, and which comes last or inferior. Let\u2019s say the order in this case is was Ne, Fi, Te, Si. That translates to the ENFP personality type.\n\nCertainly the primary and auxiliary functions are those that come most natural to an individual, and are likely to characterize their outward personality. But while these tendencies may be seen quite obviously on the surface, they don\u2019t fully address one\u2019s personality. The tertiary and inferior functions are also crucial to understand.\n\nIf we only consider the four letters in ENFP (Extraverted, Intuitive, Feeling, Perceiving), for example, it would be next to impossible to see the hidden extraverted thinking (Te) and introverted sensing (Si) in their stacking. ENFPs are more than just their bubbly, charismatic and energetic stereotype. Their Te allows them to systematically work through their tasks and Si with their (often overlooked) excellent memory for details. This can make them excellent PR managers, communications specialists, and journalists.\n\nAnother example of hidden functions in play can be seen in the INTJ (Introverted, Intuitive, Thinking, Judging). INTJs are often dubbed by the entertainment and film industry as chess grandmasters who are strategic, sometimes cunning, and sometimes cold. However, they have introverted feeling (Fi) and extraverted sensing (Se) as their respective third and fourth function. INTJs have strong morals and hold their loved ones dear to their hearts. When under stress, they can become acutely aware of their surroundings and an asset to any team.\n\nHow Does this Relate to \u201cPersonality Typing\u201d?\nThis is the underlying theory behind the Myers-Briggs model and behind most models that also use the 16 personality types nomenclature. There is no shortage of different \u201cpersonality tests\u201d online that you can take that will attempt to determine what your functions are (Fe vs Fi, Te vs Ti, etc.) and in what order they are \u201cstacked\u201d. This then determines which of the 16 types you fall into. While the tests are certainly convenient, any such self-assessment is naturally rigid and prone to testing limitations and thus is never able to get a fully-accurate picture of a human being.", "---------------------------------------------------------------------------\nLookupError Traceback (most recent call last)\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 83 try:\n---> 84 root = nltk.data.find(f\"{self.subdir}/{zip\\_name}\")\n 85 except LookupError:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\data.py in find(resource\\_name, paths)\n 582 resource\\_not\\_found = f\"\\n{sep}\\n{msg}\\n{sep}\\n\"\n--> 583 raise LookupError(resource\\_not\\_found)\n 584 \n\nLookupError: \n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n Resource omw-1.4 not found.\n Please use the NLTK Downloader to obtain the resource:\n\n >>> import nltk\n >>> nltk.download('omw-1.4')\n \n For more information see: https://www.nltk.org/data.html\n\n Attempted to load corpora/omw-1.4.zip/omw-1.4/\n\n Searched in:\n - 'C:\\\\Users\\\\rockr/nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\share\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\lib\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\AppData\\\\Roaming\\\\nltk\\_data'\n - 'C:\\\\nltk\\_data'\n - 'D:\\\\nltk\\_data'\n - 'E:\\\\nltk\\_data'\n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\nDuring handling of the above exception, another exception occurred:\n\nLookupError Traceback (most recent call last)\n~\\AppData\\Local\\Temp\\ipykernel\\_9724\\3827873343.py in \n 41 \n 42 # Preprocess train and test text data\n---> 43 train\\_df['text'] = train\\_df['text'].apply(preprocess\\_text)\n 44 test\\_df['text'] = test\\_df['text'].apply(preprocess\\_text)\n 45 \n\n~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py in apply(self, func, convert\\_dtype, args, \\*\\*kwargs)\n 4431 dtype: float64\n 4432 \"\"\"\n-> 4433 return SeriesApply(self, func, convert\\_dtype, args, kwargs).apply()\n 4434 \n 4435 def \\_reduce(\n\n~\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py in apply(self)\n 1086 return self.apply\\_str()\n 1087 \n-> 1088 return self.apply\\_standard()\n 1089 \n 1090 def agg(self):\n\n~\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py in apply\\_standard(self)\n 1141 # List[Union[Callable[..., Any], str]]]]]\"; expected\n 1142 # \"Callable[[Any], Any]\"\n-> 1143 mapped = lib.map\\_infer(\n 1144 values,\n 1145 f, # type: ignore[arg-type]\n\n~\\Anaconda3\\lib\\site-packages\\pandas\\\\_libs\\lib.pyx in pandas.\\_libs.lib.map\\_infer()\n\n~\\AppData\\Local\\Temp\\ipykernel\\_9724\\3827873343.py in preprocess\\_text(text)\n 35 # Lemmatize\n 36 lemmatizer = WordNetLemmatizer()\n---> 37 tokens = [lemmatizer.lemmatize(token) for token in tokens]\n 38 # Join tokens back into a string\n 39 text = ' '.join(tokens)\n\n~\\AppData\\Local\\Temp\\ipykernel\\_9724\\3827873343.py in (.0)\n 35 # Lemmatize\n 36 lemmatizer = WordNetLemmatizer()\n---> 37 tokens = [lemmatizer.lemmatize(token) for token in tokens]\n 38 # Join tokens back into a string\n 39 text = ' '.join(tokens)\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\stem\\wordnet.py in lemmatize(self, word, pos)\n 43 :return: The lemma of `word`, for the given `pos`.\n 44 \"\"\"\n---> 45 lemmas = wn.\\_morphy(word, pos)\n 46 return min(lemmas, key=len) if lemmas else word\n 47 \n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_getattr\\_\\_(self, attr)\n 119 raise AttributeError(\"LazyCorpusLoader object has no attribute '\\_\\_bases\\_\\_'\")\n 120 \n--> 121 self.\\_\\_load()\n 122 # This looks circular, but its not, since \\_\\_load() changes our\n 123 # \\_\\_class\\_\\_ to something new:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 87 \n 88 # Load the corpus.\n---> 89 corpus = self.\\_\\_reader\\_cls(root, \\*self.\\_\\_args, \\*\\*self.\\_\\_kwargs)\n 90 \n 91 # This is where the magic happens! Transform ourselves into\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py in \\_\\_init\\_\\_(self, root, omw\\_reader)\n 1174 )\n 1175 else:\n-> 1176 self.provenances = self.omw\\_prov()\n 1177 \n 1178 # A cache to store the wordnet data of multiple languages\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py in omw\\_prov(self)\n 1283 provdict = {}\n 1284 provdict[\"eng\"] = \"\"\n-> 1285 fileids = self.\\_omw\\_reader.fileids()\n 1286 for fileid in fileids:\n 1287 prov, langfile = os.path.split(fileid)\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_getattr\\_\\_(self, attr)\n 119 raise AttributeError(\"LazyCorpusLoader object has no attribute '\\_\\_bases\\_\\_'\")\n 120 \n--> 121 self.\\_\\_load()\n 122 # This looks circular, but its not, since \\_\\_load() changes our\n 123 # \\_\\_class\\_\\_ to something new:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 84 root = nltk.data.find(f\"{self.subdir}/{zip\\_name}\")\n 85 except LookupError:\n---> 86 raise e\n 87 \n 88 # Load the corpus.\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 79 else:\n 80 try:\n---> 81 root = nltk.data.find(f\"{self.subdir}/{self.\\_\\_name}\")\n 82 except LookupError as e:\n 83 try:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\data.py in find(resource\\_name, paths)\n 581 sep = \"\\*\" \\* 70\n 582 resource\\_not\\_found = f\"\\n{sep}\\n{msg}\\n{sep}\\n\"\n--> 583 raise LookupError(resource\\_not\\_found)\n 584 \n 585 \n\nLookupError: \n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n Resource omw-1.4 not found.\n Please use the NLTK Downloader to obtain the resource:\n\n >>> import nltk\n >>> nltk.download('omw-1.4')\n \n For more information see: https://www.nltk.org/data.html\n\n Attempted to load corpora/omw-1.4\n\n Searched in:\n - 'C:\\\\Users\\\\rockr/nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\share\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\lib\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\AppData\\\\Roaming\\\\nltk\\_data'\n - 'C:\\\\nltk\\_data'\n - 'D:\\\\nltk\\_data'\n - 'E:\\\\nltk\\_data'\n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\nplease fix this error", "---------------------------------------------------------------------------\nLookupError Traceback (most recent call last)\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 83 try:\n---> 84 root = nltk.data.find(f\"{self.subdir}/{zip\\_name}\")\n 85 except LookupError:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\data.py in find(resource\\_name, paths)\n 582 resource\\_not\\_found = f\"\\n{sep}\\n{msg}\\n{sep}\\n\"\n--> 583 raise LookupError(resource\\_not\\_found)\n 584 \n\nLookupError: \n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n Resource omw-1.4 not found.\n Please use the NLTK Downloader to obtain the resource:\n\n >>> import nltk\n >>> nltk.download('omw-1.4')\n \n For more information see: https://www.nltk.org/data.html\n\n Attempted to load corpora/omw-1.4.zip/omw-1.4/\n\n Searched in:\n - 'C:\\\\Users\\\\rockr/nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\share\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\lib\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\AppData\\\\Roaming\\\\nltk\\_data'\n - 'C:\\\\nltk\\_data'\n - 'D:\\\\nltk\\_data'\n - 'E:\\\\nltk\\_data'\n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\nDuring handling of the above exception, another exception occurred:\n\nLookupError Traceback (most recent call last)\n~\\AppData\\Local\\Temp\\ipykernel\\_9724\\3118448898.py in \n 42 \n 43 # Preprocess train and test text data\n---> 44 train\\_df['text'] = train\\_df['text'].apply(preprocess\\_text)\n 45 test\\_df['text'] = test\\_df['text'].apply(preprocess\\_text)\n 46 \n\n~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py in apply(self, func, convert\\_dtype, args, \\*\\*kwargs)\n 4431 dtype: float64\n 4432 \"\"\"\n-> 4433 return SeriesApply(self, func, convert\\_dtype, args, kwargs).apply()\n 4434 \n 4435 def \\_reduce(\n\n~\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py in apply(self)\n 1086 return self.apply\\_str()\n 1087 \n-> 1088 return self.apply\\_standard()\n 1089 \n 1090 def agg(self):\n\n~\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py in apply\\_standard(self)\n 1141 # List[Union[Callable[..., Any], str]]]]]\"; expected\n 1142 # \"Callable[[Any], Any]\"\n-> 1143 mapped = lib.map\\_infer(\n 1144 values,\n 1145 f, # type: ignore[arg-type]\n\n~\\Anaconda3\\lib\\site-packages\\pandas\\\\_libs\\lib.pyx in pandas.\\_libs.lib.map\\_infer()\n\n~\\AppData\\Local\\Temp\\ipykernel\\_9724\\3118448898.py in preprocess\\_text(text)\n 36 # Lemmatize\n 37 lemmatizer = WordNetLemmatizer()\n---> 38 tokens = [lemmatizer.lemmatize(token) for token in tokens]\n 39 # Join tokens back into a string\n 40 text = ' '.join(tokens)\n\n~\\AppData\\Local\\Temp\\ipykernel\\_9724\\3118448898.py in (.0)\n 36 # Lemmatize\n 37 lemmatizer = WordNetLemmatizer()\n---> 38 tokens = [lemmatizer.lemmatize(token) for token in tokens]\n 39 # Join tokens back into a string\n 40 text = ' '.join(tokens)\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\stem\\wordnet.py in lemmatize(self, word, pos)\n 43 :return: The lemma of `word`, for the given `pos`.\n 44 \"\"\"\n---> 45 lemmas = wn.\\_morphy(word, pos)\n 46 return min(lemmas, key=len) if lemmas else word\n 47 \n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_getattr\\_\\_(self, attr)\n 119 raise AttributeError(\"LazyCorpusLoader object has no attribute '\\_\\_bases\\_\\_'\")\n 120 \n--> 121 self.\\_\\_load()\n 122 # This looks circular, but its not, since \\_\\_load() changes our\n 123 # \\_\\_class\\_\\_ to something new:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 87 \n 88 # Load the corpus.\n---> 89 corpus = self.\\_\\_reader\\_cls(root, \\*self.\\_\\_args, \\*\\*self.\\_\\_kwargs)\n 90 \n 91 # This is where the magic happens! Transform ourselves into\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py in \\_\\_init\\_\\_(self, root, omw\\_reader)\n 1174 )\n 1175 else:\n-> 1176 self.provenances = self.omw\\_prov()\n 1177 \n 1178 # A cache to store the wordnet data of multiple languages\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py in omw\\_prov(self)\n 1283 provdict = {}\n 1284 provdict[\"eng\"] = \"\"\n-> 1285 fileids = self.\\_omw\\_reader.fileids()\n 1286 for fileid in fileids:\n 1287 prov, langfile = os.path.split(fileid)\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_getattr\\_\\_(self, attr)\n 119 raise AttributeError(\"LazyCorpusLoader object has no attribute '\\_\\_bases\\_\\_'\")\n 120 \n--> 121 self.\\_\\_load()\n 122 # This looks circular, but its not, since \\_\\_load() changes our\n 123 # \\_\\_class\\_\\_ to something new:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 84 root = nltk.data.find(f\"{self.subdir}/{zip\\_name}\")\n 85 except LookupError:\n---> 86 raise e\n 87 \n 88 # Load the corpus.\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 79 else:\n 80 try:\n---> 81 root = nltk.data.find(f\"{self.subdir}/{self.\\_\\_name}\")\n 82 except LookupError as e:\n 83 try:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\data.py in find(resource\\_name, paths)\n 581 sep = \"\\*\" \\* 70\n 582 resource\\_not\\_found = f\"\\n{sep}\\n{msg}\\n{sep}\\n\"\n--> 583 raise LookupError(resource\\_not\\_found)\n 584 \n 585 \n\nLookupError: \n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n Resource omw-1.4 not found.\n Please use the NLTK Downloader to obtain the resource:\n\n >>> import nltk\n >>> nltk.download('omw-1.4')\n \n For more information see: https://www.nltk.org/data.html\n\n Attempted to load corpora/omw-1.4\n\n Searched in:\n - 'C:\\\\Users\\\\rockr/nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\share\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\lib\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\AppData\\\\Roaming\\\\nltk\\_data'\n - 'C:\\\\nltk\\_data'\n - 'D:\\\\nltk\\_data'\n - 'E:\\\\nltk\\_data'\n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n\nstill error", "Please provide me with the relevant information that needed to be address during a presentation of this chapter\n\n2.3. Previous work of Visual Assistive Technology\n2.3.1. Head wear\n2.3.1.1. Wearable Travel Aid for Environment Perception and Navigation of Visually Impaired People\n For this project, a consumer Red, Green, Blue, and Depth (RGB-D) camera was attached to a pair of eyeglasses, along with an inertial measurement unit (IMU) attached to a camera, a smartphone, and an earphone for commands/feedback. The system is operable in both indoor and outdoor settings. Due to their ample information, lightweight nature, and low cost compared to other sensors, such as ultrasonic and LiDAR sensors, computer vision technologies were integrated into this device's routing and detection capabilities. The smartphone does the process of detecting and routing, and the feedback is sent to the user's ear through an earphone plugged into the smartphone (Bai et al., 2019).\nLimitation:\n\u2022 Weak in detecting small-size obstacle\n\u2022 Staircase detection is not implemented\u2003\n2.3.1.2. Let Blind People See: Real-Time Visual Recognition with Results Converted to 3D Audio\n Jiang et al. (2016) created a system that took video input from a portable camera. They streamed it to a server for real-time image recognition processing using the You Only Live Once (YOLO) model. The 3D location of the discovered object is derived by using the location and size of the object detection algorithm's bounding boxes. The Unity game engine will send it as 3D audio into their attached wireless earphones. The next sound output interval will be in a few seconds or when a different object is detected, whichever occurs first. The solution could conduct precise real-time objective detection with a live stream at a pace of 30 frames per second in 1080p resolution by utilising the YOLO algorithm and an enhanced wireless transmitter. Figure 4 shows the data flow pipeline of the paper\u2019s system. The video footage is captured and sent to the YOLO algorithm for detecting object. The detected object is then send to the earbuds using the unity engine. Figure 5 shows the prototype of the device of this paper.\nLimitation:\n\u2022 Can only accurately detect and classify object within 2 to 5 meters away\n\u2022 Surrounding ambient will be block when using earbuds\n\u2022 Too much information will be sent to user when camera detect multiple objects\n2.3.2. Smart Cane\n2.3.2.1. Smart Electronic Stick for Visually Impaired using Android Application and Google\u2019s Cloud Vision\n The e-stick module, integrated with a voice-controlled Android application, was designed by Bharatia et al. (2019) to replace the essential simple navigation stick that visually impaired individuals typically use. The e-stick is similar to a standard stick in that it is thin, lightweight, and easy to handle, but it has additional features. Using efficient natural language processing (NLP) features makes these functionalities affordable and possible. The e-stick uses ultrasonic sensors to find low-lying and knee-level obstacles and potholes when moving backwards. Using buzzers, active input on the presence of barriers will be delivered. For Global Positioning System (GPS) navigation to function, the user's phone will be Bluetooth-connected to the stick's circuit. In unavoidable circumstances, the live location of visually impaired individuals will be transmitted to the nearest help centre or their family for assistance. Face detection will be added so that users can tell who is trying to talk to them. With the cloud vision API, it is also possible to translate traffic lights and roadside signs so that blind people can find their way. Text recognition will also be available from photos, making it easy for people to read books, documents, newspapers, and other printed materials. A stick-tracking device has also been built in case the person loses his or her stick. These capabilities will be enabled through hardware (smart stick) and a software module (an Android application). Using Natural Language Processing technology, the user will tell these modules what to do by using voice commands. The e-stick will be charged as needed using a rechargeable circuit. Figure 6 shows how the technologies used in this paper interact.\nLimitation:\n\u2022 Coverage of obstacle detection is short as it is using sensor\n\u2022 Only suitable for indoor\n2.3.2.2. WeWalk\n WeWalk is a smart cane developed by a non-profit organisation called YGA (WeWALK Smart Cane \u2013 Smart Cane for the Visually Impaired, 2020). WeWalk looks like a traditional-looking cane, but the handle has a built-in touchpad. Users can navigate, save and discover places using the cane via the respected application. Particular layers are built into the mapping services for more accessible navigation. Users can choose to use the built-in speaker or Bluetooth for voice feedback. Users can also pair their phone with the intelligent cane via Bluetooth to control their phone. The above-ground The built-in ultrasound sensor detects an above-ground obstacle. The detected obstacle is projected back to the user in the form of vibration or audio, depending on the user\u2019s preferences. Wewalk also has an application where users can view their transit options, such as nearby bus stops and the timetable, and then navigate them to the desired stop. The application also has a built-in voice assistant for more straightforward navigation through the application. If a user loses their phone or cane, they can play a sound on each of them to locate the position of the lost device. Figure 7 shows the WeWalk Smart Cane that is currently on the market.\nLimitation:\n\u2022 The device is very expansive, with the price of 500 USD\n\u2022 Rain or snow might cause malfunction on the smart cane and the speaker\n\u2022 The tip of the cane is loud when navigating rough surface sidewalk\n2.3.2.3. Development of an Intelligent Cane for Visually Impaired Human Subjects\n Asati et al., (2019) designed an intelligent white cane that uses HR-SO4 ultrasonic sensors to identify obstacles within a range of 450 meters and determine the distance. The object above head level will also be detected, as the sensors' range is 450 meters. The warning signal is returned in beeping signals via a buzzer, advising the user to take prompt action. Object detection and classification are done utilizing the intelligent technique. The photos are recorded using the web camera for classification. They will be transformed into text and an audio signal for text-to-speech conversion. Figure 8 shows the prototype of this paper's intelligent cane.\nLimitation:\n\u2022 Cost of building the system is high\n\u2022 Unable to identify pot holes\n\u2022 Detection under rainy weather is not tested\n\u2003\n2.3.3. Handheld\n2.3.3.1. Android Application for Object Recognition Using Neural Networks for the Visually Impaired\n Dosi et al. (2018) have developed an Android application that aids the visually impaired with real-time object recognition using the phone's camera and provides feedback by speaking the recognised object. They opted for a deep learning strategy based on a convolutional neural network for improved recognition and faster response times. MobileNets is utilised because it is ideal for mobile and embedded vision applications. Figure 9 shows the results of the detected object using the object recognition application.\nLimitation:\n\u2022 Only works offline\n\u2022 Unknown or untrained objects will be predicted using existing images in the database\n\u2022 Have to retrain model for untrained object\n2.3.3.2. Design and Implementation of an Embedded Real-Time System for Guiding Visually Impaired Individuals\n Duman et al. (2019) have developed and implemented a portable gadget that detects objects and measures their distance precisely to enable visually impaired individuals to see objects and people around them. The device uses YOLO, a convolutional neural network-based real-time identification method with a single device attached to a Raspberry Pi board. The estimated object distance will be projected in audio form to visually challenged users. The accuracy of this detected distance estimation is 98.8%. Initially, the footage is captured using a handheld Raspberry Pi camera. Afterwards, the object detection module executes YOLO for real-time object recognition, and bounding box size extraction for humans is needed. The size of the bounding box is provided to the distance estimation module to determine the distance of the detected individual. The labels of detected objects and the approximated distance of any individual caught are stored temporarily. An audio generation module translates text-based saved results into audio alerts that visually challenged users can listen to using headphones. Alerts are played at a predetermined time to reduce noise and ambiguity. Figure 10 shows the block diagram of the paper\u2019s proposed system.\nLimitation:\n\u2022 Only detect humans\n\u2022 No design for any wearable option\u2003\n2.3.3.3. Real-time object detection and face recognition system to assist the visually impaired\n Anish Aralikatti et al. (2020) developed an android application that used the phone camera for real-time object and face detection using OpenCV, the You only live once (YOLO) algorithm and FaceNet. Detection of objects and human will be presented in an audio format to the user. OpenCV is used for real-time computer vision tasks. Since it is implemented into an android phone, they chose Tiny YOLO as it is a lightweight YOLO framework perfect for embedded and mobile devices. FaceNet is used for face identification systems as it can extract high-quality features of the face. Figure 12 shows the sample outputs of using the android application on a mobile phone. Figure 11 shows the face recognition feature of the android application.\nLimitation: Less accuracy than YOLO as Tiny YOLO model is smaller (Anish Aralikatti et al., 2020)", "Please provide me with the relevant information that needed to be address during a presentation of this chapter\n\n2.3. Previous work of Visual Assistive Technology\n2.3.1. Head wear\n2.3.1.1. Wearable Travel Aid for Environment Perception and Navigation of Visually Impaired People\n For this project, a consumer Red, Green, Blue, and Depth (RGB-D) camera was attached to a pair of eyeglasses, along with an inertial measurement unit (IMU) attached to a camera, a smartphone, and an earphone for commands/feedback. The system is operable in both indoor and outdoor settings. Due to their ample information, lightweight nature, and low cost compared to other sensors, such as ultrasonic and LiDAR sensors, computer vision technologies were integrated into this device's routing and detection capabilities. The smartphone does the process of detecting and routing, and the feedback is sent to the user's ear through an earphone plugged into the smartphone (Bai et al., 2019).\nLimitation:\n\u2022 Weak in detecting small-size obstacle\n\u2022 Staircase detection is not implemented\u2003\n2.3.1.2. Let Blind People See: Real-Time Visual Recognition with Results Converted to 3D Audio\n Jiang et al. (2016) created a system that took video input from a portable camera. They streamed it to a server for real-time image recognition processing using the You Only Live Once (YOLO) model. The 3D location of the discovered object is derived by using the location and size of the object detection algorithm's bounding boxes. The Unity game engine will send it as 3D audio into their attached wireless earphones. The next sound output interval will be in a few seconds or when a different object is detected, whichever occurs first. The solution could conduct precise real-time objective detection with a live stream at a pace of 30 frames per second in 1080p resolution by utilising the YOLO algorithm and an enhanced wireless transmitter. Figure 4 shows the data flow pipeline of the paper\u2019s system. The video footage is captured and sent to the YOLO algorithm for detecting object. The detected object is then send to the earbuds using the unity engine. Figure 5 shows the prototype of the device of this paper.\nLimitation:\n\u2022 Can only accurately detect and classify object within 2 to 5 meters away\n\u2022 Surrounding ambient will be block when using earbuds\n\u2022 Too much information will be sent to user when camera detect multiple objects\n2.3.2. Smart Cane\n2.3.2.1. Smart Electronic Stick for Visually Impaired using Android Application and Google\u2019s Cloud Vision\n The e-stick module, integrated with a voice-controlled Android application, was designed by Bharatia et al. (2019) to replace the essential simple navigation stick that visually impaired individuals typically use. The e-stick is similar to a standard stick in that it is thin, lightweight, and easy to handle, but it has additional features. Using efficient natural language processing (NLP) features makes these functionalities affordable and possible. The e-stick uses ultrasonic sensors to find low-lying and knee-level obstacles and potholes when moving backwards. Using buzzers, active input on the presence of barriers will be delivered. For Global Positioning System (GPS) navigation to function, the user's phone will be Bluetooth-connected to the stick's circuit. In unavoidable circumstances, the live location of visually impaired individuals will be transmitted to the nearest help centre or their family for assistance. Face detection will be added so that users can tell who is trying to talk to them. With the cloud vision API, it is also possible to translate traffic lights and roadside signs so that blind people can find their way. Text recognition will also be available from photos, making it easy for people to read books, documents, newspapers, and other printed materials. A stick-tracking device has also been built in case the person loses his or her stick. These capabilities will be enabled through hardware (smart stick) and a software module (an Android application). Using Natural Language Processing technology, the user will tell these modules what to do by using voice commands. The e-stick will be charged as needed using a rechargeable circuit. Figure 6 shows how the technologies used in this paper interact.\nLimitation:\n\u2022 Coverage of obstacle detection is short as it is using sensor\n\u2022 Only suitable for indoor\n2.3.2.2. WeWalk\n WeWalk is a smart cane developed by a non-profit organisation called YGA (WeWALK Smart Cane \u2013 Smart Cane for the Visually Impaired, 2020). WeWalk looks like a traditional-looking cane, but the handle has a built-in touchpad. Users can navigate, save and discover places using the cane via the respected application. Particular layers are built into the mapping services for more accessible navigation. Users can choose to use the built-in speaker or Bluetooth for voice feedback. Users can also pair their phone with the intelligent cane via Bluetooth to control their phone. The above-ground The built-in ultrasound sensor detects an above-ground obstacle. The detected obstacle is projected back to the user in the form of vibration or audio, depending on the user\u2019s preferences. Wewalk also has an application where users can view their transit options, such as nearby bus stops and the timetable, and then navigate them to the desired stop. The application also has a built-in voice assistant for more straightforward navigation through the application. If a user loses their phone or cane, they can play a sound on each of them to locate the position of the lost device. Figure 7 shows the WeWalk Smart Cane that is currently on the market.\nLimitation:\n\u2022 The device is very expansive, with the price of 500 USD\n\u2022 Rain or snow might cause malfunction on the smart cane and the speaker\n\u2022 The tip of the cane is loud when navigating rough surface sidewalk\n2.3.2.3. Development of an Intelligent Cane for Visually Impaired Human Subjects\n Asati et al., (2019) designed an intelligent white cane that uses HR-SO4 ultrasonic sensors to identify obstacles within a range of 450 meters and determine the distance. The object above head level will also be detected, as the sensors' range is 450 meters. The warning signal is returned in beeping signals via a buzzer, advising the user to take prompt action. Object detection and classification are done utilizing the intelligent technique. The photos are recorded using the web camera for classification. They will be transformed into text and an audio signal for text-to-speech conversion. Figure 8 shows the prototype of this paper's intelligent cane.\nLimitation:\n\u2022 Cost of building the system is high\n\u2022 Unable to identify pot holes\n\u2022 Detection under rainy weather is not tested\n\u2003\n2.3.3. Handheld\n2.3.3.1. Android Application for Object Recognition Using Neural Networks for the Visually Impaired\n Dosi et al. (2018) have developed an Android application that aids the visually impaired with real-time object recognition using the phone's camera and provides feedback by speaking the recognised object. They opted for a deep learning strategy based on a convolutional neural network for improved recognition and faster response times. MobileNets is utilised because it is ideal for mobile and embedded vision applications. Figure 9 shows the results of the detected object using the object recognition application.\nLimitation:\n\u2022 Only works offline\n\u2022 Unknown or untrained objects will be predicted using existing images in the database\n\u2022 Have to retrain model for untrained object\n2.3.3.2. Design and Implementation of an Embedded Real-Time System for Guiding Visually Impaired Individuals\n Duman et al. (2019) have developed and implemented a portable gadget that detects objects and measures their distance precisely to enable visually impaired individuals to see objects and people around them. The device uses YOLO, a convolutional neural network-based real-time identification method with a single device attached to a Raspberry Pi board. The estimated object distance will be projected in audio form to visually challenged users. The accuracy of this detected distance estimation is 98.8%. Initially, the footage is captured using a handheld Raspberry Pi camera. Afterwards, the object detection module executes YOLO for real-time object recognition, and bounding box size extraction for humans is needed. The size of the bounding box is provided to the distance estimation module to determine the distance of the detected individual. The labels of detected objects and the approximated distance of any individual caught are stored temporarily. An audio generation module translates text-based saved results into audio alerts that visually challenged users can listen to using headphones. Alerts are played at a predetermined time to reduce noise and ambiguity. Figure 10 shows the block diagram of the paper\u2019s proposed system.\nLimitation:\n\u2022 Only detect humans\n\u2022 No design for any wearable option\u2003\n2.3.3.3. Real-time object detection and face recognition system to assist the visually impaired\n Anish Aralikatti et al. (2020) developed an android application that used the phone camera for real-time object and face detection using OpenCV, the You only live once (YOLO) algorithm and FaceNet. Detection of objects and human will be presented in an audio format to the user. OpenCV is used for real-time computer vision tasks. Since it is implemented into an android phone, they chose Tiny YOLO as it is a lightweight YOLO framework perfect for embedded and mobile devices. FaceNet is used for face identification systems as it can extract high-quality features of the face. Figure 12 shows the sample outputs of using the android application on a mobile phone. Figure 11 shows the face recognition feature of the android application.\nLimitation: Less accuracy than YOLO as Tiny YOLO model is smaller (Anish Aralikatti et al., 2020)", "lease provide me with the relevant information that needed to be address during a presentation of this chapter\n\n2.3. Previous work of Visual Assistive Technology\n2.3.1. Head wear\n2.3.1.1. Wearable Travel Aid for Environment Perception and Navigation of Visually Impaired People\n For this project, a consumer Red, Green, Blue, and Depth (RGB-D) camera was attached to a pair of eyeglasses, along with an inertial measurement unit (IMU) attached to a camera, a smartphone, and an earphone for commands/feedback. The system is operable in both indoor and outdoor settings. Due to their ample information, lightweight nature, and low cost compared to other sensors, such as ultrasonic and LiDAR sensors, computer vision technologies were integrated into this device's routing and detection capabilities. The smartphone does the process of detecting and routing, and the feedback is sent to the user's ear through an earphone plugged into the smartphone (Bai et al., 2019).\nLimitation:\n\u2022 Weak in detecting small-size obstacle\n\u2022 Staircase detection is not implemented\u2003\n2.3.1.2. Let Blind People See: Real-Time Visual Recognition with Results Converted to 3D Audio\n Jiang et al. (2016) created a system that took video input from a portable camera. They streamed it to a server for real-time image recognition processing using the You Only Live Once (YOLO) model. The 3D location of the discovered object is derived by using the location and size of the object detection algorithm's bounding boxes. The Unity game engine will send it as 3D audio into their attached wireless earphones. The next sound output interval will be in a few seconds or when a different object is detected, whichever occurs first. The solution could conduct precise real-time objective detection with a live stream at a pace of 30 frames per second in 1080p resolution by utilising the YOLO algorithm and an enhanced wireless transmitter. Figure 4 shows the data flow pipeline of the paper\u2019s system. The video footage is captured and sent to the YOLO algorithm for detecting object. The detected object is then send to the earbuds using the unity engine. Figure 5 shows the prototype of the device of this paper.\nLimitation:\n\u2022 Can only accurately detect and classify object within 2 to 5 meters away\n\u2022 Surrounding ambient will be block when using earbuds\n\u2022 Too much information will be sent to user when camera detect multiple objects\n2.3.2. Smart Cane\n2.3.2.1. Smart Electronic Stick for Visually Impaired using Android Application and Google\u2019s Cloud Vision\n The e-stick module, integrated with a voice-controlled Android application, was designed by Bharatia et al. (2019) to replace the essential simple navigation stick that visually impaired individuals typically use. The e-stick is similar to a standard stick in that it is thin, lightweight, and easy to handle, but it has additional features. Using efficient natural language processing (NLP) features makes these functionalities affordable and possible. The e-stick uses ultrasonic sensors to find low-lying and knee-level obstacles and potholes when moving backwards. Using buzzers, active input on the presence of barriers will be delivered. For Global Positioning System (GPS) navigation to function, the user's phone will be Bluetooth-connected to the stick's circuit. In unavoidable circumstances, the live location of visually impaired individuals will be transmitted to the nearest help centre or their family for assistance. Face detection will be added so that users can tell who is trying to talk to them. With the cloud vision API, it is also possible to translate traffic lights and roadside signs so that blind people can find their way. Text recognition will also be available from photos, making it easy for people to read books, documents, newspapers, and other printed materials. A stick-tracking device has also been built in case the person loses his or her stick. These capabilities will be enabled through hardware (smart stick) and a software module (an Android application). Using Natural Language Processing technology, the user will tell these modules what to do by using voice commands. The e-stick will be charged as needed using a rechargeable circuit. Figure 6 shows how the technologies used in this paper interact.\nLimitation:\n\u2022 Coverage of obstacle detection is short as it is using sensor\n\u2022 Only suitable for indoor\n2.3.2.2. WeWalk\n WeWalk is a smart cane developed by a non-profit organisation called YGA (WeWALK Smart Cane \u2013 Smart Cane for the Visually Impaired, 2020). WeWalk looks like a traditional-looking cane, but the handle has a built-in touchpad. Users can navigate, save and discover places using the cane via the respected application. Particular layers are built into the mapping services for more accessible navigation. Users can choose to use the built-in speaker or Bluetooth for voice feedback. Users can also pair their phone with the intelligent cane via Bluetooth to control their phone. The above-ground The built-in ultrasound sensor detects an above-ground obstacle. The detected obstacle is projected back to the user in the form of vibration or audio, depending on the user\u2019s preferences. Wewalk also has an application where users can view their transit options, such as nearby bus stops and the timetable, and then navigate them to the desired stop. The application also has a built-in voice assistant for more straightforward navigation through the application. If a user loses their phone or cane, they can play a sound on each of them to locate the position of the lost device. Figure 7 shows the WeWalk Smart Cane that is currently on the market.\nLimitation:\n\u2022 The device is very expansive, with the price of 500 USD\n\u2022 Rain or snow might cause malfunction on the smart cane and the speaker\n\u2022 The tip of the cane is loud when navigating rough surface sidewalk\n2.3.2.3. Development of an Intelligent Cane for Visually Impaired Human Subjects\n Asati et al., (2019) designed an intelligent white cane that uses HR-SO4 ultrasonic sensors to identify obstacles within a range of 450 meters and determine the distance. The object above head level will also be detected, as the sensors' range is 450 meters. The warning signal is returned in beeping signals via a buzzer, advising the user to take prompt action. Object detection and classification are done utilizing the intelligent technique. The photos are recorded using the web camera for classification. They will be transformed into text and an audio signal for text-to-speech conversion. Figure 8 shows the prototype of this paper's intelligent cane.\nLimitation:\n\u2022 Cost of building the system is high\n\u2022 Unable to identify pot holes\n\u2022 Detection under rainy weather is not tested\n\u2003\n2.3.3. Handheld\n2.3.3.1. Android Application for Object Recognition Using Neural Networks for the Visually Impaired\n Dosi et al. (2018) have developed an Android application that aids the visually impaired with real-time object recognition using the phone's camera and provides feedback by speaking the recognised object. They opted for a deep learning strategy based on a convolutional neural network for improved recognition and faster response times. MobileNets is utilised because it is ideal for mobile and embedded vision applications. Figure 9 shows the results of the detected object using the object recognition application.\nLimitation:\n\u2022 Only works offline\n\u2022 Unknown or untrained objects will be predicted using existing images in the database\n\u2022 Have to retrain model for untrained object\n2.3.3.2. Design and Implementation of an Embedded Real-Time System for Guiding Visually Impaired Individuals\n Duman et al. (2019) have developed and implemented a portable gadget that detects objects and measures their distance precisely to enable visually impaired individuals to see objects and people around them. The device uses YOLO, a convolutional neural network-based real-time identification method with a single device attached to a Raspberry Pi board. The estimated object distance will be projected in audio form to visually challenged users. The accuracy of this detected distance estimation is 98.8%. Initially, the footage is captured using a handheld Raspberry Pi camera. Afterwards, the object detection module executes YOLO for real-time object recognition, and bounding box size extraction for humans is needed. The size of the bounding box is provided to the distance estimation module to determine the distance of the detected individual. The labels of detected objects and the approximated distance of any individual caught are stored temporarily. An audio generation module translates text-based saved results into audio alerts that visually challenged users can listen to using headphones. Alerts are played at a predetermined time to reduce noise and ambiguity. Figure 10 shows the block diagram of the paper\u2019s proposed system.\nLimitation:\n\u2022 Only detect humans\n\u2022 No design for any wearable option\u2003\n2.3.3.3. Real-time object detection and face recognition system to assist the visually impaired\n Anish Aralikatti et al. (2020) developed an android application that used the phone camera for real-time object and face detection using OpenCV, the You only live once (YOLO) algorithm and FaceNet. Detection of objects and human will be presented in an audio format to the user. OpenCV is used for real-time computer vision tasks. Since it is implemented into an android phone, they chose Tiny YOLO as it is a lightweight YOLO framework perfect for embedded and mobile devices. FaceNet is used for face identification systems as it can extract high-quality features of the face. Figure 12 shows the sample outputs of using the android application on a mobile phone. Figure 11 shows the face recognition feature of the android application.\nLimitation: Less accuracy than YOLO as Tiny YOLO model is smaller (Anish Aralikatti et al., 2020)", "please provide me with the relevant information that needed to be address during a presentation of this chapter\n\n2.3. Previous work of Visual Assistive Technology\n2.3.1. Head wear\n2.3.1.1. Wearable Travel Aid for Environment Perception and Navigation of Visually Impaired People\n For this project, a consumer Red, Green, Blue, and Depth (RGB-D) camera was attached to a pair of eyeglasses, along with an inertial measurement unit (IMU) attached to a camera, a smartphone, and an earphone for commands/feedback. The system is operable in both indoor and outdoor settings. Due to their ample information, lightweight nature, and low cost compared to other sensors, such as ultrasonic and LiDAR sensors, computer vision technologies were integrated into this device's routing and detection capabilities. The smartphone does the process of detecting and routing, and the feedback is sent to the user's ear through an earphone plugged into the smartphone (Bai et al., 2019).\nLimitation:\n\u2022 Weak in detecting small-size obstacle\n\u2022 Staircase detection is not implemented\u2003\n2.3.1.2. Let Blind People See: Real-Time Visual Recognition with Results Converted to 3D Audio\n Jiang et al. (2016) created a system that took video input from a portable camera. They streamed it to a server for real-time image recognition processing using the You Only Live Once (YOLO) model. The 3D location of the discovered object is derived by using the location and size of the object detection algorithm's bounding boxes. The Unity game engine will send it as 3D audio into their attached wireless earphones. The next sound output interval will be in a few seconds or when a different object is detected, whichever occurs first. The solution could conduct precise real-time objective detection with a live stream at a pace of 30 frames per second in 1080p resolution by utilising the YOLO algorithm and an enhanced wireless transmitter. Figure 4 shows the data flow pipeline of the paper\u2019s system. The video footage is captured and sent to the YOLO algorithm for detecting object. The detected object is then send to the earbuds using the unity engine. Figure 5 shows the prototype of the device of this paper.\nLimitation:\n\u2022 Can only accurately detect and classify object within 2 to 5 meters away\n\u2022 Surrounding ambient will be block when using earbuds\n\u2022 Too much information will be sent to user when camera detect multiple objects\n2.3.2. Smart Cane\n2.3.2.1. Smart Electronic Stick for Visually Impaired using Android Application and Google\u2019s Cloud Vision\n The e-stick module, integrated with a voice-controlled Android application, was designed by Bharatia et al. (2019) to replace the essential simple navigation stick that visually impaired individuals typically use. The e-stick is similar to a standard stick in that it is thin, lightweight, and easy to handle, but it has additional features. Using efficient natural language processing (NLP) features makes these functionalities affordable and possible. The e-stick uses ultrasonic sensors to find low-lying and knee-level obstacles and potholes when moving backwards. Using buzzers, active input on the presence of barriers will be delivered. For Global Positioning System (GPS) navigation to function, the user's phone will be Bluetooth-connected to the stick's circuit. In unavoidable circumstances, the live location of visually impaired individuals will be transmitted to the nearest help centre or their family for assistance. Face detection will be added so that users can tell who is trying to talk to them. With the cloud vision API, it is also possible to translate traffic lights and roadside signs so that blind people can find their way. Text recognition will also be available from photos, making it easy for people to read books, documents, newspapers, and other printed materials. A stick-tracking device has also been built in case the person loses his or her stick. These capabilities will be enabled through hardware (smart stick) and a software module (an Android application). Using Natural Language Processing technology, the user will tell these modules what to do by using voice commands. The e-stick will be charged as needed using a rechargeable circuit. Figure 6 shows how the technologies used in this paper interact.\nLimitation:\n\u2022 Coverage of obstacle detection is short as it is using sensor\n\u2022 Only suitable for indoor\n2.3.2.2. WeWalk\n WeWalk is a smart cane developed by a non-profit organisation called YGA (WeWALK Smart Cane \u2013 Smart Cane for the Visually Impaired, 2020). WeWalk looks like a traditional-looking cane, but the handle has a built-in touchpad. Users can navigate, save and discover places using the cane via the respected application. Particular layers are built into the mapping services for more accessible navigation. Users can choose to use the built-in speaker or Bluetooth for voice feedback. Users can also pair their phone with the intelligent cane via Bluetooth to control their phone. The above-ground The built-in ultrasound sensor detects an above-ground obstacle. The detected obstacle is projected back to the user in the form of vibration or audio, depending on the user\u2019s preferences. Wewalk also has an application where users can view their transit options, such as nearby bus stops and the timetable, and then navigate them to the desired stop. The application also has a built-in voice assistant for more straightforward navigation through the application. If a user loses their phone or cane, they can play a sound on each of them to locate the position of the lost device. Figure 7 shows the WeWalk Smart Cane that is currently on the market.\nLimitation:\n\u2022 The device is very expansive, with the price of 500 USD\n\u2022 Rain or snow might cause malfunction on the smart cane and the speaker\n\u2022 The tip of the cane is loud when navigating rough surface sidewalk\n2.3.2.3. Development of an Intelligent Cane for Visually Impaired Human Subjects\n Asati et al., (2019) designed an intelligent white cane that uses HR-SO4 ultrasonic sensors to identify obstacles within a range of 450 meters and determine the distance. The object above head level will also be detected, as the sensors' range is 450 meters. The warning signal is returned in beeping signals via a buzzer, advising the user to take prompt action. Object detection and classification are done utilizing the intelligent technique. The photos are recorded using the web camera for classification. They will be transformed into text and an audio signal for text-to-speech conversion. Figure 8 shows the prototype of this paper's intelligent cane.\nLimitation:\n\u2022 Cost of building the system is high\n\u2022 Unable to identify pot holes\n\u2022 Detection under rainy weather is not tested\n2.3.3. Handheld\n2.3.3.1. Android Application for Object Recognition Using Neural Networks for the Visually Impaired\n Dosi et al. (2018) have developed an Android application that aids the visually impaired with real-time object recognition using the phone's camera and provides feedback by speaking the recognised object. They opted for a deep learning strategy based on a convolutional neural network for improved recognition and faster response times. MobileNets is utilised because it is ideal for mobile and embedded vision applications. Figure 9 shows the results of the detected object using the object recognition application.\nLimitation:\n\u2022 Only works offline\n\u2022 Unknown or untrained objects will be predicted using existing images in the database\n\u2022 Have to retrain model for untrained object\n2.3.3.2. Design and Implementation of an Embedded Real-Time System for Guiding Visually Impaired Individuals\n Duman et al. (2019) have developed and implemented a portable gadget that detects objects and measures their distance precisely to enable visually impaired individuals to see objects and people around them. The device uses YOLO, a convolutional neural network-based real-time identification method with a single device attached to a Raspberry Pi board. The estimated object distance will be projected in audio form to visually challenged users. The accuracy of this detected distance estimation is 98.8%. Initially, the footage is captured using a handheld Raspberry Pi camera. Afterwards, the object detection module executes YOLO for real-time object recognition, and bounding box size extraction for humans is needed. The size of the bounding box is provided to the distance estimation module to determine the distance of the detected individual. The labels of detected objects and the approximated distance of any individual caught are stored temporarily. An audio generation module translates text-based saved results into audio alerts that visually challenged users can listen to using headphones. Alerts are played at a predetermined time to reduce noise and ambiguity. Figure 10 shows the block diagram of the paper\u2019s proposed system.\nLimitation:\n\u2022 Only detect humans\n\u2022 No design for any wearable option\u2003\n2.3.3.3. Real-time object detection and face recognition system to assist the visually impaired\n Anish Aralikatti et al. (2020) developed an android application that used the phone camera for real-time object and face detection using OpenCV, the You only live once (YOLO) algorithm and FaceNet. Detection of objects and human will be presented in an audio format to the user. OpenCV is used for real-time computer vision tasks. Since it is implemented into an android phone, they chose Tiny YOLO as it is a lightweight YOLO framework perfect for embedded and mobile devices. FaceNet is used for face identification systems as it can extract high-quality features of the face. Figure 12 shows the sample outputs of using the android application on a mobile phone. Figure 11 shows the face recognition feature of the android application.\nLimitation: Less accuracy than YOLO as Tiny YOLO model is smaller (Anish Aralikatti et al., 2020)", "please provide me with the relevant information that needed to be address during a presentation of this chapter\n\n2.3. Previous work of Visual Assistive Technology\n2.3.1. Head wear\n2.3.1.1. Wearable Travel Aid for Environment Perception and Navigation of Visually Impaired People\nFor this project, a consumer Red, Green, Blue, and Depth (RGB-D) camera was attached to a pair of eyeglasses, along with an inertial measurement unit (IMU) attached to a camera, a smartphone, and an earphone for commands/feedback. The system is operable in both indoor and outdoor settings. Due to their ample information, lightweight nature, and low cost compared to other sensors, such as ultrasonic and LiDAR sensors, computer vision technologies were integrated into this device's routing and detection capabilities. The smartphone does the process of detecting and routing, and the feedback is sent to the user's ear through an earphone plugged into the smartphone (Bai et al., 2019).\nLimitation:\n\u2022 Weak in detecting small-size obstacle\n\u2022 Staircase detection is not implemented\u2003\n2.3.1.2. Let Blind People See: Real-Time Visual Recognition with Results Converted to 3D Audio\nJiang et al. (2016) created a system that took video input from a portable camera. They streamed it to a server for real-time image recognition processing using the You Only Live Once (YOLO) model. The 3D location of the discovered object is derived by using the location and size of the object detection algorithm's bounding boxes. The Unity game engine will send it as 3D audio into their attached wireless earphones. The next sound output interval will be in a few seconds or when a different object is detected, whichever occurs first. The solution could conduct precise real-time objective detection with a live stream at a pace of 30 frames per second in 1080p resolution by utilising the YOLO algorithm and an enhanced wireless transmitter. Figure 4 shows the data flow pipeline of the paper\u2019s system. The video footage is captured and sent to the YOLO algorithm for detecting object. The detected object is then send to the earbuds using the unity engine. Figure 5 shows the prototype of the device of this paper.\nLimitation:\n\u2022 Can only accurately detect and classify object within 2 to 5 meters away\n\u2022 Surrounding ambient will be block when using earbuds\n\u2022 Too much information will be sent to user when camera detect multiple objects\n\n2.3.2. Smart Cane\n2.3.2.1. Smart Electronic Stick for Visually Impaired using Android Application and Google\u2019s Cloud Vision\nThe e-stick module, integrated with a voice-controlled Android application, was designed by Bharatia et al. (2019) to replace the essential simple navigation stick that visually impaired individuals typically use. The e-stick is similar to a standard stick in that it is thin, lightweight, and easy to handle, but it has additional features. Using efficient natural language processing (NLP) features makes these functionalities affordable and possible. The e-stick uses ultrasonic sensors to find low-lying and knee-level obstacles and potholes when moving backwards. Using buzzers, active input on the presence of barriers will be delivered. For Global Positioning System (GPS) navigation to function, the user's phone will be Bluetooth-connected to the stick's circuit. In unavoidable circumstances, the live location of visually impaired individuals will be transmitted to the nearest help centre or their family for assistance. Face detection will be added so that users can tell who is trying to talk to them. With the cloud vision API, it is also possible to translate traffic lights and roadside signs so that blind people can find their way. Text recognition will also be available from photos, making it easy for people to read books, documents, newspapers, and other printed materials. A stick-tracking device has also been built in case the person loses his or her stick. These capabilities will be enabled through hardware (smart stick) and a software module (an Android application). Using Natural Language Processing technology, the user will tell these modules what to do by using voice commands. The e-stick will be charged as needed using a rechargeable circuit. Figure 6 shows how the technologies used in this paper interact.\nLimitation:\n\u2022 Coverage of obstacle detection is short as it is using sensor\n\u2022 Only suitable for indoor\n2.3.2.2. WeWalkWeWalk is a smart cane developed by a non-profit organisation called YGA (WeWALK Smart Cane \u2013 Smart Cane for the Visually Impaired, 2020). WeWalk looks like a traditional-looking cane, but the handle has a built-in touchpad. Users can navigate, save and discover places using the cane via the respected application. Particular layers are built into the mapping services for more accessible navigation. Users can choose to use the built-in speaker or Bluetooth for voice feedback. Users can also pair their phone with the intelligent cane via Bluetooth to control their phone. The above-ground The built-in ultrasound sensor detects an above-ground obstacle. The detected obstacle is projected back to the user in the form of vibration or audio, depending on the user\u2019s preferences. Wewalk also has an application where users can view their transit options, such as nearby bus stops and the timetable, and then navigate them to the desired stop. The application also has a built-in voice assistant for more straightforward navigation through the application. If a user loses their phone or cane, they can play a sound on each of them to locate the position of the lost device. Figure 7 shows the WeWalk Smart Cane that is currently on the market.\nLimitation:\n\u2022 The device is very expansive, with the price of 500 USD\n\u2022 Rain or snow might cause malfunction on the smart cane and the speaker\n\u2022 The tip of the cane is loud when navigating rough surface sidewalk\n2.3.2.3. Development of an Intelligent Cane for Visually Impaired Human Subjects\n Asati et al., (2019) designed an intelligent white cane that uses HR-SO4 ultrasonic sensors to identify obstacles within a range of 450 meters and determine the distance. The object above head level will also be detected, as the sensors' range is 450 meters. The warning signal is returned in beeping signals via a buzzer, advising the user to take prompt action. Object detection and classification are done utilizing the intelligent technique. The photos are recorded using the web camera for classification. They will be transformed into text and an audio signal for text-to-speech conversion. Figure 8 shows the prototype of this paper's intelligent cane.\nLimitation:\n\u2022 Cost of building the system is high\n\u2022 Unable to identify pot holes\n\u2022 Detection under rainy weather is not tested\n2.3.3. Handheld\n2.3.3.1. Android Application for Object Recognition Using Neural Networks for the Visually Impaired\n Dosi et al. (2018) have developed an Android application that aids the visually impaired with real-time object recognition using the phone's camera and provides feedback by speaking the recognised object. They opted for a deep learning strategy based on a convolutional neural network for improved recognition and faster response times. MobileNets is utilised because it is ideal for mobile and embedded vision applications. Figure 9 shows the results of the detected object using the object recognition application.\nLimitation:\n\u2022 Only works offline\n\u2022 Unknown or untrained objects will be predicted using existing images in the database\n\u2022 Have to retrain model for untrained object\n2.3.3.2. Design and Implementation of an Embedded Real-Time System for Guiding Visually Impaired Individuals\n Duman et al. (2019) have developed and implemented a portable gadget that detects objects and measures their distance precisely to enable visually impaired individuals to see objects and people around them. The device uses YOLO, a convolutional neural network-based real-time identification method with a single device attached to a Raspberry Pi board. The estimated object distance will be projected in audio form to visually challenged users. The accuracy of this detected distance estimation is 98.8%. Initially, the footage is captured using a handheld Raspberry Pi camera. Afterwards, the object detection module executes YOLO for real-time object recognition, and bounding box size extraction for humans is needed. The size of the bounding box is provided to the distance estimation module to determine the distance of the detected individual. The labels of detected objects and the approximated distance of any individual caught are stored temporarily. An audio generation module translates text-based saved results into audio alerts that visually challenged users can listen to using headphones. Alerts are played at a predetermined time to reduce noise and ambiguity. Figure 10 shows the block diagram of the paper\u2019s proposed system.\nLimitation:\n\u2022 Only detect humans\n\u2022 No design for any wearable option\u2003\n2.3.3.3. Real-time object detection and face recognition system to assist the visually impaired\n Anish Aralikatti et al. (2020) developed an android application that used the phone camera for real-time object and face detection using OpenCV, the You only live once (YOLO) algorithm and FaceNet. Detection of objects and human will be presented in an audio format to the user. OpenCV is used for real-time computer vision tasks. Since it is implemented into an android phone, they chose Tiny YOLO as it is a lightweight YOLO framework perfect for embedded and mobile devices. FaceNet is used for face identification systems as it can extract high-quality features of the face. Figure 12 shows the sample outputs of using the android application on a mobile phone. Figure 11 shows the face recognition feature of the android application.\nLimitation: Less accuracy than YOLO as Tiny YOLO model is smaller (Anish Aralikatti et al., 2020)", "Please provide me with the relevant information that needed to be address during a presentation of this chapter\n\n2.3. Previous work of Visual Assistive Technology\n\n2.3.1. Head wear\n\n2.3.1.1. Wearable Travel Aid for Environment Perception and Navigation of Visually Impaired People\nFor this project, a consumer Red, Green, Blue, and Depth (RGB-D) camera was attached to a pair of eyeglasses, along with an inertial measurement unit (IMU) attached to a camera, a smartphone, and an earphone for commands/feedback. The system is operable in both indoor and outdoor settings. Due to their ample information, lightweight nature, and low cost compared to other sensors, such as ultrasonic and LiDAR sensors, computer vision technologies were integrated into this device's routing and detection capabilities. The smartphone does the process of detecting and routing, and the feedback is sent to the user's ear through an earphone plugged into the smartphone (Bai et al., 2019).\nLimitation:\n\u2022 Weak in detecting small-size obstacle\n\u2022 Staircase detection is not implemented\u2003\n\n2.3.1.2. Let Blind People See: Real-Time Visual Recognition with Results Converted to 3D Audio\nJiang et al. (2016) created a system that took video input from a portable camera. They streamed it to a server for real-time image recognition processing using the You Only Live Once (YOLO) model. The 3D location of the discovered object is derived by using the location and size of the object detection algorithm's bounding boxes. The Unity game engine will send it as 3D audio into their attached wireless earphones. The next sound output interval will be in a few seconds or when a different object is detected, whichever occurs first. The solution could conduct precise real-time objective detection with a live stream at a pace of 30 frames per second in 1080p resolution by utilising the YOLO algorithm and an enhanced wireless transmitter. Figure 4 shows the data flow pipeline of the paper\u2019s system. The video footage is captured and sent to the YOLO algorithm for detecting object. The detected object is then send to the earbuds using the unity engine. Figure 5 shows the prototype of the device of this paper.\nLimitation:\n\u2022 Can only accurately detect and classify object within 2 to 5 meters away\n\u2022 Surrounding ambient will be block when using earbuds\n\u2022 Too much information will be sent to user when camera detect multiple objects\n\n2.3.2. Smart Cane\n2.3.2.1. Smart Electronic Stick for Visually Impaired using Android Application and Google\u2019s Cloud Vision\nThe e-stick module, integrated with a voice-controlled Android application, was designed by Bharatia et al. (2019) to replace the essential simple navigation stick that visually impaired individuals typically use. The e-stick is similar to a standard stick in that it is thin, lightweight, and easy to handle, but it has additional features. Using efficient natural language processing (NLP) features makes these functionalities affordable and possible. The e-stick uses ultrasonic sensors to find low-lying and knee-level obstacles and potholes when moving backwards. Using buzzers, active input on the presence of barriers will be delivered. For Global Positioning System (GPS) navigation to function, the user's phone will be Bluetooth-connected to the stick's circuit. In unavoidable circumstances, the live location of visually impaired individuals will be transmitted to the nearest help centre or their family for assistance. Face detection will be added so that users can tell who is trying to talk to them. With the cloud vision API, it is also possible to translate traffic lights and roadside signs so that blind people can find their way. Text recognition will also be available from photos, making it easy for people to read books, documents, newspapers, and other printed materials. A stick-tracking device has also been built in case the person loses his or her stick. These capabilities will be enabled through hardware (smart stick) and a software module (an Android application). Using Natural Language Processing technology, the user will tell these modules what to do by using voice commands. The e-stick will be charged as needed using a rechargeable circuit. Figure 6 shows how the technologies used in this paper interact.\nLimitation:\n\u2022 Coverage of obstacle detection is short as it is using sensor\n\u2022 Only suitable for indoor\n\n2.3.2.2. WeWalkWeWalk is a smart cane developed by a non-profit organisation called YGA (WeWALK Smart Cane \u2013 Smart Cane for the Visually Impaired, 2020). WeWalk looks like a traditional-looking cane, but the handle has a built-in touchpad. Users can navigate, save and discover places using the cane via the respected application. Particular layers are built into the mapping services for more accessible navigation. Users can choose to use the built-in speaker or Bluetooth for voice feedback. Users can also pair their phone with the intelligent cane via Bluetooth to control their phone. The above-ground The built-in ultrasound sensor detects an above-ground obstacle. The detected obstacle is projected back to the user in the form of vibration or audio, depending on the user\u2019s preferences. Wewalk also has an application where users can view their transit options, such as nearby bus stops and the timetable, and then navigate them to the desired stop. The application also has a built-in voice assistant for more straightforward navigation through the application. If a user loses their phone or cane, they can play a sound on each of them to locate the position of the lost device. Figure 7 shows the WeWalk Smart Cane that is currently on the market.\nLimitation:\n\u2022 The device is very expansive, with the price of 500 USD\n\u2022 Rain or snow might cause malfunction on the smart cane and the speaker\n\u2022 The tip of the cane is loud when navigating rough surface sidewalk\n\n2.3.2.3. Development of an Intelligent Cane for Visually Impaired Human Subjects\nAsati et al., (2019) designed an intelligent white cane that uses HR-SO4 ultrasonic sensors to identify obstacles within a range of 450 meters and determine the distance. The object above head level will also be detected, as the sensors' range is 450 meters. The warning signal is returned in beeping signals via a buzzer, advising the user to take prompt action. Object detection and classification are done utilizing the intelligent technique. The photos are recorded using the web camera for classification. They will be transformed into text and an audio signal for text-to-speech conversion. Figure 8 shows the prototype of this paper's intelligent cane.\nLimitation:\n\u2022 Cost of building the system is high\n\u2022 Unable to identify pot holes\n\u2022 Detection under rainy weather is not tested\n\n2.3.3. Handheld\n\n2.3.3.1. Android Application for Object Recognition Using Neural Networks for the Visually Impaired\nDosi et al. (2018) have developed an Android application that aids the visually impaired with real-time object recognition using the phone's camera and provides feedback by speaking the recognised object. They opted for a deep learning strategy based on a convolutional neural network for improved recognition and faster response times. MobileNets is utilised because it is ideal for mobile and embedded vision applications. Figure 9 shows the results of the detected object using the object recognition application.\nLimitation:\n\u2022 Only works offline\n\u2022 Unknown or untrained objects will be predicted using existing images in the database\n\u2022 Have to retrain model for untrained object\n\n2.3.3.2. Design and Implementation of an Embedded Real-Time System for Guiding Visually Impaired Individuals\nDuman et al. (2019) have developed and implemented a portable gadget that detects objects and measures their distance precisely to enable visually impaired individuals to see objects and people around them. The device uses YOLO, a convolutional neural network-based real-time identification method with a single device attached to a Raspberry Pi board. The estimated object distance will be projected in audio form to visually challenged users. The accuracy of this detected distance estimation is 98.8%. Initially, the footage is captured using a handheld Raspberry Pi camera. Afterwards, the object detection module executes YOLO for real-time object recognition, and bounding box size extraction for humans is needed. The size of the bounding box is provided to the distance estimation module to determine the distance of the detected individual. The labels of detected objects and the approximated distance of any individual caught are stored temporarily. An audio generation module translates text-based saved results into audio alerts that visually challenged users can listen to using headphones. Alerts are played at a predetermined time to reduce noise and ambiguity. Figure 10 shows the block diagram of the paper\u2019s proposed system.\nLimitation:\n\u2022 Only detect humans\n\u2022 No design for any wearable option\u2003\n\n2.3.3.3. Real-time object detection and face recognition system to assist the visually impaired\nAnish Aralikatti et al. (2020) developed an android application that used the phone camera for real-time object and face detection using OpenCV, the You only live once (YOLO) algorithm and FaceNet. Detection of objects and human will be presented in an audio format to the user. OpenCV is used for real-time computer vision tasks. Since it is implemented into an android phone, they chose Tiny YOLO as it is a lightweight YOLO framework perfect for embedded and mobile devices. FaceNet is used for face identification systems as it can extract high-quality features of the face. Figure 12 shows the sample outputs of using the android application on a mobile phone. Figure 11 shows the face recognition feature of the android application.\nLimitation: Less accuracy than YOLO as Tiny YOLO model is smaller (Anish Aralikatti et al., 2020)", "Please provide me with the relevant information that needed to be address during a presentation of this chapter 2.3.1,2.3.2 and 2.3.3.\n2.3. Previous work of Visual Assistive Technology\n2.3.1. Head wear\n2.3.1.1. Wearable Travel Aid for Environment Perception and Navigation of Visually Impaired People\n For this project, a consumer Red, Green, Blue, and Depth (RGB-D) camera was attached to a pair of eyeglasses, along with an inertial measurement unit (IMU) attached to a camera, a smartphone, and an earphone for commands/feedback. The system is operable in both indoor and outdoor settings. Due to their ample information, lightweight nature, and low cost compared to other sensors, such as ultrasonic and LiDAR sensors, computer vision technologies were integrated into this device's routing and detection capabilities. The smartphone does the process of detecting and routing, and the feedback is sent to the user's ear through an earphone plugged into the smartphone (Bai et al., 2019).\nLimitation:\n\u2022 Weak in detecting small-size obstacle\n\u2022 Staircase detection is not implemented\u2003\n2.3.1.2. Let Blind People See: Real-Time Visual Recognition with Results Converted to 3D Audio\n Jiang et al. (2016) created a system that took video input from a portable camera. They streamed it to a server for real-time image recognition processing using the You Only Live Once (YOLO) model. The 3D location of the discovered object is derived by using the location and size of the object detection algorithm's bounding boxes. The Unity game engine will send it as 3D audio into their attached wireless earphones. The next sound output interval will be in a few seconds or when a different object is detected, whichever occurs first. The solution could conduct precise real-time objective detection with a live stream at a pace of 30 frames per second in 1080p resolution by utilising the YOLO algorithm and an enhanced wireless transmitter. Figure 4 shows the data flow pipeline of the paper\u2019s system. The video footage is captured and sent to the YOLO algorithm for detecting object. The detected object is then send to the earbuds using the unity engine. Figure 5 shows the prototype of the device of this paper.\nLimitation:\n\u2022 Can only accurately detect and classify object within 2 to 5 meters away\n\u2022 Surrounding ambient will be block when using earbuds\n\u2022 Too much information will be sent to user when camera detect multiple objects\n2.3.2. Smart Cane\n2.3.2.1. Smart Electronic Stick for Visually Impaired using Android Application and Google\u2019s Cloud Vision\n The e-stick module, integrated with a voice-controlled Android application, was designed by Bharatia et al. (2019) to replace the essential simple navigation stick that visually impaired individuals typically use. The e-stick is similar to a standard stick in that it is thin, lightweight, and easy to handle, but it has additional features. Using efficient natural language processing (NLP) features makes these functionalities affordable and possible. The e-stick uses ultrasonic sensors to find low-lying and knee-level obstacles and potholes when moving backwards. Using buzzers, active input on the presence of barriers will be delivered. For Global Positioning System (GPS) navigation to function, the user's phone will be Bluetooth-connected to the stick's circuit. In unavoidable circumstances, the live location of visually impaired individuals will be transmitted to the nearest help centre or their family for assistance. Face detection will be added so that users can tell who is trying to talk to them. With the cloud vision API, it is also possible to translate traffic lights and roadside signs so that blind people can find their way. Text recognition will also be available from photos, making it easy for people to read books, documents, newspapers, and other printed materials. A stick-tracking device has also been built in case the person loses his or her stick. These capabilities will be enabled through hardware (smart stick) and a software module (an Android application). Using Natural Language Processing technology, the user will tell these modules what to do by using voice commands. The e-stick will be charged as needed using a rechargeable circuit. Figure 6 shows how the technologies used in this paper interact.\nLimitation:\n\u2022 Coverage of obstacle detection is short as it is using sensor\n\u2022 Only suitable for indoor\n2.3.2.2. WeWalk\n WeWalk is a smart cane developed by a non-profit organisation called YGA (WeWALK Smart Cane \u2013 Smart Cane for the Visually Impaired, 2020). WeWalk looks like a traditional-looking cane, but the handle has a built-in touchpad. Users can navigate, save and discover places using the cane via the respected application. Particular layers are built into the mapping services for more accessible navigation. Users can choose to use the built-in speaker or Bluetooth for voice feedback. Users can also pair their phone with the intelligent cane via Bluetooth to control their phone. The above-ground The built-in ultrasound sensor detects an above-ground obstacle. The detected obstacle is projected back to the user in the form of vibration or audio, depending on the user\u2019s preferences. Wewalk also has an application where users can view their transit options, such as nearby bus stops and the timetable, and then navigate them to the desired stop. The application also has a built-in voice assistant for more straightforward navigation through the application. If a user loses their phone or cane, they can play a sound on each of them to locate the position of the lost device. Figure 7 shows the WeWalk Smart Cane that is currently on the market.\nLimitation:\n\u2022 The device is very expansive, with the price of 500 USD\n\u2022 Rain or snow might cause malfunction on the smart cane and the speaker\n\u2022 The tip of the cane is loud when navigating rough surface sidewalk\n2.3.2.3. Development of an Intelligent Cane for Visually Impaired Human Subjects\n Asati et al., (2019) designed an intelligent white cane that uses HR-SO4 ultrasonic sensors to identify obstacles within a range of 450 meters and determine the distance. The object above head level will also be detected, as the sensors' range is 450 meters. The warning signal is returned in beeping signals via a buzzer, advising the user to take prompt action. Object detection and classification are done utilizing the intelligent technique. The photos are recorded using the web camera for classification. They will be transformed into text and an audio signal for text-to-speech conversion. Figure 8 shows the prototype of this paper's intelligent cane.\nLimitation:\n\u2022 Cost of building the system is high\n\u2022 Unable to identify pot holes\n\u2022 Detection under rainy weather is not tested\n\u2003\n2.3.3. Handheld\n2.3.3.1. Android Application for Object Recognition Using Neural Networks for the Visually Impaired\n Dosi et al. (2018) have developed an Android application that aids the visually impaired with real-time object recognition using the phone's camera and provides feedback by speaking the recognised object. They opted for a deep learning strategy based on a convolutional neural network for improved recognition and faster response times. MobileNets is utilised because it is ideal for mobile and embedded vision applications. Figure 9 shows the results of the detected object using the object recognition application.\nLimitation:\n\u2022 Only works offline\n\u2022 Unknown or untrained objects will be predicted using existing images in the database\n\u2022 Have to retrain model for untrained object\n2.3.3.2. Design and Implementation of an Embedded Real-Time System for Guiding Visually Impaired Individuals\n Duman et al. (2019) have developed and implemented a portable gadget that detects objects and measures their distance precisely to enable visually impaired individuals to see objects and people around them. The device uses YOLO, a convolutional neural network-based real-time identification method with a single device attached to a Raspberry Pi board. The estimated object distance will be projected in audio form to visually challenged users. The accuracy of this detected distance estimation is 98.8%. Initially, the footage is captured using a handheld Raspberry Pi camera. Afterwards, the object detection module executes YOLO for real-time object recognition, and bounding box size extraction for humans is needed. The size of the bounding box is provided to the distance estimation module to determine the distance of the detected individual. The labels of detected objects and the approximated distance of any individual caught are stored temporarily. An audio generation module translates text-based saved results into audio alerts that visually challenged users can listen to using headphones. Alerts are played at a predetermined time to reduce noise and ambiguity. Figure 10 shows the block diagram of the paper\u2019s proposed system.\nLimitation:\n\u2022 Only detect humans\n\u2022 No design for any wearable option\u2003\n2.3.3.3. Real-time object detection and face recognition system to assist the visually impaired\n Anish Aralikatti et al. (2020) developed an android application that used the phone camera for real-time object and face detection using OpenCV, the You only live once (YOLO) algorithm and FaceNet. Detection of objects and human will be presented in an audio format to the user. OpenCV is used for real-time computer vision tasks. Since it is implemented into an android phone, they chose Tiny YOLO as it is a lightweight YOLO framework perfect for embedded and mobile devices. FaceNet is used for face identification systems as it can extract high-quality features of the face. Figure 12 shows the sample outputs of using the android application on a mobile phone. Figure 11 shows the face recognition feature of the android application.\nLimitation: Less accuracy than YOLO as Tiny YOLO model is smaller (Anish Aralikatti et al., 2020)", "can you do the same with this list, main body area and nested areas. If the area is not an anatomic are than ignore please\n\n teeth.\n face, neck, body.\n lower face, neck, and jawline.\n severe cystic acne.\n face, neck, and body.\n lower layers of skin tissue.\n laryngeal prominence of thyroid cartilage in the throat.\n facial rejuvenation.\n abdomen, hips, thighs, arms, buttocks, or under the chin.\n nostrils.\n Face and body \n upper or lower jawbone.\n facial reconstruction, abdominal wall reconstruction, breast reconstruction.\n gastric.\n nipple-areola complex.\n underarms.\n balding, thinning, or receding areas.\n nasolabial folds, or smile lines.\n small, uncomplicated spider veins and small varicose veins.\n cellulite on the thighs and buttocks.\n mild to severe acne.\n upper or lower back.\n mustache, beard, sideburns.\n face, cheeks, under-eyes, lips, nasolabial folds, pitted scars, breasts, buttocks.\n face.\n navel.\n moderate to severe facial wrinkles and folds, such as nasolabial folds, etched-in lip lines, crow's feet, smile lines, marionette lines, under-eye tear troughs, and deep glabellar lines.\n upper arms.\n incision or injury.\n face, neck, chest, back, hands, arms, and legs.\n abdomen, hips, lower back, buttocks.\n stomach, legs, arms.\n stomach, thighs, butt, hips, and arms.\n fat reduction anywhere on the body, most commonly treated body areas are the tummy, hips, thighs, flanks (aka love handles), and back. some providers also offer mini bodyfx, which can treat smaller fat deposits in areas like the upper arms and under the chin..\n abdomen, upper arms, thighs, knees, love handles, breasts, back, chin, jowls, cheeks, and neck.\n crow's feet, frown lines, forehead lines, lip lines, bunny lines on the nose, chin wrinkles, neck bands, above the eyebrows, above the upper lip.\n teeth straightening.\n buttocks, hips, waist, love handles, thighs, lower back.\n buttocks.\n breasts.\n face.\n face, neck, d'colletage, back of hands.\n double chin, jawline, knees, elbows, upper arms, muffin top.\n face, body contouring.\n teeth.\n face, neck, hands, chest, legs, and other areas.\n glabellar area.\n forehead and eyebrows.\n lower cheeks.\n foot.\n buttocks, hips, abdomen, waistline, lower back, thighs.\n lower legs.\n lower legs.\n outer corner of the eye where the upper and lower lid meet.\n scalp.\n breast.\n face, neck, arms, stomach, buttocks, and legs.\n lens of the eye.\n cellulite dimples on the buttocks and the backs of the thighs.\n thighs, abdomen, or buttocks.\n midface.\n midface.\n cheeks.\n midface.\n zygomatic bone (malar bone).\n face, neck, chest, hands.\n soft tissue under the skin.\n lower face.\n under the chin and jawline.\n fine lines, shrink the appearance of pores, improve skin tone and texture, and reduce melasma.\n teeth straightening.\n jawbone.\n face, neck, chest, lips, and anywhere on the body.\n broken capillaries, spider veins, vascular lesions, periorbital veins, skin discoloration.\n upper lip, nose, and roof of the mouth.\n clitoral hood.\n face, neck, chest.\n vagina and vulva.\n crow's feet, fine lines around the eyes, smile lines, frown lines, atrophic acne scars, and thin lips.\n brow, mid- and lower face, jawline, and neck.\n fine lines and wrinkles, sun damage, discoloration, and acne scars.\n fine lines and wrinkles, acne scars, large pore size, uneven skin tone, rough skin texture, age spots, and other signs of sun damage.\n abdomen, flanks, bra fat, inner and outer thighs, back fat, upper arms, buttock rolls, knees, hips, mons pubis, submental fat.\n thighs, butt, and abdomen.\n hyperpigmentation and skin discoloration.\n abdominal fat, love handles, upper arms, inner thighs, under chin, below buttocks, bra and back fat bulges.\n slimming, toning, and cellulite reduction.\n face.\n skin.\n teeth.\n teeth straightening.\n glabellar lines, forehead furrows, crow's feet, bunny lines, platysmal bands, dimpling of the chin, masseter muscles.\n middle and lower areas of the face.\n face, eyes, neck.\n teeth.\n jawbone, gums.\n missing teeth.\n teeth.\n upper or lower jawbone.\n face, eyes, lips.\n face, upper lip, cheeks.\n smile lines, marionette lines, lips, under-eye hollows, cheeks, temples, jawline, chin, nose.\n face, neck, chest, stomach, thighs.\n face.\n skin tightening.\n face, neck, d'colletage, body.\n abdominal muscles.\n chin or cheeks.\n vaginal tissue.\n craniofacial region.\n upper eyelids.\n stomach and small intestine.\n front of natural teeth.\n \n face, neck, chest, arms, back of hands, and elsewhere on the body.\n legs, buttocks, thighs, back, or stomach.\n teeth.\n face, neck, under chin.\n skin.\n hormonal acne, polycystic ovary syndrome (pcos), high blood pressure, congestive heart failure.\n anywhere on the body.\n excess pigmentation and redness, wrinkles and mild acne scars, vascular lesions and varicose veins, pigmented lesions and dark tattoos.\n eye alignment.\n breast augmentation, breast reconstruction, abdominal wall defects, hernia repair.\n depressed scars, acne scars, cellulite dimples.\n face, neck, and d\u00e9colletage.\n teeth alignment.\n epidermis.\n acne on face and body, psoriasis on body, sun damage.\n face.\n teeth.\n face.\n lips, cheeks, chin, forehead, eyes, mouth, neck, and chest.\n scrotum.\n face, eyes, eyelids, jawline, stomach, arms, backs of hands, thighs, knees, butt.\n breasts and nipples.\n cheeks, around the mouth, neck, forehead and around the eyes.\n lower face, jowls, neck, breasts, arms, tummy, and thighs.\n vulvar and vaginal tissues.\n thigh.\n brow, mid- and lower face, jawline, and neck.\n skin concerns.\n inner and outer thighs, back, abdomen, love handles, hips, saddlebags, and buttocks.\n face, neck, stomach, and upper arms.\n enamel, dentin, pulp.\n face, forehead, temples, chin, area around mouth, cheeks.\n wrinkles, sagging skin, fat cells, cellulite.\n abdomen and flanks.\n abdomen and flanks.\n abdomen, flanks, buttocks, thighs.\n abdomen, flanks, and thighs.\n reshaping, creating balanced, normal breasts.\n abdomen, love handles, hips, thighs, chin, upper arms, underarms.\n lower abdomen.\n abdomen.\n brow, neck (including jawline), under chin, lines and wrinkles on d'colletage.\n vaginal area.\n face and neck.\n fine lines and wrinkles, discoloration, and even scars.\n stomach, hips, and thighs.\n abdomen, hips, and thighs.\n fat layer just under the skin.\n upper arms, belly, love handles, thighs, chin.\n abdominal wall.\n eyelid.\n lower face.\n vaginal canal, opening, labia majora, vulva, labia minora, mons pubis.\n vaginal canal.\n cleavage area.\n face.\n face.\n abdomen and thighs.\n spider veins, varicose veins, and venous reflux disease.\n thighs, calves, and ankles, buttocks and hips, abdomen, back, and flanks (aka love handles), upper arms, neck and under the chin.\n rosacea, pigmented scars, spider veins, broken capillaries, birthmarks, hyperpigmentation, newly formed stretch marks, and other forms of red, brown, or purple facial pigmentation.\n legs.\n spider veins, cherry angiomas, small hemangiomas, skin tags, spider nevi, and redness from rosacea.\n thighs, buttocks, upper arms, stomach, excess fat and mildly sagging skin under the chin.\n thighs, abdomen, and butt.\n varicose veins.\n fat reduction on the back, abdomen, thighs and flanks, cellulite reduction on the thighs, buttocks, and abdomen, muscle conditioning and toning for biceps, triceps, abdominal and oblique muscles, glutes, hamstrings, and quadriceps.\n face, neck, and body.\n wrinkles, fine lines, cellulite, stretch marks.\n fine lines and deep wrinkles, acne scars, large pores, uneven skin texture, stretch marks, mild laxity, rosacea, and hyperpigmentation, including melasma.\n pelvic floor issues.\n face, neck, chest, hands.\n face and body.\n vaginal tissues, labia majora.\n pelvic floor muscles and skin elasticity.\n jaw.\n lines and wrinkles created by dynamic facial movements, such as smiling, frowning, or raising your eyebrows, neck pain caused by cervical dystonia, eye spasms known as blepharospasm, and upper limb spasticity.\n skin concerns, visible veins, brown spots, scars, laser hair removal, tattoo removal, cataract surgery.\n waist, chest, back, neck, upper arms, thighs, love handles, hips, and ankles.\n skin.\n teeth.\n lower third of face, jawline, neck.\n face, neck, and body.", "Input this data into that code for another ternary plot output \nCation Total O = 6.0 Group : 2020\\_12\\_18\\_noc Sample : 2020\\_12\\_18\\_noc\\_0006\\_QNT Page 1 \n \n No. Si Al Fe Ca Mn Sr Zn Ba Na Mg C Total Comment \n1 0.0000 0.0000 0.0250 1.9092 0.0171 0.0279 0.0000 0.0001 0.0016 0.0198 2.0000 4.0008 SP1\\_4\\_m1\\_p6 \n2 0.0003 0.0000 0.0267 1.9001 0.0170 0.0330 0.0000 0.0000 0.0047 0.0202 2.0000 4.0020 SP1\\_4\\_m1\\_p7 \n3 0.0002 0.0000 0.0238 1.9056 0.0168 0.0343 0.0005 0.0000 0.0012 0.0181 2.0000 4.0005 SP1\\_4\\_m2\\_p6 \n4 0.0009 0.0000 0.0005 1.9939 0.0001 0.0024 0.0000 0.0004 0.0006 0.0007 2.0000 3.9995 SP1\\_4\\_m2\\_p7 \n5 0.0000 0.0000 0.0236 1.9092 0.0165 0.0301 0.0005 0.0002 0.0017 0.0190 2.0000 4.0009 SP1\\_4\\_m3\\_p6 \n6 0.0000 0.0000 0.0251 1.9108 0.0144 0.0292 0.0008 0.0005 0.0033 0.0176 2.0000 4.0017 SP1\\_4\\_m4\\_p7 \n7 0.0007 0.0000 0.0248 1.9059 0.0168 0.0324 0.0010 0.0000 0.0030 0.0162 2.0000 4.0009 SP1\\_4\\_m5A\\_p7 \n8 0.0000 0.0001 0.0252 1.9111 0.0155 0.0289 0.0000 0.0000 0.0000 0.0192 2.0000 4.0001 SP1\\_4\\_m6\\_p5 \n9 0.0000 0.0000 0.0215 1.9174 0.0137 0.0299 0.0006 0.0000 0.0010 0.0164 2.0000 4.0005 SP1\\_4\\_m7\\_p8 \n10 0.0000 0.0003 0.0264 1.8918 0.0139 0.0257 0.0008 0.0000 0.0000 0.0410 2.0000 4.0000 SP1\\_4\\_m8\\_p5 \n11 0.0000 0.0010 0.0245 1.9129 0.0130 0.0278 0.0007 0.0003 0.0001 0.0193 2.0000 3.9997 SP2\\_20\\_m1\\_p1 \n12 0.0001 0.0001 0.0224 1.9125 0.0167 0.0289 0.0000 0.0001 0.0010 0.0184 2.0000 4.0003 SP2\\_20\\_m2\\_p6 \n13 0.0000 0.0000 0.0238 1.9176 0.0156 0.0275 0.0000 0.0000 0.0017 0.0145 2.0000 4.0008 SP2\\_20\\_m2\\_p8 \n14 0.0000 0.0000 0.0251 1.9040 0.0190 0.0314 0.0004 0.0000 0.0000 0.0200 2.0000 3.9999 SP2\\_20\\_m3\\_p5 \n15 0.0000 0.0000 0.0266 1.9101 0.0152 0.0274 0.0009 0.0006 0.0025 0.0180 2.0000 4.0013 SP2\\_20\\_m4\\_p5 \n16 0.0000 0.0000 0.0006 1.9984 0.0000 0.0004 0.0003 0.0000 0.0000 0.0004 2.0000 4.0002 SP2\\_20\\_m4\\_p6 \n17 0.0000 0.0000 0.0235 1.9135 0.0150 0.0307 0.0000 0.0002 0.0012 0.0166 2.0000 4.0008 SP2\\_20\\_m5\\_p7 \n18 0.0000 0.0000 0.0253 1.9090 0.0154 0.0307 0.0001 0.0002 0.0015 0.0185 2.0000 4.0008 SP2\\_20\\_m6\\_p4 \n19 0.0003 0.0009 0.0173 1.9178 0.0170 0.0301 0.0003 0.0000 0.0000 0.0156 2.0000 3.9994 SP2\\_20\\_m7\\_p8 \n20 0.0007 0.0000 0.0208 1.9117 0.0153 0.0295 0.0000 0.0003 0.0027 0.0196 2.0000 4.0006 SP2\\_20\\_m9A\\_p6 \n21 0.0013 0.0009 0.0066 1.9786 0.0058 0.0029 0.0000 0.0000 0.0023 0.0010 2.0000 3.9995 SP2\\_20\\_m10\\_p7 \n22 0.0000 0.0000 0.0252 1.9089 0.0159 0.0302 0.0000 0.0003 0.0018 0.0186 2.0000 4.0010 SP2\\_20\\_m10\\_p8 \n23 0.0000 0.0000 0.0185 1.9106 0.0166 0.0370 0.0000 0.0000 0.0021 0.0163 2.0000 4.0011 SP2\\_20\\_m11\\_p6 \n24 0.0003 0.0000 0.0262 1.9072 0.0168 0.0288 0.0004 0.0002 0.0049 0.0173 2.0000 4.0022 SP2\\_20\\_m12\\_p4 \n \nMinimum 0.0000 0.0000 0.0005 1.8918 0.0000 0.0004 0.0000 0.0000 0.0000 0.0004 2.0000 3.9993 \nMaximum 0.0013 0.0010 0.0267 1.9984 0.0190 0.0370 0.0010 0.0006 0.0049 0.0410 2.0000 4.0021 \nAverage 0.0002 0.0001 0.0212 1.9195 0.0141 0.0265 0.0003 0.0001 0.0016 0.0168 2.0000 4.0005 \nSigma 0.0004 0.0003 0.0076 0.0281 0.0050 0.0098 0.0003 0.0002 0.0014 0.0079 -0.0000 0.0008 \nNo. of data 24", "using System;\nusing System.Collections.Generic;\nusing System.Linq;\nusing System.Text;\nusing System.Threading.Tasks;\nusing Love;\n\nnamespace LoveCSharp\n{\n class Program : Scene\n {\n public Player player1;\n public static float deltaTime;\n static void Main(string[] args)\n {\n Boot.Init();\n Boot.Run(new Program());\n }\n public override void Load()\n {\n World.Generate(20,20);\n player1 = new Player(5, 5);\n\n // Love.Mouse.SetVisible(false);\n // Love.Mouse.SetGrabbed(true);\n Love.Mouse.SetRelativeMode(true);\n \n }\n public override void Draw()\n {\n Ray.Draw(player1.x, player1.y, Ray.distance, player1.angle, player1.fov);\n World.Draw();\n player1.Draw();\n \n }\n public override void Update(float dt)\n {\n deltaTime = dt;\n player1.Update(dt);\n Ray.Update(player1.x, player1.y, player1.angle, player1.fov);\n if (Love.Keyboard.IsDown(KeyConstant.Escape))\n {\n Love.Event.Quit();\n }\n }\n public override void MouseMoved(float x, float y, float dx, float dy, bool istouch)\n {\n player1.Rotation(dx);\n }\n }\n public enum TileType\n {\n None,\n Block,\n }\n public class World\n {\n public static int width;\n public static int height;\n public static int scale = 10;\n public static TileType[,] tiles;\n public static void Generate(int width = 20, int height = 20)\n {\n World.width = width;\n World.height = height;\n\n TileType[,] tiles = new TileType[width, height];\n\n for (int x = 0; x < width; x++)\n {\n for (int y = 0; y < height; y++)\n {\n tiles[x, y] = TileType.Block;\n }\n }\n for (int x = 0; x < width; x++)\n {\n \n for (int y = 0; y < height; y++)\n {\n if ((x > 0 && x < width - 1) && (y > 0 && y < height - 1))\n {\n tiles[x, y] = TileType.None;\n }\n }\n }\n // Generate a random number of TileType blocks in the world (tiles)\n Random random = new Random();\n int blockCount = random.Next(10, 20);\n for (int i = 0; i < blockCount; i++)\n {\n int x = random.Next(0, width);\n int y = random.Next(0, height);\n tiles[x, y] = TileType.Block;\n }\n \n World.tiles = tiles;\n }\n public static void Draw()\n {\n Graphics.SetColor(Color.White);\n Graphics.Rectangle(DrawMode.Line, 0, 0, width \\* scale, height \\* scale);\n\n Graphics.SetColor(Color.Firebrick);\n for (int x = 0; x < width; x++)\n {\n for (int y = 0; y < height; y++)\n {\n if (tiles[x, y] == TileType.Block)\n {\n Graphics.Rectangle(DrawMode.Fill, x \\* scale, y \\* scale, scale, scale);\n }\n }\n }\n }\n }\n public class Player\n {\n public float x, y, w, h, speed, angle, directionX, directionY;\n public float sensitivity = 0.3f;\n public int fov = 60;\n public Player(float x, float y, float w = 30, float h = 50, float speed = 1, float angle = 0)\n {\n this.x = x;\n this.y = y;\n this.w = w;\n this.h = h;\n this.speed = speed;\n this.angle = angle;\n }\n public void Draw()\n {\n Graphics.SetColor(Color.AliceBlue);\n Graphics.SetPointSize(3);\n Graphics.Points(this.x \\* World.scale, this.y \\* World.scale);\n Graphics.SetColor(Color.White);\n Graphics.Print(\"X: \" + this.x + \" Y: \" + this.y, 0, 0);\n Graphics.Print(\"Angle: \" + this.angle, 0, 20);\n }\n public void Update(float dt)\n {\n Movement(dt);\n\n }\n\n private void Movement(float dt)\n {\n float directionX = 0;\n float directionY = 0;\n if (Keyboard.IsDown(KeyConstant.W))\n {\n directionY = -1;\n }\n if (Keyboard.IsDown(KeyConstant.S))\n {\n directionY = 1;\n }\n if (Keyboard.IsDown(KeyConstant.A))\n {\n directionX = -1;\n }\n if (Keyboard.IsDown(KeyConstant.D))\n {\n directionX = 1;\n }\n\n float rotatedDirectionX = (float)Math.Cos(this.angle) \\* directionX - (float)Math.Sin(this.angle) \\* directionY;\n float rotatedDirectionY = (float)Math.Sin(this.angle) \\* directionX + (float)Math.Cos(this.angle) \\* directionY;\n\n float directionLength = (float)Math.Sqrt(rotatedDirectionX \\* rotatedDirectionX + rotatedDirectionY \\* rotatedDirectionY);\n if (directionLength > 0)\n {\n rotatedDirectionX /= directionLength;\n rotatedDirectionY /= directionLength;\n }\n\n this.x += rotatedDirectionX \\* this.speed \\* dt;\n this.y += rotatedDirectionY \\* this.speed \\* dt;\n }\n public void Rotation(float dx)\n {\n this.angle += dx \\* sensitivity \\* Program.deltaTime;\n \n }\n }\n public class Ray\n {\n public static float distance;\n\n public static float Cast(float x, float y, float centerAngle, float fov)\n {\n float startX = x;\n float startY = y;\n string section;\n float quality = 0.1f;\n int screenWidth = 800;\n int screenHeight = 600;\n\n for (float angle = centerAngle - fov / 2; angle < centerAngle + fov / 2; angle += Quality(fov, quality, screenWidth))\n {\n float endX = (float)(startX + Math.Cos(angle) \\* 1000);\n float endY = (float)(startY + Math.Sin(angle) \\* 1000);\n\n section = FacingSection(angle);\n\n if (section == \"NE\")\n {\n for (float i = startX; i < endX; i += quality)\n {\n float j = (float)(startY + (i - startX) \\* Math.Tan(angle));\n if (World.tiles[(int)i / World.scale, (int)j / World.scale] == TileType.Block)\n {\n distance = Distance(startX, startY, i, j);\n return distance;\n }\n }\n }\n else if (section == \"NW\")\n {\n for (float i = startX; i > endX; i -= quality)\n {\n float j = (float)(startY + (i - startX) \\* Math.Tan(angle));\n if (World.tiles[(int)i / World.scale, (int)j / World.scale] == TileType.Block)\n {\n distance = Distance(startX, startY, i, j);\n return distance;\n }\n }\n }\n else if (section == \"SW\")\n {\n for (float i = startX; i > endX; i -= quality)\n {\n float j = (float)(startY + (i - startX) \\* Math.Tan(angle));\n if (World.tiles[(int)i / World.scale, (int)j / World.scale] == TileType.Block)\n {\n distance = Distance(startX, startY, i, j);\n return distance;\n }\n }\n }\n else if (section == \"SE\")\n {\n for (float i = startX; i < endX; i += quality)\n {\n float j = (float)(startY + (i - startX) \\* Math.Tan(angle));\n if (World.tiles[(int)i / World.scale, (int)j / World.scale] == TileType.Block)\n {\n distance = Distance(startX, startY, i, j);\n return distance;\n }\n }\n }\n }\n return 0;\n }\n public static string FacingSection(float angle)\n {\n string facing = \"\";\n if (angle >= 0 && angle < Math.PI / 2)\n {\n facing = \"NE\";\n }\n else if (angle >= Math.PI / 2 && angle < Math.PI)\n {\n facing = \"NW\";\n }\n else if (angle >= Math.PI && angle < 3 \\* Math.PI / 2)\n {\n facing = \"SW\";\n }\n else if (angle >= 3 \\* Math.PI / 2 && angle < 2 \\* Math.PI)\n {\n facing = \"SE\";\n }\n return facing;\n }\n public static float Quality(float fov, float quality, float screenWidth)\n {\n \n // float angle = fov / screenWidth;\n // quality = angle / quality;\n // return quality;\n float angleBetweenRays = fov / screenWidth;\n float qualityAngle = (float)Math.Atan(quality / 2);\n float qualityAngleBetweenRays = qualityAngle / angleBetweenRays;\n return qualityAngleBetweenRays;\n }\n\n public static float Distance(float x1, float y1, float x2, float y2)\n {\n float distance = (float)Math.Sqrt((x2 - x1) \\* (x2 - x1) + (y2 - y1) \\* (y2 - y1));\n return distance;\n }\n\n public static void Draw(float x, float y, float distance, float angle, float fov)\n {\n \n float angleBetweenRays = fov / 800;\n float distanceToProjectionPlane = 800 / (2 \\* (float)Math.Tan(fov / 2));\n float distanceToWall = distance;\n float distanceToProjectionPoint = distanceToWall \\* (float)Math.Cos(angleBetweenRays);\n distanceToProjectionPlane = distanceToProjectionPoint \\* distanceToProjectionPlane / distanceToWall;\n float height = 600 / distanceToProjectionPlane;\n float width = 1;\n float color = 255 / distanceToWall;\n Graphics.SetColor(Color.FromRGBA(color, color, color, 255));\n Graphics.Rectangle(DrawMode.Fill, x, y - height / 2, width, height);\n \n\n }\n public static void Update(float x, float y, float angle, float fov)\n {\n Cast(x, y, angle, fov);\n \n \n }\n }\n}", "using System;\nusing System.Collections.Generic;\nusing System.Linq;\nusing System.Text;\nusing System.Threading.Tasks;\nusing Love;\n\nnamespace LoveCSharp\n{\n class Program : Scene\n {\n public Player player1;\n public static float deltaTime;\n static void Main(string[] args)\n {\n Boot.Init();\n Boot.Run(new Program());\n }\n public override void Load()\n {\n World.Generate(20,20);\n player1 = new Player(5, 5);\n\n // Love.Mouse.SetVisible(false);\n // Love.Mouse.SetGrabbed(true);\n Love.Mouse.SetRelativeMode(true);\n \n }\n public override void Draw()\n {\n World.Draw();\n player1.Draw();\n Ray.Draw(player1.x, player1.y, Ray.distance, player1.angle, player1.fov);\n \n }\n public override void Update(float dt)\n {\n deltaTime = dt;\n player1.Update(dt);\n Ray.Update(player1.x, player1.y, player1.angle, player1.fov);\n if (Love.Keyboard.IsDown(KeyConstant.Escape))\n {\n Love.Event.Quit();\n }\n }\n public override void MouseMoved(float x, float y, float dx, float dy, bool istouch)\n {\n player1.Rotation(dx);\n }\n }\n public enum TileType\n {\n None,\n Block,\n }\n public class World\n {\n public static int width;\n public static int height;\n public static int scale = 10;\n public static TileType[,] tiles;\n public static void Generate(int width = 20, int height = 20)\n {\n World.width = width;\n World.height = height;\n\n TileType[,] tiles = new TileType[width, height];\n\n for (int x = 0; x < width; x++)\n {\n for (int y = 0; y < height; y++)\n {\n tiles[x, y] = TileType.Block;\n }\n }\n for (int x = 0; x < width; x++)\n {\n \n for (int y = 0; y < height; y++)\n {\n if ((x > 0 && x < width - 1) && (y > 0 && y < height - 1))\n {\n tiles[x, y] = TileType.None;\n }\n }\n }\n // Generate a random number of TileType blocks in the world (tiles)\n Random random = new Random();\n int blockCount = random.Next(10, 20);\n for (int i = 0; i < blockCount; i++)\n {\n int x = random.Next(0, width);\n int y = random.Next(0, height);\n tiles[x, y] = TileType.Block;\n }\n \n World.tiles = tiles;\n }\n public static void Draw()\n {\n Graphics.SetColor(Color.White);\n Graphics.Rectangle(DrawMode.Line, 0, 0, width \\* scale, height \\* scale);\n\n Graphics.SetColor(Color.Firebrick);\n for (int x = 0; x < width; x++)\n {\n for (int y = 0; y < height; y++)\n {\n if (tiles[x, y] == TileType.Block)\n {\n Graphics.Rectangle(DrawMode.Fill, x \\* scale, y \\* scale, scale, scale);\n }\n }\n }\n }\n }\n public class Player\n {\n public float x, y, w, h, speed, angle, directionX, directionY;\n public float sensitivity = 0.3f;\n public int fov = 60;\n public Player(float x, float y, float w = 30, float h = 50, float speed = 1, float angle = 0)\n {\n this.x = x;\n this.y = y;\n this.w = w;\n this.h = h;\n this.speed = speed;\n this.angle = angle;\n }\n public void Draw()\n {\n Graphics.SetColor(Color.AliceBlue);\n Graphics.SetPointSize(3);\n Graphics.Points(this.x \\* World.scale, this.y \\* World.scale);\n Graphics.SetColor(Color.White);\n Graphics.Print(\"X: \" + this.x + \" Y: \" + this.y, 0, 0);\n Graphics.Print(\"Angle: \" + this.angle, 0, 20);\n }\n public void Update(float dt)\n {\n Movement(dt);\n\n }\n\n private void Movement(float dt)\n {\n float directionX = 0;\n float directionY = 0;\n if (Keyboard.IsDown(KeyConstant.W))\n {\n directionY = -1;\n }\n if (Keyboard.IsDown(KeyConstant.S))\n {\n directionY = 1;\n }\n if (Keyboard.IsDown(KeyConstant.A))\n {\n directionX = -1;\n }\n if (Keyboard.IsDown(KeyConstant.D))\n {\n directionX = 1;\n }\n\n float rotatedDirectionX = (float)Math.Cos(this.angle) \\* directionX - (float)Math.Sin(this.angle) \\* directionY;\n float rotatedDirectionY = (float)Math.Sin(this.angle) \\* directionX + (float)Math.Cos(this.angle) \\* directionY;\n\n float directionLength = (float)Math.Sqrt(rotatedDirectionX \\* rotatedDirectionX + rotatedDirectionY \\* rotatedDirectionY);\n if (directionLength > 0)\n {\n rotatedDirectionX /= directionLength;\n rotatedDirectionY /= directionLength;\n }\n\n this.x += rotatedDirectionX \\* this.speed \\* dt;\n this.y += rotatedDirectionY \\* this.speed \\* dt;\n }\n public void Rotation(float dx)\n {\n this.angle += dx \\* sensitivity \\* Program.deltaTime;\n \n }\n }\n public class Ray\n {\n public static float distance;\n\n public static float Cast(float x, float y, float centerAngle, float fov)\n {\n float startX = x;\n float startY = y;\n string section;\n float quality = 0.1f;\n int screenWidth = 800;\n int screenHeight = 600;\n\n for (float angle = centerAngle - fov / 2; angle < centerAngle + fov / 2; angle += Quality(fov, quality, screenWidth))\n {\n float endX = (float)(startX + Math.Cos(angle) \\* 50);\n float endY = (float)(startY + Math.Sin(angle) \\* 50);\n\n section = FacingSection(angle);\n\n if (section == \"NE\")\n {\n for (float i = startX; i < endX; i += quality)\n {\n float j = (float)(startY + (i - startX) \\* Math.Tan(angle));\n if (World.tiles[(int)i / World.scale, (int)j / World.scale] == TileType.Block)\n {\n distance = Distance(startX, startY, i, j);\n return distance;\n }\n }\n }\n else if (section == \"NW\")\n {\n for (float i = startX; i > endX; i -= quality)\n {\n float j = (float)(startY + (i - startX) \\* Math.Tan(angle));\n if (World.tiles[(int)i / World.scale, (int)j / World.scale] == TileType.Block)\n {\n distance = Distance(startX, startY, i, j);\n return distance;\n }\n }\n }\n else if (section == \"SW\")\n {\n for (float i = startX; i > endX; i -= quality)\n {\n float j = (float)(startY + (i - startX) \\* Math.Tan(angle));\n if (World.tiles[(int)i / World.scale, (int)j / World.scale] == TileType.Block)\n {\n distance = Distance(startX, startY, i, j);\n return distance;\n }\n }\n }\n else if (section == \"SE\")\n {\n for (float i = startX; i < endX; i += quality)\n {\n float j = (float)(startY + (i - startX) \\* Math.Tan(angle));\n if (World.tiles[(int)i / World.scale, (int)j / World.scale] == TileType.Block)\n {\n distance = Distance(startX, startY, i, j);\n return distance;\n }\n }\n }\n }\n return 0;\n }\n public static string FacingSection(float angle)\n {\n string facing = \"\";\n if (angle >= 0 && angle < Math.PI / 2)\n {\n facing = \"NE\";\n }\n else if (angle >= Math.PI / 2 && angle < Math.PI)\n {\n facing = \"NW\";\n }\n else if (angle >= Math.PI && angle < 3 \\* Math.PI / 2)\n {\n facing = \"SW\";\n }\n else if (angle >= 3 \\* Math.PI / 2 && angle < 2 \\* Math.PI)\n {\n facing = \"SE\";\n }\n return facing;\n }\n public static float Quality(float fov, float quality, float screenWidth)\n {\n \n // float angle = fov / screenWidth;\n // quality = angle / quality;\n // return quality;\n float angleBetweenRays = fov / screenWidth;\n float qualityAngle = (float)Math.Atan(quality / 2);\n float qualityAngleBetweenRays = qualityAngle / angleBetweenRays;\n return qualityAngleBetweenRays;\n }\n\n public static float Distance(float x1, float y1, float x2, float y2)\n {\n float distance = (float)Math.Sqrt((x2 - x1) \\* (x2 - x1) + (y2 - y1) \\* (y2 - y1));\n return distance;\n }\n\n public static void Draw(float x, float y, float distance, float angle, float fov)\n {\n \n float angleBetweenRays = fov / 800;\n float distanceToProjectionPlane = 800 / (2 \\* (float)Math.Tan(fov / 2));\n float distanceToWall = distance;\n float distanceToProjectionPoint = distanceToWall \\* (float)Math.Cos(angleBetweenRays);\n distanceToProjectionPlane = distanceToProjectionPoint \\* distanceToProjectionPlane / distanceToWall;\n float height = 600 / distanceToProjectionPlane;\n float width = 1;\n float color = 255 / distanceToWall;\n Graphics.SetColor(Color.FromRGBA(color, color, color, 255));\n Graphics.Rectangle(DrawMode.Fill, x, y - height / 2, width, height);\n \n\n }\n public static void Update(float x, float y, float angle, float fov)\n {\n Ray.distance = Cast(x, y, angle, fov);\n \n \n }\n }\n}", "did you generate this code:\nimport javax.swing.\\*;\nimport java.awt.\\*;\nimport java.awt.event.\\*;\nimport java.awt.geom.Ellipse2D;\nimport java.awt.geom.Rectangle2D;\nimport java.io.IOException;\nimport java.util.ArrayList;\npublic class PongStructure\n{\n static int NORTH\\_BORDER = 75;\n static int EAST\\_BORDER = 950;\n static int SOUTH\\_BORDER = 750;\n static int WEST\\_BORDER = 75;\n\n public static class PongGame extends JFrame\n {\n ScoreKeeper scoreKeeper;\n\n // getting some things through traversal seems strangely difficult so im just gonna store them\n ScoreBanner scoreBanner;\n\n PongField field;\n\n PongGame() throws IOException\n {\n scoreKeeper = new ScoreKeeper();\n\n this.addWindowListener(exitListener);\n this.setDefaultCloseOperation(EXIT\\_ON\\_CLOSE);\n this.setSize(1025, 875);\n this.setBackground(Color.WHITE);\n\n scoreBanner = new ScoreBanner();\n this.add(scoreBanner, BorderLayout.NORTH);\n\n field = new PongField(this);\n this.add(field, BorderLayout.CENTER);\n\n this.setVisible(true);\n }\n\n WindowListener exitListener = new WindowAdapter() {\n /\\*\\*\n \\* Invoked when a window is in the process of being closed.\n \\* The close operation can be overridden at this point.\n \\*\n \\* @param e the event representing the closing window\n \\*/\n @Override\n public void windowClosing(WindowEvent e)\n {\n try {\n ((PongGame)e.getSource()).scoreKeeper.storeScores();\n System.exit(0);\n } catch (IOException ex)\n {\n throw new RuntimeException(ex);\n }\n }\n };\n\n // pass-through functions\n\n void start()\n {\n field.startAnimation();\n }\n }\n\n public static class PongField extends JPanel\n {\n Ball ball;\n Rectangle2D paddle;\n Timer ballTimer;\n PongGame parent;\n PongField(PongGame parental)\n {\n this.parent = parental;\n\n this.setBackground(Color.BLACK);\n\n this.addMouseWheelListener(this::resetPaddle);\n\n ballTimer = new Timer(10, e -> SwingUtilities.invokeLater(this::animateBall));\n }\n\n void startAnimation()\n {\n resetGame();\n\n ballTimer.start();\n }\n\n private void resetGame()\n {\n ball = new Ball((EAST\\_BORDER - WEST\\_BORDER) / 2, (SOUTH\\_BORDER - NORTH\\_BORDER) / 2, 50, 50);\n paddle = new Rectangle2D.Double(WEST\\_BORDER + 50, 337,12, 150);\n }\n\n private void resetPaddle(MouseWheelEvent e)\n {\n double y = paddle.getY();\n if (y + (e.getPreciseWheelRotation() \\* 15) < SOUTH\\_BORDER - paddle.getHeight() && y + e.getPreciseWheelRotation() \\* 15 > NORTH\\_BORDER)\n {\n y += e.getPreciseWheelRotation() \\* 15;\n }\n paddle.setFrame(paddle.getX(), y, paddle.getWidth(), paddle.getHeight());\n }\n\n private void animateBall()\n {\n momentumCheck();\n\n Graphics graphics = this.getGraphics();\n if (graphics == null)\n {\n return;\n }\n\n ball.move();\n\n this.repaint();\n }\n\n private void momentumCheck()\n {\n if (ball.getX() >= EAST\\_BORDER - ball.getWidth())\n {\n ball.wallBounce();\n }\n\n// System.out.println(\"X: \"+ ball.getX() + \"Y: \" + ball.getY() + \" H: \" + this.getHeight());\n// System.out.println(\"paddle X: \" + paddle.getX() + \" Y: \" + paddle.getY() + \" H: \" + paddle.getHeight());\n\n if (ball.getY() <= NORTH\\_BORDER || ball.getY() + ball.getMomentum().y + ball.getHeight() >= SOUTH\\_BORDER)\n {\n ball.ceilingBounce();\n }\n\n if (ball.getX() <= WEST\\_BORDER)\n {\n this.ballTimer.stop();\n PongGame game = (PongGame) SwingUtilities.getWindowAncestor(this);\n int standings = game.scoreKeeper.checkScore(this.parent.scoreBanner.score());\n String name;\n\n if (standings < 4)\n {\n name = JOptionPane.showInputDialog(String.format(\"You got into %s place! Please enter your three letter initials.\"\n , Util.positions.get(standings)));\n\n while (name.length() != 3)\n {\n name = JOptionPane.showInputDialog(\"Your initials cannot be longer or shorter than three letters. Please enter your three letter initials.\");\n }\n } else {\n name = null;\n }\n\n game.scoreKeeper.add(new ScorePair(name, this.parent.scoreBanner.score()));\n\n GameEndBoard gameEndBoard = new GameEndBoard(this, standings, name);\n gameEndBoard.setVisible(true);\n\n }\n\n if (!ball.getBounced() && ball.intersects(paddle))\n {\n ((ScoreBanner)this.getParent().getComponent(0)).addPoint();\n\n ball.paddleBounce();\n }\n }\n\n @Override\n public void paint(Graphics g)\n {\n super.paint(g);\n\n g.setColor(Color.WHITE);\n\n g.fillRect((int) paddle.getX(), (int) paddle.getY(), (int) paddle.getWidth(), (int) paddle.getHeight());\n g.fillOval((int) ball.getX(), (int) ball.getY(), (int) ball.getWidth(), (int) ball.getHeight());\n\n // create border\n g.setColor(Color.CYAN);\n // top line\n g.drawLine(NORTH\\_BORDER, WEST\\_BORDER, EAST\\_BORDER, NORTH\\_BORDER);\n // left line\n g.drawLine(WEST\\_BORDER, NORTH\\_BORDER, WEST\\_BORDER, SOUTH\\_BORDER);\n // bottom line\n g.drawLine(WEST\\_BORDER, SOUTH\\_BORDER, EAST\\_BORDER, SOUTH\\_BORDER);\n // right line\n g.drawLine(EAST\\_BORDER, NORTH\\_BORDER, EAST\\_BORDER, SOUTH\\_BORDER);\n\n g.setColor(Color.WHITE);\n }\n }\n\n public static class ScoreBanner extends JLabel\n {\n private int score;\n ScoreBanner()\n {\n score = 0;\n\n setScoreBanner();\n this.setHorizontalAlignment(CENTER);\n }\n\n int score()\n {\n return score;\n }\n\n void addPoint()\n {\n score++;\n\n setScoreBanner();\n }\n\n void reset()\n {\n score = 0;\n\n setScoreBanner();\n }\n\n private void setScoreBanner()\n {\n this.setText(String.format(\"Score: %s\", score));\n }\n\n }\n\n static class GameEndBoard extends JFrame\n {\n PongField parent;\n\n GameEndBoard(Component pong, int place, String name)\n {\n this.parent = (PongField) pong;\n\n this.setSize(400, 500);\n this.setLayout(new GridLayout(1, 2));\n\n this.add(new ScoreBoard());\n this.add(\"MessageBoard\", new CongratsCard(this, place, name));\n\n WindowListener closingListener = new WindowAdapter()\n {\n /\\*\\*\n \\* Invoked when a window is in the process of being closed.\n \\* The close operation can be overridden at this point.\n \\*\n \\* @param e the closing of the parent window\n \\*/\n @Override\n public void windowClosing(WindowEvent e)\n {\n ((GameEndBoard)e.getSource()).parent.parent.dispatchEvent(new WindowEvent(((GameEndBoard)e.getSource()).parent.parent, WindowEvent.WINDOW\\_CLOSING));\n System.exit(0);\n }\n };\n\n this.addWindowListener(closingListener);\n }\n\n class ScoreBoard extends JPanel\n {\n ScoreBoard()\n {\n this.setLayout(new GridLayout(3, 1));\n\n ScoreKeeper leaderBoard = ((PongGame)SwingUtilities.getWindowAncestor(GameEndBoard.this.parent)).scoreKeeper;\n\n ArrayList safeLB = leaderBoard.getRankArray();\n\n ScorePair first = safeLB.get(0);\n this.add(\"First Place\", new ScoreCard(new Color(124, 116, 0), first.name, first.score));\n ScorePair second = safeLB.get(1);\n this.add(\"Second Place\", new ScoreCard(Color.GRAY, second.name, second.score));\n ScorePair third = safeLB.get(2);\n this.add(\"Third Place\", new ScoreCard(new Color(124, 72, 0), third.name, third.score));\n }\n\n }\n\n static class ScoreCard extends JPanel\n {\n ScoreCard(Color color, String name, int score)\n {\n this.setLayout(new GridLayout(1, 2));\n this.setBackground(color);\n\n this.add(\"Name\", new JLabel(name));\n this.add(\"Score\", new JLabel(String.valueOf(score)));\n }\n }\n\n static class CongratsCard extends JPanel\n {\n Component parent;\n CongratsCard(Component parent, int place, String name)\n {\n this.parent = parent;\n\n this.setLayout(new BorderLayout());\n this.setAlignmentX(CENTER\\_ALIGNMENT);\n\n String message;\n if (name != null)\n {\n message = String.format(\"Congrats %s!   \nYou achieved %s place!\", name, Util.positions.get(place));\n } else\n {\n message = String.format(\"You achieved %s place.   \nYou can do better.\", Util.positions.get(place));\n }\n\n this.add(new JLabel(message), BorderLayout.CENTER);\n\n JButton button = new JButton(\"Play Again\");\n button.addActionListener(e ->\n {\n PongGame gameFrame = ((GameEndBoard)((CongratsCard)((JButton)e.getSource()).getParent()).parent).parent.parent;\n PongField game = gameFrame.field;\n game.ballTimer.start();\n gameFrame.scoreBanner.reset();\n game.ball.wallBounce();\n game.resetGame();\n\n ((GameEndBoard)parent).dispose();\n });\n this.add(button, BorderLayout.SOUTH);\n }\n }\n }\n\n public static class Ball\n {\n private final Ellipse2D ball;\n private boolean bounced;\n private final Momentum momentum;\n\n public Ball(int x, int y, int width, int height)\n {\n ball = new Ellipse2D.Double(x,y,width,height);\n bounced = false;\n\n momentum = Momentum.generateNew();\n }\n // Movement methods\n public void move()\n {\n ball.setFrame((int) (ball.getX() + momentum.x), (int) (ball.getY() + momentum.y), (int) ball.getWidth(), (int) ball.getHeight());\n }\n\n public void paddleBounce()\n {\n bounced = !bounced;\n momentum.bouncePaddle();\n }\n\n public void wallBounce()\n {\n bounced = false;\n momentum.bounceX();\n }\n\n public void ceilingBounce()\n {\n bounced = false;\n momentum.bounceY();\n }\n\n // Getters\n public boolean getBounced()\n {\n return bounced;\n }\n\n public double getX()\n {\n return (int) ball.getX();\n }\n\n public double getY()\n {\n return (int) ball.getY();\n }\n\n public double getWidth()\n {\n return ball.getWidth();\n }\n\n public double getHeight()\n {\n return ball.getHeight();\n }\n\n public Momentum getMomentum()\n {\n return momentum;\n }\n\n // Passed methods\n public boolean intersects(Rectangle2D rec)\n {\n return ball.intersects(rec);\n }\n\n }\n}", "Information from 'The New Generation of Labor Marketplaces and the Future of Work' written by Pete\u2008Flint in May 2020. Published in NfX. https://www.nfx.com/post/labor-marketplaces\n\nWith unemployment expected to reach 20-30%, on par with the Great Depression, the COVID-19 crisis heralds a once-in-a-century moment in the job market.\n\nThe shelter-in-place orders from the pandemic have created a massive, but temporary, demand shock to the labor market. They have also accelerated many long term trends that will create permanent changes in the work that we do and how we do it. When the economy eventually normalizes, demand for labor will recover, and work will recover, but the shifts in supply and demand will result in a new and sizable set of unmet market needs for job placement.\n\nWhen this happens, online marketplaces will be a critical tool in getting people back to work quickly, efficiently, and at scale. They will also enable new ways for people to build the skills they need to succeed, and for them to work in an increasingly remote and distributed fashion.\n\nAt NFX, we see 4 trends in the next generation of online labor marketplaces.\nGreater complexity: Marketplaces are moving to onboard standardized and attributed human capital with a greater complexity of service.\nImproved experience: Marketplaces are evolving toward increased verticalization and taking over more of the value chain.\nTech-enabled labor: Startups able to use their tech to add value to their labor will be able to unlock latent supply and offer a better experience to both sides of the market.\nRe-skilling and upskilling: Education and labor have always been closely associated but they will increasingly start to happen on the same platform.\nWe believe there\u2019s an enormous opportunity here, not just for Founders, but for our society and economy at large. At NFX, we have been long time investors in goods, services, and information marketplaces with operational experience in marketplace creation and network effects. We\u2019ve also been increasingly active in investing in labor marketplaces, from our Pre-Seed investment in healthcare marketplace Incredible Health, to work-from-home AI and call-answering service Smith.ai and a number of other stealth investments.\nFounders that can understand and capitalize on the trends we\u2019ll outline below will be well-positioned to build the next generation of iconic labor marketplace companies and help redefine the future of work.\n\nThe first and most important trend we see in labor marketplaces is towards onboarding increasingly skilled workers and offering greater complexity of service.\n\nThe first generation of labor marketplaces to hit scale \u2014 now mature companies like Lyft, TaskRabbit, and DoorDash \u2014 allowed demand-side users to quickly and easily match to a delivery person or driver or furniture-builder. These jobs are relatively simple: short in tenure, well-defined, and requiring a low threshold of skill to perform: the so-called \u201cgig economy\u201d.\n\nThis meant that the supply side was relatively commoditized with little differentiation between different workers beyond a simple ratings and reviews system, and the demand side was constantly seeking new types of work. The first generation of labor marketplaces was therefore able to easily or even automatically match a commoditized supply base to carry out defined, specific tasks without much threat of disintermediation. The constant changes in demand-side needs drive high engagement and frequency which builds a sustainable business.\nWith incumbents having taken the low-hanging fruit and consumers and businesses feeling more comfortable with online labor selection, the next generation of labor marketplaces are tackling a greater complexity of service offering.\n\nBut there\u2019s a current sweet spot for new labor marketplaces between the well-trodden ground of the gig economy with temporary, discrete jobs and a high frequency of usage and the creative professional, skilled worker or information worker labor market which deals with complex jobs and a high degree of difficult-to-categorize differentiation between professionals. We call this the talent economy, where the internet enables talent with defined and understood skills to be connected to employers potentially in an instant.\n\nThe former area is already dominated by verticalized gig economy incumbents like Uber, DoorDash, and TaskRabbit, while the latter is served well by horizontal incumbents like LinkedIn, going after the knowledge economy.\n\nWhile LinkedIn is almost two decades old, we believe LinkedIn or Indeed will not be superseded by new vertical marketplaces, but rather will be complemented by them. The network effects from its core information workers are just too strong.\nIt\u2019s also worth noting that a large portion of the labor pool doesn\u2019t have LinkedIn profiles because it\u2019s largely irrelevant to the type of work they do. This suggests that new leading vertical job marketplaces will develop their own profiles highlighting skills and experience related to the particular industry.\n\nThe talent economy is about identifying labor pools that are standardized and attributed enough that demand-side users can quickly find what they\u2019re looking for with an attributed search enabled by internet marketplaces. RigUp is one company to emulate in this space. RigUp matches oil & gas workers to temporary jobs at oil rigs. The labor supply has explicit skilling \u2014 definable skills that are easy to assess and label. Also, the nature of the work requires a constant hiring effort.\n\nThere are plenty of other labor categories that also fall into this category. For example, if you\u2019re looking to hire a nurse or a construction worker, you may be looking for certain skills, certifications, and other standardized attributes that will make a hiring decision much quicker and easier than manually sifting through resumes (or LinkedIn profiles).\n\nWhile more vetting is necessary to qualify candidates in this category of jobs than would be for hiring someone to mount a TV or pick up your dinner, standardization of hard attributes like degrees and certifications makes it easier to filter candidates. With stronger filtering, the demand side can focus their time on the less easily definable \u201csoft attributes\u201d like culture fit.\n\nIt cannot be underemphasized how much demand-side value can be accrued by improving the efficiency of search.\n\nIn our essay on fintech-enabled marketplaces, we observed that the laws of physics in marketplaces push them to relentlessly focus on increasing user experience and increasing a percentage capture of revenue flowing through the marketplace.\nThat in turn leads to greater verticalization to improve the user experience, and also providing more services to the participants \u2014 in particular deepening integration into the enterprise via SaaS tools.\n\nLabor marketplaces are no exception. New marketplaces are wise to adopt a vertical focus, enabling greater participation in the transaction. There is a relentless drive towards offering better experiences for both workers and employers, and in most cases this necessitates building around a specific vertical to address the needs of both workers and employers in that market sector. With increased matching and efficiency through specialization and automation, marketplaces are able to command higher transaction fees.\n\nVertical focus is key. Skills, attributes, qualifications, and certifications vary greatly by industry, so lack of focus reduces the user experience by adding bloat and inefficiency into the matching and discovery process. It\u2019s much harder to quickly and efficiently find a relevant employment opportunity or job candidate on a horizontal platform than a marketplace purpose-built for your vertical.\n\nVertical focus also allows marketplaces to expand their offering beyond sourcing and potentially deeply embed into the HR systems of companies or the career paths of workers. For example, RigUp provides a mixture of sourcing workers with a rarefied skill set, while also offering compliance and security.\n\nA step beyond is monetization and supply-side embedding. Marketplaces have a clear incentive and opportunity to improve the experience by adding payroll, financing, and insurance directly to the platform. As long as the demand side has sufficient liquidity, which is easier with more commoditized labor, this decreases multi-tenanting and increases efficiency.\n\nThe monetization model itself must vary by industry. There are two basic models: the \u201cstaffing agency\u201d model of charging an ongoing percentage of salary, or the \u201crecruiting agency\u201d model of charging an upfront fee. The higher the turnover and the lower the salary, the more the staffing model is appropriate.\n\nFinally, as a labor marketplace, it\u2019s important to note that job tenure and role scarcity is a big variable in deciding which side of the marketplace to focus your efforts. If, for example, workers are hired to semi-permanent or permanent jobs, then it makes more sense to focus on the demand side. That\u2019s where the constraint in the marketplace typically is. Employers will be the high-frequency users, so if you own the demand side, the supply side will come to you when they are in a period of job transition or looking for work.\n\nOn the other hand, with short job tenures, focusing more on the supply side first makes more sense because workers will have a higher frequency of usage.\n\nTech-Enabled Labor Unlocks Greater Supply\nAnother concept I had written about in my essay on fintech-enabled marketplaces was that unlocking latent supply is key to marketplace success.\nOne interesting way to do that in labor is via technology and automation. The most interesting labor marketplaces tend to be where you can use technology to increase the value that labor provides. With increased specialization of labor comes the increased relevance of automation.\n\nAny kind of work where tech or automation can be used to incorporate specific guidance on how to do that job through the app at the point of service will create enormous value by unlocking latent supply \u2014 making it easier and lowering the threshold of training, skill or experience necessary for workers to be able to perform a job with excellence. This can happen via the worker-side experience or the employer-side.\n\nAs discussed earlier, SaaS tools are also a good way to power a marketplace. If you\u2019re able to provide a SaaS tool to a business, you can embed yourself into the HR systems running payroll and applicant tracking, for instance by automating compliance or licensing with a SaaS workflow that plugs into HR. This can help to build up the demand side while you\u2019re dealing with the chicken-or-egg problem, a problem we\u2019ve previously written about when we first revealed the 19 tactics for solving this classic marketplace problem.", "From the book 'Golden Grant Rules' by David Kincade:\nUNDERSTANDING GOVERNMENT\n37. Understand how government works: federalism\nIn Canada and the United States, our constitutions are similar in terms of federalism.\nSimply put, federalism means we have two levels of government: provincial/federal in Canada and state/federal in the USA.\nSince most \"voters\" or citizens do not easily understand which level of government is responsible for specific services, voters want elected officials to \"do something.\" (e.g., grow the economy).\nWhat happens is that both levels of government offer grants, sometimes even for the same thing!\nIn Canada, Alberta had the \"Export Support Fund,\" a grant for Alberta-based companies who want to export. Companies get grants for trade shows and other expenses abroad.\nThe federal government also has an export grant for CanExport SME (stands for small and medium-sized enterprises), which is for the same thing!\n 32\nHere is the grant writer tip: find out which application is easier to fill out before applying! In this case, the Export Support Fund was dramatically more straightforward to write than CanExport SME!\n38. Understand how government works: representative democracy\nCanada and the United States are \"representative democracies.\"\nWe elect people from a district or constituency to represent all people within that specific geographical area.\nThat elected official goes to the capital to represent everyone in their district (also known as ridings or constituencies).\nElected officials fund the bureaucracies; politicians \"sign the cheque\" that pays the bureaucrats their salaries.\nThink about that?\nMeeting your elected official is simple; inquire about their public itinerary or schedule a meeting in their local office. If you can get a \"letter of support\" from your elected official, how do you think that will help your grant application?\nPicture this scenario. You are a bureaucrat needing to choose between 1 of 2 applications. Only one application had a letter of recommendation from \"your boss.\" All things being equal, which grant application are you more likely to recommend?\nGrant tip: build a relationship with your provincial/state and federal representatives!\n39. Understand how government works: cabinet\nNot all elected officials are equal.\n33\n\nIn Canada, the premier or prime minister is the head of the political party that wins the most seats in the provincial legislature or parliament.\nThe leader chooses a \"cabinet\" from his or her party's elected candidates. These cabinet ministers are a small group of elected officials that officially form the \"government.\"\nOnce these elected officials (in Canada) are appointed to cabinet, they are known as cabinet ministers (or simply ministers).\nMinisters have the legislative authority to sign off on grants in their department. Read any grant guidelines in Canada. You will see a line that says something like, \"the minister has all the power, and they are the official government representative between you and the government.\"\nGrant Story\nWatch how powerful this line is from a grant called \"Community Initiatives Program Project-Based Grant.\"\nSection 6.11 states, \"The Minister of Culture and Tourism may exercise discretion in approving applications that fall outside the general intent of the program, based on the extent to which the applicant can demonstrate the project's potential and vital contributions to the community.\"\nGrant tip: find out who the cabinet minister is in your department and build trust with him or her. Sometimes the minister can even be your locally elected official.\nIf you attend grant events, take a guess who almost always speaks at them: ministers, of course! Ministers are responsible for the funds in the first place!\n40. Understand how government works: political parties\nPolitical parties play an essential role in Canada and the United States.\n34\n\nThe electoral system works in tandem with political parties.\nNearly all constituencies will represent a large national party, even when they have little to no chance of winning individual ridings.\nThe Canadian provincial or federal political party that wins the most seats on Election Day forms the government.\nThe electoral college system is different than a parliamentary system. Still, it works on a similar structure: the entire state goes to the political party with the most votes in each state.\nUS Political Party Story\nIn the 1992 election, independent candidate Ross Perot received 19,743,821 votes, which accounted for 18.91% of the popular vote. He failed to win any Electoral College states because of the relatively even distribution of support, but he did\nwin over 30% of the vote in Maine and 27% in Utah, finishing second in both states.\nCanada Political Party Story\nIn the 1987 New Brunswick election, Frank McKenna's Liberals won all 58 seats in the legislature, with 60.39% of the popular vote.\nGrant Tips: Be aware of your elected official's political philosophy and how they will view your organization/technology before you meet them.\n41. Understand how government works: election platforms\nWhen political parties run in election campaigns, they use election platforms.\nReading the party's election platform, you can predict what will happen to specific grants. If the party strongly opposes climate change, you can expect less funding for emission reductions.\n35\n\nYou might be surprised to learn how much impact individual citizens can have in shaping election platforms. Parties are usually starving for content in the lead up to elections. You can get involved early to shape future policy.\nGrant Tip\nWatch the election cycle and election platforms closely. You want to get your grant applications submitted before a new government establishes itself. In the 2019 Alberta Provincial Election, the government froze most grant spending from spring to fall. This delay caused applications to go on hold, leaving entrepreneurs wondering if they would receive funding.\n42. Understand how government works: election system\nYou should know if your local politician is on the government's side (the majority) or the opposition. This knowledge will inform you how close you are to the decision- maker.\nIn Canada and the USA, we have a \"first-past-the-post\" election system. Every candidate lines up at election time (like a horse race) in a geographical area (called a constituency, riding, or district), and only \"one\" candidate wins.\nBecause multiple candidates run in each constituency, the winning candidate often receives less than 50% of the vote. As an outcome of this electoral system, a legislature can win a majority of seats with less than 50% of the popular vote.\nFor example, if three candidates run in a district, \"Candidate A\" receives 40%, \"Candidate B\" receives \"30%, and \"Candidate C\" receives 30%, Candidate A represents 100% of the riding with only 40% of the popular vote.\nGrant Tip: Be aware of who you are dealing with. For example, does your locally elected official support Greenhouse Gas (GHG) emission reduction innovation, or are they anti-climate change? Know this information when asking for a letter of reference.\n36\n\nIf your elected official is on the side of government, you can ask how they can help you meet the minister of your grant's department.\n43. Understand government fiscal year\nMost provincial and federal government fiscal years run from April 1 to March 31.\nWhen a government refers to \"year,\" it almost always refers to a fiscal year. When the government plans to give you multi-year funding over 18 months, it is planning that on the government fiscal year, not yours.\nGrant Story\nI had a client win a significant government contribution over two years. However, the grant agency called them and asked if they could pay them upfront in March. The situation likely had to do with allocating capital in that fiscal year to help the department manage its books.\n44. Who signs the grant cheque: the minister\nThe most important person in the grant world is the minister of the department. The minister has the final say on big funding decisions, and they can make grant exceptions anytime.\nGrant Story\nI had a client going for a large non-profit capital grant. My client was told that grant staff place applications into two piles \"Recommend\" and \"Not Recommend.\" Then the bureaucrat told them the minister would take applications from the \"Not\" piles if he or she wants. The lesson: know who signs the cheques.\nRemember, elected officials are held accountable for taxpayer dollars. The buck stops with them. The system is not perfect, but it is the best we got!\n37\n\n45. Enhance the minster's mandate\nYour grant application should enhance the minister's mandate. Your chances of success are going to increase when you do that dramatically!\nWhen you write the application, you should be able to see the minister at your event presenting the cheque to you and your organization.\nElevate Aviation $426,000 grant announcement. Local MP and Minister in the background. My sister Kendra is at the podium. Keep reading! Your turn next.\n46. Understand that your audience is the taxpayer\nIf your grant doesn't \"sell\" to the taxpayer, it is likely to lose. Conversely, if your grant has a significant positive impact on taxpayers' lives, it is more likely to win.\nYour innovation or project can be complicated, so make it easy for the grant agency to understand.\n 38\n\n47. Why governments give grants\nThe easiest way for government officials to show support for something is to cut a cheque or through grants. Governments cannot possibly run every program, so grants are an excellent tool for allocating capital.\nFinally, grants work. When the government dangles free money to solve a problem, businesses put forward solutions to fix them.\n48. It's not about you \u2013 it is about them\nYour government got elected on a campaign platform. That platform is full of promises and commitments.\nWhether or not it wins the next election will have a lot to do with how well the government performed. If it fails on any of those fronts, you can imagine its competition will be all over them.\nLook at your governments' commitments. You can find them on their websites. Are they committed to reducing GHG emissions? Saving water? Seniors' Housing? Arts and Culture?\nFind out what the government wants and tailor your project to its needs. Even within government, they need to compete with other departments for funding.\nYour project should help the government tell its story. Imagine the politicians all smiling at your event with a big cheque.\n39", "This one is the text I want you to check. Alternative Radio Wave Technology\n\nRadio waves are a type of electromagnetic radiation that have been used for various purposes, including communication and navigation. However, there have been recent developments in alternative radio wave technologies that have improved the efficiency and capabilities of these systems. Some of these technologies include:\n\nMillimeter Waves: Millimeter waves (mmWaves) are high-frequency radio waves that operate in the frequency range of 30 GHz to 300 GHz. They have high bandwidth and are capable of transmitting large amounts of data at high speeds, making them ideal for 5G and other high-speed wireless communication systems.\n\nTerahertz Waves: Terahertz (THz) waves are electromagnetic waves that operate in the frequency range of 0.1 THz to 10 THz. They have unique properties that make them useful for various applications, including spectroscopy, imaging, and non-destructive testing.\n\nInfrared Waves: Infrared (IR) waves are a type of electromagnetic radiation that operate in the frequency range of 0.75 THz to 300 THz. They have high spectral resolution and are commonly used for thermal imaging, night vision, and other applications.\n\nVisible Light Communication: Visible light communication (VLC) uses light in the visible spectrum for communication purposes. This technology is useful for indoor communication systems because light can penetrate walls and other obstacles more easily than radio waves.\n\nSummary:\n\nAlternative radio wave technologies, such as millimeter waves, terahertz waves, infrared waves, and visible light communication, have improved the efficiency and capabilities of wireless communication and navigation systems. These technologies have unique properties that make them useful for various applications, including high-speed data transmission, spectroscopy, imaging, and indoor communication.\n\n\nAlternative Radio Wave Technology: Propagation, Uses, Advantages, Disadvantages, and Future Usefulness\n\nPropagation: Alternative radio wave technologies, such as millimeter waves, terahertz waves, infrared waves, and visible light communication, have different propagation characteristics compared to traditional radio waves. For example, millimeter waves have high frequency and short wavelength, which allows them to transmit large amounts of data at high speeds but also limits their range and ability to penetrate obstacles. Terahertz waves have unique properties that make them useful for spectroscopy and imaging, but their penetration depth is limited and their absorption by water vapor can also limit their use.\n\nUses: Alternative radio wave technologies have various applications, including high-speed wireless communication, spectroscopy, imaging, and indoor communication. Millimeter waves are used in 5G and other high-speed wireless communication systems, while terahertz waves are used for spectroscopy and imaging applications. Infrared waves are used for thermal imaging and night vision, while visible light communication is used for indoor communication systems.\n\nAdvantages: Alternative radio wave technologies have several advantages over traditional radio waves, such as higher bandwidth and faster data transmission rates, better penetration through obstacles, and unique properties that make them useful for specific applications. For example, millimeter waves have high bandwidth and are capable of transmitting large amounts of data at high speeds, while terahertz waves have unique properties that make them useful for spectroscopy and imaging.\n\nDisadvantages: Alternative radio wave technologies also have disadvantages, such as limited range, limited penetration depth, and sensitivity to atmospheric absorption. For example, millimeter waves have limited range and difficulty penetrating obstacles, while terahertz waves are sensitive to atmospheric absorption.\n\nFuture Usefulness: Alternative radio wave technologies are expected to be useful in the foreseeable future, especially in high-speed wireless communication and in specific applications such as spectroscopy, imaging, and indoor communication. The continued development and improvement of these technologies will likely lead to new and innovative applications in the future.\n\nSummary:\n\nAlternative radio wave technologies, such as millimeter waves, terahertz waves, infrared waves, and visible light communication, have different propagation characteristics, uses, advantages, and disadvantages compared to traditional radio waves. They are expected to be useful in the foreseeable future, especially in high-speed wireless communication and specific applications such as spectroscopy, imaging, and indoor communication. The continued development and improvement of these technologies will likely lead to new and innovative applications in the future.\n\n\nRadio Wave Technology\n\nRadio waves are a type of electromagnetic radiation that are widely used for communication and navigation purposes. They are characterized by their low frequency and long wavelength and can penetrate walls and other obstacles, making them ideal for wireless communication systems. The following is a detailed explanation of radio wave technology:\n\nFrequency: Radio waves operate in the frequency range of 3 kilohertz (kHz) to 300 gigahertz (GHz). The frequency of a radio wave determines its wavelength and the type of information it can carry.\n\nPropagation: Radio waves can travel long distances in the atmosphere and can penetrate walls and other obstacles, making them ideal for wireless communication systems. They can also be reflected by the Earth's surface, allowing them to travel around obstacles and reach remote locations.\n\nUses: Radio waves are used for various purposes, including radio and television broadcasting, cellular communication, Wi-Fi, GPS, and other navigation systems. They are also used for scientific research, such as studying the properties of the atmosphere and the Earth's magnetic field.\n\nAdvantages: Radio waves are cheap and easy to generate, making them a cost-effective solution for communication and navigation systems. They are also versatile, as they can be used for both analog and digital communication systems.\n\nSummary:\n\nRadio waves are a type of electromagnetic radiation that are widely used for communication and navigation purposes. They have a low frequency and long wavelength and can penetrate walls and other obstacles, making them ideal for wireless communication systems. Radio waves are also versatile, cheap, and easy to generate, making them a cost-effective solution for various applications, including radio and television broadcasting, cellular communication, Wi-Fi, GPS, and scientific research.\n\n\nBluetooth Technology\n\nBluetooth is a wireless communication technology that allows devices to communicate with each other over short distances. It was developed in the 1990s as a way to replace RS-232 cables used for connecting peripherals to computers. The following is a detailed explanation of Bluetooth technology:\n\nFrequency: Bluetooth operates in the frequency range of 2.4 GHz and uses a spread-spectrum frequency-hopping technology to avoid interference from other devices operating in the same frequency band.\n\nRange: The typical range of a Bluetooth connection is up to 10 meters, although the actual range can be affected by physical obstacles and radio interference.\n\nUses: Bluetooth is widely used for connecting devices such as phones, laptops, speakers, headphones, and other peripherals. It is also used in home automation systems, wearable devices, and in medical and health care applications.\n\nAdvantages: Bluetooth has several advantages over other wireless communication technologies, such as low power consumption, ease of use, and low cost. It is also compatible with a wide range of devices and can be used to connect multiple devices at once.\n\nDisadvantages: The main disadvantage of Bluetooth is its limited range, which can be affected by physical obstacles and radio interference. It is also not suitable for high-speed data transfers, although newer versions of Bluetooth have improved data transfer speeds.\n\nSummary:\n\nBluetooth is a wireless communication technology that allows devices to communicate with each other over short distances. It operates in the frequency range of 2.4 GHz and uses a spread-spectrum frequency-hopping technology to avoid interference from other devices. Bluetooth is widely used for connecting devices such as phones, laptops, speakers, headphones, and other peripherals. It has several advantages, such as low power consumption, ease of use, and low cost, but its main disadvantage is its limited range, which can be affected by physical obstacles and radio interference. Despite its limitations, Bluetooth continues to be a popular and widely used wireless communication technology.\n\n\nHiPERLAN Technology\n\nHiPERLAN (High Performance Radio LAN) is a type of wireless communication technology that provides high-speed data transfer over short distances. It was developed in the 1990s as a way to provide high-speed wireless connectivity for local area networks (LANs). The following is a detailed explanation of HiPERLAN technology:\n\nFrequency: HiPERLAN operates in the frequency range of 5 GHz, which is less congested compared to the 2.4 GHz frequency band used by other wireless technologies such as Wi-Fi and Bluetooth.\n\nRange: The typical range of a HiPERLAN connection is up to 100 meters, although the actual range can be affected by physical obstacles and radio interference.\n\nUses: HiPERLAN is used in wireless local area networks (WLANs) to provide high-speed wireless connectivity for data transfer, multimedia streaming, and other applications. It is also used in home automation systems, wearable devices, and in industrial and commercial applications.\n\nAdvantages: HiPERLAN has several advantages over other wireless communication technologies, such as high-speed data transfer rates, low power consumption, and low cost. It is also compatible with a wide range of devices and can be used to connect multiple devices at once.\n\nDisadvantages: The main disadvantage of HiPERLAN is its limited range, which can be affected by physical obstacles and radio interference. It is also not suitable for outdoor use, as the 5 GHz frequency band is absorbed by moisture and other atmospheric conditions.\n\nSummary:\n\nHiPERLAN is a type of wireless communication technology that provides high-speed data transfer over short distances. It operates in the frequency range of 5 GHz, which is less congested compared to the 2.4 GHz frequency band. HiPERLAN is used in wireless local area networks (WLANs) to provide high-speed wireless connectivity for data transfer, multimedia streaming, and other applications. It has several advantages, such as high-speed data transfer rates, low power consumption, and low cost, but its main disadvantage is its limited range, which can be affected by physical obstacles and radio interference. Despite its limitations, HiPERLAN continues to be a popular and widely used wireless communication technology.", "write it in norwegian and in the same tone and style as this text \"\"Takk, kj\u00e6re Ivar\" er en tale som 23 \u00e5r gamle Thea Ids\u00f8e holdt den 6. desember 2013. Anledningen var den offisielle avslutningen av Spr\u00e5k\u00e5ret 2013, en stor tilstelning p\u00e5 Ivar Aasen-tunet i \u00d8rsta. Hovedform\u00e5let med talen er \u00e5 overbevise tilh\u00f8rerne om viktigheten av Ivar Aasens spr\u00e5karbeid. Ids\u00f8e argumenterer for dette ved \u00e5 trekke fram at spr\u00e5ket er det \"viktigaste verkt\u00f8y for \u00e5 kunne lukkast som menneske\". Hun p\u00e5peker at Aasen har arbeidet for at avstanden mellom det talte og det skrevne ord skulle bli minst mulig, og hun hevder at dette er en forutsetning for at vi skal klare \u00e5 formidle tanker og ideer akkurat slik vi vil.\n\nIds\u00f8e utnytter kairos, det vil si mulighetene som ligger i situasjonen, p\u00e5 en meget god m\u00e5te. Spr\u00e5k\u00e5ret 2013 handlet om arbeid og arrangementer for \u00e5 vise fram alle spr\u00e5kene vi har i Norge. Ids\u00f8e taler til spr\u00e5kinteresserte deltakere om hvor viktig spr\u00e5ket er for oss, og hun kombinerer dette med en hyllest til Ivar Aasen p\u00e5 hans eget g\u00e5rdstun. Derfor passer emnet for talen godt til situasjonen. N\u00e5r det gjelder spr\u00e5ket hun bruker, er det i dette tilfellet ekstra viktig at Ids\u00f8e snakker tiln\u00e6rmet slik som det nynorske skriftspr\u00e5ket kommer til uttrykk. Spr\u00e5ket hennes understreker det hun snakker om, for hun framstiller nynorsken sv\u00e6rt positivt. Spr\u00e5ket og innholdet passer ogs\u00e5 godt fordi tilh\u00f8rerne mest sannsynlig sitter inne med samme mening som taleren.\n\nDet fins enda en grunn til at en kan si at Ids\u00f8es tale kommer p\u00e5 rett tidspunkt. Det er nemlig slik at dialektene i Norge forsvinner mer og mer. S\u00e6rlig er det ungdom som legger av seg dialekten, slik at vi n\u00e5 er i ferd med \u00e5 prate mer og mer likt. Mange ungdommer i bygdestr\u00f8k velger i dag \u00e5 prate tiln\u00e6rmet likt bym\u00e5let. Dette f\u00f8rer til at spr\u00e5ket mister b\u00e5de mangfold og s\u00e6rpreg. Dessuten er utviklingen slik at flere og flere har et talem\u00e5l som n\u00e6rmer seg bokm\u00e5let fordi mange som bor i byer i n\u00e6rheten av Oslo, snakker slik. Dette kan v\u00e6re med p\u00e5 \u00e5 true nynorsken da det vil bli f\u00e6rre som \"prater nynorsk\". At Ids\u00f8e da, som en ung jente med utpreget dialekt, i denne talen sl\u00e5r et slag for nynorsk og spr\u00e5kmangfold, b\u00f8r kunne vekke interesse hos mange, ettersom det er sv\u00e6rt dagsaktuelt.\n\nTaleren Thea Ids\u00f8e vil nok for mannen i gata virke noks\u00e5 ukjent, og i s\u00e5 m\u00e5te ikke ha altfor sterk etos i en slik sammenheng. Ser en derimot p\u00e5 hvem det faktisk er hun taler til i denne situasjonen, s\u00e5 er det folk som er sv\u00e6rt engasjerte og interesserte i spr\u00e5ket v\u00e5rt. For dem vil nok Ids\u00f8es argumentasjon for spr\u00e5kmangfold og Aasens arbeid v\u00e6re interessant \u00e5 h\u00f8re p\u00e5. Dessuten er Ids\u00f8e ung, og det jo tross alt de unge som etter hvert m\u00e5 s\u00f8rge for at slike verdier som Ids\u00f8e st\u00e5r for, bevares. Ogs\u00e5 alderen styrker derfor Ids\u00f8es etos n\u00e5r hun prater med og for sitt \"hjartespr\u00e5k\".\n\nDet viktigste virkemidlet i talen er bruken av verdiladde ord. Bruken av plussord om spr\u00e5ket v\u00e5rt, og om Ivar Aasen og hans arbeid, er gjennomg\u00e5ende i hele talen. Allerede i innledningen siterer Ids\u00f8e forfatteren Tarjei Vesaas, som kalte Aasen for \"den stille nedbrytaren av grenser, den rolege og sikre oppbyggaren av eit folk\". Hyllesten av spr\u00e5ket ser vi n\u00e5r Ids\u00f8e blant annet karakteriserer spr\u00e5ket som \"lidenskap\" og som \"mitt viktigaste verkt\u00f8y for \u00e5 lukkast som menneske\". Plussordene er der for \u00e5 understreke budskapet i talen, nemlig viktigheten av Aasens arbeid for alle som vil ha et skriftspr\u00e5k som likner p\u00e5 det spr\u00e5ket de snakker. Ordene skal vekke positive f\u00f8lelser rundt temaene Ids\u00f8e fors\u00f8ker \u00e5 belyse og bidrar til en sterk patos-appell i teksten.\n\nEt annet sentralt virkemiddel i talen er kontrastbruk. Etter \u00e5 ha delt ut plussord i fleng om spr\u00e5ket og Aasens arbeid, skaper Ids\u00f8e en kontrast gjennom et avsnitt der hun beskriver hvordan hverdagen hennes ville v\u00e6rt uten Aasen og nynorsken. Avsnittet starter med et retorisk sp\u00f8rsm\u00e5l: \"Kj\u00e6re Ivar. Korleis ville kvardagen min vore utan deg?\" Deretter beskriver hun hvordan livet hennes ville v\u00e6rt da: \"Gjennom pennen ville argumenta mine falma, krafta mi vorte veikare og engasjementet mitt ville d\u00f8ydd ut.\" Hensikten med kontrasteringen er \u00e5 gj\u00f8re det enda tydeligere hvor viktig Aasens arbeid var. Ordene skal vekke f\u00f8lelser, men Ids\u00f8e appellerer ogs\u00e5 til fornuften fordi hun viser tilh\u00f8rerne to muligheter, et liv med \"hjartespr\u00e5ket\" sitt og et liv uten.\n\nDirekte henvendelse er et annet virkemiddel Ids\u00f8e bruker mye i talen. Hele fire ganger henvender hun seg direkte til Aasen med uttrykket \"Kj\u00e6re Ivar\", og hun snakker til ham og takker og hyller ham. Denne gjentatte personlige henvendelsen til Aasen bruker Ids\u00f8e fordi hun vil vise at han er en kj\u00e6r person for henne, og fordi hun \u00f8nsker at tilh\u00f8rerne skal f\u00e5 et mer personlig og positivt forhold til ham. Virkemidlet skal alts\u00e5 f\u00f8rst og fremst forsterke patos-appellen i teksten.\n\nSpr\u00e5klige bilder er ogs\u00e5 et viktig virkemiddel i talen. Ids\u00f8e bruker for eksempel metaforer: \"Spr\u00e5k er lidenskap. Det er kj\u00e6rleik, hat og heftig debatt.\" Hun velger alts\u00e5 sterke ord for \u00e5 beskrive spr\u00e5ket. Hun fors\u00f8ker ogs\u00e5 \u00e5 gj\u00f8re talen til en kamptale, ved \u00e5 omtale arbeidet for \u00e5 bevare verdiene spr\u00e5ket gir oss, for \"ein kamp verd \u00e5 kjempe kvar einaste dag\". Ids\u00f8e \u00f8nsker gjennom disse spr\u00e5klige bildene \u00e5 engasjere, da de gir en mer engasjerende beskrivelse av spr\u00e5ket. Hun fors\u00f8ker alts\u00e5 \u00e5 oppfordre publikum til kamp med bilder som har en sterk patos-appell.\n\nEn god tale m\u00e5 oppfylle kravet til aptum og ta hensyn til alle sider ved den retoriske situasjonen. De sterke spr\u00e5klige bildene som jeg omtalte i forrige avsnitt, tror jeg vil komme godt til sin rett foran engasjerte spr\u00e5kentusiaster p\u00e5 Ivar Aasen-tunet. Talen blir holdt i en sammenheng der det er grunn til \u00e5 tro at deltakerne brenner for samme sak, og da spiller det ingen rolle at Ids\u00f8e ikke presenterer motargumenter, tvert om. Det kan til og med v\u00e6re en fordel n\u00e5r hun vil mane til kamp for spr\u00e5ket. I denne situasjonen har taleren Ids\u00f8e ogs\u00e5 sterk etos, for n\u00e5r hun snakker med s\u00e6regen uttale, blir argumentasjonen om at en m\u00e5 bevare spr\u00e5kmangfoldet og \"hjartespr\u00e5ket sitt\" mer troverdig. Jeg tror derfor at Ids\u00f8e vil f\u00e5 folk med seg n\u00e5r hun maner til kamp for \u00e5 bevare Aasens verdier og \"hjartespr\u00e5ket\". Folk liker jo tross alt litt ungdommelig p\u00e5gangsmot.\"", "please rewrite this, and write cons and pros:\n\nI've had 3 headsets prior to getting these and I must say, they blow my previous headsets out of the water. I can almost hear you reading this review because I have them on right now! Just kidding but I'm excited and strongly recommend this headset if you can afford them. I never thought wireless would be the way but I'm convinced! Turtle Beach has always been a force to be reckoned with, I just never invested in a set until now.\n4 people found this helpful\nHelpful\nReport abuse\n Jr\n5.0 out of 5 stars Good headset for music and gaming\nReviewed in the United States \ud83c\uddfa\ud83c\uddf8 on January 26, 2023\nStyle: Stealth 600 USB PSColor: WhiteVerified Purchase\nbass is good and good for gaming\nHelpful\nReport abuse\n Joseph West\n5.0 out of 5 stars Excellent head phones.\nReviewed in the United States \ud83c\uddfa\ud83c\uddf8 on January 5, 2023\nStyle: Stealth 600 MAX PSColor: BlackVerified Purchase\nGreat head phones sounds are great I highly recommend.\nOne person found this helpful\nHelpful\nReport abuse\n David Sisson\n5.0 out of 5 stars They are so perfected these days.\nReviewed in the United States \ud83c\uddfa\ud83c\uddf8 on December 31, 2022\nStyle: Stealth 600 MAX PSColor: BlackVerified Purchase\nTurtle Beach is amazing.\nGood price,. comfortable, work great!\nOne person found this helpful\nHelpful\nReport abuse\n Amazon Customer\n5.0 out of 5 stars Awesome\nReviewed in the United States \ud83c\uddfa\ud83c\uddf8 on December 30, 2022\nStyle: Stealth 600 USB PSColor: WhiteVerified Purchase\nThey are awesome, well worth the price\nOne person found this helpful\nHelpful\nReport abuse\n Isaac simpson\n5.0 out of 5 stars The set up was a little confusing but a good product\nReviewed in the United States \ud83c\uddfa\ud83c\uddf8 on December 21, 2022\nStyle: Stealth 600 USB PSColor: BlackVerified Purchase\nSound quality is pretty great. The battery life is extensive. Definitely happy with the purchase\nCustomer image\nOne person found this helpful\nHelpful\nReport abuse\n ako\n5.0 out of 5 stars Wonderful\nReviewed in the United States \ud83c\uddfa\ud83c\uddf8 on November 4, 2022\nStyle: Stealth 700 MAX PSColor: BlackVerified Purchase\nLove it sound great\nHelpful\nReport abuse\n MM1000\n5.0 out of 5 stars Well thought-out gaming headset that sounds excellent and is easy to use\nReviewed in the United States \ud83c\uddfa\ud83c\uddf8 on September 19, 2022\nStyle: Stealth 600 MAX PSColor: BlackVine Customer Review of Free Product( What's this? )\nHonestly, unboxing these was a bit underwhelming. They are just black plastic headphones. There's a cool bit of detail (a silver logo) on the inside of the ears, but otherwise, it's very conservative, and many headphones from Turtle beach have bright colors and gaming styling. In the box, there's cardboard, a box of little pamphlets (including a short manual), one sticker, a USB C cable, and the USB-A dongle. The dongle is large, not one of those really short ones, and I believe that's to increase the range on this headset. But there's nothing wow to the unboxing (this would still be a great gift).\n\nConstruction quality is great. Metal and thick plastic, a cushion on the top of the head, thick pads around the ears, two dials that are have a solid feel, two buttons next to eachother that feel different. The band around the top of the head is very overengineered. It isn't likely to break even if you try to break it. There's branding here and there, it's etched on the top, but it's all subtle. The mike rotates in and out of place. The whole thing is pretty large. There are large hinges and swivels on the side. It looks industrial, but most of all, it's very comfortable, just moving wherever you need it to and staying there, with cloth earpads and a soft pad on the top being all you actually touch. It isn't that heavy, at least in my use I never had a problem.\n\nIn use, the smart design is obvious. For example, the only light, a red or blue LED (it goes blue when it's paired to the dongle) is somewhat masked by the mike. So while it's easy to see the light if you lay the headphones down, it isn't going to reflect on your TV screen when you're gaming. A really small detail, but other headphones miss it.\n\nThe USB dongle has a switch for PS4, PS5, and the Switch, which don't work with most headsets due to high latency. With that mode on, you can use all the 3d Audio stuff in the playstation, and I'll talk about the audio performance in a minute. To use this with a computer or pretty much anything that supports USB audio, select the PC switch.\n\nPlug the USB dongle in, then turn on the headset, and in a few seconds, you'll hear a very simple series of beeps that obviously indicates it's working. That's it. No voice telling you. You get another series of beeps if you open or close the mike (to indicate it's turned on). You get a beep when hitting the 'mode' button to change the equalizer mode. That's it. All the beeps are pretty obvious, as is setting this up. I do appreciate the consistent minimalist attitude here.\n\nAudio quality is excellent. I've used these to listen to music, and the range is just great, low, high, no reverberation, crisp sounds. It's got very large 50mm drivers and is amplified so it's potentially way too loud (be careful), but so long as you're mature, it's just a great high resolution sound. Many studio grade headphones have 42mm drivers, and those are large. I compared these to several nice headphones that aren't gaming oriented, and these sound as good as all but the most expensive. You could get these just for music and while they don't really look stylish enough, they really are fantastic for audio quality.\n\nThey lack some features. I personally love that the controls are so simple. Turn them on, and dial up or down your volume. But there's no bluetooth, the USB is solely the proprietary turtle beach dongle (which has extremely low latency, and you wouldn't be able to tell the difference between this and a wired headset). There's no real way to use these except via USB. That's OK if you're only using this with your PC or playstation. I definitely use these to watch movies and TV, and would probably use them with my phone if it were possible, but it isn't. I will also add that the battery life is excellent.\n\nIf you don't mind the industrial style and the basic controls, these are excellent gaming headphones you'll use for music and movies as well.\nHelpful\nReport abuse\n DcDaddy\n5.0 out of 5 stars Was not so impressed, then I read the directions\nReviewed in the United States \ud83c\uddfa\ud83c\uddf8 on November 27, 2022\nStyle: Stealth 600 MAX PSColor: Black\nI couldn't hear footsteps or faint sounds very well and I was kind of disappointed, getting whooped in Warzone 2. I read the directions and to get the \"super human\" hearing to come on you have to push the power button again after the headset is connected. After I read the directions and tried this feature out I can hear everything. This changed my whole outlook on this headset. I can't believe how much louder and clear sounding it is with that feature on. The directions literally tell you to turn it on to hear footsteps and other faint sounds. I'm impressed. The battery last for a good amount of time. I don't think you can physically game longer than the battery lasts. This beats the other 25$ turtle beach headset I have.\n2 people found this helpful\nHelpful\nReport abuse\n Gene L.\nVINE VOICE\n5.0 out of 5 stars Low-Latency, Comfortable Wireless Headset\nReviewed in the United States \ud83c\uddfa\ud83c\uddf8 on November 7, 2022\nStyle: Stealth 600 USB PSColor: BlackVine Customer Review of Free Product( What's this? )\nI was pleasantly surprised with the fit and feel of this Turtle Beach headset. I've purchased a hand full of Turtle Beach headsets in the past, and came away disappointed each time.\n\nThis has been the exception. These fit my enormous noggin well, they remain cool and comfortable even after hours of use, and I'm thoroughly impressed.\n\nThe sound quality is alright, it's not amazing, but it's more than sufficient. These are not audiophile, studio monitor headphones, and you shouldn't expect them to be. For music, there are for sure better headphones. But for gaming, and video-conferencing? These are more than adequate.\n\nThe mic monitoring is a nice touch as well, I keep mine all the way up so I can still hear what's going on around me while the headphones are on, as the noise cancelling does a good job.\n\nThe battery life is outstanding, and working from home last week, I was able to get 3 days of ~6 hours of use each day before needing charged.\n\nShipped quickly, arrived undamaged, and I'd for sure say buy with confidence!", "=== INSTRUCTIONS ===\nYour task is ONLY to confirm receipt of this chunk, chunk 3/3, and not generate any text. You have now received all the chunks. Please wait for further instructions.\n=== SCRIPT CHUNK 3/3 ===\n wishing it were Ujunwa; the Zimbabwean said Edward\u2019s eyes were always leering when he looked at Ujunwa; the white South African said Edward would never look at a white woman like that because what he felt for Ujunwa was a fancy without respect. \u201cYou all noticed?\u201d Ujunwa asked them. \u201cYou all noticed?\u201d She felt strangely betrayed. She got up and went to her cabin. She called her mother, but the metallic voice kept saying \u201cThe number you are calling is not available at the moment, please try later,\u201d and so she hung up. She could not write. She lay in bed and stayed awake for so long that when she finally fell asleep, it was dawn. That evening, the Tanzanian read an excerpt of his story about the killings in the Congo, from the point of view of a militiaman, a man full of prurient violence. Edward said it would be the lead story in the Oratory, that it was urgent and relevant, that it brought news. Ujunwa thought it read like a piece from The Economist with cartoon characters painted in. But she didn\u2019t say that. She went back to her cabin and, although she had a stomachache, she turned on her laptop. As Chioma sits and stares at Yinka, settled on the alhaji\u2019s lap, she feels as if she is acting a play. She wrote plays in secondary school. Her class staged one during the school\u2019s anniversary celebration and, at the end, there was a standing ovation and the principal said, \u201cChioma is our future star!\u201d Her father was there, sitting next to her mother, clapping and smiling. But when she said she wanted to study literature in university, he told her it was not viable. His word, \u201cviable.\u201d He said she had to study something else and could always write on the side. The alhaji is lightly running a finger over Yinka\u2019s arm and saying, \u201cBut you know Savanna Union Bank sent people to me last week.\u201d Yinka is still smiling and Chioma wonders whether her cheeks are aching. She thinks about the stories in a metal box under her bed. Her father read them all and sometimes he wrote in the margins: Excellent! Clich\u00e9! Very good! Unclear! It was he who had bought novels for her; her mother thought novels a waste of time and felt that all Chioma needed were her textbooks. Yinka says, \u201cChioma!\u201d and she looks up. The alhaji is talking to her. He looks almost shy and his eyes do not meet hers. There is a tentativeness toward her that he does not show toward Yinka. \u201cI am saying you are too fine. Why is it that a Big Man has not married you?\u201d Chioma smiles and says nothing. The alhaji says, \u201cI have agreed that I will do business with Merchant Trust but you will be my personal contact.\u201d Chioma is uncertain what to say. \u201cOf course,\u201d Yinka says. \u201cShe will be your contact. We will take care of you. Ah, thank you, sir!\u201d The alhaji gets up and says, \u201cCome, come, I have some nice perfumes from my last trip to London. Let me give you something to take home.\u201d He starts to walk inside and then turns. \u201cCome, come, you two.\u201d Yinka follows. Chioma gets up. The alhaji turns again toward her, to wait for her to follow. But she does not follow. She turns to the door and opens it and walks out into the bright sunlight and past the Jeep in which the driver is sitting with the door hanging open, listening to the radio. \u201cAunty? Aunty, something happen?\u201d he calls. She does not answer. She walks and walks, past the high gates and out to the street where she gets in a taxi and goes to the office to clear out her almost-empty desk. Ujunwa woke up to the crashing sound of the sea, to a nervous clutch in her belly. She did not want to read her story tonight. She did not want to go to breakfast, either, but she went anyway and said a general good morning with a general smile. She sat next to the Kenyan and he leaned toward her and whispered that Edward had just told the Senegalese that he had dreamed of her naked navel. Naked navel. Ujunwa watched the Senegalese, delicately raising her teacup to her lips, sanguine, looking out at the sea. Ujunwa envied her confident calm. She felt upset, too, to hear that Edward was making suggestive remarks to someone else, and she wondered what her pique meant. Had she come to see his ogling as her due? She was uncomfortable thinking about this, about reading that night, and so in the afternoon, lingering over lunch, she asked the Senegalese what she had said when Edward spoke of her naked navel. The Senegalese shrugged and said no matter how many dreams the old man had, she would still remain a happy lesbian and there was no need to say anything to him. \u201cBut why do we say nothing?\u201d Ujunwa asked. She raised her voice and looked at the others. \u201cWhy do we always say nothing?\u201d They looked at one another. The Kenyan told the waiter that the water was getting warm and could he please get some more ice. The Tanzanian asked the waiter where in Malawi he was from. The Kenyan asked him if the cooks, too, were from Malawi as all the waiters seemed to be. Then the Zimbabwean said she did not care where the cooks were from because the food at Jumping Monkey Hill was simply sickening, all that meat and cream. Other words tumbled out and Ujunwa was not sure who said what. Imagine an African gathering with no rice and why should beer be banned at the dinner table just because Edward thought wine was proper and breakfast at eight was too early, never mind that Edward said it was the \u201cright\u201d time and the smell of his pipe was nauseating and he had to decide which he liked to smoke, anyway, and stop rolling cigarettes halfway through a pipe. Only the black South African remained silent. He looked bereft, hands clasped in his lap, before he said that Edward was just an old man who meant no harm. Ujunwa shouted at him, \u201cThis kind of attitude is why they could kill you and herd you into townships and require passes from you before you could walk on your own land!\u201d Then she stopped herself and apologized. She should not have said that. She had not meant to raise her voice. The Black South African shrugged, as if he understood that the devil would always do his work. The Kenyan was watching Ujunwa. He told her, in a low voice, that she was angry about more than just Edward and she looked away and wondered if \u201cangry\u201d was the right word. Later, she went to the souvenir shop with the Kenyan and the Senegalese and the Tanzanian and tried on jewelry made of faux ivory. They teased the Tanzanian about his interest in jewelry\u2014 perhaps he was gay, too? He laughed and said his possibilities were limitless. Then he said, more seriously, that Edward was connected and could find them a London agent; there was no need to antagonize the man, no need to close doors to opportunity. He, for one, didn\u2019t want to end up at that dull teaching job in Arusha. He was speaking as though to everyone, but his eyes were on Ujunwa. Ujunwa bought a necklace and put it on and liked the look of the white, tooth-shaped pendant against her throat. That evening Isabel smiled when she saw it. \u201cI wish people would see how faux ivory looks real and leave the animals alone,\u201d she said. Ujunwa beamed and said that it was in fact real ivory and wondered whether to add that she had killed the elephant herself during a royal hunt. Isabel looked startled, then pained. Ujunwa fingered the plastic. She needed to be relaxed, and she said this to herself over and over, as she started to read from her story. Afterwards, the Ugandan spoke first, saying how strong a story it was, how believable, his confident tone surprising Ujunwa even more than his words. The Tanzanian said she captured Lagos well, the smells and sounds, and it was incredible how similar Third World cities were. The white South African said she hated that term, Third World, but had loved the realistic portrayal of what women were going through in Nigeria. Edward leaned back and said, \u201cIt\u2019s never quite like that in real life, is it? Women are never victims in that sort of crude way and certainly not in Nigeria. Nigeria has women in high positions. The most powerful cabinet minister today is a woman.\u201d The Kenyan cut in and said he liked the story but didn\u2019t believe Chioma would give up the job; she was, after all, a woman with no other choices, and so he thought the ending was implausible. \u201cThe whole thing is implausible,\u201d Edward said. \u201cThis is agenda writing, it isn\u2019t a real story of real people.\u201d Inside Ujunwa, something shrank. Edward was still speaking. Of course one had to admire the writing itself, which was quite mah-ve-lous. He was watching her, and it was the victory in his eyes that made her stand up and start to laugh. The participants stared at her. She laughed and laughed and they watched her and then she picked up her papers. \u201cA real story of real people?\u201d she said, with her eyes on Edward\u2019s face. \u201cThe only thing I didn\u2019t add in the story is that after I left my coworker and walked out of the alhaji\u2019s house, I got into the Jeep and insisted that the driver take me home because I knew it was the last time I would be riding in it.\u201d There were other things Ujunwa wanted to say, but she did not say them. There were tears crowding up in her eyes but she did not let them out. She was looking forward to calling her mother, and as she walked back to her cabin, she wondered whether this ending, in a story, would be considered plausible.\n=== END OF CHUNK ===", "summarize the below texts to bullet point sentences\n\n3. Method\nOur approach builds on data2vec (Baevski et al., 2022) and\nwe first describe the major shared techniques including pre\u0002dicting contextualized target representations (\u00a73.1). Similar\nto Masked Autoencoders (MAE; He et al. 2021), we encode\nonly non-masked portions of a sample and use a decoder\nmodel to predict target representations for the masked por\u0002tions but instead of using a Transformer-based decoder, we\nuse a smaller convolutional decoder which we find to be eas\u0002ier and faster to train (\u00a73.2). To amortize the computational\noverhead of creating contextualized target representations,\nwe reuse each target for multiple masked versions of a train\u0002ing sample (\u00a73.3) and instead of random masking or block\nmasking, our inverse block masking strategy ensures that\ncontiguous regions of the sample are preserved to provide\nmore context for student predictions (\u00a73.4).\n3.1. Contextualized Target Prediction\nInstead of reconstructing local windows of the the raw input\ndata (He et al., 2021), or predicting discrete representations\nthereof (Bao et al., 2021), we predict representations of the\nteacher network incorporating information from the entire\ninput sample. This leads to a richer training task where\ntargets are specific to a particular training sample. Contex\u0002tualized targets are built via the self-attention mechanism\nof a Transformer-based teacher model which encodes the\nunmasked training sample (Paulus et al., 2017; Vaswani\net al., 2017) and the training targets are a weighted sum of\nall features in the sample.\nTarget Representations and Learning Objective. Train\u0002ing targets are based on averaging the top K FFN blocks\nof the teacher. Before averaging, activations are normal\u0002ized using instance normalization (Ulyanov et al., 2016).1\nThe training task is for the student network to regress these\ntargets based on the masked version of the sample.\nTeacher Weights. The teacher weights \u2206 are an expo\u0002nentially moving average of the student encoder weights \u03b8\n(Grill et al., 2020): \u2206 \u2190 \u03c4\u2206 + (1 \u2212 \u03c4 ) \u03b8 where \u03c4 follows\n1Layer normalization (Ba et al., 2016) of the averaged targets\ncan be useful for some modalities such as speech and vision.\na linearly increasing schedule from a starting value \u03c40 to a\nfinal value \u03c4e over \u03c4n updates, after which the value is kept\nconstant (Baevski et al., 2022).\nLearning Objective. We use an L2 loss based on the\ntarget representation from the teacher network y and the\nstudent network prediction f(x). This is a simplification\ncompared to the Smooth L1 loss used in Baevski et al. (2022)\nand we found it to work well across modalities.\n3.2. Model Architecture\nSimilar to data2vec (Baevski et al., 2022), our model uses\nmodality-specific feature encoders and a Transformer archi\u0002tecture where the latter makes up the the bulk of the model\nweights (Vaswani et al., 2017). For computer vision, we use\na patch mapping of 16x16 pixels as feature encoder (Doso\u0002vitskiy et al., 2020), for speech a multi-layer convolutional\nnetwork following van den Oord et al. (2018); Baevski et al.\n(2020b; 2022) and for text we use embeddings learned based\non byte-pair encoding (Sennrich et al., 2016).\nAsymmetric Encoder/Decoder Architecture. In a first\nstep, we use the teacher network to encode all parts of the\nunmasked training sample in order to create training targets\n(\u00a73.1). Next, we mask part of the sample (\u00a73.4) and em\u0002bed it with the student encoder. To improve efficiency, we\nencode only unmasked patches or time-steps of a training\nexample which leads to a large speed-up compared to encod\u0002ing all parts of the sample (He et al., 2021), depending on\nthe amount of masking. The output of the student encoder is\nthen merged with fixed representations for the masked por\u0002tions and fed to a decoder network. To represent the masked\ntokens, we found it sufficient to use random Gaussian noise\ncompared to a learned representation (He et al., 2021).2 The\ndecoder network then reconstructs the contextualized target\nrepresentation of the teacher network for time-steps which\nare masked in the student input.\nConvolutional Decoder Network. We use a lightweight\ndecoder consisting of D convolutions, each followed by\nlayer normalization (Ba et al., 2016), a GELU activation\nfunction (Hendrycks & Gimpel, 2016), and a residual con\u0002nection (He et al., 2015). For sequential data such as speech\nand text we use 1-D convolutions and for images we use\n2-D convolutions, each parameterized by groups to increase\nefficiency (Krizhevsky et al., 2012). We tune the number of\nlayers and kernel size for each modality.\n2We also experimented with adding positional embeddings but\nfound that they do not improve results.\nEfficient Self-supervised Learning with Contextualized Target Representations for Vision, Speech and Language\n3.3. Multi-mask Training\nA disadvantage of the data2vec teacher-student setup is the\nneed to process each sample twice: once to obtain targets\nwith the teacher model, and once to obtain predictions of\nthe student. Moreover, computing activations for the teacher\nmodel is also less efficient compared to the student model\nsince the teacher needs to process the full unmasked input.3\nIn order to amortize the cost of the teacher model com\u0002putation, we reuse the teacher representation for multiple\nmasked versions of the training sample. Concretely, we con\u0002sider M different masked versions of the training sample\nand compute the loss with respect to the same target repre\u0002sentation. This is possible, because target representations\nare based on the full unmasked version of the sample. As\nM grows, the computational overhead of computing target\nrepresentations becomes negligible. In practice, this enables\ntraining with a relatively small batch size compared to other\nself-supervised work (\u00a74).\nConsidering multiple masked versions of a training sam\u0002ple has been previously explored in the context of self\u0002supervised learning for computer vision with ResNet mod\u0002els (Jing et al., 2022), although the authors found that it\nperformed much less well than different image augmenta\u0002tions. Caron et al. (2020a) considers multiple crops based\non the same image but trains the model by comparing dis\u0002crete codes rather than predicting the representation of the\noriginal image. And Girdhar et al. (2022) trains MAE mod\u0002els on videos with multiple masked versions of a sample to\namortize the overhead of data loading and preparation.\nAnother efficiency improvement of data2vec 2.0 compared\nto data2vec is to share the feature encoder output across the\ndifferent masked versions of the training example to avoid\nredundant computation. This leads to significant speed\u0002ups for dense modalities such as speech where the feature\nencoder accounts for a large portion of the computation but\nless so for other modalities such as text.\n3.4. Inverse Block Masking\nThe MAE-style sample encoding improves efficiency but\nalso removes the ability to store information in the acti\u0002vations of masked time-steps which makes the training\ntask more challenging. Random masking is successful for\nMasked Autoencoders (He et al., 2021) but it may interfere\nwith the ability to build semantic representations since there\nis no structure in the masks that are created. Block mask\u0002ing (Bao et al., 2021) is more structured by masking entire\nblocks of time-steps or patches but there is no guarantee\nthat large contiguous portions of the training sample are\nunmasked. Our goal is to enable the student model to build\n3Baevski et al. (2022) found it important to build targets based\non the unmasked sample rather than another masked version.\nsemantically rich representations over local regions of the\nsample.\nWe therefore introduce inverse block masking: instead of\nchoosing which patches to mask, it chooses which patches\nto preserve in a block-wise fashion, where the size of a block\nis in terms of the number of patches or time-steps B. We\nfirst sample the starting point of each block to keep, and\nthen expand it symmetrically until the block is of width B,\nfor speech and text, or \u221a\nB for images.4 We sample the\nfollowing number of starting points without replacement\nand expand them to width\n\u221a\nB or quadratic blocks of width\nB, depending on the modality:\nL \u00d7\n(1 \u2212 R) + A\nB\nwhere L is the total number of time-steps/patches in a train\u0002ing sample, R is the mask ratio, a hyper parameter control\u0002ling the percentage of the sample that is masked and A is a\nhyper-parameter to adjust mask ratio (see below).\nWe allow blocks to overlap, which results in over-masking\nand some variance in the number of actually masked time\u0002steps for each sample. Since we only encode unmasked\ntime-steps, we use a simple strategy to assimilate the number\nof unmasked time-steps for all samples in a batch: for each\nsample, we randomly choose individual time-steps to mask\nor unmask until we reached the desired number of unmasked\ntime-steps L \u00d7 (1 \u2212 R).", "20 POINTS i should know on text in the style of in sahil bloom's tweets: Chapter I The Human Aspiration\nShe follows to the goal of those that are passing on beyond, she is the first in the eternal succession of the dawns that are coming, \u2014 Usha widens bringing out that which lives, awakening someone who was dead. . . . What is her scope when she harmonises with the dawns that shone out before and those that now must shine? She desires the ancient mornings and fulfils their light; projecting forwards her illumination she enters into communion with the rest that are to come.\n\nKutsa Angirasa \u2014 Rig Veda.[1]\n\nThreefold are those supreme births of this divine force that is in the world, they are true, they are desirable; he moves there wide-overt within the Infinite and shines pure, luminous and fulfilling.... That which is immortal in mortals and possessed of the truth, is a god and established inwardly as an energy working out in our divine powers. . . . Become high-uplifted, O Strength, pierce all veils, manifest in us the things of the Godhead.\n\nVamadeva \u2014 Rig Veda.[2]\n\nTHE EARLIEST preoccupation of man in his awakened thoughts and, as it seems, his inevitable and ultimate preoccupation, \u2014 for it survives the longest periods of scepticism and returns after every banishment, \u2014 is also the highest which his thought can envisage. It manifests itself in the divination of Godhead, the impulse towards perfection, the search after pure Truth and unmixed Bliss, the sense of a secret immortality. The ancient dawns of human knowledge have left us their witness to this constant aspiration; today we see a humanity satiated but not satisfied by victorious analysis of the externalities of Nature preparing to return to its primeval longings. The earliest formula of Wisdom promises to be its last, \u2014 God, Light, Freedom, Immortality.\n\nThese persistent ideals of the race are at once the contradiction of its normal experience and the affirmation of higher and deeper experiences which are abnormal to humanity and only to be attained, in their organised entirety, by a revolutionary individual effort or an evolutionary general progression. To know, possess and be the divine being in an animal and egoistic consciousness, to convert our twilit or obscure physical mentality into the plenary supramental illumination, to build peace and a self-existent bliss where there is only a stress of transitory satisfactions besieged by physical pain and emotional suffering, to establish an infinite freedom in a world which presents itself as a group of mechanical necessities, to discover and realise the immortal life in a body subjected to death and constant mutation, \u2014 this is offered to us as the manifestation of God in Matter and the goal of Nature in her terrestrial evolution. To the ordinary material intellect which takes its present organisation of consciousness for the limit of its possibilities, the direct contradiction of the unrealised ideals with the realised fact is a final argument against their validity. But if we take a more deliberate view of the world\u2019s workings, that direct opposition appears rather as part of Nature\u2019s profoundest method and the seal of her completest sanction.\n\nFor all problems of existence are essentially problems of harmony. They arise from the perception of an unsolved discord and the instinct of an undiscovered agreement or unity. To rest content with an unsolved discord is possible for the practical and more animal part of man, but impossible for his fully awakened mind, and usually even his practical parts only escape from the general necessity either by shutting out the problem or by accepting a rough, utilitarian and unillumined compromise. For essentially, all Nature seeks a harmony, life and matter in their own sphere as much as mind in the arrangement of its perceptions. The greater the apparent disorder of the materials offered or the apparent disparateness, even to irreconcilable opposition, of the elements that have to be utilised, the stronger is the spur, and it drives towards a more subtle and puissant order than can normally be the result of a less difficult endeavour. The accordance of active Life with a material of form in which the condition of activity itself seems to be inertia, is one problem of opposites that Nature has solved and seeks always to solve better with greater complexities; for its perfect solution would be the material immortality of a fully organised mind-supporting animal body. The accordance of conscious mind and conscious will with a form and a life in themselves not overtly self-conscious and capable at best of a mechanical or subconscious will is another problem of opposites in which she has produced astonishing results and aims always at higher marvels; for there her ultimate miracle would be an animal consciousness no longer seeking but possessed of Truth and Light, with the practical omnipotence which would result from the possession of a direct and perfected knowledge. Not only, then, is the upward impulse of man towards the accordance of yet higher opposites rational in itself, but it is the only logical completion of a rule and an effort that seem to be a fundamental method of Nature and the very sense of her universal strivings.\n\nWe speak of the evolution of Life in Matter, the evolution of Mind in Matter; but evolution is a word which merely states the phenomenon without explaining it. For there seems to be no reason why Life should evolve out of material elements or Mind out of living form, unless we accept the Vedantic solution that Life is already involved in Matter and Mind in Life because in essence Matter is a form of veiled Life, Life a form of veiled Consciousness. And then there seems to be little objection to a farther step in the series and the admission that mental consciousness may itself be only a form and a veil of higher states which are beyond Mind. In that case, the unconquerable impulse of man towards God, Light, Bliss, Freedom, Immortality presents itself in its right place in the chain as simply the imperative impulse by which Nature is seeking to evolve beyond Mind, and appears to be as natural, true and just as the impulse towards Life which she has planted in certain forms of Matter or the impulse towards Mind which she has planted in certain forms of Life. As there, so here, the impulse exists more or less obscurely in her different vessels with an ever-ascending series in the power of its will-to-be; as there, so here, it is gradually evolving and bound fully to evolve the necessary organs and faculties. As the impulse towards Mind ranges from the more sensitive reactions of Life in the metal and the plant up to its full organisation in man, so in man himself there is the same ascending series, the preparation, if nothing more, of a higher and divine life. The animal is a living laboratory in which Nature has, it is said, worked out man. Man himself may well be a thinking and living laboratory in whom and with whose conscious co-operation she wills to work out the superman, the god. Or shall we not say, rather, to manifest God? For if evolution is the progressive manifestation by Nature of that which slept or worked in her, involved, it is also the overt realisation of that which she secretly is. We cannot, then, bid her pause at a given stage of her evolution, nor have we the right to condemn with the religionist as perverse and presumptuous or with the rationalist as a disease or hallucination any intention she may evince or effort she may make to go beyond. If it be true that Spirit is involved in Matter and apparent Nature is secret God, then the manifestation of the divine in himself and the realisation of God within and without are the highest and most legitimate aim possible to man upon earth.\n\nThus the eternal paradox and eternal truth of a divine life in an animal body, an immortal aspiration or reality inhabiting a mortal tenement, a single and universal consciousness representing itself in limited minds and divided egos, a transcendent, indefinable, timeless and spaceless Being who alone renders time and space and cosmos possible, and in all these the higher truth realisable by the lower term, justify themselves to the deliberate reason as well as to the persistent instinct or intuition of mankind. Attempts are sometimes made to have done finally with questionings which have so often been declared insoluble by logical thought and to persuade men to limit their mental activities to the practical and immediate problems of their material existence in the universe; but such evasions are never permanent in their effect. Mankind returns from them with a more vehement impulse of inquiry or a more violent hunger for an immediate solution. By that hunger mysticism profits and new religions arise to replace the old that have been destroyed or stripped of significance by a scepticism which itself could not satisfy because, although its business was inquiry, it was unwilling sufficiently to inquire. The attempt to deny or stifle a truth because it is yet obscure in its outward workings and too often represented by obscurantist superstition or a crude faith, is itself a kind of obscurantism. The will to escape from a cosmic necessity because it is arduous, difficult to justify by immediate tangible results, slow in regulating its operations, must turn out eventually to have been no acceptance of the truth of Nature but a revolt against the secret, mightier will of the great Mother. It is better and more rational to accept what she will not allow us as a race to reject and lift it from the sphere of blind instinct, obscure intuition and random aspiration into the light of reason and an instructed and consciously self-guiding will. And if there is any higher light of illumined intuition or self-revealing truth which is now in man either obstructed and inoperative or works with intermittent glancings as if from behind a veil or with occasional displays as of the northern lights in our material skies, then there also we need not fear to aspire. For it is likely that such is the next higher state of consciousness of which Mind is only a form and veil, and through the splendours of that light may lie the path of our progressive self-enlargement into whatever highest state is humanity\u2019s ultimate resting-place.\n\nQuestion: 10380 chars / 1755 wordsThread: 190718 chars / 31202 words", "Rewrite 40 important points i should know in this as numbered short, simple,plain-termed sentences in the style of Sahil bloom's tweets :The calibration checking system of the present invention is used for a belt-type gravimetric feeder or conveyor assembly having an inlet section, a weigh span section and a discharge section. The system comprises a continuous conveyor belt that is disposed about a pair of pulleys, two or more support rollers positioned under an upper portion of the conveyor belt and a weigh roller disposed under the upper portion and equidistant from each of the support rollers. For the preferred embodiment, the system includes a pair of support rollers and a weigh roller, and the support rollers are level, in planar alignment and are in parallel alignment with one another. The weigh roller is disposed under the upper portion and equidistant from each of the support rollers. Preferably, the weigh roller and support rollers are in planar alignment with one another. The rollers comprising the weigh span section are preferably in parallel alignment with one another. In addition, belt supports outside of and on either side of the weigh span section preferably consist of rollers spaced one weigh span pitch away but alternate supports such as a slide pan or drive pulley may be substituted but they must be positioned such that the conveyor belt approach and retreat angles are equal and maintain symmetry across the weigh plane. The calibration checking system of the present invention is applied to a belt-type feeder or conveyor that is subject to the errors associated with chain testing. The system counters such errors with an appropriately designed test chain and corresponding weigh span section alignment procedure. In regard to the test chain, the pitch of the test chain is preferably integrally divisible into the pitch of the weigh span section of the feeder or conveyor. The weigh span section is preferably divided into two equal spans of the same pitch by the weigh roller, and the strands of the test chain are preferably uniformly distributed laterally across the weigh span section. In the event that the pitch of the chain is not integrally divisible or, to a limited extent, the two weigh span pitches are unequal, the calibration checking system provides for calculation of appropriate chain pitch and position. Also, a middle portion of the chain that rests across the weigh span section is uniform in weight along its length and known to an uncertainty between five to ten times better than the accuracy of the subject weigh scale. Also, this middle portion is adjusted so that it is nearly equivalent to the weight of bulk material that will be weighed when in normal operation. In regard to the feeder or conveyor, the geometry of the weigh span section, including one pitch to either side of the weigh span, is adjusted according to the calibration checking system and, thus, the present invention provides high accuracy by using the preferred test chain and assures insensitivity to belt tension by subjecting the weigh span section to belt tension perturbation analysis and adjustment. Referring to FIG. 1, in particular, there is provided a typical gravimetric feeder which is generally represented by reference numeral 10. Gravimetric feeder 10 is one particular type of belt conveyor that may use the calibration checking system of the present invention. Gravimetric feeder 10 represents a short centerline-to-centerline, inlet-to-discharge arrangement that is practical for accurate weighing and comprises a continuous or endless conveyor belt 12 in the form of a loop having an upper strand or portion 14 and a lower strand or portion 16 for continuously transporting bulk material 18 e. g. , crushed coal from a feed hopper 20 to a receiver e. g. , feed bin or furnace 22. Conveyor belt 12 is disposed about a pair of pulleys 24,26 that drive conveyor belt 12 in a clockwise direction 28, as viewed from the perspective of FIG. 1. Bulk material 18 is preferably evenly distributed onto conveyor belt 12 at one end of upper portion 14 and transported to the other end of upper portion 14 where it falls into receiver 22. As bulk material 18 is transported to the other end of upper portion 14 of conveyor 12, it passes over a weigh plane 32 contained within a weigh span. Weigh assembly 30 continuously weighs bulk material 18 as it passes over the weigh plane 32 of conveyor belt 12. The boundaries of weigh plane section 32 are defined by the position of two support rollers 34,36 disposed under upper portion 14 of conveyor belt 12. Accordingly, the distance or span separating support rollers 34,36 corresponds to the length of weigh plane section 32. Also, weigh assembly 30 includes a weigh roller 38 of conveyor belt 12. In accordance with the preferred embodiment of the present invention, support rollers 34,36 are disposed on opposite sides of weigh roller 38 in which the pitch between each support roller 34,36 and weigh roller 38 are in the same, or substantially the same, horizontal plane. Since weigh roller 38 is positioned exactly between support rollers 34,36, the distance from weigh roller 38 to either support roller 34,36 corresponds to the pitch of the weigh plane section or one-half the distance between the support rollers. Weigh assembly 30 includes a precision strain gauge load cell 40 having a static structure, i. e. , no moving parts, that is waterproof and barometrically insensitive. Load cell 40 provides a gross weight signal generally in the form of an analog voltage. The gravimetric feeder 10 of the preferred embodiment includes two essentially identical load cells, one disposed about each end of the weigh roller 38, in which both load cells are coupled to a microprocessor for monitoring the weight subjected to weigh roller 38 and control the position of weigh roller 38. FIGS. 2A and 2B are more general representations of the preferred embodiment of FIG. 1. In particular, FIGS. 2A and 2B focus on geometric concerns of the belt conveyor scale used by gravimetric feeder 10 in which span pitches P1, P2, P3 and P4 are all equal. Although not part of weigh plane 32, external support rollers 33,37 are preferably located one weigh span pitch Px P1 upstream and downstream, respectively, from weigh plane 32 and are adjusted vertically such that the approach and retreat angles of belt 14, which sags under load, are equal across weigh plane 32. Support rollers 34,36 and weigh roller 38 are parallel such that all angles are equal to one another and form an angle of 90 degrees to the direction of travel of upper portion 14 of conveyor belt 12. Referring to FIGS. 3A and 3B, the preferred calibration checking assembly comprises a distinct test chain 50 that is distributed longitudinally on upper portion 14 of conveyor belt 12, namely inlet section 52, weigh span section 54, and discharge section 56. As shown in FIG. 3B, test chain 50 may be composed of a plurality of chain strands 66 that are uniformly distributed across weigh plane 54 to accommodate the in-use weight capacity of weigh plane 54. Middle section 58 of test chain 50 extends across weigh span section 54 of the feeder. Pitch 60 of test chain 50 corresponds to the distance between the center of rotation of adjacent chain rollers, and weigh span pitch 62 of weigh span section 54 corresponds to one-half the distance between the boundaries of weigh span 54, i. e. the center of rotation of support rollers 34 and 36. Thus, test chain pitch 60 corresponds to the distance from weigh roller 38 to either support roller 34,36. In addition, for reasons of economics, the weight and pitch of the sections of test chain 50 that are positioned on inlet section 52 and discharge section 56 are not necessarily as precisely controlled as the middle section 58 of chain 50 that is positioned on weigh platform section 54. The weight accuracy of the chain elements on the weigh platform section 54 is necessarily held to an uncertainty between five and ten times better than the accuracy of the subject weigh scale. Because of the dependence between chain pitch 60 and weigh span pitch 62, any buildup of tolerances of any consecutive set of chain elements contained within one pitch 62 of the weigh span 54 is necessarily held to less than 0. 01. In addition, chain pitch 60 must be integrally divisible into weigh span pitch 62 of weigh span section 54. The highly accurate and reliable property of test chain 50 is also due to the precision used to measure middle section 58 of the chain. For the preferred embodiment, the weight of middle section 58 is known to an uncertainty of between five to ten times better than the accuracy of the subject weigh scale. In many cases, gravimetric feeders, such as feeder 10 shown in FIG. 1, deliver bulk material with an accuracy that exceeds 0. 25. Thus, for preferred test chain 50, the weight of middle section 58 of test chain 50 is known to a precision of no less than 0. 05. Accordingly, the weight of test chain 50 of the present invention is determined with much higher accuracy than conventional chains whose incremental weight is determined by dividing the chains gross weight by its length. Referring to FIGS. 7 and 5, the position of test chain 50 on upper portion 14 of conveyor belt 12 is also important due to the presence of a support pan and drive pulley used in place of outboard support rollers 33 and 37 shown in FIG. 3A. The test chain of the preferred embodiment is composed of up to eight strands with 25 rollers per strand. The number of strands permit the approximation of the coal load that the feeder 10 would normally see while the number of rollers in each strand satisfy the width, for example 36 inches, of weigh span section 54. Other feeder and conveyor designs may require more or less strands and rollers per strand. As described above, the weight of middle section 58 is known to a high degree of precision. In contrast, the weight of outer strands 68 on either side of middle section 58 are not controlled within such a tolerance for reasons of economics.Question: 10110 chars / 1743 wordsThread: 190718 chars / 31202 words", "summarize:\n5\u2002Discussion\nThis paper investigates the added value of aikido, a martial art, as an embodied \npedagogy in the intercultural communication classroom. Intercultural communi\u0002cation training aims to develop skills for dealing with challenges and achieving \nappropriate outcomes in intercultural interaction (Deardorff 2020). The findings \nof the benchmarking study show fundamental similarities between aikido inter\u0002action and intercultural interaction: focus, skills and embodied learning.\nThe road to a noble outcome in a challenging interaction requires focus, \nwhether it is an aikido or an intercultural interaction. Thirteen-san in (1) referred \nto this focus using the word mindful. Because the odds seem to be against at \nthe very beginning of the interactions between disparate communities, common \nground does not emerge haphazardly, and focus is the way towards a noble \noutcome. When aikido practitioners deliberately seek harmony and circulate to \nbuild common ground, they are in a focused aikido interaction. When interloc\u0002utors from different cultures consciously foster recipient design and co-create \ncommon ground (Kecsk\u00e9s 2014), they are in a focused interaction. The circula\u0002tion, typical of aikido interaction (Figure 6), is similar to Varela\u2019s definition of \ncirculation (Varela 1989). Circulation in aikido and circulation in intercultural \ncommunication refer to the capacity and sensitivity for tuning behavior to inter\u0002action partners. \nIntercultural interaction that does not end up in a communication break\u0002down has many similarities with aikido interaction that ends with a noble \noutcome. Taken together, aikido practitioners start an aikido interaction by \nassuming an attitude of calmness, centeredness, groundedness and alertness \nin the moment. This tranquility alters the physiological and the mental state \nand remains throughout the interaction. They behave effectively and efficiently \nwithout doing harm to others, self and the environment. They intend to achieve \na noble outcome, i.e. an outcome in which all people involved feel adequately \nsatisfied. They are open. They take an inviting attitude of observation, positivity \nand flexibility, focusing on the moment, not on prior assumptions, judgments or \nthoughts. At the same time, they are curious. They have the motivation to inter\u0002act, discover and learn. They see their attacker as a partner in an aikido interac\u0002tion. They move, then blend with their partner by fostering physical closeness, \nsensitivity and a willingness to build or co-create common ground: they unify. \nThey circulate physically to take the perspective of the other and to cooperate. \nThe result is a noble outcome.\nA model with seven core principles emerged from the study\u2019s analysis \n(Figure 7). It visualizes the course of an interaction and shows the relationship \nbetween the seven core principles. This interaction model stems from aikido, \n326 \u2003Greet Ang\u00e8le De Baets and Ellen Van Praet\nwhich can explain each principle with physical techniques and bodily move\u0002ments. The principles thus shift into physical, mental and interactional skills. \nThe seven principles in the model present two interwoven sets of skills that \nrevolve around harmony and common ground. Figure 7 shows persons A and \nB in an intercultural interaction based on the two skill sets. Person A is moti\u0002vated to seek harmony and adopts mental and physiological tranquility. Person A \nassures safety throughout the interaction by not sending signals of unsafety and \nnot taking any unsafety signals of person B personally. The safety effort creates a \nwelcoming, inviting and cooperative atmosphere for person B. To achieve a noble \noutcome that is appropriate and acceptable for both persons A and B, person A \nfocuses on co-creating common ground. Person A takes an open, inviting atti\u0002tude of observation, positivity and flexibility, focusing on the moment, not on \nprior assumptions, judgments or thoughts. The openness goes hand in hand with \ncuriosity, i.e. the motivation to interact, discover and learn. Person A\u2019s openness \nand curiosity result in active circulation: to take the perspective of the other and \nto cooperate. The more person A succeeds in circulating, the more persons A and \nB unify. They blend and co-create common ground. The interaction has a high \nprobability of achieving a noble outcome.\nAikido moves and exercises turn principles into skills for interaction. From \nparticipants\u2019 point of view in an intercultural training course, they discover \nthe physical activities as a multisensory message. The physical discovery gains \nmeaning by linking moves to the main principles for harmony (tranquility, safety \nand noble outcome) and common ground (openness, curiosity, circulation and \nFigure 7: Aikido interaction model of harmony and common ground.\nHarmony and common ground: Aikido principles for intercultural training\u2003 327\nunification). If an intercultural communication course applied the physical dis\u0002covery of an aikido interaction, it would alternate aikido movements with discus\u0002sion moments. In the discussions, the course participants give meaning to what \nthey discover in the aikido movements. Both the movement and the discussion \nparts of the training course serve as an example of experiential discovery. The \ntrainer guides the translation process from aikido interaction into intercultural \ninteraction.\nIntroducing the physical practice of aikido into an intercultural communi\u0002cation training course adds the kinesthetic stimulus to other obvious stimuli \nsuch as visual (slides, whiteboard and pictures) and auditory (explanations and \nstories) stimuli. Such a multisensory learning environment benefits \u201cencoding, \nstoring and retrieving perceptual information\u201d (Shams and Seitz 2008: 5). After \nall, learning is acquiring knowledge and skills, and having them readily available \nfrom memory to make sense of future problems and opportunities (Brown 2014). \nAlthough easy aikido movements will suffice to learn about applying aikido prin\u0002ciples in intercultural interaction, it will take some effort from the learners to do \naikido. The effort is an advantage: learning is deeper and more durable when \neffortful. Learning that is easy is like writing in sand, here today and gone tomor\u0002row (Brown 2014).\nAikido exercises teach interactional skills. In addition, some of the aikido \nexercises offer somatic (Hanna 1988) learning: techniques resulting in internal \nphysiological and mental changes. Practicing tranquility involves breathing, \nposture and movement exercises to become calm, centered, grounded and alert \nin the moment. Somatic exercises can create changes in the autonomic nervous \nsystem that influence behavior positively: resilience, creativity and empathy \n(Porges 2007; Porges 2021; Swinnen 2020; Swinnen 2021; Park and Thayer 2014). \nPositive behavior, empathy and creativity (Kecsk\u00e9s 2020) are critical factors \nin intercultural interaction and the development of intercultural competence \n(Deardorff 2020).\n6\u2002Conclusion\nIntercultural communication training that relies on conventional didactic expla\u0002nations results in knowledge about intercultural communication, not in com\u0002petence in intercultural interaction. Competence is the result of experiential \ndiscovery, of learning through experience. Intercultural communication training \ncan bring experiential discovery into its classroom by introducing the embod\u0002ied pedagogy of aikido. Firstly, aikido interaction and intercultural interaction \n328 \u2003Greet Ang\u00e8le De Baets and Ellen Van Praet\nshare the significance of focused interaction in which participants consciously \nseek harmony and co-create common ground. Secondly, aikido\u2019s embodied ped\u0002agogy provides the classroom with multisensory learning practice and somatic \ndiscovery.\nHarmony and common ground in challenging interaction, such as in aikido, \nresult from focused action. Aikido practitioners consciously seek harmony by \npracticing tranquility, creating safety and pursuing a noble outcome, i.e. an \noutcome in which all people involved feel adequately satisfied. They build or \nco-create common ground on an attitude of openness and curiosity on the one \nhand and by unifying and circulating with any person involved in the interaction \non the other hand. \nWe found similarities between seeking harmony and building common ground \nin aikido interaction and conscious recipient design and co-created common \nground in intercultural interaction. The way interlocutors in intercultural inter\u0002action consciously foster recipient design is similar to how aikido practitioners \nseek harmony in aikido interaction. Interlocutors in intercultural interaction do \nnot readily find common ground. Instead, they co-create it with the same focus \naikido practitioners have when building common ground in aikido interaction. In \nsum, focused interactions in intercultural and aikido situations achieve a noble \noutcome by seeking harmony and co-creating common ground.\nThe embodied pedagogy of aikido comprises multisensory learning and \nsomatic discovery. Pedagogical and educational research showed the benefits \nof multisensory learning, of combining visual, auditory and physical stimuli \nin the learning process. To train physiological and mental tranquility, aikido \ninvolves somatic exercises. Medical, biological and behavioral research showed \nthat the somatic practice of tranquility creates changes in the autonomic nervous \nsystem that influence behavior positively: resilience, creativity and empathy. \nThese advantages in behavior are favorable for seeking harmony and co-creating \ncommon ground in challenging interactions. Participants in an intercultural \ncommunication training course that relies on aikido discover conscious recip\u0002ient design by physical contact and movements. They train tranquility and feel \nhow it creates conditions for seeking harmony and co-creating common ground. \nThe trainer facilitates the embodied discovery process and the translation from \naikido interaction into intercultural interaction. We, therefore, conclude that \naikido has potential as an embodied pedagogy for intercultural communication \ntraining.", "I'm going to give you my entire code. Something isn't right. The mouse isn't moving to zoom around focus or zooming on the active node. It seems to only zoom ONCE. Also, the animation isn't stoppping when you hover a node. \n\nconst scene = new THREE.Scene();\n\n// Add a light source\nconst light = new THREE.PointLight(0xffffff, 1, 100);\nlight.position.set(0, 0, 20);\nscene.add(light);\n\nconst camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);\nconst renderer = new THREE.WebGLRenderer();\nrenderer.setSize(window.innerWidth, window.innerHeight);\ndocument.body.appendChild(renderer.domElement);\n\nlet nodeCount = 30;\nconst radius = 15;\nconst circleGeometry = new THREE.CircleGeometry(0.5, 32);\nconst lineMaterial = new THREE.LineBasicMaterial({ color: 0xffa500, opacity: 1, transparent: true });\n\nconst nodes = [];\nlet currentNodeIndex = 0;\nlet currentConnectionIndex = 1;\nlet connectionCount = 0;\nlet matchLikelihood = 0;\nfunction initializeNodes() {\n for (let i = 0; i < nodeCount; i++) {\n const circleMaterial = new THREE.MeshBasicMaterial({ color: Math.random() \\* 0xffffff });\n const circle = new THREE.Mesh(circleGeometry, circleMaterial);\n const angle = (i / nodeCount) \\* 2 \\* Math.PI;\n circle.position.set(radius \\* Math.cos(angle), radius \\* Math.sin(angle), 0);\n scene.add(circle);\n nodes.push(circle);\n }\n\n animate();\n}\nlet previousLines = [];\n// Add this function to reduce color saturation\nfunction reduceSaturation(material, amount) {\n const color = material.color;\n const hsl = color.getHSL({ h: 0, s: 0, l: 0 });\n hsl.s -= amount;\n color.setHSL(hsl.h, Math.max(hsl.s, 0), hsl.l);\n}\n\nfunction connectNodes(nodeA, nodeB) {\n if (previousLines.length > 0) {\n // Change the color of all other lines to white\n previousLines.forEach((line, index) => {\n line.material.color.set(0xffffff);\n\n // Reduce the opacity of all previous lines by 5% (except the current line)\n if (index !== previousLines.length - 1) {\n line.material.opacity = Math.max(line.material.opacity \\* 0.95, 0.5);\n }\n });\n\n // Remove the thickness from the previous line\n const lastLine = previousLines[previousLines.length - 1];\n lastLine.material.linewidth = 1;\n\n // Reduce the saturation of the previously completed person\n reduceSaturation(nodeA.material, 0.2);\n }\n\n const points = [nodeA.position, nodeB.position];\n const geometry = new THREE.BufferGeometry().setFromPoints(points);\n\n // Create a copy of the lineMaterial to avoid modifying the original\n const currentLineMaterial = lineMaterial.clone();\n currentLineMaterial.linewidth = 6; // Increase the linewidth of the current connection by 2px\n\n const line = new THREE.Line(geometry, currentLineMaterial);\n scene.add(line);\n\n previousLines.push(line);\n}\n\nconst speedSlider = document.getElementById('speed-slider');\nconst speedLabel = document.getElementById('speed-label');\nlet animationSpeed = 510 - parseInt(speedSlider.value);\n\nspeedSlider.addEventListener('input', (event) => {\n const value = event.target.value;\n speedLabel.textContent = 510 - value;\n animationSpeed = 510 - parseInt(value);\n});\n\nconst confirmButton = document.getElementById('confirm-button');\nconfirmButton.addEventListener('click', () => {\n resetAnimation();\n});\nconst resetButton = document.getElementById('reset-button');\nresetButton.addEventListener('click', () => {\n resetAnimation();\n});\n\nconst peopleInput = document.getElementById('people-input');\npeopleInput.addEventListener('change', () => {\n resetAnimation();\n});\n\nconst loader = new THREE.FontLoader();\nlet font;\n\nloader.load('https://threejs.org/examples/fonts/helvetiker\\_bold.typeface.json', (loadedFont) => {\n font = loadedFont;\n startVisualization();\n});\n\nfunction updateLikelihoodText(likelihood) {\n if (scene.getObjectByName('likelihoodText')) {\n scene.remove(scene.getObjectByName('likelihoodText'));\n }\n\n const text = `Likelihood: ${(likelihood \\* 100).toFixed(2)}% | Connections: ${connectionCount}`;\n const textGeometry = new THREE.TextGeometry(text, {\n font: font,\n size: 2,\n height: 0.1,\n });\n\n const textMaterial = new THREE.MeshBasicMaterial({ color: 0x90ee90 });\n const textMesh = new THREE.Mesh(textGeometry, textMaterial);\n textMesh.name = 'likelihoodText';\n\n textGeometry.computeBoundingBox();\n const textWidth = textGeometry.boundingBox.max.x - textGeometry.boundingBox.min.x;\n textMesh.position.set(-textWidth / 2, 0, 0);\n\n scene.add(textMesh);\n}\nlet lastUpdateTime = 0;\n// Add raycaster and mouse vector\nconst raycaster = new THREE.Raycaster();\nconst mouse = new THREE.Vector2();\n\n// Add an event listener for mousemove\nwindow.addEventListener('mousemove', onMouseMove, false);\n\n// Store the index of the currently hovered node\nlet hoveredNodeIndex = null;\n\nfunction onMouseMove(event) {\n // Calculate mouse position in normalized device coordinates (-1 to +1) for both components\n mouse.x = (event.clientX / window.innerWidth) \\* 2 - 1;\n mouse.y = -(event.clientY / window.innerHeight) \\* 2 + 1;\n\n // Update the picking ray with the camera and mouse position\n raycaster.setFromCamera(mouse, camera);\n\n // Calculate objects intersecting the picking ray\n const intersects = raycaster.intersectObjects(nodes);\n\n if (intersects.length > 0) {\n // Get the index of the intersected node\n const intersectedNode = intersects[0].object;\n hoveredNodeIndex = nodes.indexOf(intersectedNode);\n\n // Change the line color to orange for all connections of the hovered node\n for (let i = 0; i < previousLines.length; i++) {\n const line = previousLines[i];\n if (line.geometry.attributes.position.array.includes(intersectedNode.position.x)) {\n line.material.color.set(0xffa500);\n } else {\n line.material.color.set(0xffffff);\n }\n }\n } else {\n // Reset the hovered node index and line colors when no node is hovered\n hoveredNodeIndex = null;\n previousLines.forEach((line) => {\n line.material.color.set(0xffffff);\n });\n }\n}\n\n// Update the animate function to stop the animation when a node is hovered\nfunction animate(time) {\n \n}\n\nfunction animate(time) {\n\n if (currentNodeIndex < nodeCount - 1 && hoveredNodeIndex === null) {\n // ... (the rest of the animate function remains unchanged)\n \n if (time - lastUpdateTime >= animationSpeed) {\n // Reset the size of the active person's circle\n if (currentNodeIndex > 0) {\n nodes[currentNodeIndex - 1].scale.set(1, 1, 1);\n }\n\n if (currentConnectionIndex < nodeCount) {\n // Increase the size of the active person's circle\n nodes[currentNodeIndex].scale.set(5, 5, 1);\n\n connectNodes(nodes[currentNodeIndex], nodes[currentConnectionIndex]);\n connectionCount++;\n\n // Update the likelihood of matching birthdays\n matchLikelihood = 1 - (365 / 365) \\* ((365 - 1) / 365) \\*\\* connectionCount;\n updateLikelihoodText(matchLikelihood);\n\n currentConnectionIndex++;\n } else {\n currentNodeIndex++;\n currentConnectionIndex = currentNodeIndex + 1;\n }\n\n lastUpdateTime = time;\n } \n }\n requestAnimationFrame(animate);\n}\n\n\ninitializeNodes();\n\nfunction resetAnimation() {\n // Remove the light source from the scene\n scene.remove(light);\n\n scene.clear();\n nodes.length = 0;\n currentNodeIndex = 0;\n currentConnectionIndex = 1;\n connectionCount = 0;\n matchLikelihood = 0;\n nodeCount = parseInt(peopleInput.value);\n initializeNodes();\n animate();\n\n // Re-add the light source to the scene\n scene.add(light);\n}\n\nfunction startVisualization() {\n initializeNodes();\n animate();\n}\nconst simplex = new SimplexNoise();\nlet time = 0;\n\ncamera.position.set(0, 0, 25);\n\n// Add a target camera position\nlet targetCameraPosition = new THREE.Vector3(0, 0, 25);\nfunction onMouseMove(event) {\n // ... (the rest of the onMouseMove function remains unchanged)\n\n // Calculate the target camera position based on the mouse position\n const targetCameraOffset = new THREE.Vector3(mouse.x \\* 2.5, mouse.y \\* 2.5, 0);\n targetCameraPosition = new THREE.Vector3(0, 0, 25).add(targetCameraOffset);\n\n // Update the target camera position when a node is hovered\n if (hoveredNodeIndex !== null) {\n const nodeWorldPosition = nodes[hoveredNodeIndex].getWorldPosition(new THREE.Vector3());\n targetCameraPosition.x = nodeWorldPosition.x;\n targetCameraPosition.y = nodeWorldPosition.y;\n targetCameraPosition.z = 20; // Zoom in 20% when hovering a node\n } else {\n targetCameraPosition.z = 22.5; // Zoom in 10% based on mouse position\n }\n}\nfunction render() {\n requestAnimationFrame(render);\n\n // Update the camera position\n time += 0.005;\n const cameraRadius = 25;\n const offsetX = cameraRadius \\* 0.1 \\* simplex.noise2D(time, 0);\n const offsetZ = cameraRadius \\* 0.1 \\* simplex.noise2D(time, 1);\n\n camera.position.lerp(targetCameraPosition, 0.05); // Smoothly interpolate the camera position towards the target position\n camera.lookAt(scene.position);\n\n renderer.render(scene, camera);\n}\n\n\nrender();", "This is my code. Do you understand. All looks good?\n\nconst scene = new THREE.Scene();\n\n// Add a light source\nconst light = new THREE.PointLight(0xffffff, 1, 100);\nlight.position.set(0, 0, 20);\nscene.add(light);\n\nconst camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);\nconst renderer = new THREE.WebGLRenderer();\nrenderer.setSize(window.innerWidth, window.innerHeight);\ndocument.body.appendChild(renderer.domElement);\n\nlet nodeCount = 30;\nconst radius = 15;\nconst circleGeometry = new THREE.CircleGeometry(0.5, 32);\nconst lineMaterial = new THREE.LineBasicMaterial({ color: 0xffa500, opacity: 1, transparent: true });\n\nconst nodes = [];\nlet currentNodeIndex = 0;\nlet currentConnectionIndex = 1;\nlet connectionCount = 0;\nlet matchLikelihood = 0;\nfunction initializeNodes() {\n for (let i = 0; i < nodeCount; i++) {\n const circleMaterial = new THREE.MeshBasicMaterial({ color: Math.random() \\* 0xffffff });\n const circle = new THREE.Mesh(circleGeometry, circleMaterial);\n const angle = (i / nodeCount) \\* 2 \\* Math.PI;\n circle.position.set(radius \\* Math.cos(angle), radius \\* Math.sin(angle), 0);\n scene.add(circle);\n nodes.push(circle);\n }\n\n animate();\n}\nlet previousLines = [];\n// Add this function to reduce color saturation\nfunction reduceSaturation(material, amount) {\n const color = material.color;\n const hsl = color.getHSL({ h: 0, s: 0, l: 0 });\n hsl.s -= amount;\n color.setHSL(hsl.h, Math.max(hsl.s, 0), hsl.l);\n}\n\nfunction connectNodes(nodeA, nodeB) {\n if (previousLines.length > 0) {\n // Change the color of all other lines to white\n previousLines.forEach((line, index) => {\n line.material.color.set(0xffffff);\n\n // Reduce the opacity of all previous lines by 5% (except the current line)\n if (index !== previousLines.length - 1) {\n line.material.opacity = Math.max(line.material.opacity \\* 0.95, 0.5);\n }\n });\n\n // Remove the thickness from the previous line\n const lastLine = previousLines[previousLines.length - 1];\n lastLine.material.linewidth = 1;\n\n // Reduce the saturation of the previously completed person\n reduceSaturation(nodeA.material, 0.2);\n }\n\n const points = [nodeA.position, nodeB.position];\n const geometry = new THREE.BufferGeometry().setFromPoints(points);\n\n // Create a copy of the lineMaterial to avoid modifying the original\n const currentLineMaterial = lineMaterial.clone();\n currentLineMaterial.linewidth = 6; // Increase the linewidth of the current connection by 2px\n\n const line = new THREE.Line(geometry, currentLineMaterial);\n scene.add(line);\n\n previousLines.push(line);\n}\n\nconst speedSlider = document.getElementById('speed-slider');\nconst speedLabel = document.getElementById('speed-label');\nlet animationSpeed = 510 - parseInt(speedSlider.value);\n\nspeedSlider.addEventListener('input', (event) => {\n const value = event.target.value;\n speedLabel.textContent = 510 - value;\n animationSpeed = 510 - parseInt(value);\n});\n\nconst confirmButton = document.getElementById('confirm-button');\nconfirmButton.addEventListener('click', () => {\n resetAnimation();\n});\nconst resetButton = document.getElementById('reset-button');\nresetButton.addEventListener('click', () => {\n resetAnimation();\n});\n\nconst peopleInput = document.getElementById('people-input');\npeopleInput.addEventListener('change', () => {\n resetAnimation();\n});\n\nconst loader = new THREE.FontLoader();\nlet font;\n\nloader.load('https://threejs.org/examples/fonts/helvetiker\\_regular.typeface.json', (loadedFont) => {\n font = loadedFont;\n startVisualization();\n});\n\n\nfunction updateLikelihoodText(likelihood) {\n if (scene.getObjectByName('likelihoodText')) {\n scene.remove(scene.getObjectByName('likelihoodText'));\n }\n\n const text = `Likelihood: ${(likelihood \\* 100).toFixed(2)}% | Connections: ${connectionCount}`;\n const textGeometry = new THREE.TextGeometry(text, {\n font: font,\n size: 2,\n height: 0.1,\n });\n\n const textMaterial = new THREE.MeshBasicMaterial({ color: 0x90ee90 });\n const textMesh = new THREE.Mesh(textGeometry, textMaterial);\n textMesh.name = 'likelihoodText';\n\n textGeometry.computeBoundingBox();\n const textWidth = textGeometry.boundingBox.max.x - textGeometry.boundingBox.min.x;\n textMesh.position.set(-textWidth / 2, 0, 0);\n\n scene.add(textMesh);\n}\nlet lastUpdateTime = 0;\n// Add raycaster and mouse vector\nconst raycaster = new THREE.Raycaster();\nconst mouse = new THREE.Vector2();\n\n// Add an event listener for mousemove\nwindow.addEventListener('mousemove', onMouseMove, false);\n\n// Store the index of the currently hovered node\nlet hoveredNodeIndex = null;\n\nfunction onMouseMove(event) {\n // Calculate mouse position in normalized device coordinates (-1 to +1) for both components\n mouse.x = (event.clientX / window.innerWidth) \\* 2 - 1;\n mouse.y = -(event.clientY / window.innerHeight) \\* 2 + 1;\n\n // Update the picking ray with the camera and mouse position\n raycaster.setFromCamera(mouse, camera);\n\n // Calculate objects intersecting the picking ray\n const intersects = raycaster.intersectObjects(nodes);\n\n if (intersects.length > 0) {\n // Get the index of the intersected node\n const intersectedNode = intersects[0].object;\n hoveredNodeIndex = nodes.indexOf(intersectedNode);\n\n // Change the line color to orange for all connections of the hovered node\n for (let i = 0; i < previousLines.length; i++) {\n const line = previousLines[i];\n if (line.geometry.attributes.position.array.includes(intersectedNode.position.x)) {\n line.material.color.set(0xffa500);\n } else {\n line.material.color.set(0xffffff);\n }\n }\n } else {\n // Reset the hovered node index and line colors when no node is hovered\n hoveredNodeIndex = null;\n previousLines.forEach((line) => {\n line.material.color.set(0xffffff);\n });\n }\n\n // Calculate the target camera position based on the mouse position\n const targetCameraOffset = new THREE.Vector3(mouse.x \\* 2.5, mouse.y \\* 2.5, 0);\n targetCameraPosition = new THREE.Vector3(0, 0, 25).add(targetCameraOffset);\n\n // Update the target camera position when a node is hovered\n if (hoveredNodeIndex !== null) {\n const nodeWorldPosition = nodes[hoveredNodeIndex].getWorldPosition(new THREE.Vector3());\n targetCameraPosition.x = nodeWorldPosition.x;\n targetCameraPosition.y = nodeWorldPosition.y;\n targetCameraPosition.z = 20; // Zoom in 20% when hovering a node\n } else {\n targetCameraPosition.z = 22.5; // Zoom in 10% based on mouse position\n }\n}\n\nfunction animate(time) {\n\n if (currentNodeIndex < nodeCount - 1 && hoveredNodeIndex === null) {\n // ... (the rest of the animate function remains unchanged)\n \n if (time - lastUpdateTime >= animationSpeed) {\n // Reset the size of the active person's circle\n if (currentNodeIndex > 0) {\n nodes[currentNodeIndex - 1].scale.set(1, 1, 1);\n }\n\n if (currentConnectionIndex < nodeCount) {\n // Increase the size of the active person's circle\n nodes[currentNodeIndex].scale.set(5, 5, 1);\n\n connectNodes(nodes[currentNodeIndex], nodes[currentConnectionIndex]);\n connectionCount++;\n\n // Update the likelihood of matching birthdays\n matchLikelihood = 1 - (365 / 365) \\* ((365 - 1) / 365) \\*\\* connectionCount;\n updateLikelihoodText(matchLikelihood);\n\n currentConnectionIndex++;\n } else {\n currentNodeIndex++;\n currentConnectionIndex = currentNodeIndex + 1;\n }\n\n lastUpdateTime = time;\n } \n \n requestAnimationFrame(animate);\n \n \n \n }\n \n}\n\n\ninitializeNodes();\n\nfunction resetAnimation() {\n // Remove the light source from the scene\n scene.remove(light);\n\n scene.clear();\n nodes.length = 0;\n currentNodeIndex = 0;\n currentConnectionIndex = 1;\n connectionCount = 0;\n matchLikelihood = 0;\n nodeCount = parseInt(peopleInput.value);\n initializeNodes();\n animate();\n\n // Re-add the light source to the scene\n scene.add(light);\n}\n\nfunction startVisualization() {\n initializeNodes();\n animate();\n}\nconst simplex = new SimplexNoise();\nlet time = 0;\n\ncamera.position.set(0, 0, 25);\n\n// Add a target camera position\nlet targetCameraPosition = new THREE.Vector3(0, 0, 25);\n\n// Add a new function for updating the camera position\nfunction updateCamera() {\n if (hoveredNodeIndex !== null) {\n camera.position.lerp(nodes[hoveredNodeIndex].position, 0.05);\n camera.position.z = 20;\n } else {\n const targetCameraOffset = new THREE.Vector3(mouse.x \\* 2.5, mouse.y \\* 2.5, 0);\n targetCameraPosition = new THREE.Vector3(0, 0, 25).add(targetCameraOffset);\n camera.position.lerp(targetCameraPosition, 0.05);\n }\n camera.lookAt(scene.position);\n}\n\nfunction render() {\n requestAnimationFrame(render);\n\n // Update the camera position\n time += 0.005;\n const cameraRadius = 25;\n const offsetX = cameraRadius \\* 0.1 \\* simplex.noise2D(time, 0);\n const offsetZ = cameraRadius \\* 0.1 \\* simplex.noise2D(time, 1);\n\n // Update camera position based on the hovered node and mouse position\n updateCamera();\n\n renderer.render(scene, camera);\n}\n\nrender();", "```c\n#include \n#include \n#include \"raylib.h\"\n#include \"string.h\"\n\n#define BOARD\\_SIZE 3\n#define CELL\\_SIZE 100\n#define SCREEN\\_WIDTH (CELL\\_SIZE \\* BOARD\\_SIZE)\n#define SCREEN\\_HEIGHT (CELL\\_SIZE \\* BOARD\\_SIZE)\n\ntypedef enum\n{\n EMPTY,\n PLAYER1,\n PLAYER2\n} Cell;\n\nCell board[BOARD\\_SIZE][BOARD\\_SIZE];\n\nint GetWinningDirection(int player);\nbool CheckDraw();\nvoid DrawBoard(bool gameOver, int winner);\nvoid DrawWinMessage(int player);\nvoid ResetBoard();\n\nVector2 GetMouseCell();\nVector2 AIGetMove();\n\nint main()\n{\n InitWindow(SCREEN\\_WIDTH, SCREEN\\_HEIGHT, \"Tic Tac Toe\");\n SetTargetFPS(60);\n ResetBoard();\n\n int currentPlayer = PLAYER1;\n bool gameOver = false;\n int winner = 0;\n\n while (!WindowShouldClose())\n {\n if (!gameOver)\n {\n Vector2 move;\n if (currentPlayer == PLAYER1 && IsMouseButtonPressed(MOUSE\\_LEFT\\_BUTTON))\n {\n move = GetMouseCell();\n if (board[(int)move.y][(int)move.x] == EMPTY)\n {\n board[(int)move.y][(int)move.x] = currentPlayer;\n currentPlayer = PLAYER2;\n }\n }\n else if (currentPlayer == PLAYER2)\n {\n move = AIGetMove();\n if (board[(int)move.y][(int)move.x] == EMPTY)\n {\n board[(int)move.y][(int)move.x] = currentPlayer;\n currentPlayer = PLAYER1;\n }\n }\n\n if (board[(int)move.y][(int)move.x] == EMPTY)\n {\n board[(int)move.y][(int)move.x] = currentPlayer;\n int winningDirection = GetWinningDirection(currentPlayer);\n if (winningDirection)\n {\n gameOver = true;\n winner = currentPlayer;\n }\n else if (CheckDraw())\n {\n gameOver = true;\n }\n else\n {\n currentPlayer = (currentPlayer == PLAYER1) ? PLAYER2 : PLAYER1;\n }\n }\n }\n\n if (gameOver && IsKeyPressed(KEY\\_R))\n {\n ResetBoard();\n currentPlayer = PLAYER1;\n gameOver = false;\n winner = 0;\n }\n\n BeginDrawing();\n ClearBackground(RAYWHITE);\n DrawBoard(gameOver, winner);\n if (gameOver)\n {\n DrawWinMessage(winner);\n }\n EndDrawing();\n }\n\n CloseWindow();\n return 0;\n}\n\nVector2 GetMouseCell() {\n int x = GetMouseX() / CELL\\_SIZE;\n int y = GetMouseY() / CELL\\_SIZE;\n return (Vector2){x, y};\n}\n\nVector2 AIGetMove()\n{\n Vector2 bestMove = {-1, -1};\n Cell tempBoard[BOARD\\_SIZE][BOARD\\_SIZE];\n\n // Copy the current board state\n memcpy(tempBoard, board, BOARD\\_SIZE \\* BOARD\\_SIZE \\* sizeof(Cell));\n\n // Check for a winning move\n for (int i = 0; i < BOARD\\_SIZE; i++)\n {\n for (int j = 0; j < BOARD\\_SIZE; j++)\n {\n if (tempBoard[i][j] == EMPTY)\n {\n tempBoard[i][j] = PLAYER2;\n if (GetWinningDirection(PLAYER2))\n {\n return (Vector2){j, i};\n }\n tempBoard[i][j] = EMPTY;\n }\n }\n }\n\n // Check for the opponent's winning move and block it\n for (int i = 0; i < BOARD\\_SIZE; i++)\n {\n for (int j = 0; j < BOARD\\_SIZE; j++)\n {\n if (tempBoard[i][j] == EMPTY)\n {\n tempBoard[i][j] = PLAYER1;\n if (GetWinningDirection(PLAYER1))\n {\n return (Vector2){j, i};\n }\n tempBoard[i][j] = EMPTY;\n }\n }\n }\n\n // If neither of the above, make a random move\n Vector2 moves[BOARD\\_SIZE \\* BOARD\\_SIZE];\n int moveCount = 0;\n\n for (int i = 0; i < BOARD\\_SIZE; i++)\n {\n for (int j = 0; j < BOARD\\_SIZE; j++)\n {\n if (board[i][j] == EMPTY)\n {\n moves[moveCount++] = (Vector2){j, i};\n }\n }\n }\n\n if (moveCount > 0)\n {\n bestMove = moves[GetRandomValue(0, moveCount - 1)];\n }\n\n return bestMove;\n}\n\n/\\*\n \\* GetWinningDirection returns an integer representing the winning direction for a given player.\n \\* Return values:\n \\* 0 - No win\n \\* 1 to BOARD\\_SIZE - Horizontal win in the corresponding row\n \\* BOARD\\_SIZE + 1 to 2 \\* BOARD\\_SIZE - Vertical win in the corresponding column\n \\* 2 \\* BOARD\\_SIZE + 1 - Diagonal win from top-left to bottom-right\n \\* 2 \\* BOARD\\_SIZE + 2 - Diagonal win from top-right to bottom-left\n \\*/\nint GetWinningDirection(int player)\n{\n for (int i = 0; i < BOARD\\_SIZE; i++)\n {\n if ((board[i][0] == player && board[i][1] == player && board[i][2] == player))\n { // Check rows\n return i + 1;\n }\n if ((board[0][i] == player && board[1][i] == player && board[2][i] == player))\n { // Check columns\n return i + BOARD\\_SIZE + 1;\n }\n }\n\n // Check diagonals\n if ((board[0][0] == player && board[1][1] == player && board[2][2] == player))\n {\n return 2 \\* BOARD\\_SIZE + 1;\n }\n if ((board[0][2] == player && board[1][1] == player && board[2][0] == player))\n {\n return 2 \\* BOARD\\_SIZE + 2;\n }\n\n return 0;\n}\n\nbool CheckDraw()\n{\n for (int i = 0; i < BOARD\\_SIZE; i++)\n {\n for (int j = 0; j < BOARD\\_SIZE; j++)\n {\n if (board[i][j] == EMPTY)\n {\n return false;\n }\n }\n }\n return true;\n}\n\nvoid DrawBoard(bool gameOver, int winner)\n{\n for (int i = 1; i < BOARD\\_SIZE; i++)\n {\n DrawLine(i \\* CELL\\_SIZE, 0, i \\* CELL\\_SIZE, SCREEN\\_HEIGHT, BLACK);\n DrawLine(0, i \\* CELL\\_SIZE, SCREEN\\_WIDTH, i \\* CELL\\_SIZE, BLACK);\n }\n\n for (int i = 0; i < BOARD\\_SIZE; i++)\n {\n for (int j = 0; j < BOARD\\_SIZE; j++)\n {\n int x = j \\* CELL\\_SIZE;\n int y = i \\* CELL\\_SIZE;\n\n if (board[i][j] == PLAYER1)\n {\n DrawText(\"X\", x + CELL\\_SIZE / 2 - 10, y + CELL\\_SIZE / 2 - 10, 20, BLACK);\n }\n else if (board[i][j] == PLAYER2)\n {\n DrawText(\"O\", x + CELL\\_SIZE / 2 - 10, y + CELL\\_SIZE / 2 - 10, 20, BLACK);\n }\n }\n }\n\n if (gameOver && winner)\n {\n int dir = GetWinningDirection(winner);\n if (dir >= 1 && dir <= BOARD\\_SIZE)\n { // Horizontal line\n int y = (dir - 1) \\* CELL\\_SIZE + CELL\\_SIZE / 2;\n DrawLine(0, y, SCREEN\\_WIDTH, y, RED);\n }\n else if (dir >= BOARD\\_SIZE + 1 && dir <= 2 \\* BOARD\\_SIZE)\n { // Vertical line\n int x = (dir - BOARD\\_SIZE - 1) \\* CELL\\_SIZE + CELL\\_SIZE / 2;\n DrawLine(x, 0, x, SCREEN\\_HEIGHT, RED);\n }\n else if (dir == 2 \\* BOARD\\_SIZE + 1)\n { // Diagonal from top-left to bottom-right\n DrawLine(0, 0, SCREEN\\_WIDTH, SCREEN\\_HEIGHT, RED);\n }\n else if (dir == 2 \\* BOARD\\_SIZE + 2)\n { // Diagonal from top-right to bottom-left\n DrawLine(SCREEN\\_WIDTH, 0, 0, SCREEN\\_HEIGHT, RED);\n }\n }\n}\n\nvoid DrawWinMessage(int winner)\n{\n const char \\*messageLine1;\n const char \\*messageLine2 = \"Press R to restart.\";\n\n if (winner == PLAYER1)\n {\n messageLine1 = \"Player 1 (X) wins!\";\n }\n else if (winner == PLAYER2)\n {\n messageLine1 = \"Player 2 (O) wins!\";\n }\n else\n {\n messageLine1 = \"It's a draw!\";\n }\n\n int textWidth1 = MeasureText(messageLine1, 20);\n int textWidth2 = MeasureText(messageLine2, 20);\n int textHeight = 20;\n\n // Draw a semi-transparent background rectangle to improve readability\n DrawRectangle((SCREEN\\_WIDTH - textWidth1) / 2 - 20, SCREEN\\_HEIGHT / 2 - 50, textWidth1 + 40, textHeight \\* 2 + 40, (Color){0, 0, 0, 128});\n\n DrawText(messageLine1, (SCREEN\\_WIDTH - textWidth1) / 2, SCREEN\\_HEIGHT / 2 - 30, 20, RAYWHITE);\n DrawText(messageLine2, (SCREEN\\_WIDTH - textWidth2) / 2, SCREEN\\_HEIGHT / 2, 20, RAYWHITE);\n}\n\nvoid ResetBoard()\n{\n for (int i = 0; i < BOARD\\_SIZE; i++)\n {\n for (int j = 0; j < BOARD\\_SIZE; j++)\n {\n board[i][j] = EMPTY;\n }\n }\n}\n```", "on playing further, it feels like the ai is choosing completely randomly no matter what. here is my current code: \n```c\n#include \n#include \n#include \"raylib.h\"\n#include \"string.h\"\n\n#define BOARD\\_SIZE 3\n#define CELL\\_SIZE 100\n#define SCREEN\\_WIDTH (CELL\\_SIZE \\* BOARD\\_SIZE)\n#define SCREEN\\_HEIGHT (CELL\\_SIZE \\* BOARD\\_SIZE)\n\ntypedef enum\n{\n EMPTY,\n PLAYER1,\n PLAYER2\n} Cell;\n\nCell board[BOARD\\_SIZE][BOARD\\_SIZE];\n\nint GetWinningDirection(int player);\nbool CheckDraw();\nvoid DrawBoard(bool gameOver, int winner);\nvoid DrawWinMessage(int player);\nvoid ResetBoard();\n\nVector2 GetMouseCell();\nVector2 AIGetMove();\n\nint main()\n{\n InitWindow(SCREEN\\_WIDTH, SCREEN\\_HEIGHT, \"Tic Tac Toe\");\n SetTargetFPS(60);\n ResetBoard();\n\n int currentPlayer = PLAYER1;\n bool gameOver = false;\n int winner = 0;\n\n while (!WindowShouldClose())\n {\n if (!gameOver)\n {\n Vector2 move = {-1, -1};\n if (currentPlayer == PLAYER1 && IsMouseButtonPressed(MOUSE\\_LEFT\\_BUTTON))\n {\n move = GetMouseCell();\n }\n else if (currentPlayer == PLAYER2)\n {\n move = AIGetMove();\n }\n\n if (move.x != -1 && move.y != -1 && board[(int)move.y][(int)move.x] == EMPTY)\n {\n board[(int)move.y][(int)move.x] = currentPlayer;\n int winningDirection = GetWinningDirection(currentPlayer);\n if (winningDirection)\n {\n gameOver = true;\n winner = currentPlayer;\n }\n else if (CheckDraw())\n {\n gameOver = true;\n }\n else\n {\n currentPlayer = (currentPlayer == PLAYER1) ? PLAYER2 : PLAYER1;\n }\n }\n }\n\n if (gameOver && IsKeyPressed(KEY\\_R))\n {\n ResetBoard();\n currentPlayer = PLAYER1;\n gameOver = false;\n winner = 0;\n }\n\n BeginDrawing();\n ClearBackground(RAYWHITE);\n DrawBoard(gameOver, winner);\n if (gameOver)\n {\n DrawWinMessage(winner);\n }\n EndDrawing();\n }\n\n CloseWindow();\n return 0;\n}\n\nVector2 GetMouseCell() {\n int x = GetMouseX() / CELL\\_SIZE;\n int y = GetMouseY() / CELL\\_SIZE;\n return (Vector2){x, y};\n}\n\nVector2 AIGetMove()\n{\n Vector2 bestMove = {-1, -1};\n Cell tempBoard[BOARD\\_SIZE][BOARD\\_SIZE];\n\n // Copy the current board state\n memcpy(tempBoard, board, BOARD\\_SIZE \\* BOARD\\_SIZE \\* sizeof(Cell));\n\n // Check for a winning move\n for (int i = 0; i < BOARD\\_SIZE; i++)\n {\n for (int j = 0; j < BOARD\\_SIZE; j++)\n {\n if (tempBoard[i][j] == EMPTY)\n {\n tempBoard[i][j] = PLAYER2;\n if (GetWinningDirection(PLAYER2))\n {\n return (Vector2){j, i};\n }\n tempBoard[i][j] = EMPTY;\n }\n }\n }\n\n // Check for the opponent's winning move and block it\n for (int i = 0; i < BOARD\\_SIZE; i++)\n {\n for (int j = 0; j < BOARD\\_SIZE; j++)\n {\n if (tempBoard[i][j] == EMPTY)\n {\n tempBoard[i][j] = PLAYER1;\n if (GetWinningDirection(PLAYER1))\n {\n return (Vector2){j, i};\n }\n tempBoard[i][j] = EMPTY;\n }\n }\n }\n\n // If neither of the above, make a random move\n Vector2 moves[BOARD\\_SIZE \\* BOARD\\_SIZE];\n int moveCount = 0;\n\n for (int i = 0; i < BOARD\\_SIZE; i++)\n {\n for (int j = 0; j < BOARD\\_SIZE; j++)\n {\n if (board[i][j] == EMPTY)\n {\n moves[moveCount++] = (Vector2){j, i};\n }\n }\n }\n\n if (moveCount > 0)\n {\n bestMove = moves[GetRandomValue(0, moveCount - 1)];\n }\n\n return bestMove;\n}\n\n/\\*\n \\* GetWinningDirection returns an integer representing the winning direction for a given player.\n \\* Return values:\n \\* 0 - No win\n \\* 1 to BOARD\\_SIZE - Horizontal win in the corresponding row\n \\* BOARD\\_SIZE + 1 to 2 \\* BOARD\\_SIZE - Vertical win in the corresponding column\n \\* 2 \\* BOARD\\_SIZE + 1 - Diagonal win from top-left to bottom-right\n \\* 2 \\* BOARD\\_SIZE + 2 - Diagonal win from top-right to bottom-left\n \\*/\nint GetWinningDirection(int player)\n{\n for (int i = 0; i < BOARD\\_SIZE; i++)\n {\n if ((board[i][0] == player && board[i][1] == player && board[i][2] == player))\n { // Check rows\n return i + 1;\n }\n if ((board[0][i] == player && board[1][i] == player && board[2][i] == player))\n { // Check columns\n return i + BOARD\\_SIZE + 1;\n }\n }\n\n // Check diagonals\n if ((board[0][0] == player && board[1][1] == player && board[2][2] == player))\n {\n return 2 \\* BOARD\\_SIZE + 1;\n }\n if ((board[0][2] == player && board[1][1] == player && board[2][0] == player))\n {\n return 2 \\* BOARD\\_SIZE + 2;\n }\n\n return 0;\n}\n\nbool CheckDraw()\n{\n for (int i = 0; i < BOARD\\_SIZE; i++)\n {\n for (int j = 0; j < BOARD\\_SIZE; j++)\n {\n if (board[i][j] == EMPTY)\n {\n return false;\n }\n }\n }\n return true;\n}\n\nvoid DrawBoard(bool gameOver, int winner)\n{\n for (int i = 1; i < BOARD\\_SIZE; i++)\n {\n DrawLine(i \\* CELL\\_SIZE, 0, i \\* CELL\\_SIZE, SCREEN\\_HEIGHT, BLACK);\n DrawLine(0, i \\* CELL\\_SIZE, SCREEN\\_WIDTH, i \\* CELL\\_SIZE, BLACK);\n }\n\n for (int i = 0; i < BOARD\\_SIZE; i++)\n {\n for (int j = 0; j < BOARD\\_SIZE; j++)\n {\n int x = j \\* CELL\\_SIZE;\n int y = i \\* CELL\\_SIZE;\n\n if (board[i][j] == PLAYER1)\n {\n DrawText(\"X\", x + CELL\\_SIZE / 2 - 10, y + CELL\\_SIZE / 2 - 10, 20, BLACK);\n }\n else if (board[i][j] == PLAYER2)\n {\n DrawText(\"O\", x + CELL\\_SIZE / 2 - 10, y + CELL\\_SIZE / 2 - 10, 20, BLACK);\n }\n }\n }\n\n if (gameOver && winner)\n {\n int dir = GetWinningDirection(winner);\n if (dir >= 1 && dir <= BOARD\\_SIZE)\n { // Horizontal line\n int y = (dir - 1) \\* CELL\\_SIZE + CELL\\_SIZE / 2;\n DrawLine(0, y, SCREEN\\_WIDTH, y, RED);\n }\n else if (dir >= BOARD\\_SIZE + 1 && dir <= 2 \\* BOARD\\_SIZE)\n { // Vertical line\n int x = (dir - BOARD\\_SIZE - 1) \\* CELL\\_SIZE + CELL\\_SIZE / 2;\n DrawLine(x, 0, x, SCREEN\\_HEIGHT, RED);\n }\n else if (dir == 2 \\* BOARD\\_SIZE + 1)\n { // Diagonal from top-left to bottom-right\n DrawLine(0, 0, SCREEN\\_WIDTH, SCREEN\\_HEIGHT, RED);\n }\n else if (dir == 2 \\* BOARD\\_SIZE + 2)\n { // Diagonal from top-right to bottom-left\n DrawLine(SCREEN\\_WIDTH, 0, 0, SCREEN\\_HEIGHT, RED);\n }\n }\n}\n\nvoid DrawWinMessage(int winner)\n{\n const char \\*messageLine1;\n const char \\*messageLine2 = \"Press R to restart.\";\n\n if (winner == PLAYER1)\n {\n messageLine1 = \"Player 1 (X) wins!\";\n }\n else if (winner == PLAYER2)\n {\n messageLine1 = \"Player 2 (O) wins!\";\n }\n else\n {\n messageLine1 = \"It's a draw!\";\n }\n\n int textWidth1 = MeasureText(messageLine1, 20);\n int textWidth2 = MeasureText(messageLine2, 20);\n int textHeight = 20;\n\n // Draw a semi-transparent background rectangle to improve readability\n DrawRectangle((SCREEN\\_WIDTH - textWidth1) / 2 - 20, SCREEN\\_HEIGHT / 2 - 50, textWidth1 + 40, textHeight \\* 2 + 40, (Color){0, 0, 0, 128});\n\n DrawText(messageLine1, (SCREEN\\_WIDTH - textWidth1) / 2, SCREEN\\_HEIGHT / 2 - 30, 20, RAYWHITE);\n DrawText(messageLine2, (SCREEN\\_WIDTH - textWidth2) / 2, SCREEN\\_HEIGHT / 2, 20, RAYWHITE);\n}\n\nvoid ResetBoard()\n{\n for (int i = 0; i < BOARD\\_SIZE; i++)\n {\n for (int j = 0; j < BOARD\\_SIZE; j++)\n {\n board[i][j] = EMPTY;\n }\n }\n}\n```", "the ai finally works! just to be safe, are there any memory leaks at the moment? current code for ref:\n```c\n#include \n#include \n#include \"raylib.h\"\n#include \"string.h\"\n\n#define BOARD\\_SIZE 3\n#define CELL\\_SIZE 100\n#define SCREEN\\_WIDTH (CELL\\_SIZE \\* BOARD\\_SIZE)\n#define SCREEN\\_HEIGHT (CELL\\_SIZE \\* BOARD\\_SIZE)\n\ntypedef enum\n{\n EMPTY,\n PLAYER1,\n PLAYER2\n} Cell;\n\nCell board[BOARD\\_SIZE][BOARD\\_SIZE];\n\nint GetWinningDirection(int player, Cell currentBoard[BOARD\\_SIZE][BOARD\\_SIZE]);\nbool CheckDraw();\nvoid DrawBoard(bool gameOver, int winner);\nvoid DrawWinMessage(int player);\nvoid ResetBoard();\n\nVector2 GetMouseCell();\nVector2 AIGetMove();\n\nint main()\n{\n InitWindow(SCREEN\\_WIDTH, SCREEN\\_HEIGHT, \"Tic Tac Toe\");\n SetTargetFPS(60);\n ResetBoard();\n\n int currentPlayer = PLAYER1;\n bool gameOver = false;\n int winner = 0;\n\n while (!WindowShouldClose())\n {\n if (!gameOver)\n {\n Vector2 move = {-1, -1};\n if (currentPlayer == PLAYER1 && IsMouseButtonPressed(MOUSE\\_LEFT\\_BUTTON))\n {\n move = GetMouseCell();\n }\n else if (currentPlayer == PLAYER2)\n {\n move = AIGetMove();\n }\n\n if (move.x != -1 && move.y != -1 && board[(int)move.y][(int)move.x] == EMPTY)\n {\n board[(int)move.y][(int)move.x] = currentPlayer;\n int winningDirection = GetWinningDirection(currentPlayer, board);\n if (winningDirection)\n {\n gameOver = true;\n winner = currentPlayer;\n }\n else if (CheckDraw())\n {\n gameOver = true;\n }\n else\n {\n currentPlayer = (currentPlayer == PLAYER1) ? PLAYER2 : PLAYER1;\n }\n }\n }\n\n if (gameOver && IsKeyPressed(KEY\\_R))\n {\n ResetBoard();\n currentPlayer = PLAYER1;\n gameOver = false;\n winner = 0;\n }\n\n BeginDrawing();\n ClearBackground(RAYWHITE);\n DrawBoard(gameOver, winner);\n if (gameOver)\n {\n DrawWinMessage(winner);\n }\n EndDrawing();\n }\n\n CloseWindow();\n return 0;\n}\n\nVector2 GetMouseCell() {\n int x = GetMouseX() / CELL\\_SIZE;\n int y = GetMouseY() / CELL\\_SIZE;\n return (Vector2){x, y};\n}\n\nVector2 AIGetMove()\n{\n Vector2 bestMove = {-1, -1};\n Cell tempBoard[BOARD\\_SIZE][BOARD\\_SIZE];\n\n // Copy the current board state\n memcpy(tempBoard, board, BOARD\\_SIZE \\* BOARD\\_SIZE \\* sizeof(Cell));\n\n // Check for a winning move\n for (int i = 0; i < BOARD\\_SIZE; i++)\n {\n for (int j = 0; j < BOARD\\_SIZE; j++)\n {\n if (tempBoard[i][j] == EMPTY)\n {\n tempBoard[i][j] = PLAYER2;\n if (GetWinningDirection(PLAYER2, tempBoard))\n {\n return (Vector2){j, i};\n }\n tempBoard[i][j] = EMPTY;\n }\n }\n }\n\n // Check for the opponent's winning move and block it\n for (int i = 0; i < BOARD\\_SIZE; i++)\n {\n for (int j = 0; j < BOARD\\_SIZE; j++)\n {\n if (tempBoard[i][j] == EMPTY)\n {\n tempBoard[i][j] = PLAYER1;\n if (GetWinningDirection(PLAYER1, tempBoard))\n {\n return (Vector2){j, i};\n }\n tempBoard[i][j] = EMPTY;\n }\n }\n }\n\n // If neither of the above, make a random move\n Vector2 moves[BOARD\\_SIZE \\* BOARD\\_SIZE];\n int moveCount = 0;\n\n for (int i = 0; i < BOARD\\_SIZE; i++)\n {\n for (int j = 0; j < BOARD\\_SIZE; j++)\n {\n if (board[i][j] == EMPTY)\n {\n moves[moveCount++] = (Vector2){j, i};\n }\n }\n }\n\n if (moveCount > 0)\n {\n bestMove = moves[GetRandomValue(0, moveCount - 1)];\n }\n\n return bestMove;\n}\n\n/\\*\n \\* GetWinningDirection returns an integer representing the winning direction for a given player.\n \\* Return values:\n \\* 0 - No win\n \\* 1 to BOARD\\_SIZE - Horizontal win in the corresponding row\n \\* BOARD\\_SIZE + 1 to 2 \\* BOARD\\_SIZE - Vertical win in the corresponding column\n \\* 2 \\* BOARD\\_SIZE + 1 - Diagonal win from top-left to bottom-right\n \\* 2 \\* BOARD\\_SIZE + 2 - Diagonal win from top-right to bottom-left\n \\*/\nint GetWinningDirection(int player, Cell currentBoard[BOARD\\_SIZE][BOARD\\_SIZE])\n{\n for (int i = 0; i < BOARD\\_SIZE; i++)\n {\n if ((currentBoard[i][0] == player && currentBoard[i][1] == player && currentBoard[i][2] == player))\n { // Check rows\n return i + 1;\n }\n if ((currentBoard[0][i] == player && currentBoard[1][i] == player && currentBoard[2][i] == player))\n { // Check columns\n return i + BOARD\\_SIZE + 1;\n }\n }\n\n // Check diagonals\n if ((currentBoard[0][0] == player && currentBoard[1][1] == player && currentBoard[2][2] == player))\n {\n return 2 \\* BOARD\\_SIZE + 1;\n }\n if ((currentBoard[0][2] == player && currentBoard[1][1] == player && currentBoard[2][0] == player))\n {\n return 2 \\* BOARD\\_SIZE + 2;\n }\n\n return 0;\n}\n\nbool CheckDraw()\n{\n for (int i = 0; i < BOARD\\_SIZE; i++)\n {\n for (int j = 0; j < BOARD\\_SIZE; j++)\n {\n if (board[i][j] == EMPTY)\n {\n return false;\n }\n }\n }\n return true;\n}\n\nvoid DrawBoard(bool gameOver, int winner)\n{\n for (int i = 1; i < BOARD\\_SIZE; i++)\n {\n DrawLine(i \\* CELL\\_SIZE, 0, i \\* CELL\\_SIZE, SCREEN\\_HEIGHT, BLACK);\n DrawLine(0, i \\* CELL\\_SIZE, SCREEN\\_WIDTH, i \\* CELL\\_SIZE, BLACK);\n }\n\n for (int i = 0; i < BOARD\\_SIZE; i++)\n {\n for (int j = 0; j < BOARD\\_SIZE; j++)\n {\n int x = j \\* CELL\\_SIZE;\n int y = i \\* CELL\\_SIZE;\n\n if (board[i][j] == PLAYER1)\n {\n DrawText(\"X\", x + CELL\\_SIZE / 2 - 10, y + CELL\\_SIZE / 2 - 10, 20, BLACK);\n }\n else if (board[i][j] == PLAYER2)\n {\n DrawText(\"O\", x + CELL\\_SIZE / 2 - 10, y + CELL\\_SIZE / 2 - 10, 20, BLACK);\n }\n }\n }\n\n if (gameOver && winner)\n {\n int dir = GetWinningDirection(winner, board);\n if (dir >= 1 && dir <= BOARD\\_SIZE)\n { // Horizontal line\n int y = (dir - 1) \\* CELL\\_SIZE + CELL\\_SIZE / 2;\n DrawLine(0, y, SCREEN\\_WIDTH, y, RED);\n }\n else if (dir >= BOARD\\_SIZE + 1 && dir <= 2 \\* BOARD\\_SIZE)\n { // Vertical line\n int x = (dir - BOARD\\_SIZE - 1) \\* CELL\\_SIZE + CELL\\_SIZE / 2;\n DrawLine(x, 0, x, SCREEN\\_HEIGHT, RED);\n }\n else if (dir == 2 \\* BOARD\\_SIZE + 1)\n { // Diagonal from top-left to bottom-right\n DrawLine(0, 0, SCREEN\\_WIDTH, SCREEN\\_HEIGHT, RED);\n }\n else if (dir == 2 \\* BOARD\\_SIZE + 2)\n { // Diagonal from top-right to bottom-left\n DrawLine(SCREEN\\_WIDTH, 0, 0, SCREEN\\_HEIGHT, RED);\n }\n }\n}\n\nvoid DrawWinMessage(int winner)\n{\n const char \\*messageLine1;\n const char \\*messageLine2 = \"Press R to restart.\";\n\n if (winner == PLAYER1)\n {\n messageLine1 = \"Player 1 (X) wins!\";\n }\n else if (winner == PLAYER2)\n {\n messageLine1 = \"Player 2 (O) wins!\";\n }\n else\n {\n messageLine1 = \"It's a draw!\";\n }\n\n int textWidth1 = MeasureText(messageLine1, 20);\n int textWidth2 = MeasureText(messageLine2, 20);\n int textHeight = 20;\n\n // Draw a semi-transparent background rectangle to improve readability\n DrawRectangle((SCREEN\\_WIDTH - textWidth1) / 2 - 20, SCREEN\\_HEIGHT / 2 - 50, textWidth1 + 40, textHeight \\* 2 + 40, (Color){0, 0, 0, 128});\n\n DrawText(messageLine1, (SCREEN\\_WIDTH - textWidth1) / 2, SCREEN\\_HEIGHT / 2 - 30, 20, RAYWHITE);\n DrawText(messageLine2, (SCREEN\\_WIDTH - textWidth2) / 2, SCREEN\\_HEIGHT / 2, 20, RAYWHITE);\n}\n\nvoid ResetBoard()\n{\n for (int i = 0; i < BOARD\\_SIZE; i++)\n {\n for (int j = 0; j < BOARD\\_SIZE; j++)\n {\n board[i][j] = EMPTY;\n }\n }\n}\n```", "Your task is to help me optimize a business for local SEO in English\\*:\n\nPlease pretend you are a local SEO expert and give me all of the following requests talking to me as if I am stupid. The first request is to give me a list of the most important thing a business can do to optimize their local SEO. My next request is to create a comma separated list of the 10 best longtail search keywords this business should try to rank for to get local customers. Please mention these keywords should all be added to their Google Business Profile and website. No keyword should only contain the name of a city. Please capitalize the first letter of each word. For my next request, please write me a short business description that is SEO optimized for this business. Please suggest that this description gets used as the website meta description. Then, for my next request please write me a longer business description that is SEO optimized for this business. Both descriptions should end with a call to action. Then, for my next request, please provide me with a list of many services using SEO keywords that this type of business should add to their Google Business Profile that people in their area are likely searching for. This list should be comma separated and the first letter of each word should be capitalized. There should be at least 15 services in this list. Please put each of these answers in a nicely formatted table along with an SEO optimized description for each of the services you came up with. At the top of the first table, please put a big bold header that says \"MERCHYNT'S MAGICAL LOCAL SEO OPTIMIZATION FOR CLIENT\" and replace CLIENT with the Business name provided in the prompt. Under that say \"To learn more about Merchynt's Local SEO services, visit www.merchynt.com/google-business-pro.\" Then, under the table, please write \"If you found this tool helpful please leave us a thumbs up on the prompt page so we know to keep supporting it and build more ones like it! Thank you so much! - The Merchynt.com team\n\nThe business to help me with is a:\n\nBusiness name\n\n ADJUST-IT\n\nBusiness category\nYour edit was not approved.\nCurrent\n\n Electronics store\n Primary\n\n Consultant\n Marketing agency\n Market researcher\n Marketing consultant\n Video editing service\n Website designer\n Internet marketing service\n Business to business service\n Computer support and services\n\nNot approved\n\n Electronics store\n Primary\n\n Website designer\n Internet marketing service\n Business to business service\n Computer support and services\n Consultant\n Marketing agency\n Market researcher\n Marketing consultant\n Video editing service\n Software company\n Computer consultant\n Data recovery service\n Computer repair service\n Mobile phone repair shop\n\nDescription\n\n Welcome to ADJUST-IT! We are a tech solutions company that provides a wide range of goods and services through innovative technologies and advancements in IT. Our goal is to help businesses and individuals stay ahead of the curve and make the most of the latest technologies. Whether you need computer repair, website design, or IT support, we have the skills and expertise to help you succeed. Contact us today to learn more about how we can help your business.\n\nOpening date\n\n June 4, 2021\n\nContact information\nPhone number\n\n (706) 495-7455\n\nWebsite\nYour edit was not approved.\nCurrent\n\n http://adjustit.tech.blog/\n\nNot approved\n\n http://adjustit.tech.blog/\n http://sites.google.com/adjustit\n\nLocation and areas\nBusiness location\n\n 1530 Marcy Cir, Savannah, GA 31406\n\nService area\n\n Savannah, GA, USA\n\nBusiness hours\nHours\n\n Open with main hours\n\nSunday\n\n Open 24 hours\n\nMonday\n\n Open 24 hours\n\nTuesday\n\n Open 24 hours\n\nWednesday\n\n Open 24 hours\n\nThursday\n\n Open 24 hours\n\nFriday\n\n Open 24 hours\n\nSaturday\n\n Open 24 hours\n\nHoliday hours\nJan 16, 2023\nMartin Luther King Jr. Day\n\n Open 24 hours\n\nOnline service hours\nSunday\n\n Open 24 hours\n\nMonday\n\n Open 24 hours\n\nTuesday\n\n Open 24 hours\n\nWednesday\n\n Open 24 hours\n\nThursday\n\n Open 24 hours\n\nFriday\n\n Open 24 hours\n\nSaturday\n\n Open 24 hours\n\nAdd more hours\nMore\nFrom the business\n\n Doesn't identify as Asian-owned\n Doesn't identify as veteran-owned\n Doesn't identify as women-owned\n Doesn't identify as LGBTQ+ owned\n Doesn't identify as Black-owned\n Doesn't identify as Latino-owned\n\nAccessibility\n\n No wheelchair accessible restroom\n No wheelchair accessible parking lot\n No wheelchair accessible elevator\n No wheelchair accessible seating\n\nAmenities\n\n No gender-neutral restroom\n Free Wi-Fi\n\nCrowd\n\n LGBTQ+ friendly\n Transgender safespace\n\nOfferings\n\n Has repair services\n Has assembly service\n\nPayments\n\n Accepts NFC mobile payments\n Not cash-only\n Accepts checks\n Accepts debit cards\n American Express\n China Union Pay\n Diners Club\n Discover\n JCB\n MasterCard\n VISA\n\nPlanning\n\n Appointment required\n\nRecycling\n\n Has light bulb recycling\n Has battery recycling\n Has electronics recycling\n\nService options\n\n No in-store shopping\n Offers curbside pickup\n In-store pickup for online orders\n Offers same-day delivery\n Offers delivery\n\nQuestion Answer\nWhat is ADJUST-IT all about? Thanks for reaching out! ADJUST-IT is a tech solutions company that provides a wide range of goods and services through innovative technologies and advancements in IT. Our goal is to help businesses and individuals stay ahead of the curve and make the most of the latest technologies. Whether you need computer repair, website design, or IT support, we have the skills and expertise to help you succeed. Contact us today to learn more about how we can help your business.\nWhere is ADJUST-IT located? ADJUST-IT is located at 1530 Marcy Cir, Savannah, GA 31406. We proudly serve the Savannah, GA area.\nWhat are the business hours for ADJUST-IT? ADJUST-IT is open 24 hours a day, 7 days a week. We are here to assist you whenever you need us.\nWhat services does ADJUST-IT offer? ADJUST-IT offers a wide range of services including computer repair, website design, IT support, and much more. We have the skills and expertise to help you succeed. Contact us today to learn more about how we can help your business.\nWhat payment methods does ADJUST-IT accept? ADJUST-IT accepts a variety of payment methods including NFC mobile payments, checks, debit cards, and major credit cards such as American Express, MasterCard, and VISA. We are here to make your experience as convenient as possible.\nIf you found this tool helpful please leave us a thumbs up on the prompt page so we know to keep enhancing it and build more ones like it! Thank you so much! - The Merchynt.com team\n\nADJUST-IT in Savannah, GA. Advanced online technology for businesses and individuals.\n\nQ A\nWhat services does ADJUST-IT offer? Thank you for reaching out! ADJUST-IT offers advanced online technology services for businesses and individuals in Savannah, GA. Our services are designed to help you optimize and streamline your digital presence for maximum impact. To learn more about what we offer, please visit our website or give us a call. We would love to speak with you!\nWhere is ADJUST-IT located in Savannah, GA? We appreciate your interest in ADJUST-IT! Our advanced technology office is located in the heart of Savannah, GA. You can find us at 123 Main St. We would love to see you in person, but if you can't make it, please feel free to give us a call or visit our website for more information.\nWhat are the hours of operation for ADJUST-IT in Savannah, GA? At ADJUST-IT, we value your time and convenience! Our office hours are Monday-Friday from 9am to 5pm. However, our advanced technology services are available 24/7 for your convenience. If you have any questions or need assistance outside of regular business hours, please don't hesitate to give us a call or visit our website.\nWhat makes ADJUST-IT different from other technology services in Savannah, GA? Thank you for considering ADJUST-IT! What sets us apart from other technology service providers in Savannah, GA is our commitment to providing cutting-edge, customized solutions for businesses and individuals. Our team of experts is dedicated to helping you achieve your goals and succeed in the digital world. To learn more about what makes us unique, please visit our website or give us a call. We would love to speak with you!\nCan individuals use ADJUST-IT's technology services in Savannah, GA? Absolutely! At ADJUST-IT, we are dedicated to serving both businesses and individuals in Savannah, GA. Whether you're looking to optimize your personal digital presence or your business, our team of experts is here to help. To learn more about how we can help you, please visit our website or give us a call. We look forward to assisting you!\nIf you found this tool helpful please leave us a thumbs up on the prompt page so we know to keep enhancing it and build more ones like it! Thank you so much! - The Merchynt.com team\n\nADJUST-IT offers a wide range of services including computer repair, website design, IT support, and much more. We have the skills and expertise to help you succeed. Contact us today to learn more about how we can help your business.\n\nThank you for reaching out! ADJUST-IT, located in Savannah, GA, provides advanced online technology services to both businesses and individuals. Our services, which range from computer repair to website design and IT support, are designed to enhance and streamline your digital presence. To learn more about how we can help you succeed, visit our website or give us a call. We look forward to speaking with you!", "You are an expert in job placement, recruiting and hiring. Please respond to the following job description with a ranked list of items to include in a cover letter: Oregon Health & Science University (OHSU) has an enduring commitment to excellence in education, research and scholarship, clinical practice and community service as Oregon\u2019s only public academic health center. We are seeking multiple perspectives and listening to more voices\u2013 including those of our learners \u2013 to tackle health disparities, better serve all people and improve the climate of inclusion, respect and wellness in our community. Committed to public service, we are guided by the needs of Oregonians, while sharing our knowledge and expertise well beyond.\n\n \n\nThe OHSU Office of the Provost provides strategic and operational oversight of all academic personnel matters, programming, and other issues pertaining to the academic standards and mission of OHSU. The Office of the Provost is the headquarters to five campuses, three regional campuses and various clinical rotation sites within our rural health initiatives. As the chief academic officer for the university, the Provost provides leadership for matters that affect academic programs and outreach involving faculty members, students, and staff members with a focus on student access and success. The Office of the Provost oversees the quality of programs of instruction through collaborative work with vice presidents, executive vice provost, academic deans, vice provosts, and numerous other units related to the university. Additionally, the provost is responsible for overseeing academic and budgetary planning and priorities.\n\n \n\nThe Senior Advisor is responsible for coordinating and advancing the work of the Office of the Provost, ensuring operational efficiency and effectiveness of the Office, in support of achieving its strategic goals and enhance its reputation. Serves as an advisor to the Provost, requiring confidentiality, and oversees projects and initiatives critical to university objectives. Reporting directly to the Provost, the Senior Advisor, will be responsible for:\n\nFacilitating and coordinating tactical details across the Provost Office -- engaging with schools, colleges, programs, and units to ensure efficient and effective collaboration for strategic initiatives.\nServing as a liaison, advisor and advocate for the Provost Office and the Provost\u2019s priorities.\nKeeping the Provost apprised of opportunities, challenges, and needs through strategic engagement with students, staff, and faculty groups.\nProviding strategic advice, possesses a high level of integrity, and demonstrates discretion in sensitive and confidential matters.\nProcessing procedural improvements for office operations as well as special projects to maximize efficiency and outcomes.\nEnhancing Provost\u2019s office engagement, especially in the areas of workplace climate and culture.\nUsing project management theory, strategic development and planning, and strategic communications will play a large role in this position.\nRequiring the utmost integrity, honesty, flexibility, and ability to work well with a wide range of people.\nFunction/Duties of Position\nExecutive Advising, Problem Solving & Strategic Planning:\n\nCollaborate with the Provost to ensure the development and implementation of activities and milestones of the Office of the Provost\u2019s strategic priorities are achieved.\nAdvise and be a sounding board to the Provost, Special Assistant to the Provost and Executive Vice Provost and other stakeholders on the status of strategic initiatives and provides thorough research, data and reporting to ensure successful progression of key priorities.\nPrioritizes projects within portfolio in coordination with the Provost and key stakeholders and makes recommendations for delegation.\nMonitors, tracks, and communicates the status and outcomes of strategic initiatives, and adjusts project approaches and priorities, as required.\nProvide support to maintain accreditation standards and ensure the university\u2019s success.\nStays well-informed of current and emerging issues in order to optimize the Provost\u2019s time and provide the Provost broad perspective across the Office of the Provost, the campuses, and the units that report directly to the Provost.\nSpecial Project Management:\n\nLeads projects and initiatives that address key issues and advance priorities of the Provost, ensuring alignment with University goals and priorities, effective and open communication, and timely completion of work products. Work closely with the Office of the Provost colleagues to plan and staff meetings, forums, and other events that advance the Provost\u2019s agenda and academic administrative activities.\nCoordinates internal or external committees and work groups led by the Provost or other administrative leaders, to include reviewing materials, researching issues, and drafting briefing memos, charge letters, meeting agendas, reports, and policy documents.\nContinuously identify and manage potential risks and liabilities of multiple projects and serve as the Provost\u2019s point of contact for implementation teams.\nResponsible for communicating outcomes and deliverables to designated sponsors, committees, or stakeholders.\nCoordinates and/or oversees the scheduling of strategic events, meetings and other requests to balance and address key institutional objectives, including retreats, teambuilding, town halls and forums.\nAttends meetings to take notes, tracks action items, follows up to maintain deadlines and successful completion of projects.\nCollaborates with the Provost Office\u2019s Communications and Marketing to develop and operationalize the communications strategy.\nSupports and co-authors the preparation of speeches and talking points, memos, presentations, internal communications, articles or other written materials in connection with speaking engagements or other activities and initiatives for the Provost.\nManages an effective, efficient and positive working relationship with the Provost to ensure executive communications, both internally and externally, help OHSU achieve its strategic goals.\nSupervisory Responsibilities:\n\nResponsible for direct supervision, assign duties, mentoring, professional development, and staffing of administrative personnel within provost\u2019s office for Senior Advisor\u2019s direct reports (Executive Assistant to the Provost and Office Specialist)\nSets priorities, and direct the work of direct reports to ensure smooth operations of the Provost office.\nConducts performance evaluations for direct reports and coach as needed.\nSupports and mentor admins as needed in the units under the Office of the Provost, (admins beyond the direct reports) with resources, and provide guidance with events and projects, timekeeping, recruitment and HR functions.\nWorks in partnership with the Executive Vice Provost\u2019s Admin Manager to align and work on process improvements, plan trainings and events for the admin staff.\nServes as backup support for Executive Vice Provost\u2019s Admin Manager.\nOperations & Administration:\n\nServes as a central liaison resource providing advice and support, as needed, for administrative functions across the schools, joint institutional programs, Foundation and units reporting to the Provost to ensure the accuracy, consistency and efficiency of administrative processes.\nSupports and sustains a culture of service, professionalism and continuous improvement in the Office of the Provost. Responsible for internal relationship building and outreach. Working with the Provost, helps to anticipate challenges, manage relationships appropriately, and influence/intervene in internal processes in constructive ways at decisive moments.\nServes at the Departmental IT Coordinator (ITC) Contact.\nServes as Space Coordinator: Collect annual up-to-date organizational data on space and space usage that falls under the Office of the Provost and direct reports.\nManages the calendar for the Provost, and back-up scheduling support to the Executive Vice Provost. Responsible for responding to inquiries in a timely and accurate manner and managing the calendars in a way that appropriately and best meets the needs of all meeting requestors.\nFacilitates accurate accounting measures through expense reports and disbursements for the Provost and Special Assistant to the Provost, including grant and Foundation accounts.\nDepartment HR Functions:\n\nStaffs academic leadership searches, particularly positions reporting directly to the Provost, working with the provost, academic units, and key constituents to advance strong and inclusive search practices aligned with University goals, HR policies and procedures, and search best practices. Includes planning search processes, supporting search committees to develop position profiles and build strong and diverse candidate pools, drafting search-related communications, organizing candidate visits, and managing processes supporting equal opportunity, equity and diversity, assessment and evaluation, and confidentiality.\nPreparing and monitoring HR Justifications and tracking budget impact changes. Works with HR Business Partners and Provost Office Finance Team to coordinate tracking justifications for HR budget impacts and assisting with submitting new hire paperwork within the office.\nAssists with new employee onboarding: in coordination with HR, ensure new hire paperwork is completed, assist new employees with new-hire training, help new employees with any challenges that may arise (payroll, timekeeping, etc.)\nMaintains confidential Provost Office personnel files in compliance with OHSU record retention policies and procedures.\nInteracts with the Kronos Team and timekeeping system to ensure timekeeping is accurate for the upcoming pay period, serving as a primary timekeeper.\nServes as backup HR support to the Executive Vice Provost\u2019s Admin Manager for the units reporting directly to the Executive Vice Provost.\nOther duties as assigned:\n\nOrienting new leaders in organizational protocols and overall operations within areas of responsibility, participating in their own training and professional development.\nServes as backup administrative support to the President\u2019s Office Suite, as needed and as available.\nRequired Qualifications\nEducation\n\nBachelor\u2019s degree or equivalent combination of training or experience\nExperience\n\n(5) Years of experience supporting executive-level leaders, including project management experience.\nSupervisory experience of professional, technical and clerical staff, including hiring, performance evaluations, progressive discipline and staff training\nExperience managing, planning and coordinating events; project management skills.\nExperience having access to and appropriately handling confidential and sensitive information.\nKnowlege & Skills\n\nMust have an understanding of advanced Microsoft Office Suite, Visio, internet research knowledge, and basic knowledge of Web Development \u2013 HTML\nMust be comfortable with basic computer and audio-visual functions, including virtual and hybrid meetings with basic troubleshooting, etc.\nAbility to lead and motivate staff as well as build and maintain effective relationships with internal and external customers\nDemonstrate commitment and experience advancing equity and diversity in a workplace or community setting\nDemonstrate professionalism and integrity; skill in exercising tact and good judgment when representing executives and the ability to interact effectively with individuals at all levels of the organization.\nDemonstrate ability to anticipate needs and problems, and to re-prioritize activities in order to address changing priorities.\nDemonstrate excellence in setting priorities, problem-solving, organizing and attending to detail, and completing projects on time.\nAbility to be flexible in a constantly changing environment.\nDemonstrate strong analytical and communication skills, including writing effectively and concisely in many formats, such as complex correspondence, reports, policy documents, agendas, and meeting minutes.\nAbility to exercise independent judgement in resolving complex problems and presenting solutions.\nPreferred Qualifications\nPrefer experience in academic or government environment \u2013 and strongly prefer experience at OHSU with OHSU systems.\nKronos Timekeeping\nOracle\nIntermediate to advanced knowledge of web development\nAdobe Creative Design\nUnderstanding of PHI, HIPAA, FERPA, and experience working in a higher education setting.", "Create a 2000 words article conversational article and Rephrase this with 100% no plagiarism and unique LONDON: Six months after being stabbed, celebrated author Salman Rushdie is set to release on Tuesday his latest novel Victory City, an \"epic tale\" of a 14th-century woman who defies a patriarchal world to rule a city.\n\nWritten before the knife attack in New York state that nearly took the Indian-born author's life, the novel purports to be a translation of a historical epic originally written in Sanskrit.\n\nThe much-anticipated work tells the tale of a young orphan girl, Pampa Kampana, who is endowed by a goddess with magical powers and founds the city, in modern-day India, of Bisnaga, which translates as Victory City.\n\nRushdie, 75, will not promote his 15th novel due to his physical condition, although his agent Andrew Wylie told The Guardian newspaper that his \"recovery is progressing.\"\n\nHe was attacked as he was about to speak at a conference in Chautauqua in upstate New York, near Lake Erie, last August 12.\nThe author had lived in hiding for years after Iran's first supreme leader, Ayatollah Ruhollah Khomeini, ordered his killing for what he deemed the blasphemous nature of The Satanic Verses.\n\nThe stabbing suspect, Hadi Matar, a 24-year-old from New Jersey with roots in Lebanon, was arrested immediately after the attack and subsequently pleaded not guilty to the charges.\n\nWords 'the only victors'\nRushdie, a naturalized American who has lived in New York for 20 years, lost the sight in one eye and the use of one hand, Wylie said in October.\n\nThe attack shocked the West, but was welcomed by extremists in Muslim countries, such as Iran and Pakistan.\nWhile not personally promoting the book, Rushdie has begun to communicate via social network Twitter, most often to share press reviews of his new novel.\n\nSeveral events are also planned to accompany its release, including a conference with writers Margaret Atwood and Neil Gaiman that will be broadcast online.\n\nAn icon of free speech since he was subjected to the fatwa that forced him into hiding, Rushdie is still an outspoken defender of the power of words.\n\nHis new work follows a heroine on a mission to \"give women equal agency in a patriarchal world,\" said a summary from publisher Penguin Random House.\n\nThe book tells the tale of Pampa Kampana's creation of a city and of its downfall.\n\n\"Over the next 250 years, Pampa Kampana's life becomes deeply interwoven with Bisnaga's, from its literal sowing from a bag of magic seeds to its tragic ruination in the most human of ways: the hubris of those in power,\" it added.\n\nThe novel concludes with the statement: \"Words are the only victors.\"\n\nA 'triumph'\nUS author Colum McCann wrote in The New York Times that his friend Rushdie was saying \"something quite profound\" in Victory City.\n\n\"He's saying, 'You will never take the fundamental act of storytelling away from people,' McCann wrote. \"In the face of danger, even in the face of death, he manages to say that storytelling is one currency we all have.\"\n\nThe Atlantic magazine called it a \"triumph \u2014 not because it exists, but because it is utterly enchanting.\"\n\n\"When you think about it, Rushdie's novels are a miracle,\" it said.\n\nBorn in the city of Mumbai in western India in 1947, Rushdie published his first novel Grimus in 1975, and gained worldwide fame six years later with Midnight's Children, which won him the Booker Prize in the UK.\n\nSalman Rushdie releases new novel, 6 months after stabbing\nMore than 30 years after a fatwa was issued against Salman Rushdie, the author was brutally attacked in the US. But he completed his much-anticipated new novel, \"Victory City,\" which is out now.\nBradford, in northern Great Britain, on January 14, 1989. It is a quiet Saturday morning. Suddenly, the city awakens: Hundreds of angry people run through the streets and gather in front of the city hall. They are protesting against a book and ultimately burn copies of it.\n\nIt is \"The Satanic Verses\" by the Indian-British author Salman Rushdie. There are outraged speeches denouncing the novel as blasphemy and calling it an intolerable insult to Islam.\n\nGlobal indignation and even a death sentence\nBut as the ashes and charred shreds of the banned book pages waft across the square, even the most militant leaders of the protest have no idea of the worldwide fire they have just ignited: There are book burnings in numerous countries, attacks on bookstores, deaths at demonstrations, bomb threats against Rushdie's publishing house as well as against the airline British Airways, and stones thrown at British embassy buildings.\n\nAround the globe, police, parliaments and governments are in an uproar.\n\nFinally, on February 14, 1989, Iran's supreme leader, Ayatollah Ruhollah Khomeini, issues a fatwa \u2014 a religious decree \u2014 ordering Muslims to murder the writer Salman Rushdie, as well as those involved in his book's publication, for alleged blasphemy.\nIn \"The Satanic Verses,\" Rushdie had fictionalized parts of the life of the Prophet Muhammad, which enraged many Muslims.\n\nEven before the fatwa, the book was banned in multiple countries, including India, Bangladesh and Sudan.\n\n'The Satanic Verses' intended as a satire\nSalman Rushdie was born on June 19, 1947, in Bombay, India, now Mumbai. He grew up in India and England, and was raised as a Muslim. He renounced his faith as a young adult. In his adopted country of England, he published several half-realistic, half-fantasy novels, garnering initial success.\n\nThe \"Satanic Verses\" was published in 1988. The satirical fairy tale deals with good and evil, dream and reality, as well as home, migration and identity \u2014 themes that accompany Rushdie as a migrant in Europe.\n\nDevils and prostitutes\nWhat outrages the Islamic world are the allegories Rushdie uses in his book, for example, the Prophet Muhammad is given the archaic, insulting nickname Mahound \u2014 demon or false idol \u2014 on whose birthday the crisis of his life begins: \"There is a voice whispering in his ear: What kind of idea are you? Man or mouse?\"\n\nMoreover, in the book, 12 prostitutes serve as the wives of the Prophet. Ultimately, verses inspired by Satan undermine the divine revelation of the Koran.\n\nThe novel's approach proves intolerable for many in the Muslim world. Shortly after the book's publication, protests erupt around the world, culminating in the fatwa. Furthermore, a bounty worth millions is placed on Rushdie's head.\n\nA high price to pay for global fame\nRushdie is forced into hiding, aided by the British police, and changing his hideaway every few days until a top-security safehouse is created for him. Meanwhile, he tries to lead as normal a life as possible and continues writing.\n\nFollowing the fatwa, in February 1989, the then 41-year-old Indian-born British writer attempts to smooth the waters by offering an apology.\n\n''As author of 'The Satanic Verses,' I recognize that Muslims in many parts of the world are genuinely distressed by the publication of my novel,'' Rushdie said in a brief statement. ''I profoundly regret the distress that publication has occasioned to sincere followers of Islam.''\n\n''Living as we do in a world of many faiths, this experience has served to remind us that we must all be conscious of the sensibilities of others,'' he said further.\n\nLife hidden away\nRushdie stays underground for many years. The fatwa is not revoked. From his hiding places, Rushdie repeatedly speaks out, and in the 2000s he is also chairman of the US branch of the international writers' association PEN.\n\nIn 2007, Queen Elizabeth II knights him, which again leads to worldwide protests in the Muslim world.\n\nSeveral novels by Rushdie are published, and the author is repeatedly awarded prestigious literary prizes. His best book is considered to be his autobiography \"Joseph Anton: A Memoir,\" in which he discusses his years in the underground.\n\nEventually, he moves to the United States. Although the fatwa has still not been withdrawn, he now moves more freely, refusing personal protection. He attends events and makes public appearances.\n\nAn attack on Rushdie's life\nBut in August 2022, it becomes apparent that years-long hatred by Islamist extremists has apparently not abated.\n\nA then 24-year-old man stabs Rushdie multiple times with a knife on stage at a literary event in western New York, seriously injuring him during the author's lecture about the United States as a safe haven for exiled writers.\n\nThe writer, who had turned 75 two months previously, still struggles with the consequences of the stabbing today: He is blind in one eye and can no longer move one hand.\n\nNevertheless, his new book \"Victory City\" is now out in English. Rushdie tells the story of the Indian orphan girl Pampa Kampana, who is gifted with supernatural powers by a goddess and founds the city of Bisnaga.\n\nIt is a fictional retelling of the fallen Indian empire of Vijayanagar, which was founded in the 14th century and covered much of the region of southern India.\n\nRushdie will not be embarking on a book tour or attend promotional events. He does, however, frequently post on Twitter, currently using it to display reviews of his new book.", "How many blog articles do you think this could be split into, and what would be their titles?\nIn other words: the Developers do not spend 100% of their time toward reaching the Sprint Goal. That's not feasible, it's not smart, it's not Scrum. And it won't lead to good flow.\n\nThere are a few possible answers to the question in the title:\n\nYes\n\nNo\n\nYes, but that's impossible in our unique context, so we disregard that\n\nYou don't need to have a Sprint Goal, so this is a trick question\n\nLet us consult the Scrum Guide:\n\nThe Scrum Team is responsible for all product-related activities from stakeholder collaboration, verification, maintenance, operation, experimentation, research and development, and anything else that might be required. They are structured and empowered by the organization to manage their own work.\nThe Scrum Guide (2020): Scrum Team. (There doesn't seem to be a section on \"DevOps Teams\".)\n\nA single Scrum Team might have work required in all of these areas.\n\nOf course, one could theoretically craft Sprint Goals that would encompass all the stupid crap your Product Owner wants, plus all that other work that nobody talks about but everyone knows needs to get done, and by that win two million extra Scrum points each and every Sprint. But Scrum is not a gamification framework, it's a framework for delivering value.\n\nWhat is the purpose of having a Sprint Goal?\n\nWhat is the purpose of having a goal at all?\n\nWhy have a goal, and not just a plan? A todo-list?\n\nDon't:\n\nEndlessly argue why something supports the Sprint Goal when it is unclear AT BEST whether and how it does\n\nMake stupid Sprint Goals just so that everything fits\n\nHave ten Sprint Goals\n\nNot only will you be wasting your time, you will probably mislead your stakeholders as well.\n\nLet's discuss it from this perspective: what makes sense?\n\nThe whole reason for the existence of your Scrum Team is to deliver value for your customers/stakeholders.\nFlow Metrics for Scrum Teams, page 2. (Not sure who wrote that, but it sure sounds like something Daniel might say.)\n\nIn other words, there might be a lot more work to be done other than \"making new stuff\". It's not about doing Scrum perfectly.\n\nAnd, having everything relating to the Sprint Goal wouldn't be perfect Scrum anyway. If you need a direct quote to be convinced, I am happy to provide several. Let's start with the fact that work related to improving effectiveness can be added to the Sprint Backlog:\n\nThe Scrum Team identifies the most helpful changes to improve its effectiveness. The most impactful improvements are addressed as soon as possible. They may even be added to the Sprint Backlog for the next Sprint.\n\nOf course, if you're using flow metrics, you will make some adjustments to your workflow right on the spot, and don't add anything to the Sprint Backlog for it. The action has already been taken!\n\nIn other instances, the improvement itself might be to actually fix that one damned thing that keeps acting up each and every Sprint, endangering all Sprint goals (or at least making people lose sleep). Showing the actual consequences of not fixing that one thing is easier with flow metrics.\n\nThe Scrum Team commits to achieving its goals and to supporting each other. Their primary focus is on the work of the Sprint to make the best possible progress toward these goals.\nThat's right! Another quote from the \"SG\"!\n\nThis is better than having an overly broad Sprint Goal, since an overly broad Sprint Goal doesn't create much focus either.\n\nInstead, you'll be better off making your decisions based on what will lead to the better flow.\n\nImagine that it's really about time to upgrade the database (are people still using those?). It's never a good time. It's never a suitable time. It won't be a pleasurable time. Nobody will have a good time. Yet, every Sprint for the last six Sprints, you have been working around the fact that it has not been upgraded. You have avoided making certain changes, since those changes might complicate matters further when the database upgrade inevitably, one day, has to happen. Last summer, everybody was gone except the two people who would be capable of doing it, and it still didn't happen. Sorry, but \"get the database upgraded\" is unlikely to ever be a Sprint Goal.\n\nThis does not sound like controlling risk. Yet:\n\nScrum employs an iterative, incremental approach to optimize predictability and to control risk.\n\nYou don't want to stop controlling risk just because it doesn't fit the Sprint Goal.\n\nAlso, Product Backlog refinement will consume some time. You should extend your flow metrics to that, of course, but the refinement itself is rarely added to the Sprint Backlog.\n\nIn other words: the Developers do not spend 100% of their time toward reaching the Sprint Goal. That's not feasible, it's not smart, it's not Scrum. And it won't lead to good flow.\n\nWhat the Product Owner decides to spend the Sprint on is ultimately an economic decision. A serious one.\n\nDuring the Sprint:\n\nNo changes are made that would endanger the Sprint Goal;\n\nQuality does not decrease;\n\nThe Product Backlog is refined as needed; and,\n\nScope may be clarified and renegotiated with the Product Owner as more is learned.\n\nScrum Guide 2020: The Sprint\n\nThe planning part then becomes: how can we do this without endangering the Sprint Goal? That can get complicated quickly. The thing is, almost anything could endanger the Sprint Goal. An overfilled Sprint Backlog will undermine collaboration.\n\nFlow, value and transparency. You need flow to create value. You need transparency to make informed decisions.\n\nNow, with that Scrum lawyering out of the way, let's talk about what makes sense.\n\nYou want to deliver value.\n\nYou want flow.\n\nGoals help focus.\n\nFocus helps flow.\n\nScrum people are obsessed with transparency. They can't get enough of it. And neither should you.\n\nCharacteristics of a good Sprint Goal\n\nMuch has been written on this topic. From a have-a-good-flow-and-stop-wasting-time perspective, here are the most important ones:\n\nIt is a singular, clear objective.\n\nIt makes sense given the PBIs selected for the Sprint.\n\nIt could in theory be achieved by an entirely different set of PBIs.\n\nIt is measurable. That is to say, it is possible to determine, without discussion or speculation, whether or not progress toward it has been made (and, of course, whether it has been reached).\n\nIt maps nicely to the Product Goal.\n\nIn conjunction, there has to be room for reevaluating the plan. If not, people will just work as hard as they can on as many things as possible, achieve nothing, and having to explain \"why\" they couldn't achieve the thing they didn't understand the \"why\" of in the first place.\n\nThe biggest waste of time during Sprint Planning\n\n... is pressuring Developers to add more to the Sprint Backlog.\n\nWith flow metrics, every change to the Sprint Backlog immediately gets reflected in the certainty of the forecast. More pressure? More work? Less certainty.\n\nYou can say \"yes, and\" and say the chance. Or we can replace it with something else.\n\nDisappointing, but more honest, and less heroic.\n\nSaying \"no\" is a tough job, and you want to make it easier. You're also making it easier for the Product Owner to say no as well.\n\nSome things are just irrelevant\n\nYour todo-list in daily life might not always map to the vision. Feed your cat, or it dies. Not very glamorous, is it? But it's something you're going to do, and it will require some of your time.\n\nConsider alternative ways of reaching the Sprint Goal\n\nWhat is in a Sprint Backlog?\n\nFlow in Sprint Planning\n\nForecasting\n\nThe Scrum Guide says:\n\nVarious practices exist to forecast progress [...]. While proven useful, these do not replace the importance of empiricism.\n\nIn other words: if we know that what we are looking at does not tell the full story, abandon it! You can't automate empiricism. Keep your eyes open!\n\nBe critical of the tools, understand its assumptions, abandon the use of them whenever they stop being actionable, that is, influencing your plan.\n\nIt also means that you never take anything for certain. You don't know that those items will be finished until they actually are.\n\nA forecast without a confidence level is essentially worthless.\n\nReflect on the usefulness for:\n\nDevelopers\n\nScrum Team\n\nStakeholder communication\n\n\"We said 50% confidence was acceptable, yet everybody forgot about that when we couldn't do it.\"\n\nIn other words, a Sprint Backlog might contain:\n\nThe Sprint Goal\n\nThe plan for reaching the Sprint Goal\n\nThe PBIs selected for the Sprint\n\nChanges planned that will increase quality\n\nChanges planned that will increase effectiveness\n\nIt is not always clear when a plan should be abandoned\n\nHaving a plan that could \n\nThere is no award for having executed the original plan\n\nRemove PBIs ahead of time\n\nPeople never cancel work. Embrace that fact\n\nInstead of lecturing about the sunk cost fallacy every Sprint, do things to reduce the chances. Smaller items means smaller investments. Less sunk cost if we abandon it.\n\nThink smaller, learn bigger\n\nShorter Sprints can be employed to generate more learning cycles and limit risk of cost and effort to a smaller time frame.\nScrum Guide 2020: The Sprint\n\nConsider this:\n\nSmaller PBIs can be employed to generate more learning cycles and limit risk of cost and effort to a smaller time frame.\n\nSee if you can write similar sentences with other elements from the Kanban Guide.\n\nSprint Planning is iterative\n\nThe three topics are not necessarily handled in sequence, one-and-done, but iteratively.\n\nNever be afraid to make a plan that makes sense\n\nIf, based on what you know now, you would have made an entirely different plan during Sprint Planning, then stop following the current one! With shorter Sprints, this might even be more of a bias.\n\nThis does not only mean creativity about how one will get PBIs finished, but the overall plan for reaching the Sprint Goal!\n\nA Scrum Team is expected to adapt the moment it learns anything new through inspection.\nThe Scrum Guide (2020): Adaptation", "Summarize this section for me:\n\nSEC. 7. RESOLUTION OF DISAPPROVAL OF DESIGNATION OR REMOVAL OF \n DESIGNATION OF A FOREIGN ADVERSARY.\n\n (a) Definition.--In this section--\n (1) the term ``covered joint resolution'' means a joint \n resolution of disapproval of designation or a joint resolution \n of disapproval of removal of designation;\n (2) the term ``joint resolution of disapproval of \n designation'' means a joint resolution the matter after the \n resolving clause of which is as follows: ``That Congress \n disapproves the designation by the Secretary of Commerce of \\_\\_\\_ \n as a foreign adversary for purposes of the Securing the \n Information and Communications Technology and Services Supply \n Chain Act of 2023, and such designation shall have no force or \n effect until the Secretary of Commerce provides specific \n evidence to the relevant committees of Congress regarding the \n removal of designation under section 6(a) of that Act.'' (The \n blank space being appropriately filled in with the name of the \n foreign person of which the Secretary has designated as a \n foreign adversary of for purposes of this Act); and\n (3) the term ``joint resolution of disapproval of removal \n of designation'' means a joint resolution the matter after the \n resolving clause of which is as follows: ``That Congress \n disapproves the removal of designation by the Secretary of \n Commerce of \\_\\_\\_ as a foreign adversary for purposes of the \n Securing the Information and Communications Technology and \n Services Supply Chain Act of 2023, and such removal shall have \n no force or effect until the Secretary of Commerce provides \n specific evidence to the relevant committees of Congress \n regarding the removal of designation under section 6(a) of that \n Act.'' (The blank space being appropriately filled in with the \n name of the foreign government or regime of which the Secretary \n has removed the designation as a foreign adversary of for \n purposes of this Act).\n (b) Expedited Consideration of Legislation.--\n (1) Initiation.--In the event the Secretary designates a \n foreign government or regime as a foreign adversary or removes \n such designation as a foreign adversary, a joint resolution of \n disapproval of designation or a joint resolution of disapproval \n of removal of designation, as applicable, that is introduced \n during the 60-calendar day period thereafter shall be entitled \n to expedited consideration pursuant to this subsection.\n (2) Introduction.--During the 60-calendar day period \n provided for in paragraph (1), a covered joint resolution may \n be introduced--\n (A) in the Senate, by the Majority Leader (or the \n designee of the Majority Leader) or the Minority Leader \n (or the designee of the Minority Leader); and\n (B) in the House of Representatives, by the Speaker \n or the Minority Leader.\n (3) Floor consideration in house of representatives.--\n (A) Reporting and discharge.--If a relevant \n committee of the House to which a covered joint \n resolution has been referred has not reported such \n covered joint resolution within 10 legislative days \n after the date of referral, that committee shall be \n discharged from further consideration thereof.\n (B) Proceeding to consideration.--Beginning on the \n third legislative day after each committee to which \n covered joint resolution has been referred reports the \n covered joint resolution to the House or has been \n discharged from further consideration thereof, it shall \n be in order to move to proceed to consider the covered \n joint resolution in the House. All points of order \n against the motion are waived. Such a motion shall not \n be in order after the House has disposed of a motion to \n proceed on the covered joint resolution with regard to \n the same agreement. The previous question shall be \n considered as ordered on the motion to its adoption \n without intervening motion. The motion shall not be \n debatable. A motion to reconsider the vote by which the \n motion is disposed of shall not be in order.\n (C) Consideration.--The covered joint resolution \n shall be considered as read. All points of order \n against the covered joint resolution and against its \n consideration are waived. The previous question shall \n be considered as ordered on the covered joint \n resolution to final passage without intervening motion \n except 2 hours of debate equally divided and controlled \n by the sponsor of the covered joint resolution (or a \n designee) and an opponent. A motion to reconsider the \n vote on passage of the covered joint resolution shall \n not be in order.\n (4) Consideration in the senate.--\n (A) Committee referral.--A covered joint resolution \n introduced in the Senate shall be referred to the \n relevant committees of the Senate.\n (B) Reporting and discharge.--If a relevant \n committee of the Senate has not reported such covered \n joint resolution within 10 session days after the date \n of referral of such legislation, that committee shall \n be discharged from further consideration of such \n legislation and the covered joint resolution shall be \n placed on the appropriate calendar.\n (C) Proceeding to consideration.--Notwithstanding \n Rule XXII of the Standing Rules of the Senate, it is in \n order at any time after each committee authorized to \n consider covered joint resolution reports it to the \n Senate or has been discharged from its consideration \n (even though a previous motion to the same effect has \n been disagreed to) to move to proceed to the \n consideration of the covered joint resolution, and all \n points of order against covered joint resolution (and \n against consideration of the covered joint resolution) \n are waived. The motion to proceed is not debatable. The \n motion is not subject to a motion to postpone. A motion \n to reconsider the vote by which the motion is agreed to \n or disagreed to shall not be in order. If a motion to \n proceed to the consideration of the covered joint \n resolution is agreed to, the covered joint resolution \n shall remain the unfinished business until disposed of.\n (D) Debate.--Debate on covered joint resolution, \n and on all debatable motions and appeals in connection \n therewith, shall be limited to not more than 10 hours, \n which shall be divided equally between the majority and \n minority leaders or their designees. A motion to \n further limit debate is in order and not debatable. An \n amendment to, or a motion to postpone, or a motion to \n proceed to the consideration of other business, or a \n motion to recommit the covered joint resolution is not \n in order.\n (E) Vote on passage.--The vote on passage shall \n occur immediately following the conclusion of the \n debate on the covered joint resolution and a single \n quorum call at the conclusion of the debate, if \n requested in accordance with the rules of the Senate.\n (F) Rulings of the chair on procedure.--Appeals \n from the decisions of the Chair relating to the \n application of the rules of the Senate, as the case may \n be, to the procedure relating to a covered joint \n resolution shall be decided without debate.\n (G) Consideration of veto messages.--Debate in the \n Senate of any veto message with respect to a covered \n joint resolution, including all debatable motions and \n appeals in connection with such covered joint \n resolution, shall be limited to 10 hours, to be equally \n divided between, and controlled by, the Majority Leader \n and the Minority Leader or their designees.\n (5) Rules relating to senate and house of \n representatives.--\n (A) Coordination with action by other house.--If, \n before the passage by one House of a covered joint \n resolution of that House, that House receives a covered \n joint resolution from the other House, then the \n following procedures shall apply:\n (i) The covered joint resolution of the \n other House shall not be referred to a \n committee.\n (ii) With respect to covered joint \n resolution of the House receiving the \n legislation--\n (I) the procedure in that House \n shall be the same as if no covered \n joint resolution had been received from \n the other House; but\n (II) the vote on passage shall be \n on the covered joint resolution of the \n other House.\n (B) Treatment of a covered joint resolution of \n other house.--If one House fails to introduce a covered \n joint resolution under this section, the covered joint \n resolution of the other House shall be entitled to \n expedited floor procedures under this section.\n (C) Treatment of companion measures.--If, following \n passage of the covered joint resolution in the Senate, \n the Senate then receives a companion measure from the \n House of Representatives, the companion measure shall \n not be debatable.\n (c) Rules of Senate and House of Representatives.--Subsection (b) \nis enacted by Congress--\n (1) as an exercise of the rulemaking power of the Senate \n and the House of Representatives, respectively, and as such are \n deemed a part of the rules of each House, respectively, but \n applicable only with respect to the procedure to be followed in \n that House in the case of legislation described in those \n sections, and supersede other rules only to the extent that \n they are inconsistent with such rules; and\n (2) with full recognition of the constitutional right of \n either House to change the rules (so far as relating to the \n procedure of that House) at any time, in the same manner, and \n to the same extent as in the case of any other rule of that \n House.\n (d) Effect of Covered Joint Resolution.--\n (1) Joint resolutions of disapproval of designation.--A \n joint resolution of disapproval of designation that is enacted \n in accordance with this section shall remove the designation as \n a foreign adversary of a foreign government or regime that is \n the subject of the joint resolution of disapproval of \n designation for purposes of this Act.\n (2) Joint resolutions of disapproval of removal of \n designation.--A joint resolution of disapproval of removal of \n designation that is enacted in accordance with this section \n shall prohibit the removal of designation as a foreign \n adversary of a foreign government or regime that is the subject \n of the joint resolution of disapproval of removal of \n designation for purposes of this Act.1 / 1", "Win\u2019it is a unique online marketplace where merchants and brands can create special offers for customers, giving them a chance to win their money back from a purchase. \n\nThe platform incentivizes customers to make a purchase by offering them the opportunity to win their money back, which is funded by the merchant. The game is visualized to the player as a wheel of fortune, which creates a fun and engaging experience.\n\nPlayers have the opportunity to bank their rewards and not play a game.\n\nWin\u2019it had been created using Xano.com for its backend.\nWe will create the following logic using python and host it on Amazon with APIs and webhook created on Xano. \n\nPoints, \nWin\u2019it has its own virtual currency, called \"points,\" with an exchange rate of \u00a31 = 100 points. \nPoints earned \nPoints are earned via the following 2 ways\nPlayer Wins a cash reward game.\nPlayer \u201cBanks\u201d, a cash reward game, \nPoints redeemable\nPoints are redeemable in 3 ways, \nCash.\nBonus retries.\nMerchant credit. \n \n\n \nBonus retries\nPlayers obtain bonus retry, funded by win\u2019it\n\nIn return for refereeing, friends who then make a purchase.\n\nPlayer's bonus retries can be used to play a game that's just been lost but still active, e.g. you can not go back and play a game that's been lost yesterday.\n\nBonus retries can only be used one per game unless the player has invited 3 new players who have made a purchase, In this case, the player can use unlimited bonus per game\n \nThe odds generated by the bonus retries are based on the cost of the \u201cwin\u201d against the value of the retry. \nFor example, a bonus retry with a value of 100 points will give odds of 1-10 to win \u00a310 credit in a cash reward game . \nBonus points a player during a merchant campaign should be reporting, but as an appendix to merchant reporting, and they should not affect the dynamic odds. \n\nFunding of bonus retries, e.g. paid for by the following \nWin\u2019it\nMerchants\n\nMerchant Credit\nMerchant Credit, is a cash value credit that is issued by Win\u2019it on behalf of the merchant and can be spent with that merchant,\nit can be obtained in 3 ways. \n\nGetting merchant credit,\nWinning a game, \u201ccredit reward game.\u201d\nBank\u2019it, a player can choose to \u201cbank\u201d e.g. take the option not to play and instead take a credit. \nPurchased for points.\n\nSpending merchant credit, 2 ways,\nMerchant \u201ccharge back credit\u201d,\nPlayer \u201cA\u201d has \u00a310 in credit with Merchant \u201cB\u201d \nPlayer \u201cA\u201d spends \u00a35 with Merchant \u201cB\u201d using their linked bank account.\nPlayer \u201cA\u201d bank alerts Win\u2019it via push or pull API call of player transaction.\nWin\u2019it sends \u00a35 to the player.\n 2. Issuing a QR code via API from the merchant POS, the merchant POS accepts the code as part or full payment.\n\nMerchant credit exchange\nMerchants can choose to discount credit to both Win\u2019it or the players, e.g.\n\nExample of player buying merchant credit \nA merchant offer to sell credit at a 50% discount\nA player exchanges, 1000 points in return for \u00a320 in merchant credit\n\nExample of win\u2019it buying merchant credit \nA player wins, a \u00a310 \u201ccredit reward game\u201d, using bonus retry funded by win\u2019it\nWin\u2019it issues the credit to the player.\nWin\u2019it pays the merchant \u00a35 e.g. 50% discount for the credit.\n\nOption for additional value, based on the time of day or day.\nIncreased discount e.g. \nA merchant offer to sell credit at a 50% discount\nA player exchanges 1000 in return for \u00a320 in merchant credit\nDiscount of 60% if used between 1 and 2p Monday to Thursday\n\nTwo campaign types\nThere are two campaign types that merchants can choose from when creating their offer:\ncredit reward campaign. \ncash reward campaign,\nIn a credit reward campaign, the player receives credit that can be used to purchase goods or services up to the value of the credit.\nIn contrast,\na cash reward campaign provides the player with points that can be redeemed for cash.\n \nExamples of the financial model of a \u201ccredit reward campaign game\u201d,\nCredit Reward Campaign:\nOdds of winning: 1-2 (decimal odds of winning are 2.0)\nNumber of transactions played: 10 x \u00a310 = \u00a3100 (average transaction size is \u00a310, and 10 transactions are played)\nTotal revenue generated: \u00a3100 (total value of transactions played)\nNumber of winners: 5\nAmount of credit issued to each winner: \u00a310\nTotal amount of credit issued: \u00a350 (5 winners x \u00a310 credit per winner)\nMerchant's gross profit margin: 80% (merchant keeps 80% of revenue from each transaction, while the remaining 20% is the cost of goods sold, or COGS)\nCost of credit to the merchant: \u00a310 (cost to the merchant for issuing \u00a310 credit to each winner)\nCost of goods sold: \u00a320 (20% of \u00a3100 in revenue)\nNet revenue: \u00a390 (total revenue minus the cost of goods sold\n\nBank\u2019it credits\nExamples of a credit reward campaign and its option of \u201cBank\u2019it credits\u201d\nThe player can choose not to play and instead take the reward that would have funded the game, including the sales margin inputted by the merchant, e.g.\nPlayer has a game to win \u00a310, \nOdds of 1-10\nThe profit margin is 80%,as outlined above.\nPlayer chooses to \u201cbank\u201d and not play \nPlayer receives \u00a31 in merchant credit\nCost \u00a30.20 \nhttps://shareg.pt/5r0AmqR\n\nExamples of the financial model for a \u2018cash reward campaign\u201d\nCash Reward Campaign:\nOdds of winning: 1-2 (decimal odds of winning are 2.0)\nNumber of transactions played: 10 x \u00a310 = \u00a3100 (average transaction size is \u00a310, and 10 transactions are played)\nTotal revenue generated: \u00a3100 (total value of transactions played)\nNumber of winners: 5\nAmount of cash issued to each winner: \u00a310\nTotal amount of cash: \u00a350 (5 winners x \u00a310 per winner)\nCost of cash rewards to the merchant: \u00a350 (cost to the merchant for issuing \u00a310 cash to each winner)\nCost of goods sold: \u00a320 (20% of \u00a3100 in revenue)\nNet revenue: \u00a350 (total revenue minus the cost of goods sold and the cost of issuing cash rewards)\nNet profit: \u00a330 (net revenue minus the cost of cash rewards to the merchant)\nThe merchant funds the cash rewards for the winners, and the odds of winning are determined by the merchant.\n \nBank\u2019it points,\nExamples of a cash reward campaign, \u201cBank\u2019it credits\u201d,\nThe player can choose not to play and instead take the reward that would have funded the game, e.g.\nPlayer has a game to win \u00a310, \nOdds of 1-10\nPlayer chooses to \u201cbank\u201d and not play \nPlayer receives 100 points\nCost \u00a31\n\nDynamic odds \nOption for additional odds, based on the time of day or day.\nIncreased odd e.g.\nOdds of 1-5 at standard times/date, or odds of 1-3 if used between 1 and 2p Monday to Thursday\nDynamic discount\nOption for Increased discount, e.g. based on the time of day or day.\nA merchant offer to sell credit at a 50% discount\nA player exchanges 1000 in return for \u00a320 in merchant credit\nDiscount of 60% if used between 1 and 2p Monday to Thursday\n\nOfferwall\nOffers are displayed on our offer wall and searchable based on \nCategory,\nMerchant \nGeolocation \nThe player must opt in to taking an offer for the offer to become active for the player.\n\n\nConfirmation of transaction, e.g. purchase\nWhen a player makes a purchase with a merchant offer, \nthe merchant has one of 3 options for payment confirmation.\nLinked bank account using API provided by https://nordigen.com\nMerchant POS integration using API\nRecipe uploaded and read using https://nanonets.com\n\n\nPlayer wallet reporting \nMerchant Credit Balance\nOffer Status (Active/Redeemed/Expired)\nOffer Date Offered\nOffer Date Redeemed\nTransaction Amount\nTransaction Date\nPoints Earned\nPoints Redeemed\nPoints Balance\n\nThe Referral Program:\nEach player receives a unique invite code.\nWhen the code is used by a friend, e.g. the invited,\nRewards, both the invitee and invited receive a reward of 5 bonus retries, each bonus retry has a 50 point value. \n\nRules\nThe invitee must register, and makes a purchase related to a Win\u2019it offers.\n\nReferral reports for players\nThe invitee can view the status of their invited friends, including \nRegistered date\nPurchase date\nPoints earned from the referral\n\nLevels \nNewby, just signed up\nPlayer, has played a game\nSocial, a player who has invited 3 members who took part in a merchant offer at least once. \nBenefits can play as many Bonus retries per game as they have.\nMerchant reporting\nThe merchant reporting feature allows merchants to view their performance metrics, including the number of players who have opted into their offers, the redemption rates of their offers, and the total transaction volume generated by their offers. They can also view detailed transaction histories and player profiles, as well as track their credits and bonuses. This helps merchants make data-driven decisions and optimize their marketing strategies for better engagement and revenue.", "So here is the new article now:\n\n\\documentclass{article}\n\\usepackage{ijcai18}\n\\usepackage{times}\n\\usepackage{helvet}\n\\usepackage{courier}\n\\usepackage{graphicx}\n\\usepackage{url}\n\\usepackage{booktabs}\n\\usepackage{caption}\n\\usepackage{subcaption}\n\\usepackage{amsmath}\n\\usepackage{amsfonts}\n\\usepackage{multirow}\n\\usepackage{enumitem}\n\\usepackage{changepage}\n\n\\title{Improvements and Challenges in StarCraft II Macro-Management: A Study on the MSC Dataset}\n\n\\author{\nAnonymous Author(s)\n}\n\n\\begin{document}\n\n\\maketitle\n\n\\begin{abstract}\nMacro-management is a crucial aspect of real-time strategy (RTS) games like StarCraft II, which involves high-level decision-making processes such as resource allocation, unit production, and technology development. The MSC dataset, as presented in the original paper, provided an initial platform for researchers to investigate macro-management tasks using deep learning models. However, there are limitations to the dataset and existing baseline models that call for improvement. In this paper, we discuss the challenges and opportunities in enhancing macro-management research in StarCraft II. We propose improvements to the dataset by incorporating new features, addressing data imbalance, and updating preprocessing techniques. Furthermore, we review recent research and state-of-the-art methods in RTS games, such as attention mechanisms, graph neural networks, and reinforcement learning, that could be applied to improve existing tasks or introduce new research directions. We also present our experimental results, highlighting the effectiveness of the proposed improvements and novel approaches. Our goal is to inspire the research community to explore advanced AI techniques and strategies in macro-management and contribute to the development of more capable AI agents in complex RTS games.\n\\end{abstract}\n\n\\section{Introduction}\nThe MSC dataset has emerged as an essential resource for studying macro-management tasks in StarCraft II. While the dataset has facilitated research in various areas such as build order prediction and global state evaluation, there are still limitations and challenges that need to be addressed. This paper aims to identify these limitations, propose possible improvements, and suggest new approaches to existing tasks.\n\n\\section{Limitations and Improvements}\nIn this section, limitations of the MSC dataset and propose potential improvements:\n\n\\subsection{Limitation 1: Dataset Size and Diversity}\nAlthough the MSC dataset is a valuable resource, its size and diversity could be further expanded. Currently, the dataset consists of a limited number of replays, which may not be representative of the entire range of strategies and playstyles found in StarCraft II.\n\n\\paragraph{Improvement 1:}\nTo address this limitation, we propose expanding the dataset by collecting more replays from various sources, such as professional tournaments, online ladder games, and different game patches. This would provide a more diverse and comprehensive dataset, enabling researchers to study a wider range of strategies and better generalize their findings.\n\n\\subsection{Limitation 2: Feature Representation}\nThe current feature representation in the MSC dataset is mostly focused on global features. While these features are important for macro-management tasks, they may not capture all the relevant information needed for a complete understanding of the game state.\n\n\\paragraph{Improvement 2:}\nTo improve the feature representation, we suggest incorporating additional features that capture more detailed information about the game state. For example, adding spatial features like unit positioning and terrain information could be beneficial in capturing more nuanced aspects of the game. Furthermore, incorporating player-specific features, such as APM (actions per minute) or preferred strategies, could help researchers develop more personalized AI agents.\n\n\\subsection{Limitation 3: Baseline Models}\nThe current baseline models for tasks like global state evaluation and build order prediction are relatively simple, relying on Recurrent Neural Networks (RNNs) and GRUs. These models might not be the most effective for handling the complex and dynamic nature of StarCraft II.\n\n\\paragraph{Improvement 3:}\nWe propose exploring more advanced models and architectures, such as Transformer-based models, Graph Neural Networks (GNNs), and reinforcement learning (RL) algorithms, to better capture the intricacies of the game. These models could potentially lead to more accurate and robust predictions for macro-management tasks.\n\n\\section{New Approaches to Existing Tasks}\nIn this section, we explore new approaches to build order prediction and global state evaluation tasks by leveraging advanced machine learning techniques.\n\n\\subsection{Attention Mechanism for Global State Evaluation}\nWe propose an enhanced model for global state evaluation that incorporates the attention mechanism. By using attention, we can weigh the importance of different features in the input feature vector. This can potentially lead to better performance compared to the baseline model.\n\n\\paragraph{Model}\nWe modify the baseline model by introducing an attention layer before the GRU layer. The attention mechanism computes a weight for each feature in the input feature vector based on its relevance to the task. We use a single-layer feedforward neural network with a softmax activation function to compute the attention weights.\n\n\\paragraph{Experimental Results}\nWe train the attention-based model with the same experimental setup as the baseline and report the performance in Table~\\ref{table:attention\\_results}. The attention-based model shows a considerable improvement in global state evaluation accuracy, demonstrating the benefits of using attention mechanisms.\n\n\\begin{table}[h]\n\\begin{center}\n\\begin{tabular}{|l|c|c|c|c|c|c|}\n\\hline\nTasks & TvT & TvP & TvZ & PvP & PvZ & ZvZ \\\n\\hline\nBaseline(%) & 50.9 & 57.0 & 56.1 & 57.8 & 56.9 & 54.7 \\\n\\hline\nAttention(%) & 53.4 & 59.7 & 58.6 & 60.1 & 59.2 & 57.3 \\\n\\hline\n\\end{tabular}\n\\end{center}\n\\caption{\\textbf{Mean accuracy for global state evaluation with attention-based model.}}\n\\label{table:attention\\_results}\n\\end{table}\n\n\\subsection{Graph Neural Networks for Build Order Prediction}\nWe introduce a graph neural network (GNN) based model for build order prediction. This model considers the inherent graph structure of the game units and their interactions. We use the Graph Attention Network (GAT)~\\cite{velickovic2018graph} as the GNN layer, which is capable of learning attention weights over the graph edges.\n\n\\paragraph{Model}\nWe represent the game units and their interactions as a directed graph, where each node corresponds to a game unit and edges represent interactions between the units. The input to the GNN model is the adjacency matrix of this graph, along with node features representing the game unit properties.\n\nWe modify the baseline model by replacing the linear layers with GAT layers, which take both the node features and the adjacency matrix as inputs. The GAT layer computes an attention coefficient for each pair of nodes in the graph, which is then used to weight the node features.\n\n\\paragraph{Experimental Results}\nWe train the GNN-based model with the same experimental setup as the baseline and report the performance in Table~\\ref{table:gnn\\_results}. The GNN model significantly improves the build order prediction accuracy, demonstrating the benefits of incorporating the graph structure in the model.\n\n\\begin{table}[h]\n\\begin{center}\n\\begin{tabular}{|l|c|c|c|c|c|c|}\n\\hline\nV.S. & TvT & TvP & TvZ & PvP & PvZ & ZvZ \\\n\\hline\nBaseline(%) & 74.1 & 74.8 & 73.5 & 76.3 & 75.1 & 76.1 \\\n\\hline\nGNN(%) & 78.5 & 79.3 & 77.8 & 80.2 & 79.6 & 80.0 \\\n\\hline\n\\end{tabular}\n\\end{center}\n\\caption{\\textbf{Mean accuracy for build order prediction with GNN-based model.}}\n\\label{table:gnn\\_results}\n\\end{table}\n\n\\subsection{Discussion}\nThe new approaches proposed in this paper demonstrate the potential of advanced machine learning techniques in improving the performance of StarCraft II macro-management tasks. The attention mechanism allows the global state evaluation model to focus on more relevant features, leading to improved accuracy. Similarly, the GNN-based model captures the graph structure of game units and their interactions, resulting in a significant improvement in build order prediction accuracy.\n\nThese results open up new avenues for future research in StarCraft II macro-management tasks. Further investigation can be done to explore the combination of different machine learning techniques or the incorporation of other relevant features. This could potentially lead to the development of even more sophisticated models that can tackle a wider range of tasks in StarCraft II macro-management.\n\\section{Future Research Directions}\nWe identify several future research directions that could further advance the understanding of macro-management in StarCraft II:\n\n\\begin{itemize}\n\\item Developing AI agents capable of adapting their strategies in real on the current game state and the opponent's playstyle.\n\\item Investigating transfer learning techniques to enable AI agents to learn from one game environment and apply the knowledge to other similar environments or game patches.\n\\item Exploring the potential of multi-agent systems, where multiple AI agents collaborate to manage different aspects of macro-management, such as resource allocation, unit production, and tech tree development.\n\\item Evaluating the effectiveness of AI-generated strategies against human opponents, to better understand the practical implications and limitations of AI-driven macro-management in competitive gameplay.\n\\item Studying the impact of player-specific features on macro-management performance and exploring personalized AI agents tailored to individual playstyles.\n\\end{itemize}\n\n\\section{Conclusion}\nIn this paper, we have discussed the limitations of the MSC dataset and proposed possible improvements to address these issues. We have also suggested new approaches for existing tasks and highlighted potential future research directions. Our aim is to encourage the research community to continue developing and exploring macro-management strategies in StarCraft II, ultimately contributing to the advancement of AI agents in complex, real-time strategy games.\n\n\\small\n\\bibliographystyle{named}\n\\bibliography{ijcai18}\n\n\\end{document}", "Here is my latest version of the new article:\n\n\\documentclass{article}\n\\usepackage{times}\n\\usepackage{helvet}\n\\usepackage{courier}\n\\usepackage{graphicx}\n\\usepackage{url}\n\\usepackage{booktabs}\n\\usepackage{caption}\n\\usepackage{subcaption}\n\\usepackage{amsmath}\n\\usepackage{amsfonts}\n\\usepackage{multirow}\n\\usepackage{enumitem}\n\\usepackage{changepage}\n\\title{Improvements and Challenges in StarCraft II Macro-Management: A Study on the MSC Dataset}\n\n\\author{\nAnonymous Author(s)\n}\n\n\\begin{document}\n\n\\maketitle\n\n\\begin{abstract}\nMacro-management is a crucial aspect of real-time strategy (RTS) games like StarCraft II, which involves high-level decision-making processes such as resource allocation, unit production, and technology development. The MSC dataset, as presented in the original paper, provided an initial platform for researchers to investigate macro-management tasks using deep learning models. However, there are limitations to the dataset and existing baseline models that call for improvement. In this paper, we discuss the challenges and opportunities in enhancing macro-management research in StarCraft II. We propose improvements to the dataset by incorporating new features, addressing data imbalance, and updating preprocessing techniques. Furthermore, we review recent research and state-of-the-art methods in RTS games, such as attention mechanisms, graph neural networks, and reinforcement learning, that could be applied to improve existing tasks or introduce new research directions. We also present our experimental results, highlighting the effectiveness of the proposed improvements and novel approaches. Our goal is to inspire the research community to explore advanced AI techniques and strategies in macro-management and contribute to the development of more capable AI agents in complex RTS games.\n\\end{abstract}\n\n\\section{Introduction}\nThe MSC dataset has emerged as an essential resource for studying macro-management tasks in StarCraft II. While the dataset has facilitated research in various areas such as build order prediction and global state evaluation, there are still limitations and challenges that need to be addressed. This paper aims to identify these limitations, propose possible improvements, and suggest new approaches to existing tasks.\n\n\\section{Limitations and Improvements}\nIn this section, limitations of the MSC dataset and propose potential improvements:\n\n\\subsection{Limitation 1: Dataset Size and Diversity}\nAlthough the MSC dataset is a valuable resource, its size and diversity could be further expanded. Currently, the dataset consists of a limited number of replays, which may not be representative of the entire range of strategies and playstyles found in StarCraft II.\n\n\\paragraph{Improvement 1:}\nTo address this limitation, we propose expanding the dataset by collecting more replays from various sources, such as professional tournaments, online ladder games, and different game patches. This would provide a more diverse and comprehensive dataset, enabling researchers to study a wider range of strategies and better generalize their findings.\n\n\\subsection{Limitation 2: Feature Representation}\nThe current feature representation in the MSC dataset is mostly focused on global features. While these features are important for macro-management tasks, they may not capture all the relevant information needed for a complete understanding of the game state.\n\n\\paragraph{Improvement 2:}\nTo improve the feature representation, we suggest incorporating additional features that capture more detailed information about the game state. For example, adding spatial features like unit positioning and terrain information could be beneficial in capturing more nuanced aspects of the game. Furthermore, incorporating player-specific features, such as APM (actions per minute) or preferred strategies, could help researchers develop more personalized AI agents.\n\n\\subsection{Limitation 3: Baseline Models}\nThe current baseline models for tasks like global state evaluation and build order prediction are relatively simple, relying on Recurrent Neural Networks (RNNs) and GRUs. These models might not be the most effective for handling the complex and dynamic nature of StarCraft II.\n\n\\paragraph{Improvement 3:}\nWe propose exploring more advanced models and architectures, such as Transformer-based models, Graph Neural Networks (GNNs), and reinforcement learning (RL) algorithms, to better capture the intricacies of the game. These models could potentially lead to more accurate and robust predictions for macro-management tasks.\n\n\\section{New Approaches to Existing Tasks}\nIn this section, we explore new approaches to build order prediction and global state evaluation tasks by leveraging advanced machine learning techniques.\n\n\\subsection{Attention Mechanism for Global State Evaluation}\nWe propose an enhanced model for global state evaluation that incorporates the attention mechanism. By using attention, we can weigh the importance of different features in the input feature vector. This can potentially lead to better performance compared to the baseline model.\n\n\\paragraph{Model}\nWe modify the baseline model by introducing an attention layer before the GRU layer. The attention mechanism computes a weight for each feature in the input feature vector based on its relevance to the task. We use a single-layer feedforward neural network with a softmax activation function to compute the attention weights.\n\n\\paragraph{Experimental Results}\nWe train the attention-based model with the same experimental setup as the baseline and report the performance in Table~\\ref{table:attention\\_results}. The attention-based model shows a considerable improvement in global state evaluation accuracy, demonstrating the benefits of using attention mechanisms.\n\n\\begin{table}[h]\n\\begin{center}\n\\begin{tabular}{|l|c|c|c|c|c|c|}\n\\hline\nTasks & TvT & TvP & TvZ & PvP & PvZ & ZvZ \\\n\\hline\nBaseline(%) & 50.9 & 57.0 & 56.1 & 57.8 & 56.9 & 54.7 \\\n\\hline\nAttention(%) & 53.4 & 59.7 & 58.6 & 60.1 & 59.2 & 57.3 \\\n\\hline\n\\end{tabular}\n\\end{center}\n\\caption{\\textbf{Mean accuracy for global state evaluation with attention-based model.}}\n\\label{table:attention\\_results}\n\\end{table}\n\n\\subsection{Graph Neural Networks for Build Order Prediction}\nWe introduce a graph neural network (GNN) based model for build order prediction. This model considers the inherent graph structure of the game units and their interactions. We use the Graph Attention Network (GAT)~\\cite{velickovic2018graph} as the GNN layer, which is capable of learning attention weights over the graph edges.\n\n\\paragraph{Model}\nWe represent the game units and their interactions as a directed graph, where each node corresponds to a game unit and edges represent interactions between the units. The input to the GNN model is the adjacency matrix of this graph, along with node features representing the game unit properties.\n\nWe modify the baseline model by replacing the linear layers with GAT layers, which take both the node features and the adjacency matrix as inputs. The GAT layer computes an attention coefficient for each pair of nodes in the graph, which is then used to weight the node features.\n\n\\paragraph{Experimental Results}\nWe train the GNN-based model with the same experimental setup as the baseline and report the performance in Table~\\ref{table:gnn\\_results}. The GNN model significantly improves the build order prediction accuracy, demonstrating the benefits of incorporating the graph structure in the model.\n\n\\begin{table}[h]\n\\begin{center}\n\\begin{tabular}{|l|c|c|c|c|c|c|}\n\\hline\nV.S. & TvT & TvP & TvZ & PvP & PvZ & ZvZ \\\n\\hline\nBaseline(%) & 74.1 & 74.8 & 73.5 & 76.3 & 75.1 & 76.1 \\\n\\hline\nGNN(%) & 78.5 & 79.3 & 77.8 & 80.2 & 79.6 & 80.0 \\\n\\hline\n\\end{tabular}\n\\end{center}\n\\caption{\\textbf{Mean accuracy for build order prediction with GNN-based model.}}\n\\label{table:gnn\\_results}\n\\end{table}\n\n\\subsection{Discussion}\nThe new approaches proposed in this paper demonstrate the potential of advanced machine learning techniques in improving the performance of StarCraft II macro-management tasks. The attention mechanism allows the global state evaluation model to focus on more relevant features, leading to improved accuracy. Similarly, the GNN-based model captures the graph structure of game units and their interactions, resulting in a significant improvement in build order prediction accuracy.\n\nThese results open up new avenues for future research in StarCraft II macro-management tasks. Further investigation can be done to explore the combination of different machine learning techniques or the incorporation of other relevant features. This could potentially lead to the development of even more sophisticated models that can tackle a wider range of tasks in StarCraft II macro-management.\n\\section{Future Research Directions}\nWe identify several future research directions that could further advance the understanding of macro-management in StarCraft II:\n\n\\begin{itemize}\n\\item Developing AI agents capable of adapting their strategies in real on the current game state and the opponent's playstyle.\n\\item Investigating transfer learning techniques to enable AI agents to learn from one game environment and apply the knowledge to other similar environments or game patches.\n\\item Exploring the potential of multi-agent systems, where multiple AI agents collaborate to manage different aspects of macro-management, such as resource allocation, unit production, and tech tree development.\n\\item Evaluating the effectiveness of AI-generated strategies against human opponents, to better understand the practical implications and limitations of AI-driven macro-management in competitive gameplay.\n\\item Studying the impact of player-specific features on macro-management performance and exploring personalized AI agents tailored to individual playstyles.\n\\end{itemize}\n\n\\section{Conclusion}\nIn this paper, we have discussed the limitations of the MSC dataset and proposed possible improvements to address these issues. We have also suggested new approaches for existing tasks and highlighted potential future research directions. Our aim is to encourage the research community to continue developing and exploring macro-management strategies in StarCraft II, ultimately contributing to the advancement of AI agents in complex, real-time strategy games.\n\n\\small\n\\bibliographystyle{named}\n\\bibliography{ijcai18}\n\n\\end{document}\n\nThere are two Experimental Results tables, but the table has no data. Please add some lab data.", "Write me a title for this article:\nAs a homeowner in NSW, it's vital to understand the legal mechanisms governing contractual obligations transfer. One such mechanism is Deed of Novation, useful when businesses change name or transfer contracts to third parties. This article explores Deed of Novation's definition, its importance to homeowners, and its differences from other legal mechanisms. By the end, you'll have a better understanding of Deed of Novation's relevance to homeowners in NSW.\nWhat is a Deed of Novation?\nA deed of novation is a legal document that allows one party to transfer its rights and obligations under an existing contract to a new party, who takes on these responsibilities and benefits from the original contract. This document enables the original party to be released from the contract while the new party assumes all legal obligations and rights under the agreement. \n\nNovation is typically used when a business undergoes significant changes such as mergers, acquisitions, or restructuring, and there is a need to transfer existing contractual agreements to a third party.\n\nNovation differs from an assignment in that it transfers all rights and obligations, while an assignment only transfers contractual benefits. It is essential to understand the implications of novation and seek legal advice to ensure that the deed is legally binding and effectively transfers contractual rights and obligations.\nKey Components of a Deed of Novation\nA deed of novation is a simple and effective tool for transferring the rights and obligations of one party under a contract to a third party. \n\nHere are the key components that a deed of novation should include:\n\nNovation or Effective Date\nThe novation or effective date is the date on which the new party will assume all the rights and obligations under the original contract. This date is critical, as it marks the point at which the transfer of rights and obligations takes place.\n\nRelease\nA release clause in a deed of novation releases the original party from all the obligations and liabilities under the contract from the date of novation. This clause ensures that the original party is no longer liable for any obligations or liabilities under the contract.\n\nRepresentations and Warranties\nRepresentations and warranties are promises made by both parties regarding the validity of the contract and their authority to enter into it. They also ensure that both parties are aware of each other's obligations and liabilities under the contract.\n\nFees and Payments\nThe fees and payments clause outlines any fees or payments that either party must make under the contract. This clause is critical, as it ensures that both parties are aware of their financial obligations under the contract.\n\nIt is essential to ensure that all these key components are included in the deed of novation to ensure that the transfer of rights and obligations is complete and legally binding. It is always recommended to consult with a legal professional before drafting or signing any legal documents.\n\nBenefits of a Deed of Novation\nA Deed of Novation offers several benefits to parties involved in a contract. By using a Deed of Novation, you can transfer your rights and obligations under an existing contract to a third party, without the need for extensive negotiation or the termination of the original contract. This can save time, money and resources, especially if the transfer involves complex contracts or multiple parties.\n\nOne of the key benefits of a Deed of Novation is that it allows you to simplify the process of transferring contractual obligations. Rather than renegotiating a new contract, you can simply transfer the existing contract to a new party. This can be particularly useful in situations where you are selling your business or restructuring your operations.\n\nAnother advantage of a Deed of Novation is that it minimizes the need for negotiation. Since the terms of the original contract remain the same, you can avoid lengthy and complicated negotiations with the other party. This can make the process of transferring contractual obligations more straightforward and efficient.\n\nFinally, a Deed of Novation can help you avoid the termination of existing contracts. If you need to transfer your contractual obligations to a third party, but do not want to terminate the existing contract, a Deed of Novation may be the best option. This way, you can transfer the obligations to a new party, while keeping the existing contract intact.\n\nRisks Associated with a Deed of Novation\nWhile a deed of novation is a useful legal tool, it is important to be aware of the potential risks that come with it. Here are some of the most significant risks to consider:\nUnforeseen obligations and liabilities: When entering into a deed of novation, it is essential to carefully consider the obligations and liabilities that are being transferred. There may be unforeseen obligations or liabilities that the new party may not be aware of, which could lead to disputes or legal action in the future.\nLack of clarity regarding the terms of the novation: A deed of novation must clearly outline the terms of the agreement to avoid any confusion or misunderstandings between the parties. Without clear and concise terms, there is a risk that the parties may have different interpretations of their obligations and responsibilities.\nThe need for careful consideration and legal advice: As with any legal agreement, it is important to seek professional legal advice before entering into a deed of novation. This will ensure that you understand the legal implications of the agreement and the risks associated with it.\nBy being aware of these risks and taking the necessary precautions, you can mitigate potential issues and ensure that the novation process runs smoothly.\n\nCommon Scenarios for Using a Deed of Novation\nA deed of novation can be a useful legal instrument in several scenarios, some of which include:\nSale or transfer of a business: If you're selling your business or transferring its ownership to another entity, a deed of novation can help transfer the contracts and obligations to the new owner.\nChanges in business structure: When you change your business structure, for example, from a sole trader to a company, a deed of novation can be used to transfer the contractual obligations to the new entity.\nTermination of contracts: A deed of novation can be used to transfer the obligations and rights under a contract to a third party, effectively terminating the contract.\nIt's important to note that while a deed of novation can be a useful legal tool in these scenarios, it's essential to obtain legal advice to ensure that the novation is done correctly and that all parties understand their rights and obligations.\n\nHow to Draft a Deed of Novation\nA Deed of Novation is a legal document that requires careful drafting to ensure that the transfer of obligations and rights is carried out smoothly and effectively. As such, it is important to seek legal advice from a qualified lawyer experienced in drafting and executing such deeds. Here are some key considerations to keep in mind when drafting a Deed of Novation:\nImportance of Legal Advice\nIt is essential to seek legal advice before entering into a Deed of Novation. A qualified lawyer can guide you through the process, identify any potential legal issues, and ensure that the deed is legally binding and enforceable.\nKey Considerations When Drafting a Deed of Novation\nWhen drafting a Deed of Novation, it is important to consider the following:\nParties involved - Clearly identify the parties involved in the novation, including the original parties, the new parties, and any other relevant parties.\nNovation or Effective Date - Clearly state the date from which the novation applies to the parties.\nRelease - Include a clause releasing the original party from all performance of the contract from the novation date.\nRepresentations and Warranties - Include any representations or warranties made by either party.\nFees and Payments - Include any fees or payments to be made by either party.\nSample Deed of Novation\nHere is an example of a Deed of Novation template:\n[Insert date of novation]\nDeed of Novation\nParties\n[Insert original party name], (ACN/ABN [Insert ACN/ABN]) of [Insert address] (Original Party);\n[Insert new party name], (ACN/ABN [Insert ACN/ABN]) of [Insert address] (New Party).\nBackground\n[Insert details of the original contract].\nAgreed Terms\n[Insert details of the novation, including the novation or effective date, release, representations and warranties, and fees and payments].\nExecution\nExecuted as a Deed.\nExecuted by:\n[Insert name of Original Party]\n[Insert signature of Original Party]\n[Insert name of New Party]\n[Insert signature of New Party]\n\nSigning a Deed of Novation\nOnce the Deed of Novation has been drafted, it's time to execute it. The signing of a Deed of Novation is an essential step that requires careful consideration. The following are key points to keep in mind when signing a Deed of Novation:\n\nRequirements for signing a Deed of Novation:\n\nAll parties involved in the agreement must sign the Deed of Novation.\nThe signatures of witnesses may also be required, depending on the jurisdiction and the terms of the agreement.\nThe date of execution must be clearly stated on the Deed of Novation.\n\nImplications of a poorly executed Deed of Novation:\n\nThe failure to comply with the necessary legal requirements can result in the Deed of Novation being invalid, which could create legal problems down the line.\nIncomplete or unclear Deeds of Novation can cause confusion and lead to disputes.\n\nIt is therefore recommended that parties seek legal advice when executing a Deed of Novation to ensure that all legal requirements are met and that the document is executed correctly.\n\nConclusion\nIn conclusion, a Deed of Novation is an important legal document that can be used in a variety of scenarios to transfer contractual obligations. While there are benefits to using a Deed of Novation, there are also risks that must be carefully considered. Seeking legal advice is crucial to ensure that the document is drafted correctly and executed properly. \n\nAt Contracts Specialist, we offer a free consultation to homeowners in NSW who are considering a Deed of Novation. Contact us today to schedule a meeting with one of our experienced lawyers.", "can you do the same with this list, main body area and nested areas. If the area is not an anatomic are than ignore please\n\n teeth.\n face, neck, body.\n lower face, neck, and jawline.\n severe cystic acne.\n face, neck, and body.\n lower layers of skin tissue.\n laryngeal prominence of thyroid cartilage in the throat.\n facial rejuvenation.\n abdomen, hips, thighs, arms, buttocks, or under the chin.\n nostrils.\n Face and body \n upper or lower jawbone.\n facial reconstruction, abdominal wall reconstruction, breast reconstruction.\n gastric.\n nipple-areola complex.\n underarms.\n balding, thinning, or receding areas.\n nasolabial folds, or smile lines.\n small, uncomplicated spider veins and small varicose veins.\n cellulite on the thighs and buttocks.\n mild to severe acne.\n upper or lower back.\n mustache, beard, sideburns.\n face, cheeks, under-eyes, lips, nasolabial folds, pitted scars, breasts, buttocks.\n face.\n navel.\n moderate to severe facial wrinkles and folds, such as nasolabial folds, etched-in lip lines, crow's feet, smile lines, marionette lines, under-eye tear troughs, and deep glabellar lines.\n upper arms.\n incision or injury.\n face, neck, chest, back, hands, arms, and legs.\n abdomen, hips, lower back, buttocks.\n stomach, legs, arms.\n stomach, thighs, butt, hips, and arms.\n fat reduction anywhere on the body, most commonly treated body areas are the tummy, hips, thighs, flanks (aka love handles), and back. some providers also offer mini bodyfx, which can treat smaller fat deposits in areas like the upper arms and under the chin..\n abdomen, upper arms, thighs, knees, love handles, breasts, back, chin, jowls, cheeks, and neck.\n crow's feet, frown lines, forehead lines, lip lines, bunny lines on the nose, chin wrinkles, neck bands, above the eyebrows, above the upper lip.\n teeth straightening.\n buttocks, hips, waist, love handles, thighs, lower back.\n buttocks.\n breasts.\n face.\n face, neck, d'colletage, back of hands.\n double chin, jawline, knees, elbows, upper arms, muffin top.\n face, body contouring.\n teeth.\n face, neck, hands, chest, legs, and other areas.\n glabellar area.\n forehead and eyebrows.\n lower cheeks.\n foot.\n buttocks, hips, abdomen, waistline, lower back, thighs.\n lower legs.\n lower legs.\n outer corner of the eye where the upper and lower lid meet.\n scalp.\n breast.\n face, neck, arms, stomach, buttocks, and legs.\n lens of the eye.\n cellulite dimples on the buttocks and the backs of the thighs.\n thighs, abdomen, or buttocks.\n midface.\n midface.\n cheeks.\n midface.\n zygomatic bone (malar bone).\n face, neck, chest, hands.\n soft tissue under the skin.\n lower face.\n under the chin and jawline.\n fine lines, shrink the appearance of pores, improve skin tone and texture, and reduce melasma.\n teeth straightening.\n jawbone.\n face, neck, chest, lips, and anywhere on the body.\n broken capillaries, spider veins, vascular lesions, periorbital veins, skin discoloration.\n upper lip, nose, and roof of the mouth.\n clitoral hood.\n face, neck, chest.\n vagina and vulva.\n crow's feet, fine lines around the eyes, smile lines, frown lines, atrophic acne scars, and thin lips.\n brow, mid- and lower face, jawline, and neck.\n fine lines and wrinkles, sun damage, discoloration, and acne scars.\n fine lines and wrinkles, acne scars, large pore size, uneven skin tone, rough skin texture, age spots, and other signs of sun damage.\n abdomen, flanks, bra fat, inner and outer thighs, back fat, upper arms, buttock rolls, knees, hips, mons pubis, submental fat.\n thighs, butt, and abdomen.\n hyperpigmentation and skin discoloration.\n abdominal fat, love handles, upper arms, inner thighs, under chin, below buttocks, bra and back fat bulges.\n slimming, toning, and cellulite reduction.\n face.\n skin.\n teeth.\n teeth straightening.\n glabellar lines, forehead furrows, crow's feet, bunny lines, platysmal bands, dimpling of the chin, masseter muscles.\n middle and lower areas of the face.\n face, eyes, neck.\n teeth.\n jawbone, gums.\n missing teeth.\n teeth.\n upper or lower jawbone.\n face, eyes, lips.\n face, upper lip, cheeks.\n smile lines, marionette lines, lips, under-eye hollows, cheeks, temples, jawline, chin, nose.\n face, neck, chest, stomach, thighs.\n face.\n skin tightening.\n face, neck, d'colletage, body.\n abdominal muscles.\n chin or cheeks.\n vaginal tissue.\n craniofacial region.\n upper eyelids.\n stomach and small intestine.\n front of natural teeth.\n \n face, neck, chest, arms, back of hands, and elsewhere on the body.\n legs, buttocks, thighs, back, or stomach.\n teeth.\n face, neck, under chin.\n skin.\n hormonal acne, polycystic ovary syndrome (pcos), high blood pressure, congestive heart failure.\n anywhere on the body.\n excess pigmentation and redness, wrinkles and mild acne scars, vascular lesions and varicose veins, pigmented lesions and dark tattoos.\n eye alignment.\n breast augmentation, breast reconstruction, abdominal wall defects, hernia repair.\n depressed scars, acne scars, cellulite dimples.\n face, neck, and d\u00e9colletage.\n teeth alignment.\n epidermis.\n acne on face and body, psoriasis on body, sun damage.\n face.\n teeth.\n face.\n lips, cheeks, chin, forehead, eyes, mouth, neck, and chest.\n scrotum.\n face, eyes, eyelids, jawline, stomach, arms, backs of hands, thighs, knees, butt.\n breasts and nipples.\n cheeks, around the mouth, neck, forehead and around the eyes.\n lower face, jowls, neck, breasts, arms, tummy, and thighs.\n vulvar and vaginal tissues.\n thigh.\n brow, mid- and lower face, jawline, and neck.\n skin concerns.\n inner and outer thighs, back, abdomen, love handles, hips, saddlebags, and buttocks.\n face, neck, stomach, and upper arms.\n enamel, dentin, pulp.\n face, forehead, temples, chin, area around mouth, cheeks.\n wrinkles, sagging skin, fat cells, cellulite.\n abdomen and flanks.\n abdomen and flanks.\n abdomen, flanks, buttocks, thighs.\n abdomen, flanks, and thighs.\n reshaping, creating balanced, normal breasts.\n abdomen, love handles, hips, thighs, chin, upper arms, underarms.\n lower abdomen.\n abdomen.\n brow, neck (including jawline), under chin, lines and wrinkles on d'colletage.\n vaginal area.\n face and neck.\n fine lines and wrinkles, discoloration, and even scars.\n stomach, hips, and thighs.\n abdomen, hips, and thighs.\n fat layer just under the skin.\n upper arms, belly, love handles, thighs, chin.\n abdominal wall.\n eyelid.\n lower face.\n vaginal canal, opening, labia majora, vulva, labia minora, mons pubis.\n vaginal canal.\n cleavage area.\n face.\n face.\n abdomen and thighs.\n spider veins, varicose veins, and venous reflux disease.\n thighs, calves, and ankles, buttocks and hips, abdomen, back, and flanks (aka love handles), upper arms, neck and under the chin.\n rosacea, pigmented scars, spider veins, broken capillaries, birthmarks, hyperpigmentation, newly formed stretch marks, and other forms of red, brown, or purple facial pigmentation.\n legs.\n spider veins, cherry angiomas, small hemangiomas, skin tags, spider nevi, and redness from rosacea.\n thighs, buttocks, upper arms, stomach, excess fat and mildly sagging skin under the chin.\n thighs, abdomen, and butt.\n varicose veins.\n fat reduction on the back, abdomen, thighs and flanks, cellulite reduction on the thighs, buttocks, and abdomen, muscle conditioning and toning for biceps, triceps, abdominal and oblique muscles, glutes, hamstrings, and quadriceps.\n face, neck, and body.\n wrinkles, fine lines, cellulite, stretch marks.\n fine lines and deep wrinkles, acne scars, large pores, uneven skin texture, stretch marks, mild laxity, rosacea, and hyperpigmentation, including melasma.\n pelvic floor issues.\n face, neck, chest, hands.\n face and body.\n vaginal tissues, labia majora.\n pelvic floor muscles and skin elasticity.\n jaw.\n lines and wrinkles created by dynamic facial movements, such as smiling, frowning, or raising your eyebrows, neck pain caused by cervical dystonia, eye spasms known as blepharospasm, and upper limb spasticity.\n skin concerns, visible veins, brown spots, scars, laser hair removal, tattoo removal, cataract surgery.\n waist, chest, back, neck, upper arms, thighs, love handles, hips, and ankles.\n skin.\n teeth.\n lower third of face, jawline, neck.\n face, neck, and body.", "write a very short summary of 5 lines from this text: Introduction to Bookipedia\n\nWelcome to \"The Future of Reading: How Bookipedia is Changing the Way We Use Books.\" In this presentation, we will be introducing the concept of Bookipedia and discussing how it is revolutionising the way we experience literature. Bookipedia is a revolutionary platform that uses AI to enable communication with books and enhance the reading experience. With its ability to analyze the text and context of a book and generate responses to reader questions, Bookipedia offers a more interactive and personalised reading experience. This has the potential to change the way people use books and experience literature, making reading a more interactive and engaging activity. We hope that this presentation will give you a better understanding of Bookipedia and its capabilities, and encourage you to try it out for yourself and experience the future of reading.\n\nThe Limitations of Traditional Reading\n\nOne of the main limitations of traditional reading is that it is a one-sided activity. When we read a book, we absorb the information contained within the pages, but we have no way to gauge our understanding or ask for clarification. This can lead to confusion or misunderstandings, and can make it difficult to fully engage with the material. Traditional reading is also a solitary activity, which can make it harder to connect with others who have read the same book or to discuss and explore the ideas contained within it. These limitations can make reading less enjoyable and less effective as a learning tool. Bookipedia aims to overcome these limitations by providing a more interactive and personalised reading experience, enabling readers to ask questions, seek clarification, and engage in a dialogue with the book and with other readers.\n\nThe Power of AI in Reading\n\nArtificial intelligence has the power to transform many aspects of our lives, and reading is no exception. AI has the ability to analyse the text and context of a book and generate responses to reader questions, allowing for a more interactive and personalised reading experience. This can help to improve comprehension and make the reading experience more engaging and enjoyable. AI can also be used to analyse reading patterns and make recommendations for other books that a reader might be interested in, expanding the range of literature that a reader has access to. By using AI to facilitate communication with books, Bookipedia has the potential to revolutionise the way we use books and experience literature.\n\nThe Benefits of Using Bookipedia\n\nThere are many benefits to using Bookipedia as a platform for interacting with books. Some of the key benefits include:\nEnhanced reading experience: By enabling communication with books, Bookipedia makes reading a more interactive and engaging activity. This can make the reading experience more enjoyable and satisfying.\nImproved comprehension: By allowing readers to ask questions and seek clarification, Bookipedia can help to improve comprehension and ensure that readers fully understand the material they are reading.\nPersonalised learning: Bookipedia can adapt to a reader's individual needs and learning style, providing a more personalised and effective learning experience.\nAccess to a wider range of books: With its recommendation system and ability to analyze reading patterns, Bookipedia can help readers discover new books and expand their reading horizons.\nIncreased engagement with literature: By enabling dialogue and interaction with books, Bookipedia can help to foster a deeper engagement with literature and encourage readers to explore new ideas and perspectives.\nGreater convenience: Bookipedia can be accessed from any device with an internet connection, making it a convenient and portable platform for reading.\nAbility to create an action plan based on book ideas: By allowing readers to ask questions and engage with the material, Bookipedia can help readers to turn book ideas into action plans and put them into practice.\nAdaptation of book ideas to different audiences or environments: Bookipedia can help readers to adapt book ideas to different audiences or environments, making them more relevant and applicable to a wide range of situations.\nConversation with book characters: With its ability to generate responses to reader questions, Bookipedia can enable readers to have conversations with book characters, deepening their understanding and engagement with the story.\nSuggestions for alternative ideas or endings: Bookipedia can provide suggestions for alternative ideas or endings, allowing readers to explore different possibilities and perspectives.\nGreater literary analysis: By enabling dialogue and interaction with books, Bookipedia can facilitate deeper literary analysis and encourage readers to think critically about the material they are reading.\nEnhanced creativity: By providing a platform for exploration and experimentation, Bookipedia can help to enhance creativity and encourage readers to come up with new ideas and approaches.\nTesting of reader understanding through quizzes: Bookipedia can test reader understanding through quizzes and other interactive activities, helping to ensure that readers have fully grasped the material.\n\nExamples of use: \n\nWhat would you like to request about the book: Edison by Edmund Morris?write imaginary interview with Edison \nInterviewer: Welcome Mr. Edison, thank you for taking the time to speak with us today. \n\nEdison: It's my pleasure. \n\nInterviewer: You have made countless inventions in your lifetime, what would you say was your proudest accomplishment? \n\nEdison: I'm most proud of the invention of the light bulb. It was a long and arduous process, but I was determined to make a lasting contribution to humanity. The success of the light bulb changed the way people lived and worked, and it was a great honour to be a part of that. \n\nInterviewer: What advice would you give to aspiring inventors? \n\nEdison: Always be persistent and never give up. It's easy to become discouraged when faced with a difficult problem, but if you keep pushing forward, you can find a solution. Don't be afraid to take risks and try something new. You never know what you might discover.\nWhat would you like to request about the book: Edison by Edmund Morris?give me book recommendations based on this book\n1. Nikola Tesla: A Life From Beginning to End by Hourly History\n2. The Life of Thomas Alva Edison by Francis Arthur Jones\n3. Thomas Edison: A Captivating Guide to the Life of an American Inventor by Captivating History\n4. The Wizard of Menlo Park: How Thomas Alva Edison Invented the Modern World by Randall Stross\n5. The Man Who Lit the World: The Story of Thomas Edison by Robert Kraske\n6. The Inventor and the Tycoon: A Gilded Age Murder and the Birth of Moving Pictures by Edward Ball\n7. The Age of Edison: Electric Light and the Invention of Modern America by Ernest Freeberg\n8. Edison: A Biography by Matthew Josephson\n9. The Age of Invention: A Chronicle of Mechanical Conquest by Holland Thompson\n10. The Miracle of Electricity: The Life and Legacy of Thomas Edison by Charles River Editors\n\nBookipedia: A Valuable Resource for Book Authors\n\nBookipedia can be a valuable resource for book authors as well. Some of the benefits that Bookipedia can offer to authors include:\nThe ability to gauge reader understanding and provide clarification: By allowing readers to ask questions and seek clarification, Bookipedia can help authors to gauge the level of understanding of their readers and provide additional information or explanation as needed. This can lead to more engaged and satisfied readers.\nEngaging in a dialogue with readers: Bookipedia provides an opportunity for authors to engage in a dialogue with their readers and gather feedback on their work. This can be a valuable source of information and inspiration for authors, and can help them to connect with their audience in a meaningful way.\nPromoting and selling books: Bookipedia can provide a new avenue for authors to promote and sell their books, reaching a wider audience and potentially increasing the success of their work.\nIncreased popularity and success: By enabling a more interactive and personalised reading experience, Bookipedia has the potential to increase the popularity and success of an author's work. Readers who are more engaged and satisfied with their reading experience are more likely to recommend the book to others and continue reading the author's work in the future.\n\nThe Endless Possibilities of Bookipedia:\n\nBookipedia is a platform that is constantly evolving and innovating. There are endless possibilities for the future development of Bookipedia and the ways in which it can revolutionise the way we use books and experience literature. Some potential future developments and innovations for Bookipedia include:\nIntegration with virtual reality or augmented reality technologies: Bookipedia could potentially be integrated with virtual reality or augmented reality technologies to create an even more immersive reading experience. This could allow readers to explore the world of a book in a more interactive and engaging way.\nExpansion into other languages: Bookipedia has the potential to expand into other languages and reach a global audience, making it a truly international platform for reading and communication.\nNew features and functionality: Bookipedia could potentially add new features or functionality to the platform, such as the ability to connect with other readers or form book clubs. This could enhance the sense of community and encourage readers to engage with each other and discuss their reading experiences.\nContinual evolution: Bookipedia will continue to evolve and innovate as new technologies and ideas emerge. This means that the possibilities for the future of Bookipedia are truly endless, and we can look forward to exciting new developments in the world of reading.\nUseful tool for book authors to update the content of their books onlilne\n\nA Revolution in Reading: The Impact of Bookipedia\n\nBookipedia is a revolutionary platform that is changing the way we use books and experience literature. With its ability to enable communication with books and provide a more interactive and personalised reading experience, Bookipedia has the potential to transform the way we think about reading. By making reading a more interactive and engaging activity, Bookipedia can help to improve comprehension, foster a deeper engagement with literature, and encourage readers to explore new ideas and perspectives. The impact of Bookipedia is not limited to readers, however. Book authors can also benefit from the platform, using it to gauge reader understanding, gather feedback, and promote their work. The marketing approach that Bookipedia is using to reach a wide audience of readers, as well as its viral marketing strategy, is helping to spread the word about the platform and its capabilities. With its potential for future development and innovation, Bookipedia is poised to continue revolutionising the way we use books and experience literature.", "---------------------------------------------------------------------------\nLookupError Traceback (most recent call last)\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 83 try:\n---> 84 root = nltk.data.find(f\"{self.subdir}/{zip\\_name}\")\n 85 except LookupError:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\data.py in find(resource\\_name, paths)\n 582 resource\\_not\\_found = f\"\\n{sep}\\n{msg}\\n{sep}\\n\"\n--> 583 raise LookupError(resource\\_not\\_found)\n 584 \n\nLookupError: \n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n Resource omw-1.4 not found.\n Please use the NLTK Downloader to obtain the resource:\n\n >>> import nltk\n >>> nltk.download('omw-1.4')\n \n For more information see: https://www.nltk.org/data.html\n\n Attempted to load corpora/omw-1.4.zip/omw-1.4/\n\n Searched in:\n - 'C:\\\\Users\\\\rockr/nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\share\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\lib\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\AppData\\\\Roaming\\\\nltk\\_data'\n - 'C:\\\\nltk\\_data'\n - 'D:\\\\nltk\\_data'\n - 'E:\\\\nltk\\_data'\n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\nDuring handling of the above exception, another exception occurred:\n\nLookupError Traceback (most recent call last)\n~\\AppData\\Local\\Temp\\ipykernel\\_9724\\3827873343.py in \n 41 \n 42 # Preprocess train and test text data\n---> 43 train\\_df['text'] = train\\_df['text'].apply(preprocess\\_text)\n 44 test\\_df['text'] = test\\_df['text'].apply(preprocess\\_text)\n 45 \n\n~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py in apply(self, func, convert\\_dtype, args, \\*\\*kwargs)\n 4431 dtype: float64\n 4432 \"\"\"\n-> 4433 return SeriesApply(self, func, convert\\_dtype, args, kwargs).apply()\n 4434 \n 4435 def \\_reduce(\n\n~\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py in apply(self)\n 1086 return self.apply\\_str()\n 1087 \n-> 1088 return self.apply\\_standard()\n 1089 \n 1090 def agg(self):\n\n~\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py in apply\\_standard(self)\n 1141 # List[Union[Callable[..., Any], str]]]]]\"; expected\n 1142 # \"Callable[[Any], Any]\"\n-> 1143 mapped = lib.map\\_infer(\n 1144 values,\n 1145 f, # type: ignore[arg-type]\n\n~\\Anaconda3\\lib\\site-packages\\pandas\\\\_libs\\lib.pyx in pandas.\\_libs.lib.map\\_infer()\n\n~\\AppData\\Local\\Temp\\ipykernel\\_9724\\3827873343.py in preprocess\\_text(text)\n 35 # Lemmatize\n 36 lemmatizer = WordNetLemmatizer()\n---> 37 tokens = [lemmatizer.lemmatize(token) for token in tokens]\n 38 # Join tokens back into a string\n 39 text = ' '.join(tokens)\n\n~\\AppData\\Local\\Temp\\ipykernel\\_9724\\3827873343.py in (.0)\n 35 # Lemmatize\n 36 lemmatizer = WordNetLemmatizer()\n---> 37 tokens = [lemmatizer.lemmatize(token) for token in tokens]\n 38 # Join tokens back into a string\n 39 text = ' '.join(tokens)\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\stem\\wordnet.py in lemmatize(self, word, pos)\n 43 :return: The lemma of `word`, for the given `pos`.\n 44 \"\"\"\n---> 45 lemmas = wn.\\_morphy(word, pos)\n 46 return min(lemmas, key=len) if lemmas else word\n 47 \n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_getattr\\_\\_(self, attr)\n 119 raise AttributeError(\"LazyCorpusLoader object has no attribute '\\_\\_bases\\_\\_'\")\n 120 \n--> 121 self.\\_\\_load()\n 122 # This looks circular, but its not, since \\_\\_load() changes our\n 123 # \\_\\_class\\_\\_ to something new:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 87 \n 88 # Load the corpus.\n---> 89 corpus = self.\\_\\_reader\\_cls(root, \\*self.\\_\\_args, \\*\\*self.\\_\\_kwargs)\n 90 \n 91 # This is where the magic happens! Transform ourselves into\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py in \\_\\_init\\_\\_(self, root, omw\\_reader)\n 1174 )\n 1175 else:\n-> 1176 self.provenances = self.omw\\_prov()\n 1177 \n 1178 # A cache to store the wordnet data of multiple languages\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py in omw\\_prov(self)\n 1283 provdict = {}\n 1284 provdict[\"eng\"] = \"\"\n-> 1285 fileids = self.\\_omw\\_reader.fileids()\n 1286 for fileid in fileids:\n 1287 prov, langfile = os.path.split(fileid)\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_getattr\\_\\_(self, attr)\n 119 raise AttributeError(\"LazyCorpusLoader object has no attribute '\\_\\_bases\\_\\_'\")\n 120 \n--> 121 self.\\_\\_load()\n 122 # This looks circular, but its not, since \\_\\_load() changes our\n 123 # \\_\\_class\\_\\_ to something new:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 84 root = nltk.data.find(f\"{self.subdir}/{zip\\_name}\")\n 85 except LookupError:\n---> 86 raise e\n 87 \n 88 # Load the corpus.\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 79 else:\n 80 try:\n---> 81 root = nltk.data.find(f\"{self.subdir}/{self.\\_\\_name}\")\n 82 except LookupError as e:\n 83 try:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\data.py in find(resource\\_name, paths)\n 581 sep = \"\\*\" \\* 70\n 582 resource\\_not\\_found = f\"\\n{sep}\\n{msg}\\n{sep}\\n\"\n--> 583 raise LookupError(resource\\_not\\_found)\n 584 \n 585 \n\nLookupError: \n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n Resource omw-1.4 not found.\n Please use the NLTK Downloader to obtain the resource:\n\n >>> import nltk\n >>> nltk.download('omw-1.4')\n \n For more information see: https://www.nltk.org/data.html\n\n Attempted to load corpora/omw-1.4\n\n Searched in:\n - 'C:\\\\Users\\\\rockr/nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\share\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\lib\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\AppData\\\\Roaming\\\\nltk\\_data'\n - 'C:\\\\nltk\\_data'\n - 'D:\\\\nltk\\_data'\n - 'E:\\\\nltk\\_data'\n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\nplease fix this error", "---------------------------------------------------------------------------\nLookupError Traceback (most recent call last)\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 83 try:\n---> 84 root = nltk.data.find(f\"{self.subdir}/{zip\\_name}\")\n 85 except LookupError:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\data.py in find(resource\\_name, paths)\n 582 resource\\_not\\_found = f\"\\n{sep}\\n{msg}\\n{sep}\\n\"\n--> 583 raise LookupError(resource\\_not\\_found)\n 584 \n\nLookupError: \n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n Resource omw-1.4 not found.\n Please use the NLTK Downloader to obtain the resource:\n\n >>> import nltk\n >>> nltk.download('omw-1.4')\n \n For more information see: https://www.nltk.org/data.html\n\n Attempted to load corpora/omw-1.4.zip/omw-1.4/\n\n Searched in:\n - 'C:\\\\Users\\\\rockr/nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\share\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\lib\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\AppData\\\\Roaming\\\\nltk\\_data'\n - 'C:\\\\nltk\\_data'\n - 'D:\\\\nltk\\_data'\n - 'E:\\\\nltk\\_data'\n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\nDuring handling of the above exception, another exception occurred:\n\nLookupError Traceback (most recent call last)\n~\\AppData\\Local\\Temp\\ipykernel\\_9724\\3118448898.py in \n 42 \n 43 # Preprocess train and test text data\n---> 44 train\\_df['text'] = train\\_df['text'].apply(preprocess\\_text)\n 45 test\\_df['text'] = test\\_df['text'].apply(preprocess\\_text)\n 46 \n\n~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py in apply(self, func, convert\\_dtype, args, \\*\\*kwargs)\n 4431 dtype: float64\n 4432 \"\"\"\n-> 4433 return SeriesApply(self, func, convert\\_dtype, args, kwargs).apply()\n 4434 \n 4435 def \\_reduce(\n\n~\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py in apply(self)\n 1086 return self.apply\\_str()\n 1087 \n-> 1088 return self.apply\\_standard()\n 1089 \n 1090 def agg(self):\n\n~\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py in apply\\_standard(self)\n 1141 # List[Union[Callable[..., Any], str]]]]]\"; expected\n 1142 # \"Callable[[Any], Any]\"\n-> 1143 mapped = lib.map\\_infer(\n 1144 values,\n 1145 f, # type: ignore[arg-type]\n\n~\\Anaconda3\\lib\\site-packages\\pandas\\\\_libs\\lib.pyx in pandas.\\_libs.lib.map\\_infer()\n\n~\\AppData\\Local\\Temp\\ipykernel\\_9724\\3118448898.py in preprocess\\_text(text)\n 36 # Lemmatize\n 37 lemmatizer = WordNetLemmatizer()\n---> 38 tokens = [lemmatizer.lemmatize(token) for token in tokens]\n 39 # Join tokens back into a string\n 40 text = ' '.join(tokens)\n\n~\\AppData\\Local\\Temp\\ipykernel\\_9724\\3118448898.py in (.0)\n 36 # Lemmatize\n 37 lemmatizer = WordNetLemmatizer()\n---> 38 tokens = [lemmatizer.lemmatize(token) for token in tokens]\n 39 # Join tokens back into a string\n 40 text = ' '.join(tokens)\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\stem\\wordnet.py in lemmatize(self, word, pos)\n 43 :return: The lemma of `word`, for the given `pos`.\n 44 \"\"\"\n---> 45 lemmas = wn.\\_morphy(word, pos)\n 46 return min(lemmas, key=len) if lemmas else word\n 47 \n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_getattr\\_\\_(self, attr)\n 119 raise AttributeError(\"LazyCorpusLoader object has no attribute '\\_\\_bases\\_\\_'\")\n 120 \n--> 121 self.\\_\\_load()\n 122 # This looks circular, but its not, since \\_\\_load() changes our\n 123 # \\_\\_class\\_\\_ to something new:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 87 \n 88 # Load the corpus.\n---> 89 corpus = self.\\_\\_reader\\_cls(root, \\*self.\\_\\_args, \\*\\*self.\\_\\_kwargs)\n 90 \n 91 # This is where the magic happens! Transform ourselves into\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py in \\_\\_init\\_\\_(self, root, omw\\_reader)\n 1174 )\n 1175 else:\n-> 1176 self.provenances = self.omw\\_prov()\n 1177 \n 1178 # A cache to store the wordnet data of multiple languages\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py in omw\\_prov(self)\n 1283 provdict = {}\n 1284 provdict[\"eng\"] = \"\"\n-> 1285 fileids = self.\\_omw\\_reader.fileids()\n 1286 for fileid in fileids:\n 1287 prov, langfile = os.path.split(fileid)\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_getattr\\_\\_(self, attr)\n 119 raise AttributeError(\"LazyCorpusLoader object has no attribute '\\_\\_bases\\_\\_'\")\n 120 \n--> 121 self.\\_\\_load()\n 122 # This looks circular, but its not, since \\_\\_load() changes our\n 123 # \\_\\_class\\_\\_ to something new:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 84 root = nltk.data.find(f\"{self.subdir}/{zip\\_name}\")\n 85 except LookupError:\n---> 86 raise e\n 87 \n 88 # Load the corpus.\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py in \\_\\_load(self)\n 79 else:\n 80 try:\n---> 81 root = nltk.data.find(f\"{self.subdir}/{self.\\_\\_name}\")\n 82 except LookupError as e:\n 83 try:\n\n~\\Anaconda3\\lib\\site-packages\\nltk\\data.py in find(resource\\_name, paths)\n 581 sep = \"\\*\" \\* 70\n 582 resource\\_not\\_found = f\"\\n{sep}\\n{msg}\\n{sep}\\n\"\n--> 583 raise LookupError(resource\\_not\\_found)\n 584 \n 585 \n\nLookupError: \n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n Resource omw-1.4 not found.\n Please use the NLTK Downloader to obtain the resource:\n\n >>> import nltk\n >>> nltk.download('omw-1.4')\n \n For more information see: https://www.nltk.org/data.html\n\n Attempted to load corpora/omw-1.4\n\n Searched in:\n - 'C:\\\\Users\\\\rockr/nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\share\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\Anaconda3\\\\lib\\\\nltk\\_data'\n - 'C:\\\\Users\\\\rockr\\\\AppData\\\\Roaming\\\\nltk\\_data'\n - 'C:\\\\nltk\\_data'\n - 'D:\\\\nltk\\_data'\n - 'E:\\\\nltk\\_data'\n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n\nstill error", "When I run this code \n\"from pytube import YouTube\nimport os\nimport subprocess\n\n# Function to download a video\nfrom slugify import slugify\nimport os\n\ndef download\\_video(url, save\\_path):\n yt = YouTube(url)\n title = yt.title\n title = title.replace(\"The \",\"\").replace(\"the \",\"\") # remove \"The\" and \"the\" from the title\n title = slugify(title) # slugify the title\n if not os.path.exists(save\\_path):\n os.makedirs(save\\_path)\n audio\\_stream = yt.streams.filter(only\\_audio=True, file\\_extension='mp4').first()\n video\\_stream = yt.streams.filter(file\\_extension='mp4', resolution='1080p').first()\n audio\\_file\\_path = os.path.join(save\\_path, title+'\\_audio.mp3')\n video\\_file\\_path = os.path.join(save\\_path, title+'\\_video.mp4')\n try:\n audio\\_stream.download(output\\_path=save\\_path,filename=title+'\\_audio.mp3')\n except Exception as e:\n print(f\"An error occurred while downloading audio: {e}\")\n try:\n video\\_stream.download(output\\_path=save\\_path,filename=title+'\\_video.mp4')\n except Exception as e:\n print(f\"An error occurred while downloading video: {e}\")\n return title, audio\\_file\\_path, video\\_file\\_path\n\n# Function to merge the audio and video files\ndef merge\\_audio\\_video(audio\\_path, video\\_path, output\\_path):\n command = f'C:\\\\windows\\\\ffmpeg\\\\bin\\\\ffmpeg.exe -i {audio\\_path} -i {video\\_path} -c:v copy -c:a aac -strict experimental {output\\_path}'\n result = subprocess.run(command, shell=True)\n if result.returncode != 0:\n print(\"An error occurred while running ffmpeg.\")\n else:\n print(\"ffmpeg ran successfully.\")\n# Function to edit the merged file\ndef edit\\_video(input\\_path, output\\_path, start\\_time, duration):\n command = f'C:\\\\windows\\\\ffmpeg\\\\bin\\\\ffmpeg.exe -i {input\\_path} -ss {start\\_time} -t {duration} {output\\_path}'\n result = subprocess.run(command, shell=True)\n if result.returncode != 0:\n print(\"An error occurred while running ffmpeg.\")\n else:\n print(\"ffmpeg ran successfully.\")\n\n# Retrieve the URLs for the videos you want to download\nvideo\\_urls = ['https://www.youtube.com/watch?v=ySdjwk0A3n0']\n\n# Define the save path\nsave\\_path = \"C:\\\\Shorts\"\n\n# Define the start time and duration for the video\nstart\\_time = \"00:00:10\"\nduration = \"00:00:20\"\n\n# Download the videos\nfor url in video\\_urls:\n title, audio\\_file\\_path, video\\_file\\_path = download\\_video(url, save\\_path)\n output\\_path = os.path.join(save\\_path, title + '\\_merged.mp4')\n merge\\_audio\\_video(audio\\_file\\_path, video\\_file\\_path, output\\_path)\n input\\_path = output\\_path\n output\\_path = os.path.join(save\\_path, title + '\\_edited.mp4')\n edit\\_video(input\\_path, output\\_path, start\\_time, duration)\n print(\"Final Video saved in the following path: \" + output\\_path + '.mp4')\"\n\nI get this error\n\n'youtube-dl' is not recognized as an internal or external command,\noperable program or batch file.\nffmpeg version 2023-01-12-git-fc263f073e-full\\_build-www.gyan.dev Copyright (c) 2000-2023 the FFmpeg developers\n built with gcc 12.2.0 (Rev7, Built by MSYS2 project)\n configuration: --enable-gpl --enable-version3 --enable-static --disable-w32threads --disable-autodetect --enable-fontconfig --enable-iconv --enable-gnutls --enable-libxml2 --enable-gmp --enable-bzlib --enable-lzma --enable-libsnappy --enable-zlib --enable-librist --enable-libsrt --enable-libssh --enable-libzmq --enable-avisynth --enable-libbluray --enable-libcaca --enable-sdl2 --enable-libaribb24 --enable-libdav1d --enable-libdavs2 --enable-libuavs3d --enable-libzvbi --enable-librav1e --enable-libsvtav1 --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxavs2 --enable-libxvid --enable-libaom --enable-libjxl --enable-libopenjpeg --enable-libvpx --enable-mediafoundation --enable-libass --enable-frei0r --enable-libfreetype --enable-libfribidi --enable-liblensfun --enable-libvidstab --enable-libvmaf --enable-libzimg --enable-amf --enable-cuda-llvm --enable-cuvid --enable-ffnvcodec --enable-nvdec --enable-nvenc --enable-d3d11va --enable-dxva2 --enable-libvpl --enable-libshaderc --enable-vulkan --enable-libplacebo --enable-opencl --enable-libcdio --enable-libgme --enable-libmodplug --enable-libopenmpt --enable-libopencore-amrwb --enable-libmp3lame --enable-libshine --enable-libtheora --enable-libtwolame --enable-libvo-amrwbenc --enable-libilbc --enable-libgsm --enable-libopencore-amrnb --enable-libopus --enable-libspeex --enable-libvorbis --enable-ladspa --enable-libbs2b --enable-libflite --enable-libmysofa --enable-librubberband --enable-libsoxr --enable-chromaprint\n libavutil 57. 43.100 / 57. 43.100\n libavcodec 59. 56.100 / 59. 56.100\n libavformat 59. 35.100 / 59. 35.100\n libavdevice 59. 8.101 / 59. 8.101\n libavfilter 8. 53.100 / 8. 53.100\n libswscale 6. 8.112 / 6. 8.112\n libswresample 4. 9.100 / 4. 9.100\n libpostproc 56. 7.100 / 56. 7.100\nC:\\Shorts\\shorts.mp3: No such file or directory\nAn error occurred while running ffmpeg.\nffmpeg version 2023-01-12-git-fc263f073e-full\\_build-www.gyan.dev Copyright (c) 2000-2023 the FFmpeg developers\n built with gcc 12.2.0 (Rev7, Built by MSYS2 project)\n configuration: --enable-gpl --enable-version3 --enable-static --disable-w32threads --disable-autodetect --enable-fontconfig --enable-iconv --enable-gnutls --enable-libxml2 --enable-gmp --enable-bzlib --enable-lzma --enable-libsnappy --enable-zlib --enable-librist --enable-libsrt --enable-libssh --enable-libzmq --enable-avisynth --enable-libbluray --enable-libcaca --enable-sdl2 --enable-libaribb24 --enable-libdav1d --enable-libdavs2 --enable-libuavs3d --enable-libzvbi --enable-librav1e --enable-libsvtav1 --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxavs2 --enable-libxvid --enable-libaom --enable-libjxl --enable-libopenjpeg --enable-libvpx --enable-mediafoundation --enable-libass --enable-frei0r --enable-libfreetype --enable-libfribidi --enable-liblensfun --enable-libvidstab --enable-libvmaf --enable-libzimg --enable-amf --enable-cuda-llvm --enable-cuvid --enable-ffnvcodec --enable-nvdec --enable-nvenc --enable-d3d11va --enable-dxva2 --enable-libvpl --enable-libshaderc --enable-vulkan --enable-libplacebo --enable-opencl --enable-libcdio --enable-libgme --enable-libmodplug --enable-libopenmpt --enable-libopencore-amrwb --enable-libmp3lame --enable-libshine --enable-libtheora --enable-libtwolame --enable-libvo-amrwbenc --enable-libilbc --enable-libgsm --enable-libopencore-amrnb --enable-libopus --enable-libspeex --enable-libvorbis --enable-ladspa --enable-libbs2b --enable-libflite --enable-libmysofa --enable-librubberband --enable-libsoxr --enable-chromaprint\n libavutil 57. 43.100 / 57. 43.100\n libavcodec 59. 56.100 / 59. 56.100\n libavformat 59. 35.100 / 59. 35.100\n libavdevice 59. 8.101 / 59. 8.101\n libavfilter 8. 53.100 / 8. 53.100\n libswscale 6. 8.112 / 6. 8.112\n libswresample 4. 9.100 / 4. 9.100\n libpostproc 56. 7.100 / 56. 7.100\nC:\\Shorts\\i-survived-50-hours-in-antarctica\\_merged.mp4: No such file or directory\nAn error occurred while running ffmpeg.\nFinal Video saved in the following path: C:\\Shorts\\i-survived-50-hours-in-antarctica\\_edited.mp4.mp4\nThe thread 'MainThread' (0x1) has exited with code 0 (0x0).\nThe program 'python.exe' has exited with code 4294967295 (0xffffffff).", "can you assess the strong points and areas for improvement ifor the research proposal of an undergraduate student below, focusing on paragraph cohesion, sentence balance, flow and spelling and grammar accuracy. if possible add an assessment if the language level in English, based on the Common European Framework - Dune Blot\nBiomedical Sciences\nAcademic Year: 2022-23\n\nA proposal to defining the correlation between endometriosis risk and gene variants through the studies of genome-wide association and exome sequencing\n\nEndometriosis is a chronic disease which is estimated to affect 10% of women globally and often manifests as pelvic pain and/or infertility1. These symptoms result from an overgrowth of ectopic endometrial tissue2. Endometriosis is commonly misdiagnosed for several reasons, the most notable being that pelvic pain is a symptom which overlaps with other gynecological diseases, and the lack of knowledge regarding its pathogenesis3.\n\nHowever, research demonstrates that endometriosis is a partly genetically inherited disease (with a heritability of ~50%)4,5 By defining the genetic profile of endometriosis, genetic screening could provide an alternative diagnosis method and eliminate unnecessary diagnostic procedures, which would facilitate patients receiving the treatment they require.\n\nRecently, genome research tools have been developed, such as genome-wide association (GWA) studies and exome sequencing. Through GWA studies, several candidate genes associated with endometriosis risk have been discovered, which will be discussed further on in light of a systematic literature review on endometriosis GWA studies. On the other hand, exome sequencing of endometriosis has been conducted in very few studies; there are no relevant systematic literature reviews published to date. Thus, a case-control study in Greece (Matalliotakis et al, 2017)6 will be discussed to illustrate the importance of investing in exome sequencing.\n\nIn light of this research, this paper proposes a novel combined research method of GWA and exome sequencing studies, addressing the lack of multidisciplinary studies on this topic. This could contribute to identifying the endometriosis genome, which is of great significance for the diagnosis and treatment of endometriosis.\n\nA systematic review of GWA-studies of endometriosis\nA GWA study takes a large population of patients that share a characteristic (ie, a disease) and a population of controls that do not share this characteristic. Then, the most frequently appearing genetic risk variants in these genomes are highlighted and considered as possible contributing genes to this characteristic\u2014in this case endometriosis risk. These highlighted genes are the candidate genes.\n\nIn 2020, Cardoso et al7 published a systematic literature review on endometriosis. The goal of this systematic review was to describe the candidate genes and single-nucleotide polymorphisms (SNP) identified thus far, and to discuss the conflicting results of these 15 studies. The results of this review pointed to 11 candidate genes or SNPs that might be associated with an increased endometriosis risk. However, the authors identified a number of confounding factors, the most notable being the overrepresentation of Caucasian patients, and the small sample sizes of many studies. Therefore, the authors emphasize the importance of conducting GWA studies on large populations of differing ethnic backgrounds to accurately identify the risk variants specific to these distinct populations.\n\nExome sequencing of endometriosis: a study in Greece\nSimilar to GWA studies, exome sequencing selects a patient population and a control group. A specific portion of DNA of these populations are sequenced, which contain the loci of the candidate genes found through GWA studies. Then, a correlation between the possible risk variants and the disease is determined. Mutations in protein-coding DNA sequences contribute to increased disease risk. Therefore, exome sequencing does not sequence the entire genome\u2014which includes junk DNA as well\u2014but only the exome. Therefore, exome sequencing is a cost-effective approach to genome research, which is interesting for conducting these studies in larger quantities, globally.\n\nIn a population of 166 Greek women with endometriosis and 150 controls, Matalliotakis et al (2017)6 examined three single nucleotide polymorphisms (SNPs) to determine if they were correlated with endometriosis risk. These SNPs were rs7521902, rs10859871, rs11031006 which map to the genetic loci WNT4, VEZT, and FSHB, respectively. These SNPs were selected based on a meta-analysis of GWA studies8. Their findings indicate that the allele variants located on the loci WNT4 and FSHB could be correlated with endometriosis risk. These results are promising and could extend our knowledge of endometriosis genomics. However, they may not be applicable to every population.\n\nThe importance of combining GWAS and exome sequencing, and discussing study parameters\nGWA studies are a fairly novel tool to quickly identify the allele frequency in patients\u2019 genomes to find a relatively plausible set of candidate genes, which subsequently can be examined in exome sequencing studies. However, there are underlying genetic factors that complicate the study of endometriosis genomics. For instance, epistatic reactions, where one gene variant can \u201covershadow\u201d another gene, thereby rendering the causal gene unidentifiable1. This is, as of date, impossible to examine through the software used in GWA studies due to limited computational power. Thus, the use of exome sequencing to fill in these gaps of genetical information will be crucial to unravel the endometriosis genome1.\n\nHowever, exome sequencing remains critically dependent on reliable GWA data. More specifically, small sample size, lack of ethnic diversity, and incomplete patient characteristics are detrimental to the proper interpretation of a GWA study1. In the study by Matalliotakis et al (2017)6, candidate genes association rates differed according to clinical disease stage. Thus, Lalami et al1 insist that classifying patients according to their clinical characteristics is a key component to improving the detection of relevant candidate genes.\n\nThe inheritable nature of endometriosis has been well established for decades. The study of genome-wide association has improved our understanding of the genetic basis of this disease. However, endometriosis is heterogeneous and complex; its genomics have yet to be extensively researched to the point where these findings can be utilized in clinical practice. The limited amount of research published to date is a testament to this. Clearly, additional exome sequencing studies are required.\n\nOverall, researchers agree on the need to conduct GWA studies in large, ethnically diverse, and clinically well characterized patient populations.. This is expected to yield a selection of reliable candidate genes which in turn may be investigated thoroughly in smaller (familial) populations through exome sequencing. Narrowing down this selection will ensure that exome sequencing can be utilized cost-effectively, therefore more studies may be conducted. Consequently, our knowledge of its pathogenesis can be broadened. This would lead to opportunities in developing medicine for treatment and genetic screenings for diagnoses. As a result, women with endometriosis would benefit from this advancement in women\u2019s medical health.\n\n\n\n\nBibliography\n1. Lalami I, Abo C, Borghese B, Chapron C, Vaiman D. Genomics of Endometriosis: From Genome Wide Association Studies to Exome Sequencing. Int J Mol Sci. Jul 7 2021;22(14)doi:10.3390/ijms22147297\n2. Sampson JA. Metastatic or Embolic Endometriosis, due to the Menstrual Dissemination of Endometrial Tissue into the Venous Circulation. Am J Pathol. Mar 1927;3(2):93-110.43. \n3. Chapron C, Marcellin L, Borghese B, Santulli P. Rethinking mechanisms, diagnosis and management of endometriosis. Nat Rev Endocrinol. Nov 2019;15(11):666-682. doi:10.1038/s41574-019-0245-z\n4. Treloar SA, O'Connor DT, O'Connor VM, Martin NG. Genetic influences on endometriosis in an Australian twin sample. sueT@qimr.edu.au. Fertil Steril. Apr 1999;71(4):701-10. doi:10.1016/s0015-0282(98)00540-8\n5. Saha R, Pettersson HJ, Svedberg P, et al. Heritability of endometriosis. Fertil Steril. Oct 2015;104(4):947-952. doi:10.1016/j.fertnstert.2015.06.035\n6. Matalliotakis M, Zervou MI, Matalliotaki C, et al. The role of gene polymorphisms in endometriosis. Mol Med Rep. Nov 2017;16(5):5881-5886. doi:10.3892/mmr.2017.7398\n7. Cardoso JV, Perini JA, Machado DE, Pinto R, Medeiros R. Systematic review of genome-wide association studies on susceptibility to endometriosis. Eur J Obstet Gynecol Reprod Biol. Dec 2020;255:74-82. doi:10.1016/j.ejogrb.2020.10.017\n8. Rahmioglu N, Nyholt DR, Morris AP, Missmer SA, Montgomery GW, Zondervan KT. Genetic variants underlying risk of endometriosis: insights from meta-analysis of eight genome-wide association and replication datasets. Hum Reprod Update. Sep-Oct 2014;20(5):702-16. doi:10.1093/humupd/dmu015", "CHAPTER FOUR\n The Spectrum of Pain: Four Patients\n From Jeremy\nYou\u2019ve read the story of my back pain. Maybe it sounded familiar (I hope not; it was a bear). In any event, read the next four case histories, because one of them is likely to remind you a lot of yourself. The idea is for you to see where you fit on the spectrum of back pain problems. \nFit Fred\nA lot of my Aspen-based patients are fit, knowledgeable, and a little surprised to find themselves in need of professional help for back pain. A recent patient, call him Fit Fred, is typical. He is fifty-five years old, a nice guy, in good shape, and smart. He has had serious back pain for six months. In his case, that means a bothersome ache in his lower back almost all the time. And intermittent periods of excruciating pain, once every two weeks or so. Those interludes\u2014which have happened more often recently\u2014last from a few minutes to more than an hour. It is those intervals that have driven him to seek treatment.\nI am not his first stop. He\u2019s tried traditional chiropractic doctors, physical therapy, massage, and Rolfing. His back pain gets a little better for a time, and then comes back full force. When the pain is at its worst, he\u2019s stuck in bed or on the floor. He has tried traditional medicine, too, and his doctor is asking him to consider surgery. He has come to me first, because he has heard how often back surgery does not work, and he dreads that option, but he\u2019s getting closer to taking it. \n\u201cMy doctor says I have degenerative disc disease. He says I have the MRI of an eighty-year-old!\u201d (It is almost a comfort to him to think that he had \u201cdegenerative disc disease\u201d and that an operation may fix it. He\u2019s had enough. He\u2019s giving the nonmedical approach one more chance. Then it\u2019s the knife.) \nIn reality, \u201cdegenerative disc disease\u201d is a term used to describe a host of changes in the spine as a result of, or in addition to, a loss of disc height (compression) over time. As a diagnostic matter, saying that someone has degenerative disc disease doesn\u2019t amount to an awful lot more than saying that he or she is getting a little older and that his or her back hurts. That sounds a little snide, I\u2019m afraid, but it\u2019s true. Because Fred seems to have decent posture and is in pretty good shape, I suspect that his problem is going to be related to the normal degenerative changes of the spine that go with aging and bad repetitive motions. Maybe golf, maybe yoga. Depending on how open he is to change, this could be a comparatively easy case. \nIt won\u2019t sound easy, if I go into the details. After all, compression of the spine through normal aging does do some serious things. They can include arthritic changes in the facet joints (remember them?), loss of cartilage around all the joints, foraminal stenosis, which\u2014you will recall\u2014is a narrowing of the opening, or foramen, from which the nerve roots exit the spine. It may be spondylolisthesis, which is a slippage of one vertebra over another, causing pain and instability\u2014and is almost as nasty as it is unpronounceable. That all sounds awful, but they are normal concomitants of aging and degeneration of the spine and bad movements\u2014my normal material. Those we can fix. \nAs for his eighty-year-old\u2019s MRI, it probably does look pretty grim. But I have to tell you, almost all MRIs of people over forty look terrible. Stuff happens, and the individual manifestations look very scary. But they are not really all that bad. Which is why I rarely prescribe MRIs unless there are signs of the scary stuff (cancer, infection, fracture, etc.); they don\u2019t tell me anything I don\u2018t already know. \u201cHey, you\u2019re getting older, your back is getting squished. What did you expect?\u201d It\u2019s more sophisticated than that, but that\u2019s a fair summary in most cases. It is also a fair description of a condition you and I can fix, with behavioral change and hard work.\nI ask Fred a couple of questions about the therapy he\u2019s had so far. The chiropractor has just been manipulating him with no mention of exercise. I know that\u2019s not going to work for a permanent fix. And the physical therapist does not seem to have much of a plan: He has had my new patient do four exercises for three months\u2014always the same four, over and over, with no supervision and no progression. And neither of them has discussed his other activities (sports, work, exercises, etc.) with him. Beyond that, they are not the kind of exercises I will suggest because, among other things, they have done nothing to affect the endurance of the muscles of the core. This is by no means a slight on all chiropractors or physical therapists. There are some great ones out there. Some practice the way Fred\u2019s did, and some don\u2019t. Later in the book, we give you some pointers on finding good ones.\nFred really is active, God bless him, but he\u2019s doing some activities that, I suspect, are not helping his back. He does quite a lot of yoga, plays golf regularly, and lifts weights in the gym. A very responsible, fit guy, as I say. But what I know, without seeing him do yoga or play golf, is that some of the movements in those two activities are often a source of serious back injury over time. There is a safe, spine-healthy way to do yoga but, done wrong, as it often is, it can cause terrible problems. For now, I tell him to lay off yoga completely for at least two months. He can get back to it in time with some modifications. The same with golf. Golf is a wonderful activity. Not great exercise (contrary to what so many insist) but a wonderful way to be with friends and go to beautiful places. It can also be, structurally, one of the worst things you can do to your back. (All that one-way twisting of your lumbar spine.) There is a spine-healthy way to play golf, but for now I just tell him to lay off the golf until he is educated enough to be open to some instruction on a \u201cright way\u201d to play. [Hint: You learn to rotate with your hips more at the end of your swing, and less with your lower back.]\nThen I asked him to walk me through his strength-training regimen. It was not the worst strength regimen I have ever heard about, but it was pretty bad. He was doing a number of things that were almost criminally bad for him. If you are doing a lot of strength training, there is a sad chance that you, too, are doing some seriously harmful stuff, from a back point of view. That\u2019s because we were all trained to do things wrong, back in the day. \nTake, for example, the traditional \u201carmy sit-up,\u201d which Fred is still doing. We all did a lot of those at one point and a lot of us are doing them still. Even the army gave them up only in recent times. But the fact is that there are few things worse for your back than the good old army sit-up. (A shallow, or four-inch \u201ccrunch\u201d is fine, and it does all you need for your core; you do not need to bend your spine like a pretzel to get a benefit.) The sit-up, where you twist to touch your elbow to the opposite knee, is the worst of all. And that\u2019s just one of a bunch of deeply familiar exercises that are fundamentally terrible for your back. The machines we all used to love are a particular peril (not all but many). The whole world of bad strength training makes me particularly crazy: Here are these terrific men and women, working so hard in an effort to make their bodies stronger and better. And what they are doing is, in fact, worse than doing nothing at all. Sad and wrong. \nMost important, Fit Fred has no notion of the importance of engaging his core and strengthening his core and glutes\u2014perhaps the most important elements in a sane strength-training regimen. And he doesn\u2019t have a clue about the importance of decent posture and of maintaining a neutral spine. So I tell him to stop all strength training until I can show him how to do it right. \nSubstantial Sally \nIf Fit Fred was on the fit end of the fitness spectrum, then Substantial Sally was the opposite. She is significantly overweight (she is close to 300 pounds, which is very significant indeed) and has had no regular exercise program for the past four years. She has had a whopping four spine surgeries, two in the past two years, including a fusion and a laminectomy. Fusions are common, but they are very serious business indeed. It is a procedure in which the surgeon uses hardware to bolt (fuse) two or more vertebrae together to prevent further movement at that joint. There is a place for fusions, but I see them as a very last resort. They give relief, but if the person does not make the necessary behavioral changes, they often find themselves having another fusion or other problems in a few years. They are not a cure, in any broad sense. A laminectomy is a less serious procedure in which the surgeon removes a small piece of bone off a vertebra to relieve pressure on a particular nerve. Again, it cures a symptom, not the basic problem. \nIn any event, Sally has been through the wars, she is still in pain, and she is both smart and wary. She is not one bit sure that I am going to be any more help than my predecessors. I don\u2019t blame her. But I think she\u2019s wrong. I think I am going to be able to help her quite a lot, if she\u2019ll listen, which she may not. \nSally is an appealing woman, the head of a company that she started herself, and which she has made a huge success of. I automatically like her, right off; she\u2019s one of those people whom everyone likes right off . . . part of her success, I assume. But she sure is in trouble, and it is making her cranky. I don\u2019t blame her, but she is not fun. Not many of my patients are fun; they hurt too much.", "CHAPTER SEVEN\n RULE #2\n Be Still So You Can Heal (The Neutral Spine)\n From Jeremy\nLet\u2019s assume that you are beginning to get the big picture. And that you have also begun to identify the \u201cdumb\u201d things that you\u2019ve been doing to wreck your back, and that you have stopped doing them. Good. Now it is time to start the healing, and that is a matter of immobilizing your lower back or lumbar spine so it can heal, after all those years of doing things that hurt it. \nThe analogy is not perfect, but think of your tortured back as being like a broken arm or leg. When you break an arm, say, the doc puts it in a stiff cast so you can\u2019t bang it or twist it and to give it time and rest to heal. The same with your back, except we can\u2019t do anything quite as dramatic as put you in a whole-body cast for your damaged back. What we can do is show you how to carry yourself so that you effectively immobilize your lower back. It\u2019s not totally easy, but it will work. And bear in mind, if you do not immobilize your back, it will not heal\u2014simple as that. Indeed, it may get worse. \nWhat do I mean by \u201cimmobilizing\u201d your lumbar spine? I do not mean that you can\u2019t sit or walk or have a more or less normal life. What I do mean is that you have to be really serious about maintaining a neutral spine, all the time. Maintaining a neutral spine is at the heart of your cure, and will be at the heart of your life after your cure. This is the time to learn how to achieve a neutral spine and how to maintain it all the time, even when doing various movements. \nThe spine is a meticulously engineered piece of machinery, but it has a lot of redundancy built in. By this I mean that unlike the knee or shoulder, in the spine when you have a bad joint, the surrounding structures can \u201chelp\u201d bear the loads, and you can function more or less normally and without pain. Take the pressure of bad posture\u2014and dumb movement patterns\u2014off, and there is very likely enough \u201croom\u201d in this spine for the sufferer to have a normal life. For example, the \u201choles\u201d where the nerves come out of the spine (the foramina) are still big enough for the nerves to exit, pain-free, if you\u2019re not squeezing the area with lousy posture. In the same vein, there is probably still enough cushion in the flattened disc to support a correctly aligned spine (but not a bent or misshapen one). And so on. \n\u201cNeutral\u201d means the position in which the least amount of problem loads occur, all up and down the spine. The \u201cproblem loads\u201d in some pictures we\u2019ve shown are extreme, but even those inflamed joints and nerve roots will likely calm down if you leave them alone for a while. Which is to say, if you keep your spine in neutral. As bad as those injuries are (and as long as it took someone to create them) there is a strong chance that that sufferer can go about his or her life, with a neutral spine, in little or no pain. \nLearning to keep a neutral spine is not totally easy. And learning to maintain it all the time is harder. But this is the \u201ccast\u201d that lets your body heal. It is worth going to a lot of trouble to get this right. And it is a lesson that you will use for the rest of your life, long after the problem area has \u201chealed.\u201d \nOkay, step one is understanding the concept of neutral spine. Step two is learning to find it and lock it in place, and keep it in place forever (which we will teach you in Chapter 9).\nThe neutral spine is the position that allows your spine to do its job with the least amount of stress and load. And\u2014if you have already damaged your back\u2014it is the position that results in the least amount of new damage or pain.\nFor most people, the picture on the left is the neutral spine. The other two are not.\nNeutral Spine \n\nGOOD BAD\nNote the gentle curve of the lower back in the \u201cgood\u201d spine. For the majority of you, this is how your neutral spine will look. If you have developed significant degenerative changes or were born with significant abnormalities (it happens, but not a lot), your neutral spine may look a bit different. For now assume that your neutral spine looks like one on the guy on the left. Spines vary, and you may have your own unique neutral spine that is a little different from this. Whatever your own neutral spine, that is the position you want to maintain as you go about your daily life. It is also the position in which you feel the least pain. Again, maintaining a neutral spine is a fundamental behavioral change for most people. And it is readily doable. In a few months\u2019 time, I predict that it will be natural and you will scarcely need to think about it. One of the near-magic presences in our lives is \u201cmuscle memory.\u201d Maintain your spine correctly for a while and muscle memory takes over. Then it is just a question of seeing to it that your muscles are strong enough to do their job. \nHow do you keep your spine neutral and still be a dynamic, moving, active human being? By learning to brace your neutral spine with your core (Chapter 9) and maximizing movement in your hips (as opposed to your lower back). As Chris mentioned in Chapter 6, one of our cardinal rules is \u201cThou shalt not bend or twist with thy lower back.\u201d And you don\u2019t need to. You can rotate from side to side and bend forward and back using your hips. You do not need to flex or twist your lower back. \nYou may ask: Isn\u2019t range of motion important for the lumbar spine? Answer: Not really. At least, it is usually the least important factor for someone who has had significant back pain, and should be reintroduced only after pain has stopped. Most people who have experienced regular, serious back pain have already sustained significant wear and tear on the spine. The general pattern I see is a combination of two things: first, worn-down vertebral joints that are hypomobile (stiff), secondary to arthritic changes and degeneration; second, lumbar vertebral joints that are hypermobilie (loose), due to overstretched ligaments and atrophied muscles. These problems are best resolved when we protect the spine by bracing and \u201clocking down\u201d the lumbar spine and moving in a manner that completely changes the axis of motion from the lumbar spine to the hips and shoulder girdle. You can eventually introduce some gentle lumbar range-of-motion exercises in non-loaded ways. This is what the \u201cCat/Camel\u201d exercise that we introduce later is for. Small, gentle lumbar range-of-motion exercise is necessary for things like synovial joint lubrication, the reduction of friction between vertebral segments and discs, and disc nutrition, among other things. For example, walking requires a few degrees of freedom between the lumbar vertebral joints (3 or 4 degrees rotation) with coordinated muscle contractions to enhance stabilization and supply necessary lubrication and nutrition to discs and joints. For our purposes, we recommend keeping lumbar motion to a minimum, especially until your pain is gone. Once that occurs, you should make only healthy, non-loaded, non-repetitive lumbar movements, such as those necessary for walking and the cat and camel exercise. Spinal stability, core endurance, hip mobility, and core and gluteal strength are far more important for maintaining a healthy spine once you\u2019ve had back pain. You can do just fine in life with almost no rotation or excessive movement in your lower back. Let your hips do the work, and your risk of recurring back pain is sharply reduced. \nFinding Your Neutral Spine \nFinding your neutral spine can be a bit tricky for some but you can do it. Here\u2019s what you do. Lie on your back with your knees bent and your feet flat on the floor. Try to relax everything in your body, and just breathe. Then let\u2019s start by performing a pelvic tilt. \nTo do that, flatten your lower back into the floor (see top drawing), and curl your tailbone upward. This is a \u201cposterior pelvic tilt,\u201d if you want to put a name to it. Now, arch your back so that your lower back comes off of the floor (middle drawing), and point your tailbone toward the ground (an \u201canterior pelvic tilt\u201d). Now, slowly go back and forth between those two motions a few times (bottom drawing). Find the position of your lower back between these two extremes (flattening your back or arching it) that feels the most comfortable to you, and stop there. This is your neutral spine. It may take a few tries but it\u2019s not hard.\nFinding Your Neutral Spine\n\nStop here for a second. You have just reached an important point, and you don\u2019t want to \u201close\u201d it. Everyone\u2019s neutral spine is a bit different depending on the anatomical condition of their lumbar spine. For most people, there will be a gentle curve in the lower back. For those who already have some kind of a disc bulge, their neutral spine might be more arched (butt more extended). For those with spinal stenosis, their neutral spine may be a little more flattened than the one in the picture on the previous page. Don\u2019t worry about it. Whatever feels the most comfortable for you is your neutral spine for now. In time, your neutral spine will likely become more like the \u201cnormal\u201d picture as pain and inflammation subside.\nThink about your neutral spine and assume that position all the time until it becomes second nature\u2014until \u201cmuscle memory\u201d takes over. \nNext, we move on to a discussion of techniques to help you maintain a neutral spine. But first, Chris is going to tell you why it is very likely you haven\u2019t heard of these concepts before.", "CHAPTER FOURTEEN\n Trigger Points: Muscle Pain and Back Pain\n From Chris and Jeremy\nMost of us\u2014the newcomers anyway\u2014tend to think of back pain as something that is largely in the spine itself. The bones, discs, ligaments, and nerves. But what most of us don\u2019t focus on are the surrounding and supporting muscles. Which is a mistake, because they can be a major source of back pain (or something that can pass as back pain). And getting \u201cright\u201d with those muscles can be mighty important. \nTo be accurate, back pain is almost always a not-so-pleasing blend of muscle pain, joint pain, nerve pain, and other pain. This can be a little confusing. All pain is transmitted by nerves. When we speak of muscle pain or nerve pain, we are referring to the primary source of pain\u2014that is, the pain-generating tissue. Sometimes an aggravated nerve is the source of pain so it is referred to as nerve pain. In this chapter, we are talking about pain whose primary source is muscles. Even though the pain is transmitted to your brain via nerves, the tissue that\u2019s causing the pain is muscle tissue, so we refer to it as muscle pain. It is helpful to think of that which is primarily muscle pain differently, because it manifests itself differently, and Jeremy\u2019s approach to it is different, too.\nThere\u2019s good news and bad news here (wouldn\u2019t you know it). The bad news is that muscle pain is harder to locate and trickier to fix in the first instance. The good news is that it is actually easier to fix in the long run, and your prospects of a complete cure are much better. \nWhich is not to say it does not hurt like blazes. Up in the 8\u201310 range, on a scale of 10. But often the relief can be sudden and nearly complete. You still have to do serious stuff to keep it from coming back once the fix is made, but that\u2019s always true. \nMuscle Pain\nPeople in the healing professions refer to muscle pain both as \u201cmyofascial pain\u201d and \u201ctrigger point pain.\u201d For laymen like you and me, \u201ctrigger point pain\u201d may be the more useful name, because it feels like that\u2014something that gets \u201ctriggered\u201d by some silly move you made. Whatever we call it, trigger point pain has been a somewhat controversial topic for decades, mostly because no medical discipline claims ownership of the muscular system. Doctors are far more concerned with the joints, bursae, ligaments, and nerves. There has not been as much study of the muscular system and trigger point pain. But there has been enough, so that there is broad agreement on many points. And the best practitioners, and Jeremy in particular, have seen a lot of it. \nSo, what is it? Here\u2019s Jeremy: \u201cTrigger points are tight, painful bands of muscle tissue that have predictable and recognizable patterns of pain.\u201d To put it another way, they are muscle spasms (not quite right but close enough), which is what you get when a muscle or muscle segment seizes up, under pressure, and won\u2019t let go. It\u2019s like those cramps you sometimes get in your leg, except it doesn\u2019t go away and the pain can be horrendous. Unbearable, some of the time. These spasms or cramps not only cause terrible pain in their own right, but they can change the way some joints function. As Jeremy puts it, \u201cThey also limit range of motion and change the normal distribution of loads on nearby joints, which can also cause pain.\u201d So trigger point pain is serious, and it has more than one way to grab you. If it has started to affect the range of motion of the nearby joint, in the way Jeremy suggests, clearing it up is harder, but the approach is the same. \nOne thing to bear in mind is that trigger points basically \u201clie\u201d to us. That is to say, the obvious pain may crop up away from the actual trigger point itself. For example, the trigger point may be in the gluteus minimus (that\u2019s a favorite spot, actually), but the pain may run down the leg, mimicking sciatica. Or a trigger point in the gluteus medius may read as pain in the lower back. There are a lot of variations, but the patterns are well known and predictable, so professionals know where to look for the originating problem. Most of the time, anyway. Pretty soon, you will, too. \nOne thing that helps is that trigger point or muscle pain in general is recognizably different from nerve pain (again, this means pain in which an aggravated nerve is the source of the pain, not just the means of transmission to your brain) and other pain, so that you know what you are dealing with. Most of the time, nerve pain, for example, is \u201cburning, sharp, electric,\u201d and you can pinpoint exactly where it is. Trigger point pain, on the other hand, is achy, diffuse, hard to localize, and dull. And it often arises far from the source, which is a trigger point in a muscle. \nOne reason it is called trigger point pain is that it is usually \u201ctriggered\u201d by an actual event, just the way it feels. You rolled over funny in bed, you opened the Sub-Zero too vigorously, you picked up the box of books with your back, not your legs. Sometimes, those triggering events are one-off incidents, which is the way they feel. But more often, the trigger point (or vulnerability) has been building for a long time. Vulnerable muscles or muscle segments have been under repetitious pressure for a long time, and they are ready to \u201cgo\u201d at the drop of a hat. You open the Sub-Zero funny and pow! A terrifying spasm. A latent trigger point like that can \u201cgo\u201d without any trigger event at all or with a trifling one. Let us hope that yours is a \u201cone-off,\u201d not one that has been building for years, because the one-off takes less time to heal. But never mind, the approach is just the same. \nThe most common trigger points are the ones that have been caused by muscular overload, and that have developed over time. Think of the familiar situation: You sit at your desk for months and years. It is an \u201cunnatural\u201d position, and it puts repetitive pressure on muscles that aren\u2019t built for it. Or it can be repetitively misplaced loads, caused by you doing some move the same wrong way, year after year, like a faulty golf swing. Say you sprain an ankle and you never quite rehab the ankle the way you should. Over the following weeks and months you walk slightly differently than you used to. This subtle change causes muscles in your legs and pelvis to bear loads in a different way. Some now bear more loads, some less. Over time, those muscles that are now bearing more loads get stressed and strained, and trigger points develop. The pain from these can come on gradually or suddenly. As we have said all along, most of the time, you have built your own back pain, over time, with the way you behave. That is true for most muscle pain, too. \nFinding Trigger Points\nOkay, on to the details. \n\u201cFor low back pain sufferers, the most important and common areas for trigger points to occur are in the lumbar paraspinals, quadratus lumborum, gluteus maximus, gluteus medius, gluteus minimus, and piriformis.\u201d Sorry, that\u2019s Jeremy; he just can\u2019t help himself. But you don\u2019t have to memorize the names; you just have to look at the pictures to get the general idea. And then feel around for the real source of the pain. When I say look at the pictures, I mean look and see if you can relate what you feel to the typical patterns the pictures show. The Xs represent the location of the real trigger point and the red shaded areas represent the area where you may perceive the pain. So think about where you feel the pain. Then look at the pictures. Then go to work to find where the X may mark the spot. When you find it, it will hurt a lot more than the surrounding area. Bingo! Think of these pictures as \u201ctreasure maps\u201d and the treasure is eventual release from pain. \nThis process is very much \u201chands on.\u201d It can be challenging to distinguish areas of perceived pain from actual trigger points until you get a feel for what you are looking for. If you try multiple times and fail, you may need the assistance of a good chiropractor, massage therapist, or physical therapist to get the hang of this. To get started, grope around with your hands (using the pictures as a guide to the general area) until you have a fair idea of where the real trigger points are. You will know them because they hurt more. For once, the pain is the good news. It means that you\u2019re getting close. Or you\u2019re there. \nBy the way, the muscles where the trigger point lies can be deep. The gluteus minimus, for example, is buried beneath two other muscles and a layer of fat. Some of you are not going to have the strength or leverage to reach that trigger point with your hand alone. You may need to use a tennis ball or foam roller, which will be discussed in the following pages. But, to start, just use your hand until you get a general idea if there is something deep in those muscles that needs to be released. And don\u2019t forget: Use the pictures as your guide. \nOnce you have a general idea of where the trigger point is, mash away at it, if you like, with your bare hands, and see if that manual manipulation is enough to \u201crelease\u201d the rascal. What you do is hold down hard on the place that hurts the most and\u2014in ten to thirty seconds or so\u2014you should feel an easing of the pain. That is the trigger point letting go. Nice work. If the pain does not ease up after thirty seconds or so, either you are not directly", "this is chapter 20 of original book\n{CHAPTER TWENTY\n The Sacrum and Coccyx\n From Chris and Jeremy\nFrom Chris\nThe sacrum is the last section of the spine, the vestigial collection of vertebrae that are welded into one solid piece, down at the bottom. And the coccyx is the tippety-tip of the sacrum, the last bit of bone at the end of that long chain, which has been such a torment to you for so long. \nAnd this is the end of the book. The end of the long chain of chapters that we hope\u2014with all our hearts\u2014will deliver you from such torment forever. From now on, it\u2019s up to you. Go back through the book, do the exercises, and change your behavior the way you know you should. Up to you now. \nMay I say, here at the end, that putting this book together has been great fun for Jeremy and me. It has taken more than a year, and it has been a ton of work. We hope it reads as if it were easy as pie, but it wasn\u2019t. We worked like crazy to make it seem easy\u2014and to make it truly accurate without driving you crazy. Don\u2019t know how well we did on that, but we sure did try. And it was fun for a couple of reasons. First, from my point of view, Jeremy is awfully good company. He is deadly serious about his profession but he loves to laugh, too. And, God bless us, we think we\u2019re funny. That helped a lot. On a slightly more serious note, learning all the stuff I had to learn about the back this past year was fascinating and a privilege. Interesting piece of machinery, the back, and Jeremy could not have been a better guide. \nFinally, both of us are true believers in this \u201crevolution\u201d I mentioned up front, and that is a tremendous help. The whole time we were digging away at this boring detail or that, we had the agreeable conviction that we were not just ink-stained wretches, noses to the page. We were centurions in the great war against cruel, needless pain. That helped a lot, too. \nBut the whole business won\u2019t be satisfying to us if it doesn\u2019t work, for you. And that takes me back to my one great worry, the one I mentioned before. \nI worry that we leave so much of this up to you, when we know that Americans just aren\u2019t used to that. Americans are used to going to the magician/doctor. He has a look around, maybe does an MRI. And then hands us a prescription, or gives us a shot. Or sends us to his pal the back surgeon, who does some clever thing to make us all better. As we\u2019ve said again and again, that\u2019s not going to work here. You have to do it yourself\u2014you have to do the exercise, make the changes. But the great question is, will you find the resolve to make it happen? Jeremy says he\u2019s sure you will, because he knows your pain. He knows just how deep and sharp your motivation is. I hope he\u2019s right. \nWhat we are urging is not really that hard; it is mostly just unfamiliar. And you surely have the resources and motivation to make it happen. I know you\u2019re smart enough; you just read this darned book, after all. I know you are disciplined enough; you\u2019ve been going to work all these years. And I know you care, because I know about your pain. Now just take those three things and reorient them a little. And save your life. Then spread the word and save your family, save the country. Get the ogre out of all our lives. It can and should be done. \nFrom Jeremy\nI can\u2019t agree more with Chris\u2019s words. He and I had such a great time writing this book, and we are both deeply optimistic about what it can do for you. As you well know by now, I am not the \u201cword guy\u201d; that\u2019s Chris. So I will be uncharacteristically brief and just say I have seen this protocol work a thousand times in my practice. Now I want to see it work a million times, perhaps more than that, with this book. As we mentioned at the beginning, we want a revolution in back care in this country. Starting with you. We want to take this scourge out of all our lives. \nJEREMY\u2019S RULES\n1\nStop doing dumb stuff.\n2\nBe still so you can heal.\n3\nBrace yourself.\n4\nCommit to your core.\n5\nUse the power in your posterior.\n6\nCrawl before you walk. Walk before you run.\n7\nStand tall for the long haul.\nAPPENDIX\nThe \u201cCheat Sheet\u201d\nWe threw a lot at you in this book. In time, it will seem like second nature. When you get to that point, it may still be useful to have a simple guide to remind you where you are, what to do next, and so on. To that end, I give you this \u201ccheat sheet\u201d to summarize all the exercises we have told you to do and to tell you when to do them. Here is your daily and weekly plan.\nI strongly encourage you to read this book a few times a year. Trust me, you are trying to change lifelong habits and it\u2019s very easy to default back to the old ways. Come back to the book and think through each exercise every so often. Avoid the trap of falling into those same bad habits that got you here in the first place. The book is the key to taking your life back and leaving the anxiety, stress, and pain of back problems in the past. In between readings of the book, there\u2019s this Exercise Cheat Sheet. \nBasic Core Exercises\nThese exercises (see Chapter 10) should be done every day, and are best done in the morning after being out of bed for thirty minutes or so. Remember to do progressions or regressions as needed for each. Move on to the next progression of a particular exercise when and if you feel ready. Start with one circuit and work your way up to two full circuits in time, and make that your daily habit. In time, this will take you ten to fifteen minutes.\n1. Slow March with Neutral Spine with Shoulder Flexion\n2. The Bridge \n3. Crunch and Plank\n4. Dynamic Hamstring Stretch\n5. Side Plank\n6. Cat/Camel Mobilization\n7. \u201cBird Dog,\u201d or Opposite Arm/Leg Extension\nGlute Strengthening Routine \nDo these exercises three times a week on nonconsecutive days in addition to your core routine. Start with two sets and work your way up to three in time. This will likely add an additional ten minutes or so on those three days a week that you do these. \n1. Hip Circles Do these first!\n2. Clamshell\n3. Quadruped Hip Extension\n4. Split Squat\n5. Squat\nTrigger Point Release\nDo this as needed. If you got noticeable improvement in back, hip, or leg pain after mastering this, do it prior to your glute workouts until it is no longer needed. \nStretches \nFollow up your glute routine with the following stretches from Chapter 17.\nThis will take three to four minutes.\n1. Hamstring Stretch\n2. Glute Stretch\n3. Piriformis Stretch\n4. Psoas Stretch\nTHE BACKFOREVER VIDEOS\nFor those of you who want to safely return to more demanding activities like weightlifting, skiing, golf, tennis, Pilates, yoga, etc., we invite you to become members of BackForever.com, where you will find hundreds of hours of detailed video instruction on these subjects. Visit BackForever.com to learn more. Enter this promo code to receive two free weeks of membership: YNYTRIAL.\nACKNOWLEDGMENTS\nThanks to Jeremy, first of all, for being such a joy to work with. Coauthorship is supposed to be hard. For me\u2014especially in this book\u2014it has been a joy. We worked mighty hard, but we laughed a lot too.\nJeremy and I have been blessed\u2014and we know it\u2014to have a superb editor in a smart, kind, diplomatic, literate Bruce Tracy at Workman. (That is a shortened list of attributes; Bruce was terrific. And he really got down into the weeds as well as the big picture. As good as they get.) And, as always, thanks to the wise and kind Suzie Bolotin, editor of the Younger Next Year\u00ae books and Uber-editor of this one. Heaven!\nLast, thanks to Bill Fabrocini, just about the smartest and most effective guy Jeremy and I know in the broad world of physical therapy and serious training. And about as nice a human being as I have ever met. Deep thanks, Bill.\n\u2014C. C.\nI\u2019d like to thank all of the people who have helped me become the clinician I am today. I\u2019d like to thank Clinton Phillips, Michael Fox, Tim Powersmith, and Bill Fabrocini for their friendship, guidance, and the opportunities they have given me. Back pain has been one of the most misunderstood afflictions in modern society. Many of the concepts in this book are the result of the research and teaching of a handful of dedicated and pioneering individuals. There are many, but I would like to give special mention to Vladimir Janda, MD; David Simons, MD; Janet Travell, MD; Nikolai Bogduk, MD, PhD; and Stuart McGill, PhD. This book wouldn\u2019t have been possible without your accomplishments. }\nRead the chapter 20 of original book that I sent you and save it in your memory. Then, based on this text of chapter 20 of original book and your own information, continue the text of chapter 20 of the new book as much as you like. morover, with explaining with deep learning to me as if i were 10 years old.The text should be completely scientific and academic and based on science World Day should be written and repetition should be avoided. that are not repetitive and related to this topic. this chapter of an original book that I gave you is just a starting point and he has the right to add relevant foliage to this section. based on chapter 20 of original book, you can start", "Brooks, S. (2015). Does personal social media usage affect efficiency and well-being? Computers in Human Behavior, 46, 26-37. https://doi.org/10.1016/j.chb.2014.12.053\n\nArticle:\nAbstract\nPersonal social media usage is pervasive in both personal and professional lives. Practitioner articles and news stories have commented on the addicting and distracting nature of social media. Previous empirical research has established the negative effects of distractions on primary tasks. To date, little research has looked at the potentially distracting nature of social media and the negative effects that can arise from usage. This research addresses this gap by investigating the effects of personal social media usage on task performance. To extend this research, I also examined the effects that the personal social media usage has on individuals\u2019 technostress and happiness levels. I tested these effects by creating a classroom task environment and measuring subjects\u2019 usage of social media and their task performance. From this, it was found that higher amounts of personal social media usage led to lower performance on the task, as well as higher levels of technostress and lower happiness. These results are consistent across different levels of attentional control and multitasking computer self-efficacy. These results suggest that the personal usage of social media during professional (vs. personal or play) times can lead to negative consequences and is worthy of further study.\n\nIntroduction\nA recent survey found that 86% of online adults in the US and 79% of online adults in Europe use social media (Sverdlov, 2012). It would be hard to argue with the ubiquity of social media, and thus researchers have also paid attention to this growingly popular topic. Within the business disciplines, much research has been conducted on how businesses can leverage social media to increase exposure, profits, and other business goals. These studies have been very useful in examining social media; however, little work has been done on the effects of individual\u2019s personal social media usage and negative effects of such usage. There are at least 2.3 billion registered users for the ten most popular social networking websites worldwide combined (Socialnomics.net., 2011). Given this enormous population of users, it comes as no surprise that Facebook.com and YouTube.com are the two most-visited sites on the web, as of August 2014, and that social media usage has become the most common activity on the web (Socialnomics.net., 2012). Due to its ease of use, speed, and reach, social media is fast changing the public discourse in society and setting trends and agendas in topics that range from the environment and politics, to technology and the entertainment industry (Asur & Huberman, 2010).\n\nSocial media sites are frequently accessed both at home and at work. Though individuals can maintain a cognitive difference between personal life and professional life, these two aspects are both a part of the whole that is the individual. Understanding effects to both sides of a person\u2019s life is important for gaining a holistic picture of the individual. An argument can be made that the time spent using social media is not beneficial to the users, especially in the long term. Popular news outlets frequently report on stories involving negative outcomes of social media usage. For example, though people with low self-esteem consider Facebook an appealing venue for self-disclosure, the low positivity/high negativity of their disclosures elicited generally negative feedback from others (Forest & Wood, 2012). This cycle can lower users\u2019 happiness from not receiving the encouragement and positive feedback that they were hoping for. Also, extended use of a technology can lead to greater stresses. These technostresses can lower an individual\u2019s well-being.\n\nSocial media can also be distracting to users. The hedonic appeal of the technologies along with the ability to be connected to friends and family provides a strong pull to use the systems, both during professional and personal time. A typical worker gets interrupted at least six to eight times a day, which consumes about 28% of a knowledge worker\u2019s day (Spira & Feintuch, 2006). Research has shown that workers jump to an interruption about 40% of the time instead of focusing on the original task. When they come back to the primary task from the interruption, it can take up to 25 min to return to the original cognitive state (Czerwinski, Cutrell, & Horvitz, 2000). Inefficiencies in task performance can result from the time spent on the interruption and the challenge in mentally returning to the primary task.\n\nFor many students, being in the classroom can be analogous to being in a work environment. Students have work tasks to perform while in the classroom and a duty to perform these tasks efficiently, whether listening to a lecture, participating in discussion, working on a task, etc. Students accessing social media sites while in the classroom have the potential to experience many of the same drawbacks as do professionals in the workplace. A survey from Cengage Learning (2014) found that 59% of students are accessing social media in class. Given the potential for individuals to be affected when giving into these distractions/interruptions, this paper investigates this gap by exploring the effect of social media usage on students in a classroom environment. The results from this study will extend the literature concerned with technological distractors, provide preliminary empirical support for or against imposing personal social media usage limits in a classroom, and give justification for further study in more generalizable environments.\n\nThe results of this exploratory study will contribute to the literature on social media and distractions by showing what effects social media usage can have on both external efficiency (performance) and internal states (well-being). As most research investigates only one of these two foci, combining both sides provides value to the literature.\n\nThe organization of the paper is as follows. The next section provides background on prior work on social media and the theoretical lens of Distraction\u2013Conflict Theory. The research models, both the efficiency model and the well-being model, are presented along with their hypotheses. Next, the methodology is described and the analysis is performed. Finally, the discussion of the results is presented along with the conclusions.\n\nSection snippets\nSocial media\nSocial media are a group of Internet-based applications that allow the creation and exchange of user generated content (UGC) (Kaplan and Haenlein (2010). UGC, which describes the various forms of media content created by end-users outside of a professional context and is publically available (Kaplan and Haenlein (2010), is what differentiates social media from other more traditional forms of media. As an example, online newspapers, such as the New York Times, are not considered UGC due to the\n\nDistraction\u2013Conflict Theory\nDistraction\u2013Conflict Theory (DCT) (Baron, 1986, Groff et al., 1983, Sanders and Baron, 1975) provides a theoretical lens for understanding the effect that distractions and interruptions have on performance. The distraction\u2013conflict model can be broken down into three causal steps (Baron, 1986): (1) others are distracting, (2) distraction can lead to attentional conflict, and (3) attentional conflict elevates drive. This elevated drive leads to impaired performance and motor behavior on complex\n\nTask performance (PERF)\nRegarding DCT, interruptions have been found to lower performance on complex tasks (Speier, Vessey, & Valacich, 2003). With complex tasks, how often an interruption occurs, and how different the content of the material in the interruption is from the content of the task affect performance. In a mobile computing environment, widely recognized as being susceptible to multiple disturbances, even low-level distractions have been indicated to lead to a performance reduction (Nicholson, Parboteeah,\n\nStudy\nThe hypotheses are examined using surveys before and after a specific task was provided. Two surveys were created to measure self-reported information on the constructs of interest.\n\nSubjects\nThe sample consists of undergraduate students enrolled in an information systems course in a large Western US university. Subjects were given course credit for participating. College students were selected for the sample because social media usage is prevalent among this demographic. Social media sites, especially\n\nAnalysis and results\nThe data was analyzed using SmartPLS 2.0 (Ringle, Wende, & Will, 2005). PLS was chosen for analysis due to the exploratory nature of this model and the desire to identify key constructs (Hair, Hult, Ringle, & Sarstedt, 2013, p. 19). The sample size (N = 209) is of sufficient size for this analysis (Chin & Newsted, 1999). Both the bootstrapping procedure (cases = 209, samples = 5000) and the PLS algorithm were used for analysis.\n\nDiscussion\nFrom this exploratory investigation, support was found that social media usage can be detrimental to both halves of an individual\u2019s life: the professional and the personal. Table 5 provides a summation of the hypotheses.\n\nFor the efficiency model, in line with Distraction\u2013Conflict Theory, social media usage was found to negatively affect performance. Neither attentional control nor multitasking computer self-efficacy has a significant effect on this relationship. As often as students and\n\nLimitations and future directions\nLike all research, this study is not without limitations that need to be identified and addressed in future studies. First, the usage of college students for the sample is not generalizable to the workplace. After all, the pressure that a student faces while sitting in the classroom vary greatly from the professional, economic, and possible familial pressure felt by employees in the workforce. The choice of sample is relevant for this study due to the familiarity and usage of the social media\n\nConclusions\nThis study investigated the effects of personal social media usage on efficiency and well-being. As mentioned earlier, the popular press is rife with stories of people feeling negative consequences of social media usage. Given that social media usage is the most popular activity on the Internet, it is important to investigate what effects this usage is actually having so that future research may uncover effective ways to handle these issues.\n\nEnd of journal.", "There is a special travel pillow in the shape of a neck scarf. I will send you its specifications and the opinions of its buyers.\nI want from you:\n1- Give your opinion about this pillow and its advantages and disadvantages\n2- List me at least twenty different uses of this pillow, other than travel, and write a paragraph for each item.\nThe information about this neck scarf travel pillow is:\n\"The Best Pillow For Sleeping Sitting Up!\nMAIN FEATURES \n\nOur neck pillow is better than a U-shaped neck pillow and has been strategically designed to prevent stiff necks and sore shoulders. \n\n\\* The Travel Pillow is a SCIENTIFICALLY PROVEN travel pillow to keep your head in a BETTER POSITION when sleeping upright by holding your head in an ergonomic position during rest. No more nodding heads!\n\n\\* SUPER SOFT fleece combined with a unique hidden internal SUPPORT, plus some EXTRA COSY CUSHIONING creates a comfortable resting place for your head and neck.\n\n\\* Available in RED, GREY, and BLACK so you can find a color that suits your style.\n\n\\* Our UNIQUE PATENTED DESIGN is your ticket to an awesome night\u2019s sleep, wherever you are. Designed to look like a SCARF, the Trtl Pillow can be easily adjusted to your comfort.\n\n\\* The Pillow is EASY TO ATTACH to the handle of your backpack or outside of your luggage, and it only WEIGHS HALF A POUND (148 grams)! Say goodbye to bulky neck pillows taking up precious space in your carry-on, or weighing you down duty-free.\n\n\\* ALWAYS FRESH and ready to go, The Pillow is also MACHINE WASHABLE!\n\nHOW TO USEKh\u00f4ng c\u00f3 m\u00f4 t\u1ea3.Kh\u00f4ng c\u00f3 m\u00f4 t\u1ea3.Kh\u00f4ng c\u00f3 m\u00f4 t\u1ea3.\n\nOUR GUARANTEE\n\ud83d\udce6 Insured Worldwide Shipping: Each order includes real-time tracking details and insurance coverage in the unlikely event that a package gets lost or stolen in transit.\n\n\ud83d\udcb0 Money-Back Guarantee: If your items arrive damaged or become defective within 15 days of normal usage, we will gladly issue out a replacement or refund.\n\n\u2709\ufe0f 24/7 Customer Support: We have a team of live reps ready to help and answer any questions you have within a 24-hour time frame, 7 days a week.\n\n\ud83d\udd12 Safe & Secure Checkouts: We use state-of-the-art SSL Secure encryption to keep your personal and financial information 100% protected.\n\n\nTRAVEL NECK PILLOW\n\n\u20ac16,82 \u20ac33,66\nColor\n\nGray\nCombo\n\n1 PC\nQuantity\n1\n\nADD TO CART\nOverall rating: 5/5\nSee all reviews (215)\n5\n\n100%\n4\n\n0%\n3\n\n0%\n2\n\n0%\n1\n\n0%\n\nMost recent\nProduct reviews (20)Store reviews (0)\nLorrie Burcin\nLorrie Burcin\n02/09/2023\nI was impressed with the support of the trtl pillow. I have tried the traditional neck pillow in the past and was never able to sleep. It is still difficult to sleep sitting upright, but it was pretty comfy and I didn't wake up with a sore neck. It really did feel like I was sleeping on someone's shoulder. My only beef was that my wireless headphones wouldn't stay in my ears. The next generation could incorporate headphones and I would be set.\n\nErrol Favaro\nErrol Favaro\n02/07/2023\nI acutally really like this thing.\n\nLuana Marrietta\nLuana Marrietta\n02/07/2023\nI started with 2, but my brother stole one because he has trouble finding masks that fit his large-ish head and beard! I replaced that one. Shortly thereafter, I bought 3 more so I have one for every day of the week. They are easy to pull on and off, easy to adjust to the perfect size, and are comfortable enough for all day wear - with no ear pain.\n\nKyong Croce\nKyong Croce\n02/06/2023\nVery very good.\nCarlotta Rinn\nCarlotta Rinn\n01/31/2023\nIn the past I have tried different methods and products to try sleeping on flights. Nothing really works very well. I have not yet flown using my trtl pillow but just putting it on while sitting at home I felt I could easily take a nice nap. It is very soft and truly does provide good support for my head and neck. Can\u2019t wait to fly again!\nShira Billigmeier\nShira Billigmeier\n01/29/2023\nThis is a great Neck pillow When you want to be comfortable on a chair or upright position and you can't lay down! I also have back and neck problems and it supports my neck pretty comfortably. You can swivel it around to each side each side, front or or back. I prefer switching it around from right to left, Depending on what feels comfortable at that moment. I would get this pillow For any of my family members. This is a unique great gift idea. I love this travel neck pillow because it works!\n\nGemma Machi\nGemma Machi\n01/29/2023\nMy dad loves this so muchhh. Thank shop\n\nKasey Buggs\nKasey Buggs\n01/27/2023\nExcellent product. I loved. I recommend it. I bought this for a long flight and haven't used it for that yet, but I did try it out for a sitting up nap. It worked well and wasn't too warm. If it survives an 8 hour flight along with my neck, it will get five\n\nVicenta Fotheringham\nVicenta Fotheringham\n01/27/2023\nThis thing is weird, but wonderful! Soft and cozy, it doesn't get hot (and I sleep HOT), and I can wear my noise-cancelling headphones and shades without issue! I did disassemble to wash and had a hard time getting the sewn-in foam insert to dry all the way. Hung it for a day or two and that did the job. Also the velcro looks gentle but could be lethal to other clothes in the laundry. I put it in a lingerie sack and the velcro stuck right to the sack and messed the fabric up a bit-definitely velcro it closed and/or use a lingerie sack when washing. All that said, the pillow has elevated my car travel experience immensely. I am very happy with it. Highly recommend!\n\nJeanie Iguina\nJeanie Iguina\n01/26/2023\nThis pillow was very helpful to me and supported my neck very well during my flight. You may consider Junior size if your hight is under 170cm.\n\nFrancine Feiertag\nFrancine Feiertag\n01/23/2023\nI've honestly never slept while traveling much at all. I'm perimenopausal, so hot flashes are a thing, but as long as I have cooled down enough before I put it on I can go right to sleep. It is made of a very soft fleece, though, so it can get hot. It's not the kind of fleece that is super silky, but it's durable and comfortable on your face. The head support is springy, but supportive. This doesn't work well with over-the-ear headphones, and it's uncomfortable to wear an earbud in the ear that is against the support. All that said, I am very happy with this purchase.\n\nTreena Nansteel\nTreena Nansteel\n01/23/2023\nWhat I love about this is that it\u2019s easy to wash so that after you travel if you don\u2019t feel like burning the pillow. Regular travel pillows kind of get gross and musty when they are stored and otherwise are kind of disposable. I\u2019m bad for the environment. I\u2019m hoping this thing will last for many years. The only thing I wish it came with was a little travel bag to keep it clean. It\u2019s a little hard to pack because it\u2019s an odd 3-D shape.\nJessie Casaus\nJessie Casaus\n01/20/2023\nI have a pain on my neck so every time I traveled that pain get worse. I gave a try to trtl and was great to help me keep my neck in a better position. Also I like your neck get warm with the cold A/C from the plane\n\nDelta Neidert\nDelta Neidert\n01/18/2023\nI was hesitant at first on purchasing this pillow. I flew from California to Hawaii so comfortably! I didn\u2019t have to bend my neck against the window. This was probably one of my best purchases ever!\n\nAbe Ehrismann\nAbe Ehrismann\n01/16/2023\nAmazing pillow! I wish I had known about this years ago as it would have been perfect for so many occasions. I was a bit unsure about how the internal plastic support structure would feel but it is very comfortable. I have already bought 2 of these and will definitely be buying more especially as gifts as I know a lot of people that would love this! I use it all the time and take it everywhere with me.\nGustavo Surman\nGustavo Surman\n10/24/2022\nVery practical I reccommend this pillow.Thanks\nKaryl Warley\nKaryl Warley\n09/21/2022\nArrived on time. Good service by Favocy shop! Do a great job and keep going.\n\nCandelaria Camaj\nCandelaria Camaj\n09/14/2022\nAt last I can enjoy my rides on the bus. Excellent device.\n\nBrendon Panameno\nBrendon Panameno\n08/26/2022\nThis is one of the more comfortable travel pillows I have used. Excellent!\n\nVeronica Konno\nVeronica Konno\n08/19/2022\nThe track was tracked, picked up in the post office. An interesting scarf pillow, made with high quality, the fleece is not thin, pleasant to the touch, the threads do not stick out, the Velcro is strong, there is a plastic insert inside, you can get and wash the shell. I tried it, it holds my head quite comfortably. Thanks seller\"", "Lab Overview:\n\nBuffer overflow is defined as the condition in which a program attempts to write data beyond the boundary of a buffer. This vulnerability can be used by a malicious user to alter the flow control of the program, leading to the execution of malicious code. The objective of this lab is for students to gain practical insights into this type of vulnerability, and learn how to exploit the vulnerability in attacks. In this lab, students will be given a program with a buffer-overflow vulnerability; their task is to develop a scheme to exploit the vulnerability and finally gain the root privilege. In addition to the attacks, students will be guided to walk through several protection schemes that have been implemented in the operating system to counter against buffer-overflow attacks. Students need to evaluate whether the schemes work or not and explain why. This lab covers the following topics: \n\u2022 Buffer overflow vulnerability and attack \n\u2022 Stack layout \n\u2022 Address randomization, non-executable stack, and StackGuard \n\u2022 Shellcode (32-bit and 64-bit) \n\u2022 The return-to-libc attack, which aims at defeating the non-executable stack countermeasure, is covered in a separate lab.\n\nLab environment: This lab has been tested on the SEED Ubuntu 20.04 VM. You can download a pre-built image from the SEED website, and run the SEED VM on your own computer. However, most of the SEED labs can be conducted on the cloud, and you can follow our instruction to create a SEED VM on the cloud.\n\nEnvironment Setup:\n\nTurning Off Countermeasures \n\nModern operating systems have implemented several security mechanisms to make the buffer-overflow at-tack difficult. To simplify our attacks, we need to disable them first. Later on, we will enable them and see whether our attack can still be successful or not. \n\nAddress Space Randomization. Ubuntu and several other Linux-based systems uses address space randomization to randomize the starting address of heap and stack. This makes guessing the exact addresses difficult; guessing addresses is one of the critical steps of buffer-overflow at tacks. This feature can be disabled using the following command:\n\n$ sudo sysctl -w kernel.randomize\\_va\\_space=0\n\nConfiguring / bin/sh. In the recent versions of Ubuntu OS, the /bin/sh symbolic link points to the /bin/dash shell. The dash program, as well as bash, has implemented a security countermeasure that prevents itself from being executed in a Set-UID process. Basically, if they detect that they are executed in a Set-UID process, they will immediately change the effective user ID to the process\u2019s real user ID, essentially dropping the privilege. \nSince our victim program is a Set-UID program, and our attack relies on running /bin/sh, the countermeasure in /bin/dash makes our attack more difficult. Therefore, we will link /bin/sh to another shell that does not have such a countermeasure (in later tasks, we will show that with a little bit more effort, the countermeasure in /bin/dash can be easily defeated). We have installed a shell program called zsh in our Ubuntu 20.04 VM. The following command can be used to link /bin/sh to zsh:\n\n$ sudo ln -sf /bin/zsh/bin/sh\n\nStackGuard and Non-Executable Stack. These are two additional countermeasures implemented in the system. They can be turned off during the compilation. We will discuss them later when we compile the vulnerable program. \nTroubleshoot: Make sure setuid is installed. If not use sudo apt-get install super. If zsh is not installed then use sudo apt install zsh\nIf you get dependency error while compiling try: sudo apt-get install gcc-multilib\n\nTask 1: Getting familiar with Shellcode\n\nThe ultimate goal of buffer-overflow attacks is to inject malicious code into the target program, so the code can be executed using the target program\u2019s privilege. Shellcode is widely used in most code-injection attacks. Let us get familiar with it in this task.\n\n1.1 The C Version of Shellcode\n\nA shellcode is basically a piece of code that launches a shell. If we use C code to implement it, it will look like the following:\n\n#include \n\nint main() { \nchar \\*name[2];\nname[0] = \"/bin/sh\"; \nname[1] = NULL; \nexecve(name[0], name, NULL); \n}\n\nUnfortunately, we cannot just compile this code and use the binary code as our shellcode (detailed explanation is provided in the SEED book). The best way to write a shellcode is to use assembly code. In this lab, we only provide the binary version of a shellcode, without explaining how it works (it is non-trivial). If you are interested in how exactly shellcode works and you want to write a shellcode from scratch, you can learn that from a separate SEED lab called Shellcode Lab.\n\n1.2 32-bit Shellcode\n; Store the command on stack \nxor eax, eax \npush eax \npush \"//sh\" \npush \"/bin\" \nmov ebx, esp ; ebx --> \"/bin//sh\": execve()\u2019s 1st argument \n\n; Construct the argument array argv[] \npush eax ; argv[1] = 0 \npush ebx ; argv[0] --> \"/bin//sh\" \nmov ecx, esp ; ecx --> argv[]: execve()\u2019s 2nd argument \n\n; For environment variable \nxor edx, edx ; edx = 0: execve()\u2019s 3rd argument \n\n; Invoke execve() \nxor eax, eax ; \nmov al, 0x0b ; execve()\u2019s system call number \nint 0x80\n\nThe shellcode above basically invokes the execve() system call to execute /bin/sh. In a separate SEED lab, the Shellcode lab, we guide students to write shellcode from scratch. Here we only give a very brief explanation. \n\u2022 The third instruction pushes \"//sh\", rather than \"/sh\" into the stack. This is because we need a 32-bit number here, and \"/sh\" has only 24 bits. Fortunately, \"//\" is equivalent to \"/\", so we can get away with a double slash symbol. \n\u2022 We need to pass three arguments to execve() via the ebx, ecx and edx registers, respectively. The majority of the shellcode basically constructs the content for these three arguments. \n\u2022 The system call execve() is called when we set al to 0x0b, and execute \"int 0x80\"\n\n1.3 64-Bit Shellcode\n\nWe provide a sample 64-bit shellcode in the following. It is quite similar to the 32-bit shellcode, except that the names of the registers are different and the registers used by the execve() system call are also different. Some explanation of the code is given in the comment section, and we will not provide detailed explanation on the shellcode.\n\nxor rdx, rdx ; rdx = 0: execve()\u2019s 3rd argument \npush rdx \nmov rax, \u2019/bin//sh\u2019 ; the command we want to run \npush rax ; \nmov rdi, rsp ; rdi --> \"/bin//sh\": execve()\u2019s 1st argument \npush rdx ; argv[1] = 0 \npush rdi ; argv[0] --> \"/bin//sh\" \nmov rsi, rsp ; rsi --> argv[]: execve()\u2019s 2nd argument \nxor rax, rax \nmov al, 0x3b ; execve()\u2019s system call number syscall\nsyscall\n\n1.4 Task: Invoking the Shellcode\n\nWe have generated the binary code from the assembly code above, and put the code in a C program called call shellcode.c inside the shellcode folder. If you would like to learn how to generate the binary code yourself, you should work on the Shellcode lab. In this task, we will test the shellcode.\n\n#include \n#include \n#include \n\nconst char shellcode[] =\n#if \\_\\_x86\\_64\\_\\_\n\"\\x48\\x31\\xd2\\x52\\x48\\xb8\\x2f\\x62\\x69\\x6e\"\n\"\\x2f\\x2f\\x73\\x68\\x50\\x48\\x89\\xe7\\x52\\x57\"\n\"\\x48\\x89\\xe6\\x48\\x31\\xc0\\xb0\\x3b\\x0f\\x05\"\n#else\n\"\\x31\\xc0\\x50\\x68\\x2f\\x2f\\x73\\x68\\x68\\x2f\"\n\"\\x62\\x69\\x6e\\x89\\xe3\\x50\\x53\\x89\\xe1\\x31\"\n\"\\xd2\\x31\\xc0\\xb0\\x0b\\xcd\\x80\"\n#endif\n;\n\nint main(int argc, char \\*\\*argv) \n{ \nchar code[500]; \nstrcpy(code, shellcode); // Copy the shellcode to the stack \nint (\\*func)() = (int(\\*)())code; \nfunc(); // Invoke the shellcode from the stack \nreturn 1; \n}\n\nThe code above includes two copies of shellcode, one is 32-bit and the other is 64-bit. When we compile the program using the -m32 flag, the 32-bit version will be used; without this flag, the 64-bit version will be used. Using the provided Makefile, you can compile the code by typing make. Two binaries will be created, a32.out (32-bit) and a64.out (64-bit). Run them and describe your observations. It should be noted that the compilation uses the execstack option, which allows code to be executed from the stack; without this option, the program will fail. Compile it again by typing make setuid and run them again. Report the difference in your observation.\n\nHow do I do Task 1", "Tengo el siguiente error al intentar subir im\u00e1genes con az artifacts universal publish en Ubuntu 22.04\npablo@PC:~/repos/project-ban-ahorro-backup$ ./scripts/generate-docker-images-links.sh \nEncountered an unexpected error.\nSystem.Net.Http.HttpRequestException: The SSL connection could not be established, see inner exception.\n ---> System.TypeInitializationException: The type initializer for 'WorkingChain' threw an exception.\n ---> System.TypeInitializationException: The type initializer for 'System.Security.Cryptography.SafeEvpPKeyHandle' threw an exception.\n ---> System.DllNotFoundException: Unable to load shared library 'libSystem.Security.Cryptography.Native.OpenSsl' or one of its dependencies. In order to help diagnose loading problems, consider setting the LD\\_DEBUG environment variable: liblibSystem.Security.Cryptography.Native.OpenSsl: cannot open shared object file: No such file or directory\n at Interop.OpenSsl.OpenSslVersionNumber()\n at System.Security.Cryptography.SafeEvpPKeyHandle..cctor()\n --- End of inner exception stack trace ---\n at System.Security.Cryptography.SafeEvpPKeyHandle.get\\_OpenSslVersion()\n at Internal.Cryptography.Pal.OpenSslX509ChainProcessor.WorkingChain..cctor()\n --- End of inner exception stack trace ---\n at Internal.Cryptography.Pal.OpenSslX509ChainProcessor.Finish(OidCollection applicationPolicy, OidCollection certificatePolicy)\n at Internal.Cryptography.Pal.ChainPal.BuildChain(Boolean useMachineContext, ICertificatePal cert, X509Certificate2Collection extraStore, OidCollection applicationPolicy, OidCollection certificatePolicy, X509RevocationMode revocationMode, X509RevocationFlag revocationFlag, DateTime verificationTime, TimeSpan timeout)\n at System.Security.Cryptography.X509Certificates.X509Chain.Build(X509Certificate2 certificate, Boolean throwOnException)\n at System.Security.Cryptography.X509Certificates.X509Chain.Build(X509Certificate2 certificate)\n at System.Net.Security.CertificateValidation.BuildChainAndVerifyProperties(X509Chain chain, X509Certificate2 remoteCertificate, Boolean checkCertName, String hostName)\n at System.Net.Security.SecureChannel.VerifyRemoteCertificate(RemoteCertValidationCallback remoteCertValidationCallback, ProtocolToken& alertToken)\n at System.Net.Security.SslStream.CompleteHandshake(ProtocolToken& alertToken)\n at System.Net.Security.SslStream.CheckCompletionBeforeNextReceive(ProtocolToken message, AsyncProtocolRequest asyncRequest)\n at System.Net.Security.SslStream.StartSendBlob(Byte[] incoming, Int32 count, AsyncProtocolRequest asyncRequest)\n at System.Net.Security.SslStream.ProcessReceivedBlob(Byte[] buffer, Int32 count, AsyncProtocolRequest asyncRequest)\n at System.Net.Security.SslStream.StartReadFrame(Byte[] buffer, Int32 readBytes, AsyncProtocolRequest asyncRequest)\n at System.Net.Security.SslStream.StartReceiveBlob(Byte[] buffer, AsyncProtocolRequest asyncRequest)\n at System.Net.Security.SslStream.CheckCompletionBeforeNextReceive(ProtocolToken message, AsyncProtocolRequest asyncRequest)\n at System.Net.Security.SslStream.StartSendBlob(Byte[] incoming, Int32 count, AsyncProtocolRequest asyncRequest)\n at System.Net.Security.SslStream.ProcessReceivedBlob(Byte[] buffer, Int32 count, AsyncProtocolRequest asyncRequest)\n at System.Net.Security.SslStream.StartReadFrame(Byte[] buffer, Int32 readBytes, AsyncProtocolRequest asyncRequest)\n at System.Net.Security.SslStream.StartReceiveBlob(Byte[] buffer, AsyncProtocolRequest asyncRequest)\n at System.Net.Security.SslStream.CheckCompletionBeforeNextReceive(ProtocolToken message, AsyncProtocolRequest asyncRequest)\n at System.Net.Security.SslStream.StartSendBlob(Byte[] incoming, Int32 count, AsyncProtocolRequest asyncRequest)\n at System.Net.Security.SslStream.ProcessReceivedBlob(Byte[] buffer, Int32 count, AsyncProtocolRequest asyncRequest)\n at System.Net.Security.SslStream.StartReadFrame(Byte[] buffer, Int32 readBytes, AsyncProtocolRequest asyncRequest)\n at System.Net.Security.SslStream.PartialFrameCallback(AsyncProtocolRequest asyncRequest)\n--- End of stack trace from previous location where exception was thrown ---\n at System.Net.Security.SslStream.ThrowIfExceptional()\n at System.Net.Security.SslStream.InternalEndProcessAuthentication(LazyAsyncResult lazyResult)\n at System.Net.Security.SslStream.EndProcessAuthentication(IAsyncResult result)\n at System.Net.Security.SslStream.EndAuthenticateAsClient(IAsyncResult asyncResult)\n at System.Net.Security.SslStream.<>c.b\\_\\_65\\_1(IAsyncResult iar)\n at System.Threading.Tasks.TaskFactory`1.FromAsyncCoreLogic(IAsyncResult iar, Func`2 endFunction, Action`1 endAction, Task`1 promise, Boolean requiresSynchronization)\n--- End of stack trace from previous location where exception was thrown ---\n at System.Net.Http.ConnectHelper.EstablishSslConnectionAsyncCore(Stream stream, SslClientAuthenticationOptions sslOptions, CancellationToken cancellationToken)\n --- End of inner exception stack trace ---\n at Microsoft.VisualStudio.Services.Common.VssHttpRetryMessageHandler.SendAsync(HttpRequestMessage request, CancellationToken cancellationToken)\n at System.Net.Http.HttpClient.FinishSendAsyncBuffered(Task`1 sendTask, HttpRequestMessage request, CancellationTokenSource cts, Boolean disposeCts)\n at Microsoft.VisualStudio.Services.WebApi.VssHttpClientBase.SendAsync(HttpRequestMessage message, HttpCompletionOption completionOption, Object userState, CancellationToken cancellationToken)\n at Microsoft.VisualStudio.Services.WebApi.VssHttpClientBase.SendAsync[T](HttpRequestMessage message, Object userState, CancellationToken cancellationToken)\n at Microsoft.VisualStudio.Services.Location.Client.LocationHttpClient.GetConnectionDataAsync(ConnectOptions connectOptions, Int64 lastChangeId, CancellationToken cancellationToken, Object userState)\n at Microsoft.VisualStudio.Services.WebApi.Location.VssServerDataProvider.GetConnectionDataAsync(ConnectOptions connectOptions, Int32 lastChangeId, CancellationToken cancellationToken)\n at Microsoft.VisualStudio.Services.WebApi.Location.VssServerDataProvider.ConnectAsync(ConnectOptions connectOptions, CancellationToken cancellationToken)\n at Microsoft.VisualStudio.Services.WebApi.Location.VssServerDataProvider.EnsureConnectedAsync(ConnectOptions optionsNeeded, CancellationToken cancellationToken)\n at Microsoft.VisualStudio.Services.WebApi.Location.VssServerDataProvider.GetInstanceIdAsync(CancellationToken cancellationToken)\n at Microsoft.VisualStudio.Services.WebApi.Location.LocationService.GetLocationDataAsync(Guid locationAreaIdentifier, CancellationToken cancellationToken)\n at Microsoft.VisualStudio.Services.WebApi.VssConnection.GetClientInstanceAsync(Type managedType, Guid serviceIdentifier, CancellationToken cancellationToken, VssHttpRequestSettings settings, DelegatingHandler[] handlers)\n at Microsoft.VisualStudio.Services.WebApi.VssConnection.GetClientServiceImplAsync(Type requestedType, Guid serviceIdentifier, Func`4 getInstanceAsync, CancellationToken cancellationToken)\n at Microsoft.VisualStudio.Services.WebApi.VssConnection.GetClientAsync[T](CancellationToken cancellationToken)\n at Microsoft.VisualStudio.Services.Content.Common.AsyncHttpRetryHelper`1.InvokeAsync(CancellationToken cancellationToken)\n at Microsoft.VisualStudio.Services.Content.Common.ExceptionExtensions.ReThrow(Exception ex)\n at Microsoft.VisualStudio.Services.Content.Common.AsyncHttpRetryHelper`1.InvokeAsync(CancellationToken cancellationToken)\n at ArtifactTool.DedupManifestArtifactClientProvider.GetDedupManifestArtifactClientAsync(String serviceUrl, String patVar, ILogger commandBaseLogger, IAppTraceSource tracer, String cacheDirectory, Boolean cacheWriteAllowed, CancellationToken cancellationToken) in D:\\a\\1\\s\\src\\ArtifactTool\\Providers\\DedupManifestArtifactClient\\DedupManifestArtifactClientProvider.cs:line 56\n at ArtifactTool.Commands.UPackPublishCommand.ExecuteAsync() in D:\\a\\1\\s\\src\\ArtifactTool\\Commands\\UPack\\UPackPublishCommand.cs:line 51\n at ArtifactTool.Commands.CommandBase.OnExecuteAsync() in D:\\a\\1\\s\\src\\ArtifactTool\\Commands\\CommandBase.cs:line 105\n at McMaster.Extensions.CommandLineUtils.Conventions.ExecuteMethodConvention.InvokeAsync(MethodInfo method, Object instance, Object[] arguments) in C:\\projects\\commandlineutils\\src\\CommandLineUtils\\Conventions\\ExecuteMethodConvention.cs:line 77\n at McMaster.Extensions.CommandLineUtils.Conventions.ExecuteMethodConvention.OnExecute(ConventionContext context) in C:\\projects\\commandlineutils\\src\\CommandLineUtils\\Conventions\\ExecuteMethodConvention.cs:line 62\n at McMaster.Extensions.CommandLineUtils.Conventions.ExecuteMethodConvention.<>c\\_\\_DisplayClass0\\_0.<b\\_\\_0>d.MoveNext() in C:\\projects\\commandlineutils\\src\\CommandLineUtils\\Conventions\\ExecuteMethodConvention.cs:line 25\n--- End of stack trace from previous location where exception was thrown ---\n at McMaster.Extensions.CommandLineUtils.CommandLineApplication.<>c\\_\\_DisplayClass126\\_0.b\\_\\_0() in C:\\projects\\commandlineutils\\src\\CommandLineUtils\\CommandLineApplication.cs:line 505\n at McMaster.Extensions.CommandLineUtils.CommandLineApplication.Execute(String[] args) in C:\\projects\\commandlineutils\\src\\CommandLineUtils\\CommandLineApplication.cs:line 611\n at McMaster.Extensions.CommandLineUtils.CommandLineApplication.Execute[TApp](CommandLineContext context) in C:\\projects\\commandlineutils\\src\\CommandLineUtils\\CommandLineApplication.Execute.cs:line 57\n at McMaster.Extensions.CommandLineUtils.CommandLineApplication.ExecuteAsync[TApp](CommandLineContext context) in C:\\projects\\commandlineutils\\src\\CommandLineUtils\\CommandLineApplication.Execute.cs:line 145\n at McMaster.Extensions.CommandLineUtils.CommandLineApplication.ExecuteAsync[TApp](IConsole console, String[] args) in C:\\projects\\commandlineutils\\src\\CommandLineUtils\\CommandLineApplication.Execute.cs:line 130\n at McMaster.Extensions.CommandLineUtils.CommandLineApplication.ExecuteAsync[TApp](String[] args) in C:\\projects\\commandlineutils\\src\\CommandLineUtils\\CommandLineApplication.Execute.cs:line 112\nProcess ['/home/pablo/.azure/azuredevops/cli/tools/artifacttool/ArtifactTool\\_linux-x64\\_0.2.267/artifacttool', 'universal', 'publish', '--service', 'https://dev.azure.com/bkinfra/', '--patvar', 'AZURE\\_DEVOPS\\_EXT\\_ARTIFACTTOOL\\_PATVAR', '--feed', 'feed-be-coinscrap', '--package-name', 'coinscrap-us', '--package-version', '4.7.1', '--path', '/tmp/coinscrap-us.tar'] with PID 45800 exited with return code 1", "I have a powershell function (Invoke-DeployWorkflow) that triggers a github workflow (https://github.com/iNECTA/HENDA/actions/workflows/PublishToEnvironment.yaml (see below)). \n\nI want the Invoke-DeployWorkflow to have called like this \"Invoke-DeployWorkflow -CustomerApp \"HENDA\" -ArtifactTag \"230328.125132\" -Environment \"ALGODemo\" where the ArtifactTag is a git tag to a release artifact of similar format (230328.125132) that can then be referenced to a release, such as https://github.com/iNECTA/HENDA/releases/tag/230328.125132.\n\nWhat changes do I need to make to the Invoke-DeployWorkflow and the PublishToEnvironment.yaml so that I can use the \"ArtifactTag\" parmeter.\n\nfunction Invoke-DeployWorkflow :\nfunction Invoke-DeployWorkflow {\n [CmdletBinding()]\n param(\n [Parameter(Mandatory = $true)]\n [string]$App,\n\n [Parameter(Mandatory = $true)]\n [string]$Environment \n ) \n\n $Token = Get-Content -Path \"GitHubAccessToken.txt\" \n $RepoOwner = \"iNECTA\"\n $workflow\\_id = \"InectaBuild.yaml\" \n\n $headers = @{\n \"Accept\" = \"application/vnd.github.v3+json\"\n \"Authorization\" = \"token $Token\"\n }\n\n $Tag = Get-DateTimeVersionString\n\n $workflowDispatchBody = @{\n ref = \"refs/heads/main\"\n inputs = @{\n Environment = $Environment\n Tag = $Tag\n\n }\n }\n\n $workflowDispatchUrl = \"https://api.github.com/repos/$RepoOwner/$App/actions/workflows/$workflow\\_id/dispatches\"\n\n try { \n Invoke-RestMethod -Method Post -Uri $workflowDispatchUrl -Headers $headers -Body ($workflowDispatchBody | ConvertTo-Json -Compress)\n\n $returnString = \"https://github.com/iNECTA/$App/releases/tag/$Tag\"\n Write-Host \"Workflow triggered successfully.: $returnString\"\n return $returnString\n }\n catch {\n Write-Error \"Failed to trigger workflow. Error: $($\\_.Exception.Message)\"\n Write-Error \"Error details: $($\\_.ErrorDetails.Message)\"\n }\n}\n\nPublishToEnvironment.yaml:\nname: ' Publish To Environment'\n\non:\n workflow\\_dispatch:\n inputs:\n appVersion:\n description: App version to deploy to environment(s) (current, prerelease, draft, latest or version number)\n required: false\n default: 'current'\n environmentName:\n description: Environment mask to receive the new version (\\* for all, PROD\\* for all environments starting with PROD)\n required: true\n\npermissions:\n contents: read\n actions: read\n\ndefaults:\n run:\n shell: powershell\n\nenv:\n ALGoOrgSettings: ${{ vars.ALGoOrgSettings }}\n ALGoRepoSettings: ${{ vars.ALGoRepoSettings }}\n\njobs:\n Initialization:\n runs-on: [ windows-latest ]\n outputs:\n telemetryScopeJson: ${{ steps.init.outputs.telemetryScopeJson }}\n settings: ${{ steps.ReadSettings.outputs.SettingsJson }}\n environments: ${{ steps.ReadSettings.outputs.EnvironmentsJson }}\n environmentCount: ${{ steps.ReadSettings.outputs.EnvironmentCount }}\n steps:\n - name: Checkout\n uses: actions/checkout@v3\n\n - name: Initialize the workflow\n id: init\n uses: microsoft/AL-Go-Actions/WorkflowInitialize@v2.4\n with:\n shell: powershell\n eventId: \"DO0097\"\n\n - name: Read settings\n id: ReadSettings\n uses: microsoft/AL-Go-Actions/ReadSettings@v2.4\n with:\n shell: powershell\n parentTelemetryScopeJson: ${{ steps.init.outputs.telemetryScopeJson }}\n getEnvironments: ${{ github.event.inputs.environmentName }}\n includeProduction: 'Y'\n\n Deploy:\n needs: [ Initialization ]\n if: ${{ needs.Initialization.outputs.environmentCount > 0 }}\n strategy: ${{ fromJson(needs.Initialization.outputs.environments) }}\n runs-on: ${{ fromJson(matrix.os) }}\n name: Deploy to ${{ matrix.environment }}\n environment:\n name: ${{ matrix.environment }}\n steps:\n - name: Checkout\n uses: actions/checkout@v3\n\n - name: EnvName\n id: envName\n run: |\n $ErrorActionPreference = \"STOP\"\n Set-StrictMode -version 2.0\n $envName = '${{ matrix.environment }}'.split(' ')[0]\n Add-Content -Path $env:GITHUB\\_OUTPUT -Value \"envName=$envName\"\n\n - name: Read settings\n uses: microsoft/AL-Go-Actions/ReadSettings@v2.4\n with:\n shell: powershell\n\n - name: Read secrets\n uses: microsoft/AL-Go-Actions/ReadSecrets@v2.4\n env:\n secrets: ${{ toJson(secrets) }}\n with:\n shell: powershell\n settingsJson: ${{ env.Settings }}\n secrets: '${{ steps.envName.outputs.envName }}-AuthContext,${{ steps.envName.outputs.envName }}\\_AuthContext,AuthContext,${{ steps.envName.outputs.envName }}-EnvironmentName,${{ steps.envName.outputs.envName }}\\_EnvironmentName,EnvironmentName,projects'\n\n - name: AuthContext\n id: authContext\n run: |\n $ErrorActionPreference = \"STOP\"\n Set-StrictMode -version 2.0\n $envName = '${{ steps.envName.outputs.envName }}'\n $deployToSettingStr = [System.Environment]::GetEnvironmentVariable(\"DeployTo$envName\")\n if ($deployToSettingStr) {\n $deployToSetting = $deployToSettingStr | ConvertFrom-Json\n }\n else {\n $deployToSetting = [PSCustomObject]@{}\n }\n $authContext = $null\n \"$($envName)-AuthContext\", \"$($envName)\\_AuthContext\", \"AuthContext\" | ForEach-Object {\n if (!($authContext)) {\n $authContext = [System.Environment]::GetEnvironmentVariable($\\_)\n if ($authContext) {\n Write-Host \"Using $\\_ secret as AuthContext\"\n }\n } \n }\n if (!($authContext)) {\n Write-Host \"::Error::No AuthContext provided\"\n exit 1\n }\n if ((\"$deployToSetting\" -ne \"\") -and $deployToSetting.PSObject.Properties.name -eq \"EnvironmentName\") {\n $environmentName = $deployToSetting.EnvironmentName\n }\n else {\n $environmentName = $null\n \"$($envName)-EnvironmentName\", \"$($envName)\\_EnvironmentName\", \"EnvironmentName\" | ForEach-Object {\n if (!($environmentName)) {\n $EnvironmentName = [System.Text.Encoding]::UTF8.GetString([System.Convert]::FromBase64String([System.Environment]::GetEnvironmentVariable($\\_)))\n if ($EnvironmentName) {\n Write-Host \"Using $\\_ secret as EnvironmentName\"\n Write-Host \"Please consider using the DeployTo$\\_ setting instead, where you can specify EnvironmentName, projects and branches\"\n }\n } \n }\n }\n if (!($environmentName)) {\n $environmentName = '${{ steps.envName.outputs.envName }}'\n }\n $environmentName = [Convert]::ToBase64String([System.Text.Encoding]::UTF8.GetBytes(($environmentName + '${{ matrix.environment }}'.SubString($envName.Length)).ToUpperInvariant()))\n if ((\"$deployToSetting\" -ne \"\") -and $deployToSetting.PSObject.Properties.name -eq \"projects\") {\n $projects = $deployToSetting.projects\n }\n else {\n $projects = [System.Environment]::GetEnvironmentVariable(\"$($envName)-projects\")\n if (-not $projects) {\n $projects = [System.Environment]::GetEnvironmentVariable(\"$($envName)\\_Projects\")\n if (-not $projects) {\n $projects = [System.Text.Encoding]::UTF8.GetString([System.Convert]::FromBase64String([System.Environment]::GetEnvironmentVariable('projects')))\n }\n }\n }\n if ($projects -eq '') {\n $projects = '\\*'\n }\n elseif ($projects -ne '\\*') {\n $buildProjects = '${{ needs.Initialization.outputs.projects }}' | ConvertFrom-Json\n $projects = ($projects.Split(',') | Where-Object { $buildProjects -contains $\\_ }) -join ','\n }\n Add-Content -Path $env:GITHUB\\_OUTPUT -Value \"authContext=$authContext\"\n Write-Host \"authContext=$authContext\"\n Add-Content -Path $env:GITHUB\\_OUTPUT -Value \"environmentName=$environmentName\"\n Write-Host \"environmentName=$([System.Text.Encoding]::UTF8.GetString([System.Convert]::FromBase64String($environmentName)))\"\n Write-Host \"environmentName (as Base64)=$environmentName\"\n Add-Content -Path $env:GITHUB\\_OUTPUT -Value \"projects=$projects\"\n Write-Host \"projects=$projects\"\n\n - name: Deploy\n uses: microsoft/AL-Go-Actions/Deploy@v2.4\n env:\n AuthContext: ${{ steps.authContext.outputs.authContext }}\n with:\n shell: powershell\n parentTelemetryScopeJson: ${{ needs.Initialization.outputs.telemetryScopeJson }}\n type: 'Publish'\n projects: ${{ steps.authContext.outputs.projects }}\n environmentName: ${{ steps.authContext.outputs.environmentName }}\n artifacts: ${{ github.event.inputs.appVersion }}\n\n PostProcess:\n if: always()\n runs-on: [ windows-latest ]\n needs: [ Initialization, Deploy ]\n steps:\n - name: Checkout\n uses: actions/checkout@v3\n\n - name: Finalize the workflow\n id: PostProcess\n uses: microsoft/AL-Go-Actions/WorkflowPostProcess@v2.4\n with:\n shell: powershell\n eventId: \"DO0097\"\n telemetryScopeJson: ${{ needs.Initialization.outputs.telemetryScopeJson }}", "the Deploy section in the yaml file runs the Deploy.ps1 file (see below). \n\nHow do have the \"PublishToEnviornment\" pipeline use the artifacts from a specific release, such as this one with tag 230328.125132, (with this url https://github.com/iNECTA/HENDA/releases/tag/230328.125132)\nDeploy.ps1:\nParam(\n [Parameter(HelpMessage = \"The GitHub actor running the action\", Mandatory = $false)]\n [string] $actor,\n [Parameter(HelpMessage = \"The GitHub token running the action\", Mandatory = $false)]\n [string] $token,\n [Parameter(HelpMessage = \"Specifies the parent telemetry scope for the telemetry signal\", Mandatory = $false)]\n [string] $parentTelemetryScopeJson = '7b7d',\n [Parameter(HelpMessage = \"Projects to deploy\", Mandatory = $false)]\n [string] $projects = '',\n [Parameter(HelpMessage = \"Name of environment to deploy to\", Mandatory = $true)]\n [string] $environmentName,\n [Parameter(HelpMessage = \"Artifacts to deploy\", Mandatory = $true)]\n [string] $artifacts,\n [Parameter(HelpMessage = \"Type of deployment (CD or Publish)\", Mandatory = $false)]\n [ValidateSet('CD','Publish')]\n [string] $type = \"CD\"\n)\n\n$ErrorActionPreference = \"Stop\"\nSet-StrictMode -Version 2.0\n$telemetryScope = $null\n$bcContainerHelperPath = $null\n\nif ($projects -eq '') {\n Write-Host \"No projects to deploy\"\n}\nelse {\n\n# IMPORTANT: No code that can fail should be outside the try/catch\n\ntry {\n . (Join-Path -Path $PSScriptRoot -ChildPath \"..\\AL-Go-Helper.ps1\" -Resolve)\n $BcContainerHelperPath = DownloadAndImportBcContainerHelper -baseFolder $ENV:GITHUB\\_WORKSPACE\n\n import-module (Join-Path -path $PSScriptRoot -ChildPath \"..\\TelemetryHelper.psm1\" -Resolve)\n $telemetryScope = CreateScope -eventId 'DO0075' -parentTelemetryScopeJson $parentTelemetryScopeJson\n\n $EnvironmentName = [System.Text.Encoding]::UTF8.GetString([System.Convert]::FromBase64String($environmentName))\n\n $artifacts = $artifacts.Replace('/',([System.IO.Path]::DirectorySeparatorChar)).Replace('\\',([System.IO.Path]::DirectorySeparatorChar))\n\n $apps = @()\n $artifactsFolder = Join-Path $ENV:GITHUB\\_WORKSPACE \".artifacts\"\n $artifactsFolderCreated = $false\n if ($artifacts -eq \".artifacts\") {\n $artifacts = $artifactsFolder\n }\n\n if ($artifacts -like \"$($ENV:GITHUB\\_WORKSPACE)\\*\") {\n if (Test-Path $artifacts -PathType Container) {\n $projects.Split(',') | ForEach-Object {\n $project = $\\_.Replace('\\','\\_').Replace('/','\\_')\n $refname = \"$ENV:GITHUB\\_REF\\_NAME\".Replace('/','\\_')\n Write-Host \"project '$project'\"\n $apps += @((Get-ChildItem -Path $artifacts -Filter \"$project-$refname-Apps-\\*.\\*.\\*.\\*\") | ForEach-Object { $\\_.FullName })\n if (!($apps)) {\n throw \"There is no artifacts present in $artifacts matching $project-$refname-Apps-.\"\n }\n $apps += @((Get-ChildItem -Path $artifacts -Filter \"$project-$refname-Dependencies-\\*.\\*.\\*.\\*\") | ForEach-Object { $\\_.FullName })\n }\n }\n elseif (Test-Path $artifacts) {\n $apps = $artifacts\n }\n else {\n throw \"Artifact $artifacts was not found. Make sure that the artifact files exist and files are not corrupted.\"\n }\n }\n elseif ($artifacts -eq \"current\" -or $artifacts -eq \"prerelease\" -or $artifacts -eq \"draft\") {\n # latest released version\n $releases = GetReleases -token $token -api\\_url $ENV:GITHUB\\_API\\_URL -repository $ENV:GITHUB\\_REPOSITORY\n if ($artifacts -eq \"current\") {\n $release = $releases | Where-Object { -not ($\\_.prerelease -or $\\_.draft) } | Select-Object -First 1\n }\n elseif ($artifacts -eq \"prerelease\") {\n $release = $releases | Where-Object { -not ($\\_.draft) } | Select-Object -First 1\n }\n elseif ($artifacts -eq \"draft\") {\n $release = $releases | Select-Object -First 1\n }\n if (!($release)) {\n throw \"Unable to locate $artifacts release\"\n }\n New-Item $artifactsFolder -ItemType Directory | Out-Null\n $artifactsFolderCreated = $true\n DownloadRelease -token $token -projects $projects -api\\_url $ENV:GITHUB\\_API\\_URL -repository $ENV:GITHUB\\_REPOSITORY -release $release -path $artifactsFolder -mask \"Apps\"\n DownloadRelease -token $token -projects $projects -api\\_url $ENV:GITHUB\\_API\\_URL -repository $ENV:GITHUB\\_REPOSITORY -release $release -path $artifactsFolder -mask \"Dependencies\"\n $apps = @((Get-ChildItem -Path $artifactsFolder) | ForEach-Object { $\\_.FullName })\n if (!$apps) {\n throw \"Artifact $artifacts was not found on any release. Make sure that the artifact files exist and files are not corrupted.\"\n }\n }\n else {\n New-Item $artifactsFolder -ItemType Directory | Out-Null\n $baseFolderCreated = $true\n $allArtifacts = @(GetArtifacts -token $token -api\\_url $ENV:GITHUB\\_API\\_URL -repository $ENV:GITHUB\\_REPOSITORY -mask \"Apps\" -projects $projects -Version $artifacts -branch \"main\")\n $allArtifacts += @(GetArtifacts -token $token -api\\_url $ENV:GITHUB\\_API\\_URL -repository $ENV:GITHUB\\_REPOSITORY -mask \"Dependencies\" -projects $projects -Version $artifacts -branch \"main\")\n if ($allArtifacts) {\n $allArtifacts | ForEach-Object {\n $appFile = DownloadArtifact -token $token -artifact $\\_ -path $artifactsFolder\n if (!(Test-Path $appFile)) {\n throw \"Unable to download artifact $($\\_.name)\"\n }\n $apps += @($appFile)\n }\n }\n else {\n throw \"Could not find any Apps artifacts for projects $projects, version $artifacts\"\n }\n }\n\n Write-Host \"Apps to deploy\"\n $apps | Out-Host\n\n Set-Location $ENV:GITHUB\\_WORKSPACE\n if (-not ($ENV:AuthContext)) {\n throw \"An environment secret for environment($environmentName) called AUTHCONTEXT containing authentication information for the environment was not found.You must create an environment secret.\"\n }\n $authContext = [System.Text.Encoding]::UTF8.GetString([System.Convert]::FromBase64String($ENV:AuthContext))\n\n try {\n $authContextParams = $authContext | ConvertFrom-Json | ConvertTo-HashTable\n $bcAuthContext = New-BcAuthContext @authContextParams\n } catch {\n throw \"Authentication failed. $([environment]::Newline) $($\\_.exception.message)\"\n }\n\n $envName = $environmentName.Split(' ')[0]\n Write-Host \"$($bcContainerHelperConfig.baseUrl.TrimEnd('/'))/$($bcAuthContext.tenantId)/$envName/deployment/url\"\n $response = Invoke-RestMethod -UseBasicParsing -Method Get -Uri \"$($bcContainerHelperConfig.baseUrl.TrimEnd('/'))/$($bcAuthContext.tenantId)/$envName/deployment/url\"\n if ($response.Status -eq \"DoesNotExist\") {\n OutputError -message \"Environment with name $envName does not exist in the current authorization context.\"\n exit\n }\n if ($response.Status -ne \"Ready\") {\n OutputError -message \"Environment with name $envName is not ready (Status is $($response.Status)).\"\n exit\n }\n\n try {\n if ($response.environmentType -eq 1) {\n if ($bcAuthContext.ClientSecret) {\n Write-Host \"Using S2S, publishing apps using automation API\"\n Publish-PerTenantExtensionApps -bcAuthContext $bcAuthContext -environment $envName -appFiles $apps\n }\n else {\n Write-Host \"Publishing apps using development endpoint\"\n Publish-BcContainerApp -bcAuthContext $bcAuthContext -environment $envName -appFile $apps -useDevEndpoint -checkAlreadyInstalled\n }\n }\n else {\n if ($type -eq 'CD') {\n Write-Host \"Ignoring environment $environmentName, which is a production environment\"\n }\n else {\n # Check for AppSource App - cannot be deployed\n Write-Host \"Publishing apps using automation API\"\n Publish-PerTenantExtensionApps -bcAuthContext $bcAuthContext -environment $envName -appFiles $apps\n }\n }\n }\n catch {\n OutputError -message \"Deploying to $environmentName failed.$([environment]::Newline) $($\\_.Exception.Message)\"\n exit\n }\n\n if ($artifactsFolderCreated) {\n Remove-Item $artifactsFolder -Recurse -Force\n }\n\n TrackTrace -telemetryScope $telemetryScope\n\n}\ncatch {\n OutputError -message \"Deploy action failed.$([environment]::Newline)Error: $($\\_.Exception.Message)$([environment]::Newline)Stacktrace: $($\\_.scriptStackTrace)\"\n TrackException -telemetryScope $telemetryScope -errorRecord $\\_\n}\nfinally {\n CleanupAfterBcContainerHelper -bcContainerHelperPath $bcContainerHelperPath\n}\n}", "Now after all this, the contractor is filing claims against the architect. Here is the Contractor's arbitration demands: DEMAND FOR ARBITRATION\nBY GOOD AND CHEAP CONSTRUCTION CORP.\nAND STATEMENT OF CLAIM\nClaimant Good + Cheap Construction Corp. (\u201cContractor\u201d) hereby demands arbitration of its claims against Respondents Warbucks Enterprises LLC (\u201cWarbucks\u201d) and Columbia Architects PLLC (Architect\u201d) under the Construction Arbitration Rules established by the American Arbitration Association, for the reasons set forth below.\nTHE ARBITRATION AGREEMENTS\n1. Contractor demands arbitration against Warbucks under the arbitration clause in the AIA A101-2007 Owner/Contractor Agreement executed by Warbucks and Contractor and dated as of September 1, [D-4] (the \u201cArbitration Clause\u201d). Section 6.2 of the agreement shows that \u201cArbitration pursuant to Section 15.4 of Document A201-2007\u201d has been checked off. The Arbitration Clause set forth in Section 15.4.1 of the latter document states in pertinent part as follows:\nIf the parties have selected arbitration as the method for binding dispute resolution in the Agreement, any Claim subject to, but not resolved by,\n- 2 -\nmediation shall be subject to arbitration which, unless the parties mutually agree otherwise, shall be administered by the American Arbitration Association in accordance with its Construction Industry Arbitration Rules in effect on the date of the Agreement.\n2. Contractor also demands arbitration against Architect pursuant to the arbitration clause in the AIA B101-2007 Agreement between Owner and Architect. Section 8.2.4 of the agreement shows that \u201cArbitration pursuant to Section 8.3 of this Agreement\u201d has been checked off. The Arbitration Clause is Section 8.3.1 of the same document and states as follows:\n[A]ny claim, dispute or other matter in question arising out of or related to this Agreement subject to, but not resolved by, mediation shall be subject to arbitration which, unless the parties mutually agree otherwise, shall be administered by the American Arbitration Association in accordance with its Construction Industry Arbitration Rules in effect on the date of this Agreement.\n3. This paragraph requires arbitration of \u201cany claim, dispute or other matter in question arising out of or related to [the agreement between Architect and Owner] \u2026.\u201d Contractor\u2019s claims against Architect directly arise out of that agreement as well as out of the Owner/Contractor\u2019s Agreement (which also has an arbitration clause) and, accordingly, are subject to arbitration even if Contractor does not have a direct agreement with Architect providing for arbitration.\n4. On October 20, [D-2] Architect filed a request to commence mediation with the American Arbitration Association, thereby putting in motion the condition precedent to arbitration. Mediation took place on March 30, [D-1], without resulting in a settlement of the issues. The condition precedent to arbitration has therefore been satisfied, and arbitration should proceed not just with respect to Architect\u2019s claims against Owner but also with respect to Contractor\u2019s claims against Architect.\nTHE PARTIES\n5. Claimant Good + Cheap Construction Corp. (referred to throughout this demand as \u201cContractor\u201d as previously indicated) is a New York corporation engaged in providing general contracting and construction management services. Contractor concentrates in the construction of high-rise mixed-use buildings in the New York metropolitan area.\n6. At all relevant times and information and belief, respondent Warbucks Enterprises LLC (referred to throughout this demand as \u201cWarbucks\u201d) is and was a New York limited liability company with an office at 250 Park Avenue, New York, NY 10022. Warbucks is in the business of developing real estate for commercial and residential use.\n7. At all relevant times and upon information and belief, respondent Columbia Architects (referred to throughout this demand as \u201cArchitect\u201d) is and was a firm of licensed New York architects providing architecture and interior design services, with an office at 180 Willoughby Avenue, Brooklyn, NY 11205.\n8. In May [D-5], Warbucks engaged Architect to draft and provide construction drawings for a twenty-story mixed-use condominium tower in Tribeca, City of New York, with commercial space on the ground floor and nineteen floors of high-end condominium units (one apartment per floor) (the \u201cProject\u201d). The engagement is reflected in the parties\u2019 AIA B101-2007 professional services agreement (the \u201cB101 Agreement\u201d).\n9. After Architect was engaged, the contract for construction of the project was put out to bid in a competitive bidding process. Contractor was the successful bidder. An AIA A101-2007 Owner/Contractor Agreement with accompanying general conditions (A201-2007) was executed by Warbucks and Contractor. 10. The Contract provides for compensation to the Contractor based upon a fixed fee to be paid out in monthly increments keyed to percentage of completion during the three-year budgeted schedule for the Project. Contractor must submit monthly applications for payment (\u201cRequisitions\u201d), certify them as accurate, and send them to Architect for review and approval. Architect must then timely sign off on the Requisitions or, if any issues are found, promptly raise questions with Contractor about the issues and arrange for appropriate adjustment. Approved Requisitions are to be paid within fifteen days of receipt. The payable amount shall be the amount set forth in the Requisition less a retainage of 10%, which is to be held for payment at the conclusion of the Project. Any short payments by Owner in any given month would properly be shown on the next month\u2019s Requisition as immediately due and payable.\nClaim against Owner.\n11. Contractor timely submitted monthly Requisitions to the Architect for approval throughout the course of Contractor\u2019s work on the Project, and in every instance, Architect approved each such Requisition. Owner, however, did not comply with its obligations under the Owner/Contractor Agreement to pay within 15 days after receipt or to withhold only 10% of the amount due as retainage. Instead, Owner made a practice of regularly delaying payments by 60 days or more and then, upon making payment, withheld typically 20% of the amount due as purported retainage.\n12. Despite objections orally and in writing by Contractor, the Architect\u2019s approval and the requirements of the Owner/Architect Agreement, Owner refused to cease the improper practices described above, resulting eventually, as of May [D-2], in an improperly withheld retainage amounting to $8,100,000 owed and unpaid to Contractor, twice the amount that was permitted. The written objections by Contractor during the six months leading up to April [D-2] expressly gave notice that continued failure to pay amounts due could leave Contractor with no choice but to stop work and bring collection proceedings. 13. Contractor finally was constrained to stop work in April [D-2], having submitted its Requisition No. 18 reflecting the work performed the previous month. Owner improperly refused to pay any part of that Requisition, including both the unpaid prior amounts reflected therein and the amount due for the month. The total amount due to Contractor for fees under the Agreement as of that date is $11,668,646.\n14. Because Owner materially breached the Owner/Contractor Agreement, Owner is liable to pay Contractor the profit it would have made on the remaining amounts due to it as provided for in the Agreement, including all retainage amounts, which add up to $9,773,376.\n15. In addition, because of lost opportunities to perform work on other, better paying projects while meeting its obligations under the Owner/Contractor Agreement, Contractor has been damaged in the amount of not less than $10 million in lost profits and must pay interest of not less than $200,000 on claims by subcontractors that Contractor could not pay because of Owner\u2019s failures to pay the amounts due under the Owner/Contractor Agreement, a substantial portion of which was intended to cover the charges payable to subcontractors that Contractor was unable to pay.\nClaim against Architect\n16. Contractor timely submitted its Requisition to Architect (AFP # 18) for review and approval by Architect on or about May 12, [D-2]. Architect had previously approved all prior Requisitions Contractor had submitted.\n17. Requisition No. 18 included the unpaid balances that Architect had repeatedly approved in prior months, and that grew each month in proportion to the excessive retainage, withheld by Owner. The amount charged for new work during the month covered by Requisition No. 18 was precisely the same as the amount charged in each prior requisition and was based upon the same calculations that Architect had previously found acceptable. Notwithstanding these facts, Architect failed and refused to approve Requisition No. 18.\n18. Architect\u2019s refusal to approve Requisition No. 18 was intentional and lacked any reasonable basis. Architect knew the terms of the Owner/Contractor Agreement, and understood that refusal to approve the Requisition interfered with the contractual intent of that agreement. On information and belief, Architect conspired with Warbucks to deny Contractor payment on the final Requisition. Accordingly, Architect\u2019s conduct as aforesaid constituted tortious interference with the contractual relations between Contractor and Owner that caused direct financial harm to Contractor.\n19. By reason of the foregoing, Architect is liable to Contractor for all charges payable to Contractor under Requisition No. 18, i.e., $3,568,646, interest on the claims by subcontractors whom Contractor could not pay due to nonpayment of Requisitions, i.e., $200,000, and $10 million in lost profits on forgone opportunities.\nWHEREFORE, Claimant respectfully requests the Arbitrator(s) to issue an Award (1) finding Warbucks to have materially breached the Agreement by failure to pay compensation in accordance with the terms thereof and directing payment to Contractor of the sum of not less than $31,641,022, (2) finding Architect to be liable to Contractor for tortious interference with contractual relations and directing payment to Contractor of the sum of not less than $13,768,646, (3) awarding interest on the sums due at the legal rate, and (4) granting such other and further relief as to the Arbitrator(s) may seem just and proper.", "Ok, now, I am showing you the form looks like:\n\nr\nUSCIS\nUse\nOnly\nPetition for a Nonimmigrant Worker\nDepartment of Homeland Security\nU.S. Citizenship and Immigration Services\nUSCIS\nForm I-129\nOMB No. 1615-0009\nExpires 11/30/2025\nClassification Approved\nConsulate/POE/PFI Notified\nExtension Granted\nCOS/Extension Granted\nReceipt Partial Approval (explain) Action Block\nClass:\nNo. of Workers:\nJob Code:\nValidity Dates:\nFrom:\nTo:\nAt:\nLegal Name of Individual Petitioner\nIf you are an individual filing this petition, complete Item Number 1. If you are a company or an organization filing this petition,\ncomplete Item Number 2.\nFamily Name (Last Name) Given Name (First Name) Middle Name\n1.\n4. Contact Information\nPart 1. Petitioner Information\n\u25ba START HERE - Type or print in black ink.\n2. Company or Organization Name\n3. Mailing Address of Individual, Company or Organization\nCity or Town State ZIP Code\nIn Care Of Name\nStreet Number and Name Apt. Ste. Flr. Number\nDaytime Telephone Number\nU.S. Social Security Number (if any)\nEmail Address (if any)\nIndividual IRS Tax Number\nMobile Telephone Number\nFederal Employer Identification Number (FEIN)\n5. Other Information\n\u25ba \u25ba\nProvince Postal Code Country\n\u25ba\n(USPS ZIP Code Lookup)\n Page 1 of 36\nForm I-129 Edition 11/02/22\nPart 2. Information About This Petition (See instructions for fee information)\n1. Requested Nonimmigrant Classification (Write classification symbol):\n2. Basis for Classification (select only one box):\nNew employment.\nNew concurrent employment.\nChange of employer.\nAmended petition.\nChange in previously approved employment.\nContinuation of previously approved employment without change with the same employer.\n3. Provide the most recent petition/application receipt number for the\nbeneficiary. If none exists, indicate \"None.\"\nNotify the office in Part 4. so each beneficiary can obtain a visa or be admitted. (NOTE: A petition is not required for\nE-1, E-2, E-3, H-1B1 Chile/Singapore, or TN visa beneficiaries.)\nChange the status and extend the stay of each beneficiary because the beneficiary(ies) is/are now in the United States in\nanother status (see instructions for limitations). This is available only when you check \"New Employment\" in Item\nNumber 2., above.\nExtend the stay of each beneficiary because the beneficiary(ies) now hold(s) this status.\nAmend the stay of each beneficiary because the beneficiary(ies) now hold(s) this status.\n4. Requested Action (select only one box):\nExtend the status of a nonimmigrant classification based on a free trade agreement. (See Trade Agreement Supplement\nto Form I-129 for TN and H-1B1.)\nChange status to a nonimmigrant classification based on a free trade agreement. (See Trade Agreement Supplement to\nForm I-129 for TN and H-1B1.)\n5. Total number of workers included in this petition. (See instructions relating to\nwhen more than one worker can be included.)\nPart 3. Beneficiary Information (Information about the beneficiary/beneficiaries you are filing for. Complete the\nblocks below. Use the Attachment-1 sheet to name each beneficiary included in this petition.)\n1. If an Entertainment Group, Provide the Group Name\n2. Provide Name of Beneficiary\nFamily Name (Last Name) Given Name (First Name) Middle Name\nFamily Name (Last Name) Given Name (First Name) Middle Name\n3. Provide all other names the beneficiary has used. Include nicknames, aliases, maiden name, and names from all previous marriages.\n4. Other Information\nDate of birth (mm/dd/yyyy) Gender\nMale Female\nU.S. Social Security Number (if any)\n\u25ba\n\u25ba\n\u25ba\na.\nb.\nc.\nd.\ne.\nf.\na.\nb.\nc.\nd.\ne.\nf.\n Page 2 of 36\nForm I-129 Edition 11/02/22\nDate Passport or Travel Document\nExpires (mm/dd/yyyy)\nCountry of Citizenship or Nationality\n6. Current Residential U.S. Address (if applicable) (do not list a P.O. Box)\nEmployment Authorization Document (EAD)\nNumber (if any)\nStudent and Exchange Visitor Information System (SEVIS) Number (if\nany)\nCity or Town State ZIP Code\nStreet Number and Name Apt. Ste. Flr. Number\nCurrent Nonimmigrant Status Date Status Expires or D/S (mm/dd/yyyy)\nPassport or Travel Document Country of\nIssuance\nDate Passport or Travel Document\nIssued (mm/dd/yyyy)\n5. If the beneficiary is in the United States, complete the following:\nCountry of Birth\nI-94 Arrival-Departure Record Number\n\u25ba\nPart 3. Beneficiary Information (Information about the beneficiary/beneficiaries you are filing for. Complete the\nblocks below. Use the Attachment-1 sheet to name each beneficiary included in this petition.) (continued)\nDate of Last Arrival (mm/dd/yyyy) Passport or Travel Document Number\nPart 4. Processing Information\n1. If a beneficiary or beneficiaries named in Part 3. is/are outside the United States, or a requested extension of stay or change of\nstatus cannot be granted, state the U.S. Consulate or inspection facility you want notified if this petition is approved.\na. Type of Office (select only one box):\nb. Office Address (City) c. U.S. State or Foreign Country\nConsulate Pre-flight inspection Port of Entry\nd. Beneficiary's Foreign Address\nCity or Town\nStreet Number and Name Apt.Ste. Flr. Number\nAlien Registration Number (A-Number)\nAProvince of Birth\n\u25ba\n2. Does each person in this petition have a valid passport?\nState\nPostal Code Country\nYes No. If no, go to Part 9. and type or print your\nexplanation.\nProvince\n Page 3 of 36\nForm I-129 Edition 11/02/22\nPart 4. Processing Information (continued)\n5. Are you filing any applications for dependents with this petition?\nYes. If yes, proceed to Part 9. and list the beneficiary's(ies) name(s).\nYes. If yes, how many? \u25ba\nYes. If yes, answer the questions below. No. If no, proceed to Item Number 9.\n4. Are you filing any applications for replacement/initial I-94, Arrival-Departure Records with this petition? Note that if the\nbeneficiary was issued an electronic Form I-94 by CBP when he/she was admitted to the United States at an air or sea port, he/\nshe may be able to obtain the Form I-94 from the CBP Website at www.cbp.gov/i94 instead of filing an application for a\nreplacement/initial I-94.\n9. Have you ever previously filed a nonimmigrant petition for this beneficiary?\n7. Have you ever filed an immigrant petition for any beneficiary in this petition?\n6. Is any beneficiary in this petition in removal proceedings?\n8. Did you indicate you were filing a new petition in Part 2.?\na. Has any beneficiary in this petition ever been given the classification you are now requesting within the last seven years?\nb. Has any beneficiary in this petition ever been denied the classification you are now requesting within the last seven years?\n10. If you are filing for an entertainment group, has any beneficiary in this petition not been with the group for at least one year?\n11.b. If you checked yes in Item Number 11.a., provide the dates the beneficiary maintained status as a J-1 exchange visitor or J-2\ndependent. Also, provide evidence of this status by attaching a copy of either a DS-2019, Certificate of Eligibility for Exchange\nVisitor (J-1) Status, a Form IAP-66, or a copy of the passport that includes the J visa stamp.\n11.a. Has any beneficiary in this petition ever been a J-1 exchange visitor or J-2 dependent of a J-1 exchange visitor?\nPart 5. Basic Information About the Proposed Employment and Employer\n1. Job Title 2. LCA or ETA Case Number\n\u25ba\n\u25ba\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nYes. If yes, how many?\nYes. If yes, how many?\nYes. If yes, proceed to Part 9. and type or print your explanation.\nYes. If yes, proceed to Part 9. and type or print your explanation.\nYes. If yes, proceed to Part 9. and type or print your explanation.\nYes. If yes, proceed to Part 9. and type or print your explanation.\nYes. If yes, proceed to Item Number 11.b.\nAttach the Form I-129 supplement relevant to the classification of the worker(s) you are requesting.\n3. Are you filing any other petitions with this one?\nYes. If yes, how many? \u25ba No\n Page 4 of 36\nForm I-129 Edition 11/02/22\nPart 5. Basic Information About the Proposed Employment and Employer (continued)\n4. Did you include an itinerary with the petition?\n5. Will the beneficiary(ies) work for you off-site at another company or organization's location?\n12. Type of Business 13. Year Established\n14. Current Number of Employees in the United States 15. Gross Annual Income 16. Net Annual Income\n10. Other Compensation (Explain)\n11. Dates of intended employment From: To:\n7. Is this a full-time position?\n6. Will the beneficiary(ies) work exclusively in the Commonwealth of the Northern Mariana Islands (CNMI)?\n8. If the answer to Item Number 7. is no, how many hours per week for the position? \u25ba\n\u25ba\n(mm/dd/yyyy) (mm/dd/yyyy)\nNo\nYes\nNo\nYes No\nYes\nNo\nYes\n9. Wages: $ per (Specify hour, week, month, or year)\n3. Address where the beneficiary(ies) will work if different from address in Part 1.\nStreet Number and Name Apt. Ste. Flr. Number\nCity or Town State ZIP Code\n Page 5 of 36", "Section 1. Complete This Section If You Are Filing For An R-1 Religious Worker (continued)\n3. Provide a summary of the type of responsibilities of those employees who work at the same location where the beneficiary will\nbe employed. If additional space is needed, provide the information on additional sheet(s) of paper.\n Position Summary of the Type of Responsibilities for That Position\n4. Describe the relationship, if any, between the religious organization in the United States and the organization abroad of which\nthe beneficiary is a member.\n5.b. Detailed description of the beneficiary's proposed daily duties.\n5.a. Title of position offered.\nProvide the following information about the prospective employment:\n5.d. Description of the proposed salaried compensation or non-salaried compensation. If the beneficiary will be self-supporting, the\npetitioner must submit documentation establishing that the position the beneficiary will hold is part of an established program\nfor temporary, uncompensated missionary work, which is part of a broader international program of missionary work sponsored\nby the denomination.\n Page 31 of 36\nForm I-129 Edition 11/02/22\nSection 1. Complete This Section If You Are Filing For An R-1 Religious Worker (continued)\nYes No. If no, type or print your explanation below and if needed, go to Part 9. of Form I-129.\n5.e. List of the address(es) or location(s) where the beneficiary will be working.\n6. The petitioner is a bona fide non-profit religious organization or a bona fide organization that is affiliated with the religious\ndenomination and is tax-exempt as described in section 501(c)(3) of the Internal Revenue Code of 1986, subsequent\namendment, or equivalent sections of prior enactments of the Internal Revenue Code. If the petitioner is affiliated with the\nreligious denomination, complete the Religious Denomination Certification included in this supplement.\nDoes the petitioner attest to all of the requirements described in Item Numbers 6. - 12. below?\nPetitioner Attestations\nYes No. If no, type or print your explanation below and if needed, go to Part 9. of Form I-129.\n7. The petitioner is willing and able to provide salaried or non-salaried compensation to the beneficiary. If the beneficiary will be\nself-supporting, the petitioner must submit documentation establishing that the position the beneficiary will hold is part of an\nestablished program for temporary, uncompensated missionary work, which is part of a broader international program of\nmissionary work sponsored by the denomination.\nYes No. If no, type or print your explanation below and if needed, go to Part 9. of Form I-129.\n8. If the beneficiary worked in the United States in an R-1 status during the 2 years immediately before the petition was filed, the\nbeneficiary received verifiable salaried or non-salaried compensation, or provided uncompensated self-support.\nYes No. If no, type or print your explanation below and if needed, go to Part 9. of Form I-129.\n9. If the position is not a religious vocation, the beneficiary will not engage in secular employment, and the petitioner will provide\nsalaried or non-salaried compensation. If the position is a traditionally uncompensated and not a religious vocation, the\nbeneficiary will not engage in secular employment, and the beneficiary will provide self-support.\n Page 32 of 36\nForm I-129 Edition 11/02/22\nSection 1. Complete This Section If You Are Filing For An R-1 Religious Worker (continued)\nYes No. If no, type or print your explanation below and if needed, go to Part 9. of Form I-129.\n10. The offered position requires at least 20 hours of work per week. If the offered position at the petitioning organization requires\nfewer than 20 hours per week, the compensated service for another religious organization and the compensated service at the\npetitioning organization will total 20 hours per week. If the beneficiary will be self-supporting, the petitioner must submit\ndocumentation establishing that the position the beneficiary will hold is part of an established program for temporary,\nuncompensated missionary work, which is part of a broader international program of missionary work sponsored by the\ndenomination.\nYes No. If no, type or print your explanation below and if needed, go to Part 9. of Form I-129.\n11. The beneficiary has been a member of the petitioner's denomination for at least two years immediately before Form I-129 was\nfiled and is otherwise qualified to perform the duties of the offered position.\nYes No. If no, type or print your explanation below and if needed, go to Part 9. of Form I-129.\n12. The petitioner will notify USCIS within 14 days if an R-1 alien is working less than the required number of hours or has been\nreleased from or has otherwise terminated employment before the expiration of a period of authorized R-1 stay.\nI certify, under penalty of perjury, that the contents of this attestation and the evidence submitted with it are true and correct.\nAttestation\nSignature of Petitioner Date (mm/dd/yyyy)\nName of Petitioner Title\nEmployer or Organization Name\n Page 33 of 36\nForm I-129 Edition 11/02/22\nSection 1. Complete This Section If You Are Filing For An R-1 Religious Worker (continued)\nDaytime Telephone Number\nCity or Town State ZIP Code\nStreet Number and Name\nEmployer or Organization Address (do not use a post office or private mail box)\nEmployer or Organization's Contact Information\nApt. Ste. Flr. Number\nFax Number Email Address (if any)\nSection 2. This Section Is Required For Petitioners Affiliated With The Religious Denomination\nReligious Denomination Certification\nI certify, under penalty of perjury, that:\nName of Employing Organization\nis affiliated with:\nName of Religious Denomination\nand that the attesting organization within the religious denomination is tax-exempt as described in section 501(c)(3) of the Internal\nRevenue Code of 1986 (codified at 26 U.S.C. 501(c)(3)), any subsequent amendment(s), subsequent amendment, or equivalent\nsections of prior enactments of the Internal Revenue Code. The contents of this certification are true and correct to the best of my\nknowledge.\nSignature of Authorized Representative of Attesting Organization Date (mm/dd/yyyy)\nCity or Town State ZIP Code\nStreet Number and Name\nAttesting Organization Name and Address (do not use a post office or private mail box)\nApt. Ste. Flr. Number\nAttesting Organization Name\nAttesting Organization's Contact Information\nDaytime Telephone Number Fax Number Email Address (if any)\nName of Authorized Representative of Attesting Organization Title\n Page 34 of 36\nForm I-129 Edition 11/02/22\nForeign Address (Complete Address)\nAddress in the United States Where You Intend to Live (Complete Address)\nFamily Name (Last Name) Given Name (First Name) Middle Name\nGender\nMale Female\nDate of birth (mm/dd/yyyy) U.S. Social Security Number (if any) A-Number (if any)\nAFamily Name (Last Name) Given Name (First Name) Middle Name\nAll Other Names Used (include aliases, maiden name and names from previous marriages)\nCity or Town State ZIP Code\nStreet Number and Name Apt. Ste. Flr. Number\nCity or Town State ZIP Code\nStreet Number and Name Apt. Ste. Flr. Number\nCountry of Birth Country of Citizenship or Nationality\nProvince Postal Code Country\nIF IN THE UNITED STATES:\nDate Passport or Travel Document\nExpires (mm/dd/yyyy)\nI-94 Arrival-Departure Record\nNumber\nCurrent Nonimmigrant Status Date Status Expires or D/S (mm/dd/yyyy)\nCountry of Issuance for Passport\nor Travel Document\nDate Passport or Travel Document\nIssued (mm/dd/yyyy)\nDate of Last Arrival\n(mm/dd/yyyy)\nEmployment Authorization Document (EAD) Number\n(if any)\nStudent and Exchange Visitor Information System (SEVIS) Number\n(if any)\nPassport or Travel Document\nNumber\n\u25ba\nAttachment-1\nAttach to Form I-129 when more than one person is included in the petition. (List each person separately. Do not\ninclude the person you named on the Form I-129.)\n Page 35 of 36\nForm I-129 Edition 11/02/22\nForeign Address (Complete Address)\nAddress in the United States Where You Intend to Live (Complete Address)\nFamily Name (Last Name) Given Name (First Name) Middle Name\nGender\nMale Female\nDate of birth (mm/dd/yyyy) U.S. Social Security Number (if any) A-Number (if any)\nAFamily Name (Last Name) Given Name (First Name) Middle Name\nAll Other Names Used (include aliases, maiden name and names from previous Marriages)\nCity or Town State ZIP Code\nStreet Number and Name Apt. Ste. Flr. Number\nCity or Town State ZIP Code\nStreet Number and Name Apt. Ste. Flr. Number\nCountry of Birth Country of Citizenship or Nationality\nProvince Postal Code Country\nIF IN THE UNITED STATES:\nDate Passport or Travel Document\nExpires (mm/dd/yyyy)\nI-94 Arrival-Departure Record\nNumber\nCurrent Nonimmigrant Status Date Status Expires or D/S (mm/dd/yyyy)\nCountry of Issuance for Passport\nor Travel Document\nDate Passport or Travel Document\nIssued (mm/dd/yyyy)\nDate of Last Arrival\n(mm/dd/yyyy)\nEmployment Authorization Document (EAD) Number\n(if any)\nStudent and Exchange Visitor Information System (SEVIS) Number\n(if any)\nPassport or Travel Document\nNumber\n\u25ba\nAttachment-1\nAttach to Form I-129 when more than one person is included in the petition. (List each person separately. Do not\ninclude the person you named on the Form I-129.)\n Page 36 of 36", "please summarise the content in bullet form for the following text. We don't even know what direction we are moving to. it's the end of the year and we do not know what number of sale/kpi we need to do to get there. It is not clear what promotions are judged against and whether I am eligible for promotions within my current role. Stop recruiting externally for positions that could be filled through internal promotions. Don't let good people (meaning in their roles) leave this company easily. Because, i've experience during this year, many talented people in our company decided to leave and it is truly demotivated me. there are lack of clarity of work/responsibility between departments, we are also lack of specialize talents to handle selected responsibility. Growth is very slow. headcount freeze. no discussion on this so far. I was hired for a different role and have been doing something else over past one year. Would probably stay given lack of better job opportunities, given the economic and covid situation. But given a better choice, unlikely to stay. no proper road map. Some people only thinks about their own cushy positions. Not thinking about the company's well being as a whole. 1. The digital journey is not all about programmers only. The leadership team needs to understand that not everyone can be a programmer or wants to be a programmer. We all made choices for our career and though from IT, we chose not to take the programming route. 2. The hiring process needs to be relooked as well. We have been unable to hire very talented people because of the current process and often settled for the third or fourth best. Someone needs to look at how the current hiring structure has actually benefited the organization in real life. People working within the group for several years are unable to transfer to our entity because of the new hiring process. Stop spending more than 2 months to issue offer letter to candidates since first interview. - Should clearly distinguish the work of BSM and DSM \\_ Currently, the VIB project - the roles of BSM are not clearly distinguished - overlapping - So most of the time DSM does it and BSM just aggregates it, but doesn't show a specific role. career opportunities are limited due to the reduced size of prudential and the reduced number of vacancies in other departments. give the opportunity to compensate and promote employees within the top management positions in the company rather than always going out to recruit people from other companies to be our managers when they were not even managers themselves before coming to PRUDENTIAL.(most are recruited from other companies as chief of services or Head of department) and we still have to train them even when employees are given such opportunities, they do not earn the same like those coming from outside that we still have to train. Lack of lateral/vertical opportunities within Angel Court. Do not recruit according to affinities or knowledge but by the real competence of the candidates; branch staff should not be isolated from the activities taking place at headquarters. If the policy of the department does not change, I would have to look elsewhere. A TL role in other insurer are fetching 7-9k. No progression and rewards but constantly tasked with new roles. stop delegating tasks for a vacant role to others and expect them to know everything. Be more understanding that it may not be that person's expertise and he/she may need time to learn how to do it. Stop being not transparent in career advancement. The promotion opportunity and route here is vague. Although the line manager always mention there is always opportunity in other departments and LBUs, that never happens. limiting the use of meeting room. Stop transferring employees from their original areas to Jakarta. Lack of career framework. Too frequent of organization restructure and job role definition are not clear. Hiring of people with redundant roles Too much initiatives that are not really needed. employee welfare, it is very unfortunate that those who have worked for a very long time do not get the opportunity to get promoted, and each dept has a different application, so that is one way to move the dept. and it is not easy to move the dept. Should not be evaluated and selected, re-examined through assessments for employees who have worked for many years. Whether an employee has the ability to fit into the new structure of the company is to look at the daily work results, not to hit an employee through each assessment. i would not recommend my company because it is beauracratic with no room to grow. people with lesser qualifications are promoted and those with degrees and not. In view of my position frankly I do not see: maybe it is done well but it is me who does not see it. I am actively considering a new job before Pru makes me redundant next year. I do not expect to be with Pru in 12 months. A lack of diverse cross-section of the leadership team does not promote a successful career path at present which in turn would lead to a good fit and succession plan. It appeared that the \u2018Chief Officer\u2019 role is given rather than earned. Stop reducing resources when growth of company has been pertinent. Here most of the time the task is delegated to the person who is more familiar/has the background, which is not according to the role and responsibility. People will be afraid to be \"all rounder\" as task on plate will be more and more but not related to the role that supposed to play. Especially when restructure happened and role changes, still carry old role + new roles as the person familiar with previous task. Stop hiring people with redundant roles. STOP TRAINING INTERNS AND NOT RECRUITING THEM AT THE END MAINWHILE THEY HAVE THE POTENTIALS AND THE ABILITY TO DO THE TASKS GIVEN TO THEM. STOP FAVORITISM. Nature of role and deliverables means work can be very stressful. This is accentuated by uncertainty around cost cutting / restructuring. a) Maybe hire more people maybe? Have a succession plan even for non managerial roles rather than to have to distribute the workload to staffs who stays loyal to the company. Or allow staffs to move easily between department to broaden their view rather than being stuck at the same place forever until they resign. That does not make sense does it? Being loyal and what you get is more work. And those who jump companies every now and then get at an average of 10% to 15% and the ones who stayed behind holding fort is subject to their performance which is very unlikely to even meet the min requirement due to the workload. b) we also need to get everyone to start listening to everyone. even when the person who is talking holds the smallest rank in the unit. some managers wings brilliant ideas and feedbacks just because they think that what we say is an \"excuse\". They ask us what is the problem, then the reply we receive it \"excuse\". Apooo? Who wants to work in a miserable place. we want to speak up because it is effecting the whole process chain tapi to them ala korang ni bagi excuse. c) start acknowledging the folks from CS are a good pool of talent and allow them to be transferred to other department and divs as part of their career progression plan. They know the ins and outs of the company process but yet we still look outside for replacements. They already know our culture, all they need is a lil guidance and they're good to go. Expect to be made redundant soon, hence often think about applying elsewhere. I think more can be done to retain talent. I see many employees stepping up to the challenge and ambitious targets set, but at the end of the day, the rewards and progression fail to match up, resulting in talent leaving. For now I don't feel that way, it's very different from when I just joined the PLA. Currently, what is felt is not considered important, because it is always emphasized that if there is something that is not appropriate at the orders of the team leader, the choice is only \"Take it\" or \"Leave it\". We should conduct a transparent study on compensation levels for new and current hires. There is no proper justification on how ranks and compensation is determined. Start to hire new employees if there are roles that are vacant because the previous staff resigned, otherwise they will definitely burden the work on existing employees. giving people titles that do not reflect their roles. it affects their CV. There is lack of clarity on where PLAL needs to be in the next 3 years - both internal and external management lack this clarity even next year is unclear. Had to go about few months to get necessary access to get my job done. All these should have been prepared as the hiring role was already determined therefore required access should have well prepared instead after joining needed to constantly liaising with respective department to get what is needed. My only comment is that AC and IFC are considered as one Head Office however role titles are not fully aligned. Although I acknowledge that our head has been pushing for this, it doesn't seem to get traction. At the beginning of the negotiation, the information will damage the internal equity, but after entering and knowing, it turns out that they were deceived or there is still room for negotiation but they are not given due to favoritism anymore. Work weight and leveling are not the same as other employees in the same position. because there is no clear career path and no promotions for us with degrees and masters degrees, we are motivated to seek better options out there. you can not be a degree holder in accounts and have a supervisor/ boss with a diploma in social work. it doesnt make sense. I don't feel much because the direction is not very clear with this position. Current role does not tally what was brief during interview. jobs are not actively advertised internally and some opportunities are provided without advertisement, and I have had several conversations about progression and development with my manager and nothing has been forthcoming despite being 4.5 years in the same role. It has been increasingly difficult to backfill roles, partly due to the lengthy interview process and unnecessary IT skills assessments even for non-technical roles. Re-evaluation of the hiring process needs to be done so that we can focus on attracting talents to our teams.", "I am trying a query in Google Sheets that looks up a postal code but encountering issues, it doesn't seem to look up postal codes that contain letters or if there is a space in the postal code like for a Swedish or Luxembourg postal code.\n\nHere is the current formula that I have:\n=QUERY('Masterfile 12/1/2022'!A:Q,\"Select \\* Where A contains \"\"\"&$C$2&\"\"\"\")\n\nHere is some sample data:\nzip\\_code country\\_code place\\_name state geometry dc1 dc1\\_ping dc1\\_distance dc2 dc2\\_ping dc2\\_distance dc3 dc3\\_ping dc3\\_distance dc4 dc4\\_ping dc4\\_distance\nT4B CA Airdrie West Alberta (-114.0398, 51.3082) USPOR01 39.50 ms 914.06 km CAMTL01 87.50 ms 3003.05 km TX1 107.00 ms 2469.22 km USWDC01 111.00 ms 3138.19 km\nT5K CA Edmonton (South Downtown / South Downtown Fringe) Alberta (-113.5103, 53.5366) USPOR01 39.50 ms 1115.31 km CAMTL01 66.00 ms 2963.98 km TX1 83.50 ms 2639.16 km USWDC01 87.25 ms 3164.88 km\nT8C CA Sherwood Park Inner Southwest Alberta (-113.1903, 53.4391) USPOR01 41.75 ms 1121.30 km USWDC01 36.75 ms 3141.48 km CAMTL01 41.75 ms 2942.49 km TX1 47.00 ms 2617.83 km\nV8V CA Victoria South British Columbia (-123.365, 48.4167) USPOR01 24.50 ms 321.32 km TX1 86.00 ms 2796.58 km USWDC01 93.00 ms 3772.56 km CAMTL01 95.00 ms 3711.16 km\nV9B CA Highlands British Columbia (-123.5271, 48.4793) USPOR01 22.00 ms 329.79 km TX1 90.50 ms 2810.41 km CAMTL01 84.50 ms 3721.14 km USWDC01 91.50 ms 3784.41 km\nB3K CA Halifax Upper Harbour Nova Scotia (-63.6017, 44.662) CAMTL01 45.00 ms 812.12 km USWDC01 55.00 ms 1337.98 km TX1 78.00 ms 3122.89 km USPOR01 106.50 ms 4545.40 km\nM4Y CA Downtown Toronto (Church and Wellesley) Ontario (-79.383, 43.6656) CAMTL01 33.25 ms 472.10 km USWDC01 56.00 ms 565.18 km TX1 68.25 ms 1917.09 km USPOR01 95.25 ms 3408.69 km\nM6J CA West Toronto (Rua A\u00c3\u00beores / Trinity) Ontario (-79.4177, 43.648) CAMTL01 31.00 ms 475.45 km USWDC01 51.00 ms 564.03 km TX1 62.50 ms 1913.68 km USPOR01 90.00 ms 3406.69 km\nM8V CA Etobicoke (New Toronto / Mimico South / Humber Bay Shores) Ontario (-79.5013, 43.6075) CAMTL01 13.00 ms 483.45 km USWDC01 27.00 ms 561.56 km TX1 51.00 ms 1905.59 km USPOR01 74.00 ms 3401.79 km\nH3G CA Downtown Montreal Southeast Quebec (-73.5793, 45.4987) CAMTL01 25.00 ms 32.34 km USWDC01 38.00 ms 822.87 km TX1 65.00 ms 2417.26 km USPOR01 89.50 ms 3779.82 km\nH1W CA Hochelaga Quebec (-73.5468, 45.5442) CAMTL01 24.75 ms 37.61 km USWDC01 38.75 ms 828.53 km TX1 62.50 ms 2421.82 km USPOR01 89.00 ms 3780.65 km\nH2J CA Plateau Mont-Royal North Central Quebec (-73.5831, 45.5302) CAMTL01 22.50 ms 34.50 km USWDC01 35.50 ms 825.90 km TX1 58.50 ms 2418.59 km USPOR01 86.00 ms 3778.45 km\nH2S CA Petite-Patrie Southwest Quebec (-73.6061, 45.5354) CAMTL01 23.00 ms 33.69 km USWDC01 37.00 ms 825.65 km TX1 62.00 ms 2417.26 km USPOR01 89.00 ms 3776.56 km\nH2V CA Outremont Quebec (-73.6072, 45.5168) CAMTL01 22.00 ms 32.12 km USWDC01 36.00 ms 823.75 km TX1 61.00 ms 2416.24 km USPOR01 88.00 ms 3777.13 km\nH3C CA Griffintown (Includes \u00c3\u017dle Notre-Dame & \u00c3\u017dle Sainte-H\u00c3\u00a9l\u00c3\u00a8ne) Quebec (-73.5472, 45.498) CAMTL01 28.00 ms 34.24 km USWDC01 40.00 ms 823.88 km TX1 64.00 ms 2419.46 km USPOR01 92.00 ms 3782.22 km\nH4C CA Saint-Henri Quebec (-73.5882, 45.4737) CAMTL01 16.00 ms 30.06 km USWDC01 32.00 ms 820.06 km TX1 55.00 ms 2415.39 km USPOR01 83.00 ms 3780.03 km\nJ4H CA Longueuil West Quebec (-73.5056, 45.5372) CAMTL01 26.00 ms 39.49 km USWDC01 45.00 ms 829.22 km TX1 66.00 ms 2424.32 km USPOR01 93.00 ms 3783.94 km\nJ4J CA Longueuil Central Quebec (-73.4721, 45.5362) CAMTL01 22.50 ms 41.47 km USWDC01 35.50 ms 830.26 km TX1 60.00 ms 2426.60 km USPOR01 85.00 ms 3786.45 km\n35206 US Birmingham Alabama (-86.7199, 33.5678) USWDC01 40.00 ms 994.78 km TX1 58.50 ms 935.54 km CAMTL01 61.00 ms 1703.79 km USPOR01 107.50 ms 3339.67 km\n36830 US Auburn Alabama (-85.4682, 32.5475) USWDC01 42.00 ms 984.77 km TX1 67.00 ms 1057.11 km CAMTL01 62.00 ms 1732.79 km USPOR01 104.00 ms 3500.23 km\n36117 US Montgomery Alabama (-86.1833, 32.3736) TX1 77.50 ms 992.60 km USWDC01 57.00 ms 1045.39 km CAMTL01 75.25 ms 1784.93 km USPOR01 109.00 ms 3456.95 km\n35603 US Decatur Alabama (-87.0004, 34.5484) TX1 79.00 ms 918.24 km USWDC01 56.00 ms 953.36 km CAMTL01 76.00 ms 1633.13 km USPOR01 118.00 ms 3257.75 km\n72034 US Conway Arkansas (-92.4683, 35.0823) TX1 62.25 ms 457.85 km CAMTL01 64.50 ms 1937.06 km USWDC01 66.50 ms 1375.08 km USPOR01 89.00 ms 2807.93 km\n72023 US Cabot Arkansas (-92.0318, 34.9457) TX1 44.75 ms 486.46 km USWDC01 57.25 ms 1343.95 km CAMTL01 67.00 ms 1917.67 km USPOR01 98.50 ms 2849.41 km\nAlso, do you think there's better ways to do this than a query as well? Maybe using FILTER or VLOOKUP? I would appreciate your suggestions.", "Here is the complete code. Beforehand, it's a plugin to a react site written in go, that hooks with a yaml file to provide buttons on the site. One set to setup tags and another to perform performer image ai upscaling of the image. When client.upscale\\_PerformerImage() is invoked, it's supposed to run through def upscale\\_PerformerImage and then findTagIdWithName to find the tag name, and then findPerformersByTag to find performer who have been tagged by the tag name, then get the image of the performer and upscale it. Here is the code import config\\_manager\nimport configparser\nimport requests\nimport sys\nimport json\nimport pathlib\nimport os\nfrom gigapixel import Gigapixel, Scale, Mode\nfrom pathlib import Path\n\n# Path to Gigapixel executable file.\nexe\\_path = Path('B:\\Program Files\\Topaz Labs LLC\\Topaz Gigapixel AI\\Topaz Gigapixel AI.exe')\n\n# Output file suffix. (e.g. pic.jpg -> pic-gigapixel.jpg)\n# You should set same value inside Gigapixel (File -> Preferences -> Default filename suffix).\noutput\\_suffix = '-gigapixel'\n\n# Create Gigapixel instance.\napp = Gigapixel(exe\\_path, output\\_suffix)\n\nconfigpath = os.path.join(pathlib.Path(\\_\\_file\\_\\_).parent.resolve(), 'config.ini')\n\ndef get\\_config\\_value(config\\_file, section, option):\n config = configparser.ConfigParser()\n config.read(config\\_file)\n return config.get(section, option)\n\n \nclass upscale\\_with:\n\n def \\_\\_init\\_\\_(self, url):\n self.url = url\n self.api\\_key = get\\_config\\_value(configpath, 'STASH', 'api\\_key')\n stash\\_url = get\\_config\\_value(configpath, 'STASH', 'url')\n if not stash\\_url:\n self.error(\"You need to set the URL in 'config.ini'\")\n return None\n self.stash\\_url = stash\\_url + \"/graphql\"\n self.headers = {\n \"Accept-Encoding\": \"gzip, deflate, br\",\n \"Content-Type\": \"application/json\",\n \"Accept\": \"application/json\",\n \"Connection\": \"keep-alive\",\n \"DNT\": \"1\",\n \"ApiKey\": self.api\\_key\n }\n \n def log(self, level, message):\n print(f\"[{level.upper()}] {message}\")\n \n def \\_\\_prefix(self,levelChar):\n startLevelChar = b'\\x01'\n endLevelChar = b'\\x02'\n\n ret = startLevelChar + levelChar + endLevelChar\n return ret.decode()\n\n def \\_\\_log(self,levelChar, s):\n if levelChar == \"\":\n return\n\n print(self.\\_\\_prefix(levelChar) + s + \"\\n\", file=sys.stderr, flush=True)\n\n def trace(self,s):\n self.\\_\\_log(b't', s)\n\n def debug(self,s):\n self.\\_\\_log(b'd', s)\n\n def info(self,s):\n self.\\_\\_log(b'i', s)\n\n def warning(self,s):\n self.\\_\\_log(b'w', s)\n\n def error(self,s):\n self.\\_\\_log(b'e', s)\n\n def progress(self,p):\n progress = min(max(0, p), 1)\n self.\\_\\_log(b'p', str(progress))\n\n def \\_\\_callGraphQL(self, query, variables=None):\n json = {}\n json['query'] = query\n if variables != None:\n json['variables'] = variables\n\n # handle cookies\n response = requests.post(self.url, json=json, headers=self.headers)\n\n if response.status\\_code == 200:\n result = response.json()\n if result.get(\"error\", None):\n for error in result[\"error\"][\"errors\"]:\n raise Exception(\"GraphQL error: {}\".format(error))\n if result.get(\"data\", None):\n return result.get(\"data\")\n else:\n raise Exception(\n \"GraphQL query failed:{} - {}. Query: {}. Variables: {}\".format(response.status\\_code, response.content, query, variables))\n \n \n def listTags(self):\n query = \"\"\"\n query {\n allTags {\n id\n name\n }\n }\"\"\"\n\n result = self.\\_\\_callGraphQL(query)\n return result[\"allTags\"]\n \n\n def findTagIdWithName(self, name):\n query = \"\"\"\nquery {\n allTags {\n id\n name\n }\n}\n \"\"\"\n\n result = self.\\_\\_callGraphQL(query)\n name = 'upscale\\_with\\_Gigapixel'\n for tag in result[\"allTags\"]:\n if tag[\"name\"] == name:\n return tag[\"id\"]\n return None\n \n\n def createTagWithName(self, name):\n query = \"\"\"\nmutation tagCreate($input:TagCreateInput!) {\n tagCreate(input: $input){\n id \n }\n}\n\"\"\"\n variables = {'input': {\n 'name': name\n }}\n\n result = self.\\_\\_callGraphQL(query, variables)\n return result[\"tagCreate\"][\"id\"]\n\n def destroyTag(self, id):\n query = \"\"\"\nmutation tagDestroy($input: TagDestroyInput!) {\n tagDestroy(input: $input)\n}\n\"\"\"\n variables = {'input': {\n 'id': id\n }}\n self.\\_\\_callGraphQL(query, variables)\n \n def findPerformersByTag(self, id):\n query = \"\"\"query performer\\_images($performer\\_filter: PerformerFilterType!) {\n findPerformers(performer\\_filter: $performer\\_filter filter: {per\\_page: -1}){\n\n performers{\n id\n name\n image\\_path\n tags{\n name\n }\n }\n}\n}\"\"\"\n variables = {'performer\\_filter': {\n 'tags': {\n 'value': id, 'modifier': 'INCLUDES', 'depth':1\n \n }\n }}\n self.error(json.dumps(variables))\n result = self.\\_\\_callGraphQL(query)\n\n for performer in tag[\"id\"]:\n return result[\"findPerformers\"][\"performers\"][\"image\\_path\"]\n\n \n# Adding Gigapixel Now\n def processPerformerImage(self, result, id):\n # for performer in self.findPerformersByTag(image\\_path):\n # id = self.findPerformersByTag(id)\n \n # Name of the image file\n file\\_name = 'image.jpg'\n \n image = requests.get(image\\_path).content\n \n # Create a Path object for the current directory\n current\\_dir = Path.cwd()\n \n # Save the image data to a file in the current directory\n with open(current\\_dir / file\\_name, 'wb') as f:\n f.write(image\\_data)\n # Variable for saved image\n image\\_saved = Path(current\\_dir + '/image.jpg')\n output\\_path = app.process(image\\_saved, scale=Scale.X2, mode=Mode.STANDARD)\n \n # processPerformerImage(output\\_path) \n \n query = \"\"\"\nmutation performerUpdate($performer\\_update\\_input: PerformerUpdateInput!){\n performerUpdate(input: $performer\\_update\\_input){\n id\n }\n}\n \"\"\"\n variables = {\"performer\\_update\\_input\": {\"image\": result, \"id\": id}}\n\n # result = self.\\_\\_callGraphQL(query, variables)\n # return result[\"performerUpdate\"]\n return self.\\_\\_callGraphQL(query, variables)\n\n def setup\\_tags(self):\n tagName='upscale\\_with\\_Gigapixel'\n tagID = self.findTagIdWithName(tagName)\n if tagID == None:\n tagID = self.createTagWithName(tagName)\n self.debug(\"adding tag \"+tagName)\n else:\n self.debug(\"tag exists, \"+tagName)\n\n def upscale\\_PerformerImage(self):\n tagName='upscale\\_with\\_Gigapixel'\n tagID=self.findTagIdWithName(tagName)\n if tagID == None:\n self.debug(\"Error no tag for upscale\\_PerformerImage\")\n else:\n self.debug(\"Tag exists for upscale\\_PerformerImage\") \n \n performers=self.findPerformersByTag(tagID)\n for performer in performers:\n if tags[\"name\"].startswith(\"upscale\\_with\\_Gigapixel\"):\n self.info(\"Upscaling all performer images with tag: \"+str(tag[\"name\"]))\n self.processPerformerImage(tag[\"id\"])\n # performers = self.findPerformersByTag('id')\n # performers = self.processPerformerImage(tag[\"id\"])\n # if tag[\"name\"][12:] in performers:\n # self.processPerformerImage(tag[\"id\"])\n\n# Press the green button in the gutter to run the script.\nif \\_\\_name\\_\\_ == '\\_\\_main\\_\\_':\n if len(sys.argv) > 1:\n url = \"http://localhost:9999/graphql\"\n if len(sys.argv) > 2:\n url = sys.argv[2]\n\n if sys.argv[1] == \"setup\":\n client = upscale\\_all(url)\n client.setup\\_tags()\n elif sys.argv[1] ==\"upscale\\_all\":\n client = upscale\\_all(url)\n client.upscale\\_PerformerImage()\n elif sys.argv[1]== \"api\":\n fragment = json.loads(sys.stdin.read())\n scheme=fragment[\"server\\_connection\"][\"Scheme\"]\n port=fragment[\"server\\_connection\"][\"Port\"]\n domain=\"localhost\"\n if \"Domain\" in fragment[\"server\\_connection\"]:\n domain = fragment[\"server\\_connection\"][\"Domain\"]\n if not domain:\n domain='localhost'\n url = scheme + \"://\" + domain + \":\" +str(port) + \"/graphql\"\n\n client=upscale\\_with(url)\n mode=fragment[\"args\"][\"mode\"]\n client.debug(\"Mode: \"+mode)\n if mode == \"setup\":\n client.setup\\_tags()\n elif mode == \"upscale\\_all\":\n # current\\_dir = Path.cwd()\n # client.processPerformerImage(str(current\\_dir) + '/image-gigapixel.jpg')\n client.upscale\\_PerformerImage()\n else:\n print(\"\")\n \n# upscaler = upscale\\_with(url)\n# result = upscaler.listTags()\n# upscaler.processPerformerImage(output\\_path)", "here is my code, can you see what is wrong? import config\\_manager\nimport configparser\nimport requests\nimport sys\nimport json\nimport pathlib\nimport os\nimport mimetypes\nimport magic\nfrom gigapixel import Gigapixel, Scale, Mode\nfrom pathlib import Path\nfrom PIL import Image\nfrom io import BytesIO\n\nmimetypes.add\\_type('image/jpeg', '.jfif', strict=True)\n\n# Path to Gigapixel executable file.\nexe\\_path = Path('B:\\Program Files\\Topaz Labs LLC\\Topaz Gigapixel AI\\Topaz Gigapixel AI.exe')\n\nconfigpath = os.path.join(pathlib.Path(\\_\\_file\\_\\_).parent.resolve(), 'config.ini')\n\ndef get\\_config\\_value(config\\_file, section, option):\n config = configparser.ConfigParser()\n config.read(config\\_file)\n return config.get(section, option)\n\n \nclass upscale\\_with:\n\n def \\_\\_init\\_\\_(self, url):\n self.url = url\n self.api\\_key = get\\_config\\_value(configpath, 'STASH', 'api\\_key')\n stash\\_url = get\\_config\\_value(configpath, 'STASH', 'url')\n if not stash\\_url:\n self.error(\"You need to set the URL in 'config.ini'\")\n return None\n self.stash\\_url = stash\\_url + \"/graphql\"\n self.headers = {\n \"Accept-Encoding\": \"gzip, deflate, br\",\n \"Content-Type\": \"application/json\",\n \"Accept\": \"application/json\",\n \"Connection\": \"keep-alive\",\n \"DNT\": \"1\",\n \"ApiKey\": self.api\\_key\n }\n \n def log(self, level, message):\n print(f\"[{level.upper()}] {message}\")\n \n def \\_\\_prefix(self,levelChar):\n startLevelChar = b'\\x01'\n endLevelChar = b'\\x02'\n\n ret = startLevelChar + levelChar + endLevelChar\n return ret.decode()\n\n def \\_\\_log(self,levelChar, s):\n if levelChar == \"\":\n return\n\n print(self.\\_\\_prefix(levelChar) + s + \"\\n\", file=sys.stderr, flush=True)\n\n def trace(self,s):\n self.\\_\\_log(b't', s)\n\n def debug(self,s):\n self.\\_\\_log(b'd', s)\n\n def info(self,s):\n self.\\_\\_log(b'i', s)\n\n def warning(self,s):\n self.\\_\\_log(b'w', s)\n\n def error(self,s):\n self.\\_\\_log(b'e', s)\n\n def progress(self,p):\n progress = min(max(0, p), 1)\n self.\\_\\_log(b'p', str(progress))\n\n def \\_\\_callGraphQL(self, query, variables=None):\n json = {}\n json['query'] = query\n if variables != None:\n json['variables'] = variables\n\n # handle cookies\n response = requests.post(self.url, json=json, headers=self.headers)\n\n if response.status\\_code == 200:\n result = response.json()\n if result.get(\"error\", None):\n for error in result[\"error\"][\"errors\"]:\n raise Exception(\"GraphQL error: {}\".format(error))\n if result.get(\"data\", None):\n return result.get(\"data\")\n else:\n raise Exception(\n \"GraphQL query failed:{} - {}. Query: {}. Variables: {}\".format(response.status\\_code, response.content, query, variables))\n \n \n def listTags(self):\n query = \"\"\"\n query {\n allTags {\n id\n name\n }\n }\"\"\"\n\n result = self.\\_\\_callGraphQL(query)\n return result[\"allTags\"]\n \n\n def findTagIdWithName(self, name):\n query = \"\"\"\nquery {\n allTags {\n id\n name\n }\n}\n \"\"\"\n\n result = self.\\_\\_callGraphQL(query)\n name = 'upscale\\_with\\_Gigapixel'\n for tag in result[\"allTags\"]:\n if tag[\"name\"] == name:\n return tag[\"id\"]\n return None\n \n\n def createTagWithName(self, name):\n query = \"\"\"\nmutation tagCreate($input:TagCreateInput!) {\n tagCreate(input: $input){\n id \n }\n}\n\"\"\"\n variables = {'input': {\n 'name': name\n }}\n\n result = self.\\_\\_callGraphQL(query, variables)\n return result[\"tagCreate\"][\"id\"]\n\n def destroyTag(self, id):\n query = \"\"\"\nmutation tagDestroy($input: TagDestroyInput!) {\n tagDestroy(input: $input)\n}\n\"\"\"\n variables = {'input': {\n 'id': id\n }}\n self.\\_\\_callGraphQL(query, variables)\n \n def findPerformersByTag(self, id):\n query = \"\"\"query performer\\_images($performer\\_filter: PerformerFilterType!) {\n findPerformers(performer\\_filter: $performer\\_filter filter: {per\\_page: -1}){\n\n performers{\n id\n name\n image\\_path\n tags{\n name\n }\n }\n}\n}\"\"\"\n variables = {'performer\\_filter': {\n 'tags': {\n 'value': id, 'modifier': 'INCLUDES', 'depth':1\n \n }\n }}\n result = self.\\_\\_callGraphQL(query, variables)\n performers = result[\"findPerformers\"][\"performers\"]\n image\\_paths\\_tags = [(performer[\"image\\_path\"], performer[\"id\"]) for performer in performers]\n return image\\_paths\\_tags\n \n # for performer in tag[\"id\"]:\n\n \n # Adding Gigapixel Now\n def processPerformerImage(self, image\\_path, performer\\_id):\n # Output file suffix. (e.g. pic.jpg -> pic-gigapixel.jpg)\n # You should set same value inside Gigapixel (File -> Preferences -> Default filename suffix).\n output\\_suffix = '-gigapixel'\n\n # Create Gigapixel instance.\n app = Gigapixel(exe\\_path, output\\_suffix)\n\n # Set current directory\n current\\_dir = Path().resolve()\n\n # Variable for saved image\n image\\_saved = current\\_dir / 'image.jpg'\n\n # If the image is not already saved, save it\n if not image\\_saved.is\\_file():\n # Get image data from the image URL\n image\\_data = requests.get(image\\_path).content\n\n # Load the image data\n image\\_Bytes = BytesIO(image\\_data)\n\n # Determine the file type of the image\n image\\_type = magic.from\\_buffer(image\\_data, mime=True)\n \n # Check if the file type is supported by PIL\n if image\\_type:\n # Save the image data to a file with the appropriate file extension\n extension = mimetypes.guess\\_extension(image\\_type)\n filename = 'image' + extension\n with open(filename, 'wb') as f:\n f.write(image\\_data)\n \n # Open the image file using PIL\n image = Image.open(filename)\n \n # Convert the image to another format (e.g. JPEG) and save it\n image.save('image.jpg', 'JPG')\n else:\n print(\"Unsupported file type\")\n else:\n print(\"Image already saved\")\n\n return\n\n # Process the image\n output\\_path = app.process(image\\_saved, scale=Scale.X6, mode=Mode.LOWRESOLUTIONM)\n\n # Return the output path\n return output\\_path\n\n # Open image file\n # image\\_file = output\\_path\n # image = Image.open(image\\_file)\n\n # Update performer with new image\n query = \"\"\"\n mutation performerUpdate($performer\\_update\\_input: PerformerUpdateInput!){\n performerUpdate(input: $performer\\_update\\_input){\n id\n }\n }\n \"\"\"\n variables = {\"performer\\_update\\_input\": {\"image\": output\\_path, \"id\": performer\\_id}}\n self.\\_\\_callGraphQL(query, variables)\n\n def setup\\_tags(self):\n tagName='upscale\\_with\\_Gigapixel'\n tagID = self.findTagIdWithName(tagName)\n if tagID == None:\n tagID = self.createTagWithName(tagName)\n self.debug(\"adding tag \"+tagName)\n else:\n self.debug(\"tag exists, \"+tagName)\n\n def upscale\\_PerformerImage(self):\n tagName = 'upscale\\_with\\_Gigapixel'\n tagID = self.findTagIdWithName(tagName)\n if tagID is None:\n self.debug(\"Error no tag for upscale\\_PerformerImage\")\n else:\n self.info(\"Tag exists for upscale\\_PerformerImage\") \n \n image\\_paths\\_tags = self.findPerformersByTag(tagID)\n for image\\_path, performer\\_id in image\\_paths\\_tags:\n self.processPerformerImage(image\\_path, performer\\_id)\n\n# Press the green button in the gutter to run the script.\nif \\_\\_name\\_\\_ == '\\_\\_main\\_\\_':\n if len(sys.argv) > 1:\n url = \"http://localhost:9999/graphql\"\n if len(sys.argv) > 2:\n url = sys.argv[2]\n\n if sys.argv[1] == \"setup\":\n client = upscale\\_all(url)\n client.setup\\_tags()\n elif sys.argv[1] ==\"upscale\\_all\":\n client = upscale\\_all(url)\n client.upscale\\_PerformerImage()\n elif sys.argv[1]== \"api\":\n fragment = json.loads(sys.stdin.read())\n scheme=fragment[\"server\\_connection\"][\"Scheme\"]\n port=fragment[\"server\\_connection\"][\"Port\"]\n domain=\"localhost\"\n if \"Domain\" in fragment[\"server\\_connection\"]:\n domain = fragment[\"server\\_connection\"][\"Domain\"]\n if not domain:\n domain='localhost'\n url = scheme + \"://\" + domain + \":\" +str(port) + \"/graphql\"\n\n client=upscale\\_with(url)\n mode=fragment[\"args\"][\"mode\"]\n client.debug(\"Mode: \"+mode)\n if mode == \"setup\":\n client.setup\\_tags()\n elif mode == \"upscale\\_all\":\n # current\\_dir = Path.cwd()\n # client.processPerformerImage(str(current\\_dir) + '/image-gigapixel.jpg')\n client.upscale\\_PerformerImage()\n else:\n print(\"\")\n \n# upscaler = upscale\\_with(url)\n# result = upscaler.listTags()\n# upscaler.processPerformerImage(output\\_path)", "can you see what is wrong? import config\\_manager\nimport configparser\nimport requests\nimport sys\nimport json\nimport pathlib\nimport os\nimport magic\nfrom gigapixel import Gigapixel, Scale, Mode\nfrom pathlib import Path\nfrom PIL import Image\nfrom io import BytesIO\n\n# Path to Gigapixel executable file.\nexe\\_path = Path('B:\\Program Files\\Topaz Labs LLC\\Topaz Gigapixel AI\\Topaz Gigapixel AI.exe')\n\nconfigpath = os.path.join(pathlib.Path(\\_\\_file\\_\\_).parent.resolve(), 'config.ini')\n\ndef get\\_config\\_value(config\\_file, section, option):\n config = configparser.ConfigParser()\n config.read(config\\_file)\n return config.get(section, option)\n\n \nclass upscale\\_with:\n\n def \\_\\_init\\_\\_(self, url):\n self.url = url\n self.api\\_key = get\\_config\\_value(configpath, 'STASH', 'api\\_key')\n stash\\_url = get\\_config\\_value(configpath, 'STASH', 'url')\n if not stash\\_url:\n self.error(\"You need to set the URL in 'config.ini'\")\n return None\n self.stash\\_url = stash\\_url + \"/graphql\"\n self.headers = {\n \"Accept-Encoding\": \"gzip, deflate, br\",\n \"Content-Type\": \"application/json\",\n \"Accept\": \"application/json\",\n \"Connection\": \"keep-alive\",\n \"DNT\": \"1\",\n \"ApiKey\": self.api\\_key\n }\n \n def log(self, level, message):\n print(f\"[{level.upper()}] {message}\")\n \n def \\_\\_prefix(self,levelChar):\n startLevelChar = b'\\x01'\n endLevelChar = b'\\x02'\n\n ret = startLevelChar + levelChar + endLevelChar\n return ret.decode()\n\n def \\_\\_log(self,levelChar, s):\n if levelChar == \"\":\n return\n\n print(self.\\_\\_prefix(levelChar) + s + \"\\n\", file=sys.stderr, flush=True)\n\n def trace(self,s):\n self.\\_\\_log(b't', s)\n\n def debug(self,s):\n self.\\_\\_log(b'd', s)\n\n def info(self,s):\n self.\\_\\_log(b'i', s)\n\n def warning(self,s):\n self.\\_\\_log(b'w', s)\n\n def error(self,s):\n self.\\_\\_log(b'e', s)\n\n def progress(self,p):\n progress = min(max(0, p), 1)\n self.\\_\\_log(b'p', str(progress))\n\n def \\_\\_callGraphQL(self, query, variables=None):\n json = {}\n json['query'] = query\n if variables != None:\n json['variables'] = variables\n\n # handle cookies\n response = requests.post(self.url, json=json, headers=self.headers)\n\n if response.status\\_code == 200:\n result = response.json()\n if result.get(\"error\", None):\n for error in result[\"error\"][\"errors\"]:\n raise Exception(\"GraphQL error: {}\".format(error))\n if result.get(\"data\", None):\n return result.get(\"data\")\n else:\n raise Exception(\n \"GraphQL query failed:{} - {}. Query: {}. Variables: {}\".format(response.status\\_code, response.content, query, variables))\n \n \n def listTags(self):\n query = \"\"\"\n query {\n allTags {\n id\n name\n }\n }\"\"\"\n\n result = self.\\_\\_callGraphQL(query)\n return result[\"allTags\"]\n \n\n def findTagIdWithName(self, name):\n query = \"\"\"\nquery {\n allTags {\n id\n name\n }\n}\n \"\"\"\n\n result = self.\\_\\_callGraphQL(query)\n name = 'upscale\\_with\\_Gigapixel'\n for tag in result[\"allTags\"]:\n if tag[\"name\"] == name:\n return tag[\"id\"]\n return None\n \n\n def createTagWithName(self, name):\n query = \"\"\"\nmutation tagCreate($input:TagCreateInput!) {\n tagCreate(input: $input){\n id \n }\n}\n\"\"\"\n variables = {'input': {\n 'name': name\n }}\n\n result = self.\\_\\_callGraphQL(query, variables)\n return result[\"tagCreate\"][\"id\"]\n\n def destroyTag(self, id):\n query = \"\"\"\nmutation tagDestroy($input: TagDestroyInput!) {\n tagDestroy(input: $input)\n}\n\"\"\"\n variables = {'input': {\n 'id': id\n }}\n self.\\_\\_callGraphQL(query, variables)\n \n def findPerformersByTag(self, id):\n query = \"\"\"query performer\\_images($performer\\_filter: PerformerFilterType!) {\n findPerformers(performer\\_filter: $performer\\_filter filter: {per\\_page: -1}){\n\n performers{\n id\n name\n image\\_path\n tags{\n name\n }\n }\n}\n}\"\"\"\n variables = {'performer\\_filter': {\n 'tags': {\n 'value': id, 'modifier': 'INCLUDES', 'depth':1\n \n }\n }}\n result = self.\\_\\_callGraphQL(query, variables)\n performers = result[\"findPerformers\"][\"performers\"]\n image\\_paths\\_tags = [(performer[\"image\\_path\"], performer[\"id\"]) for performer in performers]\n return image\\_paths\\_tags\n \n # for performer in tag[\"id\"]:\n\n \n # Adding Gigapixel Now\n def processPerformerImage(self, image\\_path, performer\\_id):\n # Output file suffix. (e.g. pic.jpg -> pic-gigapixel.jpg)\n # You should set same value inside Gigapixel (File -> Preferences -> Default filename suffix).\n output\\_suffix = '-gigapixel'\n\n # Create Gigapixel instance.\n app = Gigapixel(exe\\_path, output\\_suffix)\n\n # Set current directory\n current\\_dir = Path().resolve()\n\n # Variable for saved image\n image\\_saved = current\\_dir / 'image.jpg'\n\n # If the image is not already saved, save it\n if not image\\_saved.is\\_file():\n # Get image data from the image URL\n image\\_data = requests.get(image\\_path).content\n\n # Load the image data\n image\\_Bytes = BytesIO(image\\_data)\n\n # Determine the file type of the image\n image\\_type = magic.from\\_buffer(image\\_data, mime=True)\n \n # Check if the file type is supported by PIL\n if image\\_type:\n # Save the image data to a file with the appropriate file extension\n extension = mimetypes.guess\\_extension(image\\_type)\n filename = 'image' + extension\n with open(filename, 'wb') as f:\n f.write(image\\_data)\n \n # Open the image file using PIL\n image = Image.open(filename)\n \n # Convert the image to another format (e.g. JPEG) and save it\n image.save('image.jpg', 'JPG')\n else:\n print(\"Unsupported file type\")\n else:\n print(\"Image already saved\")\n\n return\n\n # Process the image\n output\\_path = app.process(image\\_saved, scale=Scale.X6, mode=Mode.LOWRESOLUTIONM)\n\n # Return the output path\n return output\\_path\n\n # Open image file\n # image\\_file = output\\_path\n # image = Image.open(image\\_file)\n\n # Update performer with new image\n query = \"\"\"\n mutation performerUpdate($performer\\_update\\_input: PerformerUpdateInput!){\n performerUpdate(input: $performer\\_update\\_input){\n id\n }\n }\n \"\"\"\n variables = {\"performer\\_update\\_input\": {\"image\": output\\_path, \"id\": performer\\_id}}\n self.\\_\\_callGraphQL(query, variables)\n\n def setup\\_tags(self):\n tagName='upscale\\_with\\_Gigapixel'\n tagID = self.findTagIdWithName(tagName)\n if tagID == None:\n tagID = self.createTagWithName(tagName)\n self.debug(\"adding tag \"+tagName)\n else:\n self.debug(\"tag exists, \"+tagName)\n\n def upscale\\_PerformerImage(self):\n tagName = 'upscale\\_with\\_Gigapixel'\n tagID = self.findTagIdWithName(tagName)\n if tagID is None:\n self.debug(\"Error no tag for upscale\\_PerformerImage\")\n else:\n self.info(\"Tag exists for upscale\\_PerformerImage\") \n \n image\\_paths\\_tags = self.findPerformersByTag(tagID)\n for image\\_path, performer\\_id in image\\_paths\\_tags:\n self.processPerformerImage(image\\_path, performer\\_id)\n\n# Press the green button in the gutter to run the script.\nif \\_\\_name\\_\\_ == '\\_\\_main\\_\\_':\n if len(sys.argv) > 1:\n url = \"http://localhost:9999/graphql\"\n if len(sys.argv) > 2:\n url = sys.argv[2]\n\n if sys.argv[1] == \"setup\":\n client = upscale\\_all(url)\n client.setup\\_tags()\n elif sys.argv[1] ==\"upscale\\_all\":\n client = upscale\\_all(url)\n client.upscale\\_PerformerImage()\n elif sys.argv[1]== \"api\":\n fragment = json.loads(sys.stdin.read())\n scheme=fragment[\"server\\_connection\"][\"Scheme\"]\n port=fragment[\"server\\_connection\"][\"Port\"]\n domain=\"localhost\"\n if \"Domain\" in fragment[\"server\\_connection\"]:\n domain = fragment[\"server\\_connection\"][\"Domain\"]\n if not domain:\n domain='localhost'\n url = scheme + \"://\" + domain + \":\" +str(port) + \"/graphql\"\n\n client=upscale\\_with(url)\n mode=fragment[\"args\"][\"mode\"]\n client.debug(\"Mode: \"+mode)\n if mode == \"setup\":\n client.setup\\_tags()\n elif mode == \"upscale\\_all\":\n # current\\_dir = Path.cwd()\n # client.processPerformerImage(str(current\\_dir) + '/image-gigapixel.jpg')\n client.upscale\\_PerformerImage()\n else:\n print(\"\")\n \n# upscaler = upscale\\_with(url)\n# result = upscaler.listTags()\n# upscaler.processPerformerImage(output\\_path)", "again for : \"What do you think about passive income? \n\nJack: Yeah, I mean, it's what seduced me into entrepreneurship to begin with, right? It's like, \"Oh yeah, I can...\" exactly how you described it, \"I can stop worrying about money.\" And the reality is, you never worry about money more than you do as an entrepreneur because you like...that is not something that is...at least in the early stages, that's not like the definition of it is that nothing is guaranteed on the financial side. \n\nSo passive income, You hear all these stories of people who are just sitting in Barbados and they're the wire just keeps it in months and months. And those stories are true in some cases, but those aren't people that quit their job a week ago. The idea of passive income, I think...unless you have access to just ungodly amounts of capital and you have an appetite for an insane amount of risk, get the idea of passive income out of your head, or at least get the idea of an amount of passive income that's possible to live on in the short term, out of your head like that is if it sounds too good to be true, it probably is. There's plenty of plenty of anecdotes. And there will be exceptions to the rule, but these markets are fairly efficient and as soon as an opportunity like that exists, it will get arbitraged away pretty fast. \n\nSo the difference that I've...to make the distinction between passive income and leveraged income, Like where you're...what you're really aiming for is a variable outcome on your effort. So in a service business, in a client business, your time and money have a relationship where you can get you can do your value based pricing. You know, you go from hourly pricing to value based pricing, which is essentially just increasing your hourly rate, right? And there's only so many hours in a day. And every person you hire to fulfill on the service business is making your business less efficient. However, you want to look at it. It's like you cannot add more people and get more efficient. I mean, there's, we could debate that for a little bit of time, but it's, an additional cost.\n\nSo leveraged income is about these variable outcomes of on the upside. So if you create a product, if you create a piece of media, a piece of code, whatever it is that is that runs independently of you, then your leverage becomes, \"how many people can I get to use this thing? How much more efficiently can I generate and direct attention?\" And the outcome on the other side of that is dependent on your judgment.\n\nSo for example, you launch a product and you write an email and you have a hundred people on your email list and they convert at 1%. The quality of that copy determines your leverage, right? If the product has no...if you have no responsibility or no time commitment to delivering the product on the other side of that email...let's say, for example, Visualize Value. We have a design course called \"How to Visualize.\" I send an email to a hundred people explaining what's in that course. And 1% of them convert, let's say it's $300. I make $300 on that day. Then I'm like, \"okay, I'm gonna write some tweets, and I'm going to explain what's in this course, and I'm going to get people to sign up this email list.\" I write one tweet storm. I copy over to LinkedIn. I do a YouTube breakdown on it, blah, blah, blah. They're all directed to the same URL. I eventually get a thousand people on that email list and I send to there's 900 more people that haven't read it. So I send this, new introduction and say that converts at 1%, that's 10 people. So that's, $3,000, right? If I write back a copy, I maybe get that from 1% to 2%. That's $6,000.\n\nSo this, these are like leveraged outcomes and there's definitely entropy involved here, right? This is not a perfect formula because. The longer you go, the more people have heard about the course, the more like the older is the less intensity and the less the less enthusiasm there is for this thing. It's been on the market longer. So all to say like leverage is about just tweaking these levers of judgment and getting, slightly better outcomes along the way. There's all sorts of different mechanisms for this that would take hours and hours to explain. But affiliate marketing is another example, right? If you have people that believe in your product that you'll say, Hey, I will give you 50% of the revenue of all this product. I've zero cost of replication. For me, you've been through all these courses, you've done a great job of explaining them. You can go out and explain to people that this is helped you develop Skill X, you get 10 people doing that. There's another 10,000 emails going out a day and so on and so forth. So the internet is like this leverage machine that, helps you amplify the outcome of good judgment.\n\nAnd yeah, that's, I think what we should be, that's the model we should have in our mind that we're developing versus the passive income idea, because passive income is especially in a tiny business is, a, the two ideas on as compatible as people think, because these things just have another great example. I didn't use SEO. So outside of social, and I'm not an SEO expert by any means, but I have a couple friends that have built little SAS tools. Good example is a guy I know built a tool called closet tools, which is a Poshmark plugin. Do you know Poshmark? It's like a secondhand thing, like eBay for clothes. So he built this little plugin that helps people list more efficiently on Poshmark. And he wrote, I think, five blog posts, like insanely detailed blog posts about how to better use Poshmark in this context or how to list your items. For whatever...I don't know anything about the specifics of it, but I know how his business works and those articles are so well-written and people read through all of them and they stay on the page for 10 minutes that they rank almost at the top of Google when anyone types in posh, like how to use Poshmark.\n\nAlex: Right. \n\nJack: And he has a free trial to his software attached to the bottom of that. And he literally does. He has, he doesn't have to go on Twitter. He doesn't have to go on YouTube. Doesn't have to write new organic posts every day. He has assets out there that Google is forcing traffic towards every day that are converting into his platform. He has to manage some customer support emails when sure. people have a question and things of that nature, but he has leveraged income to the point where he one feature or tweakstweaks one feature on that product sends out an email another batch of people come through. I was going to butcher a Naval quote. The the future of work is not like white collar versus blue collar. It's leverage versus unleveraged. So you either have leverage or you don't. And that just installing that little model of leverage in your mind is...again, again, it's an iterative process. And if you try and add it too soon, or you try and add like the wrong type too soon, then a lot of it builds over time. So reputation as a device for leverage is not something that happens one, right? It's something thatng that someone looks back on as like, I'm considering buying this Visualize Value course. Let me look at Visualize Value and Jack Butcher's account. Oh, there's 400,000 people following this. And there's a thousand visuals that have been posted over the course of the last two years.\n\nAlex: Right. \n\nJack: That to me is like, if I was on the other side of that transaction, that's a signal that okay this is a real thing. This is not some email that just popped up in my inbox and I'm making a decision on a whim. that's one. And then other things that you're doing in real time that might not deliver leverage today. But over the course of six months, 12 months, 18 months, two years, they start to compound like recording something, put it on YouTube. Instead of having a individual call with every one of your clients. Even if you work in a service business, there are things you can do that can add leverage to the way you work. Right? Even stuff like how to manage...our accountant has an amazing system. They run a service business, but like they do one 10 minute onboarding call and then they've got, here's a video to do this. Here's where you put, this is how you upload this, here's how you automate your emails to send receipts to our drop box. And then they get categorized this way these, tools, and like the ability to automate tasks and even like automate things that you say over and over and over again are. Underused by a lot of people, especially in the creative world, because it's a ...I guess the pop culture narrative is that's the antithesis of creativity, right? It's I need to be at my blank page and show up every morning. And that's if you want to pitch that through a different angle, that's that's what allows you to be creative. You alternate the stuff that you don't want to be doing on the admin side every single day. And you get to just sand do your thing. Thing.\"", "This is the next part of chapter five:\nHow to Bring Awareness to Your Spending\nStep 1: Track Your Spending\nThe first step to bringing awareness into your financial life is to see where your money is currently going. The best way to see where\nA\nyour money goes is to track your spending. (It isn\u2019t as painful as it sounds; you\u2019ll actually end up feeling quite proud!)\nGather up all of your receipts and bank statements from the last month. Then, make a list. I use The Budget Mom monthly expense tracker, but even just a sheet of paper will do. On the left-hand side, write each amount of money you spent, and on the right-hand side\ngo ahead and identify each expense. Don\u2019t forget to write out all of your spending: credit, debit, and cash (an easy one to forget!).\nIt\u2019s best if you can track a couple of months\u2019 worth of expenses. Again, don\u2019t forget to include credit card and cash spending. Then, I want you to examine your spending as a whole. You\u2019re looking for patterns. What consistency do you see, week to week or month to month? Write down your observations.\nIf tracking everything you spent last month seems impossible, that\u2019s okay. You can track this month. Going forward, write down every time you pay for something or swipe a card. Also, be sure to list automatic payments: any kind of subscription or automatic bill payment. In other words, every time money leaves your account or you use your credit card, write it down. If you are spending cash, saving your receipts will help. Save your receipts throughout the day and track your spending in the evening.\nThis is kind of like keeping a food journal when you\u2019re trying to identify a food allergy or other health condition. It can feel a little overwhelming to write down everything you eat (you eat as many as a dozen times during the day!), but sometimes seeing it on paper is the only way to fully grasp what\u2019s happening.\nStep 2: Create Budget Categories\nTracking your spending lays it all out for you to see; the next step is to organize it. First, determine your budget categories. Budget categories are groups of expenses. Some of your budget categories might be:\nHousehold expenses Groceries\nTransportation School expenses Clothes\nThese are just a few; chances are good you\u2019ll have many, and\nsome of your categories will be unique to you.\nTo help me identify budget categories, I break out the highlighters. I\u2019m a visual learner, so I get motivated in my budgeting when I see it laid out clearly and colorfully. As I look over my purchases, I start grouping them by color. For example, all gas transactions are highlighted yellow, all clothing purchases are highlighted in blue, all coffee transactions are highlighted in green, all makeup purchases are highlighted with pink. Once all transactions are highlighted in different colors, I add up all the pink transactions, all of the blue transactions, etc. Then, once all transactions are highlighted, I total them up to see how much I\u2019m spending in each category. I call this the highlighter method.\nPeople often ask me how many categories\u2014and how many highlighter colors\u2014they need. Should I have five, twenty, or one hundred? There isn\u2019t a \u201cright\u201d number of categories, but you will know how many you need, the more you do it. For example, when you don\u2019t have enough categories, it\u2019s hard to know what you\u2019re actually spending money on\u2014so you won\u2019t get the clarity you need. If I used a budget category called \u201cfamily\u201d to budget for my son\u2019s clothes, his wrestling lessons, and our outings together, it would be hard for me to know how much money actually went to our weekend trip and how much went to his wrestling match. It\u2019s too broad a category for my life.\nIf you find yourself spending a lot of money on one particular item (shoes, for instance, or tickets to your favorite team\u2019s games), that\u2019s a sign you might want to create a budget category just for that item.\nWithout those purchases hiding among other purchases, you can moderate your spending and see it more clearly.\nIf you have too many categories, you might not know how much to budget for it each paycheck. If you spend forty dollars this month on electronics but then don\u2019t spend in that category for another six months, it\u2019s not helpful to you to be budgeting for electronics every month. Try grouping it with a larger category.\nThis is a moment for you to make a judgment call and trust yourself.\nDon\u2019t worry about budgeting a number for each of these categories yet. You will do that when we create your budget together later. For now, you just need to identify how you are spending your money. Just take a first stab at creating a set of categories.\nStep 3: Get Curious about Your Spending\nNow that you have a solid understanding of how much money you\u2019re spending and what kinds of things you\u2019re spending it on, it\u2019s time to ask the tough questions: In what situations do you spend often? What does your tracking reveal about each dimension of money for you? Are you balanced? Where do you spot an imbalance? Can you trace that imbalance back to life experiences or childhood money beliefs?\nTake time to journal, reflect, and talk this through with someone who knows you well. How does what you\u2019ve found make you feel?\nIt\u2019s not an easy task. During this process, negative feelings will surface. You might feel shame or guilt about your spending habits. You might feel fear about the future or what your spending says about you.\nI\u2019ve been there. It\u2019s uncomfortable. Shame and guilt can feel overwhelming. But if you can withstand it, the negative feelings will\ndiminish and on the other side is a feeling of power and progress and confidence and conviction.\nWhen I started studying these dimensions during my accreditation program, I immediately recognized myself: I was that compulsive spender who didn\u2019t value saving for the future. Fortunately, my relationship with money has changed over time; now, I\u2019m balanced. I\u2019m not a compulsive overspender, but I\u2019m not a super-thrifty spender, either. I bring value into my life on a budget that I can afford.\nFor example, I used to buy all of my purses at Ross or T.J.Maxx because that\u2019s where I could find the best deal. But because I\u2019m a mom who carries the entire kitchen sink in my bag, the low-quality fabrics would give out quickly. In a matter of a year, my purse would be in pretty poor condition. So, off I went, year after year, right back down to Ross to buy another one. It might seem budget friendly, but the frequency with which I needed to replace them meant it wasn\u2019t really.\nToday, however, I take a different approach: I\u2019ll purchase one high- quality bag that I\u2019ve saved up for and have it last me many years, rather than buy a bunch of inexpensive ones I\u2019ll have to replace soon.\nThis underlines an important facet of the Budget by Paycheck system: it\u2019s not about deprivation, but about thoughtful investment. I won\u2019t tell you that you can\u2019t buy a designer purse. If that\u2019s where you find value, you absolutely can; it may just be on a different timeline. Not everyone cares so much about how they carry around their things, but this is about figuring out what you do care about and then planning for ways to attain it.\nThat\u2019s balance.\nBalance has transformed not just my purse collection, but my entire life. How did I get there? The very first step was in identifying the money messages I received as a child, identifying the significant life events that shaped my view of money, and being honest with\nmyself about how I felt about money. Only then could I begin to see reality, and only then could I start planning for the reality I wanted\u2014 not the one I had found myself in.\nMy client Kate had a similar experience. She arrived at my office late one afternoon to show me her spending and create her budget. I had asked her to track her spending, as I normally do; it\u2019s the first step toward bringing awareness to your spending habits (and the slap-in-the-face moment that so many of us need).\nAs I was reviewing her purchases, an unusual pattern caught my eye. This darling woman had racked up thousands of dollars on credit cards buying the most unexpected accessory: nail polish.\nI had to point out to her that it\u2019s unusual, to say the least, to spend that much money on nail polish. And when I asked her why she collected it, she couldn\u2019t answer me. \u201cI don\u2019t know, I just have always had this thing for nail polish,\u201d she replied. \u201cI\u2019ve just always wanted my nails to look nice.\u201d\nI suspected there was a buried reason, a hidden wound, behind these purchases, so I kept asking questions. She started talking and, sure enough, out of our conversation came this story of a young girl who, in middle school, was made to feel not good enough. \u201cI was sitting at my desk,\u201d she shared, \u201cand the girl in front of me looked down and said, 'God! You have really ugly nails!\u2019 \u201d And the moment stuck with her subconscious.\nWhat she internalized from that experience was that having perfect nails was the way to win others\u2019 approval. From that moment on, she always made sure to have these perfectly painted nails.\nMaybe she had no idea how much she was actually spending on nail polish; nine dollars a pop doesn\u2019t seem like that much in isolated buying environments. But once we started tracking her spending, we saw just how much this addiction was costing her\u2014to the tune of\n$400 a year.\nGet curious about your spending and maintain a nonjudgmental mindset. Ask yourself, \u201cWhat does this spending say about me?\u201d", "Convert the following text passage into 25 dot points, keeping in statutes and cases\n\n2.2.1.2 Reviving memory\n\nGiven the lengthy delays between event and trial, many witnesses have forgotten some or all of the detail of what they witnessed by the time they come to testify. This is especially likely to be true if what was witnessed was simply a routine part of the witness\u2019s life, as, for example, where a doctor is asked to give evidence about a medical examination he or she carried out some time before the trial, or where a police officer gives evidence about the investigation leading up to the charging of the defendant. The prohibition on leading questions in examination-in-chief means that counsel is not permitted to remind the witness of what he or she has forgotten\u2014so how may memory be revived? There are several ways.\n\nFirst, the ban on leading questions does not apply to some categories of evidence. Section 37(2) exempts written documents that are treated as the maker\u2019s evidence in chief, unless the court orders otherwise, while section 37(3) exempts civil witnesses recounting official or public reports. Police recordings of child sexual abuse complainants do not fall outside these exceptions, however, because they are not written (at least, not by the child) and because they are used in criminal trials. The bank employee\u2019s evidence about a credit card application, discussed above, is likewise not exempt because his earlier affidavit was not treated as his evidence and he was exercising commercial, not public or official duties.\n\nSecond, a witness may, with the leave of the court, be permitted to refer to a document in order to revive his or her memory. Section 32(1) provides that \u2018a witness must not, in the course of giving evidence, use a document to try and revive his or her memory about a fact or opinion unless the court gives leave\u2019. In the case of unrepresented defendants who testify, leave should be readily granted to allow defendants to remind themselves of what topics they wish to testify about: Isherwood v Tasmania.60 More generally, section 32(2) provides:\n\nWithout limiting the matters that the court may take into account in deciding whether to give leave, it is to take into account:\n\n(a) whether the witness will be able to recall the fact or opinion adequately without using the document; and\n\n(b) whether so much of the document as the witness proposes to use is, or is a copy of \na document that:\n\n (i) was written or made by the witness when the events recorded in it were fresh in his or her memory; or\n\n(ii) was, at such a time, found by the witness to be accurate.\n\nThese are matters that should be established from the witness concerned through the use of non-leading questions. An example is the following exchange:61\n\nQ. And you spoke to the police at Wollongong, the police station at Wollongong on 17 July 2015, they interviewed you?\n\nA. Yeah.\n\nQ. Do you recall that?\n\nA. I don\u2019t recall it, but I know there is a statement there, yeah.\n\nQ. You spoke to two police officers in an interview that was recorded?\n\nA. Yeah.\n\nQ. Do you recall the last occasion you saw Mark Dower?\n\nA. Nup.\n\nQ. Do you know, did you have any conversations about Mark Dower, with Mark Jenkin, before Mark Jenkin was arrested at some point; did you have some conversation with him about Mark Dower?\n\nA. Well, I can\u2019t remember but I know it\u2019s in the statement, yeah.\n\nQ. What is your memory of, what do you have a memory of, what was said to you by Mark Jenkin about that?\n\nA. Well no, I haven\u2019t. Only what I have read in my statement.\n\nQ. When did you read that last?\n\nA. I read it yesterday.\n\nQ. What can you recall the statement you gave to the police, what did that indicate in relation to your recollection of the conversations between, about between Mr Jenkin, about Mr Dower; what do you recall Mr Jenkin saying?\n\nA. Fuck, I can\u2019t remember what I said.\n\nQ. Sorry?\n\nA. I can\u2019t remember what I said.\n\nQ. Did reading the statement that you made to the police refresh your memory?\n\nA. Well, it did when I read it. You know what I mean. I don\u2019t have a very good memory because I used heaps of drugs.\n\nAs Hamill J observed, the latter answers\u2014the witness\u2019s \u2018insightful self-assessment of the quality of his memory\u2019\u2014established that his memory has been exhausted, while the initial questions showed that there is a document that could be used to revive the memory. However, the exchange did not establish either of the two matters in section 32(2)(b).\n\nIn Director of Public Prosecutions v Asling (Ruling No 7), 62 a key prosecution witness in a murder prosecution gave evidence that deviated from his police statement two years earlier in several respects, including what the accused allegedly said to him after the murder, how many times they spoke, whether he complained about the accused using his car as part of the crime, and what he did with materials left in the car. After refusing to let the prosecutor ask leading questions about these matters under section 37(1)(a), Kaye JA also refused to allow the witness to read the statement to revive his memory, noting that the events described in the statement occurred in 2003, twelve years before the statement was made. Although he conceded that section 32(2)(b)(i) does not say that statements used to revive memory must have been made when the witness\u2019s memory was fresh, he nevertheless thought the time delay was fatal in this case. He added that his view was confirmed by the witness\u2019s concession that, when he spoke to the police, he \u2018was trying to recollect memories from a long time earlier. A lot of memories I tried to forget\u2019 and that he was \u2018under a lot of stress\u2019 when the statement was made. By contrast, Hamill J granted his \u2018insightful\u2019 witness leave to use his earlier statement to \u2018revive\u2019 his memory, noting that his use of the document as an aid would be obvious to the jury, the conversation he recounted was important to the trial and that the context\u2014a murder trial\u2014favoured allowing the witness to try to remember.\n\nIf a witness is permitted to use a document to try and revive his or her memory, he or she may, with the leave of the court, read aloud from that document: section 32(3).63Victoria\u2019s Court of Appeal has observed: \n\nThere is nothing to suggest that this provision is capable of applying only when the attempt to revive memory has been successful. On the contrary, on the plain meaning of the provision all that is required is that the witness should have used the document \u2018to try to revive his or her memory\u2019. This is unsurprising, in our view, as it would be a task of great difficulty for a judge to decide, in any given case, whether what had occurred was an actual \u2018revival\u2019 of an earlier memory or the short-term creation of a fresh memory of the content of the document.64\n\nIn other words, the read-out document will be treated exactly the same as in-court testimony, even if the witness no longer remembers the events described in the document. That means that the contents of the document will still be subject to rules of use, such as the hearsay rule, again in the same way as if the witness simply testified in the document\u2019s terms. In CSR Ltd v Amaca Pty Ltd,65 a medical report, read out in court by the doctor who wrote it years earlier (and obviously could not now recall its details), could be used to find facts that the (now deceased) patients had told the doctor (about whether they had been exposed to asbestos), under a first-hand hearsay exception to the hearsay rule (see Chapter 6: Hearsay Exceptions.) By contrast, Hamill J refused to permit a statement to be read out where, \u2018given the witness\u2019s manifest memory issues, it would not have been fair to allow him to read from an interview which he scarcely remembered making.\u201966\n\nThird, section 33(1) goes even further, recognising the unique position of police officers, by allowing them in criminal proceedings to \u2018give evidence-in-chief for the prosecution by reading or being led through a written statement previously made by the police officer\u2019. Section 33(2) stipulates, among other things, that a written statement can only be used for this purpose if it was made \u2018at the time of or soon after the occurrence of the events to which it refers\u2019. In Salmon v The Queen, 67 it was held that section 33 is not available for police notes made weeks after the events described; section 32 should be used instead. As will be discussed in Chapter 8: Admissions, local rules on confessions generally bar police from reading out notes of admissions supposedly made by a suspect in relation to a serious criminal offence unless those admissions were electronically recorded.\n\nFinally, if the witness chooses instead to attempt to revive his or her memory before coming to court, then there are no limitations on what he or she may use for this purpose. For example, a police officer can read over a statement before she testifies, even if it was written months after the events it describes.68 Certainly, no objection can be taken to a witness being shown a copy of a statement he or she may have made earlier. If counsel becomes aware that the witness has attempted to revive his or her memory in this way, then counsel may call for the production of the document\u2014 again \u2018without penalty\u2019\u2014and production will be ordered.69 Under section 34, failure to produce a document used to revive memory out of court, may result in the witness\u2019s evidence being ruled unusable.", "1. Bacteria are:\n\na. Virus\nb. Pathogen\nc. Microorganism\nd. Non-pathogen\ne. Fomite\n\n2. A microorganism that causes disease is a:\n\na. Vector\nb. Pathogen\nc. Host\nd. Bacteria\ne. Parasite\n\n3. Which agar is normally used when culture Neisseria Gonorrhea\n\na. Blood agar\nb. Chocolate agar\nc. Thayer- Martin agar\nd. All of the above\n\n4. Escherichia coli normally resides in the\n\na. Vagina\nb. Urinary tract\n \nc. Intestinal tract\nd. Stomach\ne. Eye\n\n5. Which factor does not help a microorganism grow?\n\na. Darkness\nb. Proper nutrition\nc. Moisture\nd. 7.1 pH\ne. 4-5 pH\n\n6. Which factor would interfere with the growth of a pathogen?\n\na. Appropriate oxygen and/or carbon dioxide\nb. Light\nc. Moisture\nd. Acidic pH\ne. Two of the above\n7. What term describes a microorganism that requires oxygen to grow?\n\na. Microaerophiles\nb. Thermolabile\nc. Facultative anaerobe\nd. Aerobe\ne. Cryophile\n8. The \u2018optimum growth temperature\u2019 is defined as:\n\na. 37oC or body temperature\nb. The temperature at which microorganism grows best\nc. Room temperature\nd. Temperature that reduces number of pathogens\ne. Refrigerator temperatures\n\n9. The time period when symptoms have subsided, and the patient is regaining health is the:\n\na. Prodromal period\nb. Incubation period\nc. Decline period\nd. Acute period\ne. Convalescent period\n \n10. List 2 specimens an MLA can collect according to the Specimen Collection Centre Act.\n\na. \nb. \n\n11. List 3 general guidelines to properly collect a microbiological specimen.\n\na. \nb. \nc. \n\n12. Throat swabs are collected to diagnose:\n\na. Herpes\nb. Gangrene\nc. Streptococcus\nd. Typhoid fever\ne. Gastroenteritis\n\n13. The source of the specimen should be indicated on a swab for C&S to:\n\na. Assist the lab staff for billing purposes\nb. Alert the lab staff that the swab is potentially hazardous\nc. Determine of the swab is set up STAT\nd. Assist in the selection of the plating media\ne. Ensure that swabs do not get mixed up\n\n14. Activated charcoal in transport medium will:\n\na. Inhibit growth of non-pathogens\nb. Help maintain a neutral pH by neutralizing fatty acids and absorbing toxic substances\nc. Maintain aerobic conditions\nd. Keep the specimen from drying out\n\n15. Which procedure is used to collect urine for C&S?\n\na. Clean catch MSU\nb. Catheterization\nc. Supra-public aspiration\nd. Pediatric urine bag\ne. All of the above\n\n16. Which statement is false when giving instructions to collect a clean catch MSU?\n\na. An antiseptic cleanser must be used\n \nb. Male patients must pull back the foreskin and cleanse the tip of penis\nc. Female patients must cleanse from front to back\nd. The first part of the urine is voided into the toilet; the next part is collected\ne. None of the above\n\n17. A Cutaneous mycosis is collected by performing a:\n\na. Gram stain\nb. Skin scraping\nc. Fecal concentration\nd. Wet mount preparation\ne. Venipuncture using culture tubes\n\n18. Septicemia is detected by collecting:\n\na. Feces\nb. Urine\nc. Blood\nd. CFS\ne. Genital swab\n\n19. Blood culture collection does not require:\n\na. That the specimen is collected first before all other tubes\nb. Special cleansing with iodine and alcohol\nc. An anaerobic and aerobic collection\nd. The specimens to be kept at room temperature until they are incubated\ne. An arterial specimen\n20. Which statement is false regarding collecting a stool specimen for C&S?\n\na. A wide mouth sterile container must be used\nb. A special diet must be followed several days prior to collection\nc. Stool must not be contaminated with urine, toilet water, or toilet paper\nd. The specimen is brought to the lab as soon as possible or kept refrigerated\ne. The patient must label the specimen with date and time of collection\n\n21. A specimen for pinworm testing is collected:\n\na. By a physician only\nb. At the laboratory\nc. Four days prior to antibiotic therapy\nd. First thing in the morning before a bowel movement\ne. Late at night after a bowel movement\n \n22. What container is required for pinworm exam?\n\na. Sterile wide-mouth jar\nb. Large metal can\nc. Scotch tape/glass slide or sticky paddle\nd. Jar containing SAF fluid\ne. Swab containing Amies clear transport media\n\n23. Cocci are:\n\na. Round is shape\nb. A form of bacillus\nc. Rod shaped\nd. Always found is pairs\ne. A category of microorganism\n\n24. \u2018Pyogenic\u2019 means producing:\n\na. Pneumonia\nb. Cough in the chest\nc. Pus\nd. Fever\ne. Toxins\n\n25. \u2018Pyrogenic\u2019 means producing:\n\na. Pneumonia\nb. Cough in the chest\nc. Pus\nd. Fever\ne. Toxins\n26. Staphylococci:\n\na. Are arranged in pairs\nb. Are pus producers\nc. Are responsible for veneral disease\nd. Are arranged in chains\ne. Two of the above\n\n27. Staphylococcus aureus causes everything except:\n\na. Boils\nb. Wound infections\nc. Meningitis\n \nd. Abscesses\ne. UTI\n\n28. Streptococci are:\n\na. A form of diplococcic\nb. Pyrogenic\nc. Found in clusters\nd. Are in chain formation\ne. Two of the above\n\n29. Which agar is used to culture Lactose fermenter Bacteria?\n\na. Blood agar\nb. MacConkey agar\nc. Colombia agar\nd. Thayer-Martin agar\ne. All agars\n\n30. Which body fluid is collected to detect septicemia?\n\na. Urine\nb. Blood\nc. Sputum\nd. CFS\ne. Feces\n\n31. This microorganism causes throat infection:\n\na. E. coli\nb. Salmonella species\nc. Streptococcus\nd. Clostridium botulinum\ne. All of the above might cause throat infection\n32. Group A Streptococci cause:\n\na. Glomerulonephritis\nb. Salmonella food poisoning\nc. Rheumatic fever\nd. Tuberculosis\ne. \u2018a\u2019 and \u2018c\u2019 only\n\n33. Some bacteria form a hard-protective covering resistant to heat and chemicals called a:\n \n\na. Scab\nb. Cyst\nc. Shell\nd. Capsule\ne. Spore\n34. Bacilli may be:\n\na. A form of fungus\nb. Round\nc. Spore formers\nd. All motile\ne. None of the above\n\n35. Blood agar media is:\n\na. Universal\nb. Enriched\nc. 5% sheep blood\nd. Can show hemolytic activities\ne. All of the above\n\n36. Cylindrical shaped bacteria that have a lot of flexibility and movement are:\n\na. Spirochetes\nb. Streptococci\nc. Vibrios\nd. Bacilli\ne. Staphylococci\n\n37. Bacteria that resemble a comma are:\n\na. Spirochetes\nb. Streptococci\nc. Vibrio\nd. Spirillum\ne. Staphylococci\n38. What body fluid is collected to detect Neisseria meningitides?\n\na. Sputum\nb. Blood\nc. CSF\n \nd. Vaginal/urethral\ne. Two of the above\n\n39. What organisms cause Gonorrhea? \n40. What specimen is submitted for testing? \n41. What organisms often cause Gastroenteritis? \n42. What specimen is submitted for testing? \n43. What organism causes syphilis? \n44. What specimen is submitted for testing? \n\n45. On a microscope, what adjusts the amount of light coming into the lens system?\n\na. Ocular\nb. Revolving nosepiece\nc. Objectives\nd. Stage\ne. Diaphragm\n\n46. What is the total magnification of the oil immersion objectives and a 10X ocular?\n\na. 10X\nb. 100X\nc. 430X\nd. 450X\ne. 1000X\n\n47. Which objective allows the largest field of vision?\n\na. Scanning objective\nb. Low power objective\nc. Medium power objective\nd. High-dry objective\ne. Oil immersion objective\n\n48. Which is not done when a microscope is put away after use?\n\na. Remove the slide from the stage\nb. Clean all the glass pieces of the microscope with lens paper and alcohol\nc. Unplug the microscope\nd. Turn off the light\ne. Put on the dust cover", "Write me a title for this article:\nAs a homeowner in NSW, it's vital to understand the legal mechanisms governing contractual obligations transfer. One such mechanism is Deed of Novation, useful when businesses change name or transfer contracts to third parties. This article explores Deed of Novation's definition, its importance to homeowners, and its differences from other legal mechanisms. By the end, you'll have a better understanding of Deed of Novation's relevance to homeowners in NSW.\nWhat is a Deed of Novation?\nA deed of novation is a legal document that allows one party to transfer its rights and obligations under an existing contract to a new party, who takes on these responsibilities and benefits from the original contract. This document enables the original party to be released from the contract while the new party assumes all legal obligations and rights under the agreement. \n\nNovation is typically used when a business undergoes significant changes such as mergers, acquisitions, or restructuring, and there is a need to transfer existing contractual agreements to a third party.\n\nNovation differs from an assignment in that it transfers all rights and obligations, while an assignment only transfers contractual benefits. It is essential to understand the implications of novation and seek legal advice to ensure that the deed is legally binding and effectively transfers contractual rights and obligations.\nKey Components of a Deed of Novation\nA deed of novation is a simple and effective tool for transferring the rights and obligations of one party under a contract to a third party. \n\nHere are the key components that a deed of novation should include:\n\nNovation or Effective Date\nThe novation or effective date is the date on which the new party will assume all the rights and obligations under the original contract. This date is critical, as it marks the point at which the transfer of rights and obligations takes place.\n\nRelease\nA release clause in a deed of novation releases the original party from all the obligations and liabilities under the contract from the date of novation. This clause ensures that the original party is no longer liable for any obligations or liabilities under the contract.\n\nRepresentations and Warranties\nRepresentations and warranties are promises made by both parties regarding the validity of the contract and their authority to enter into it. They also ensure that both parties are aware of each other's obligations and liabilities under the contract.\n\nFees and Payments\nThe fees and payments clause outlines any fees or payments that either party must make under the contract. This clause is critical, as it ensures that both parties are aware of their financial obligations under the contract.\n\nIt is essential to ensure that all these key components are included in the deed of novation to ensure that the transfer of rights and obligations is complete and legally binding. It is always recommended to consult with a legal professional before drafting or signing any legal documents.\n\nBenefits of a Deed of Novation\nA Deed of Novation offers several benefits to parties involved in a contract. By using a Deed of Novation, you can transfer your rights and obligations under an existing contract to a third party, without the need for extensive negotiation or the termination of the original contract. This can save time, money and resources, especially if the transfer involves complex contracts or multiple parties.\n\nOne of the key benefits of a Deed of Novation is that it allows you to simplify the process of transferring contractual obligations. Rather than renegotiating a new contract, you can simply transfer the existing contract to a new party. This can be particularly useful in situations where you are selling your business or restructuring your operations.\n\nAnother advantage of a Deed of Novation is that it minimizes the need for negotiation. Since the terms of the original contract remain the same, you can avoid lengthy and complicated negotiations with the other party. This can make the process of transferring contractual obligations more straightforward and efficient.\n\nFinally, a Deed of Novation can help you avoid the termination of existing contracts. If you need to transfer your contractual obligations to a third party, but do not want to terminate the existing contract, a Deed of Novation may be the best option. This way, you can transfer the obligations to a new party, while keeping the existing contract intact.\n\nRisks Associated with a Deed of Novation\nWhile a deed of novation is a useful legal tool, it is important to be aware of the potential risks that come with it. Here are some of the most significant risks to consider:\nUnforeseen obligations and liabilities: When entering into a deed of novation, it is essential to carefully consider the obligations and liabilities that are being transferred. There may be unforeseen obligations or liabilities that the new party may not be aware of, which could lead to disputes or legal action in the future.\nLack of clarity regarding the terms of the novation: A deed of novation must clearly outline the terms of the agreement to avoid any confusion or misunderstandings between the parties. Without clear and concise terms, there is a risk that the parties may have different interpretations of their obligations and responsibilities.\nThe need for careful consideration and legal advice: As with any legal agreement, it is important to seek professional legal advice before entering into a deed of novation. This will ensure that you understand the legal implications of the agreement and the risks associated with it.\nBy being aware of these risks and taking the necessary precautions, you can mitigate potential issues and ensure that the novation process runs smoothly.\n\nCommon Scenarios for Using a Deed of Novation\nA deed of novation can be a useful legal instrument in several scenarios, some of which include:\nSale or transfer of a business: If you're selling your business or transferring its ownership to another entity, a deed of novation can help transfer the contracts and obligations to the new owner.\nChanges in business structure: When you change your business structure, for example, from a sole trader to a company, a deed of novation can be used to transfer the contractual obligations to the new entity.\nTermination of contracts: A deed of novation can be used to transfer the obligations and rights under a contract to a third party, effectively terminating the contract.\nIt's important to note that while a deed of novation can be a useful legal tool in these scenarios, it's essential to obtain legal advice to ensure that the novation is done correctly and that all parties understand their rights and obligations.\n\nHow to Draft a Deed of Novation\nA Deed of Novation is a legal document that requires careful drafting to ensure that the transfer of obligations and rights is carried out smoothly and effectively. As such, it is important to seek legal advice from a qualified lawyer experienced in drafting and executing such deeds. Here are some key considerations to keep in mind when drafting a Deed of Novation:\nImportance of Legal Advice\nIt is essential to seek legal advice before entering into a Deed of Novation. A qualified lawyer can guide you through the process, identify any potential legal issues, and ensure that the deed is legally binding and enforceable.\nKey Considerations When Drafting a Deed of Novation\nWhen drafting a Deed of Novation, it is important to consider the following:\nParties involved - Clearly identify the parties involved in the novation, including the original parties, the new parties, and any other relevant parties.\nNovation or Effective Date - Clearly state the date from which the novation applies to the parties.\nRelease - Include a clause releasing the original party from all performance of the contract from the novation date.\nRepresentations and Warranties - Include any representations or warranties made by either party.\nFees and Payments - Include any fees or payments to be made by either party.\nSample Deed of Novation\nHere is an example of a Deed of Novation template:\n[Insert date of novation]\nDeed of Novation\nParties\n[Insert original party name], (ACN/ABN [Insert ACN/ABN]) of [Insert address] (Original Party);\n[Insert new party name], (ACN/ABN [Insert ACN/ABN]) of [Insert address] (New Party).\nBackground\n[Insert details of the original contract].\nAgreed Terms\n[Insert details of the novation, including the novation or effective date, release, representations and warranties, and fees and payments].\nExecution\nExecuted as a Deed.\nExecuted by:\n[Insert name of Original Party]\n[Insert signature of Original Party]\n[Insert name of New Party]\n[Insert signature of New Party]\n\nSigning a Deed of Novation\nOnce the Deed of Novation has been drafted, it's time to execute it. The signing of a Deed of Novation is an essential step that requires careful consideration. The following are key points to keep in mind when signing a Deed of Novation:\n\nRequirements for signing a Deed of Novation:\n\nAll parties involved in the agreement must sign the Deed of Novation.\nThe signatures of witnesses may also be required, depending on the jurisdiction and the terms of the agreement.\nThe date of execution must be clearly stated on the Deed of Novation.\n\nImplications of a poorly executed Deed of Novation:\n\nThe failure to comply with the necessary legal requirements can result in the Deed of Novation being invalid, which could create legal problems down the line.\nIncomplete or unclear Deeds of Novation can cause confusion and lead to disputes.\n\nIt is therefore recommended that parties seek legal advice when executing a Deed of Novation to ensure that all legal requirements are met and that the document is executed correctly.\n\nConclusion\nIn conclusion, a Deed of Novation is an important legal document that can be used in a variety of scenarios to transfer contractual obligations. While there are benefits to using a Deed of Novation, there are also risks that must be carefully considered. Seeking legal advice is crucial to ensure that the document is drafted correctly and executed properly. \n\nAt Contracts Specialist, we offer a free consultation to homeowners in NSW who are considering a Deed of Novation. Contact us today to schedule a meeting with one of our experienced lawyers.", "Part 4:\nIV. ENCRYPTED PRODUCT INFORMATION \nRETRIEVAL SCHEME \nA. CONSTRUCTION OF PRODUCT RETRIEVAL TREE A PRF tree has three main parameters: branching factors B1, and B2 and threshold T , which are preset by the data owner. Each non-leaf node NLi contains at most B1 child nodes, and it is defined as follows: \nNLi = (PRF, PRF1, child1, \u00b7 \u00b7 \u00b7 , PRFB1, childB1) (9) \nwhere PRF is the PRF vector of the whole cluster, PRFiis the PRF vector of the i-th sub-cluster and childiis a pointer to the child node representing the sub-cluster. A non-leaf node represents a cluster made up of all the sub-clusters represented by its child nodes. A leaf node Li contains at most B2 product vectors, and it is defined as follows: \nLi = (PRF, child1, \u00b7 \u00b7 \u00b7 , childB2), (10)\nwhere PRF is the PRF vector of the cluster, childiis a pointer to the i-th product vector in the cluster. Furthermore, the cluster of a leaf node must satisfy a threshold requirement: the radius of the cluster (11) must be less than T . The default values in the nodes are set to null. \nThe PRF tree is constructed in an incremental manner, and the process of inserting a product vector Vjinto the PRF tree is presented as follows: \n\u2022 Identifying the appropriate leaf node: Starting from the root, Vj recursively descends the PRF tree by choosing the closest child node according to the relevance scores between Vj and the sub-clusters as defined in (11) until it reaches a leaf node. \n\u2022 Modifying the leaf node: When Vj reaches a leaf node Li, it tests whether Li can \u2018\u2018absorb\u2019\u2019 Vj without violating the constraints of B2 and T. If so, Vjis inserted into Li and the PRF vector of Liis updated. If not, we must split Lito two leaf nodes. Node splitting is performed by choosing the farthest pair of product vectors as seeds and redistributing the remaining product vectors based on the closest criteria. The PRF vectors of the two new leaf nodes need to be recalculated. \n\u2022 Modifying the path from the root node to the leaf node: After inserting Vjinto a leaf node, we need to update the PRF vector for all the nodes on the path to the leaf node. In the absence of a split, this simply involves updating PRF vectors based on Theorem 1. A leaf node split requires us to insert a new leaf node into the parent node. If the parent node has space for the new leaf node, we only need to insert the new leaf node into it and then update the PRF vector for the parent node. In general, however, we may have to split the parent node as well, and so on, up to the root. If the root is split, the tree height increases by one. \nB. RETRIEVAL PROCESS OF THE INTERESTED PRODUCTS In this paper, the data users can retrieve the interested product in two ways, i.e., retrieving the products by their identi fiers or the product feature vector. When a data user wants to search a product based on its identifier, she first needs to encrypt the identifier based the on the hash function, hash(). Next, the hash value of the identifier is sent to the cloud server. The cloud server is responsible for searching for the \nhash value in the ID-AVL tree, and once the hash value is found, the corresponding encrypted production information is sent to the data user. Finally, the data user can decrypt the product information based on the secret keys, and the data retrieval process is completed. \nMoreover, in certain cases, the data user may want to search the product based on the features. Initially, the data user needs to construct the feature vector of the product as discussed in Section 3.3. Then, we need to design a depth-first search algorithm for the PRF tree, and that algorithm is presented in Algorithm 1. \nAlgorithm 1 DepthFirstSearch(a PRF Tree With Root r, a Query Vector VQ) \n1: u \u2190 r; \n2: while u is not a leaf node \n3: Calculate all the relevance scores between the child nodes of u with VQ based on (5); \n4: u\u2190 the most relevant child node; \n5: end while \n6: Select the most relevant k document vectors in u by RScore(Vi, VQ) and construct RList; \n7: Stack.push(r); \n8: while Stack is not empty \n9: u\u2190Stack.pop(); \n10: if the node u is not a leaf node \n11: if RScore Vu,max , VQ >kthScore \n12: Sort the child nodes of u in ascending order based on the relevant scores with VQ; \n13: Push the children of u into Stack in order, i.e., the most relevant child is latest inserted into Stack; 14: else \n15: break; \n16: end if \n17: else \n18: Calculate the relevance scores between the document vectors in the leaf node with VQ and update RList; \n19: end if \n20: end while \n21: return RList; \nIn Algorithm 1, the kthScore represents the smallest rele vance score in the current result list RList, which stores the most k relevant accessed document vectors with VQ and the corresponding relevance scores. In addition, we employ the variable Stack to store the nodes which need to be searched in the future. In addition, Stack.push(u) inserts node u into Stack and Stack.pop() returns the latest inserted node. In the initial phase, we need to first locate the most relevant leaf node with the query vector in the tree to initialize RList as presented in line 2 to line 6. Then, the result list is continuously updated by searching the necessary paths in the tree until the final search result is obtained as presented in line 8 to line 19. Compared with the search process of the keyword balanced binary tree proposed in [27], the search process presented in Algorithm 1 is much more efficient considering that many \nsearch paths are pruned in the searching process. \n\nC. ENCRYPTION OF THE PRODUCT RETRIEVAL TREE \nFor each product Pi, two types of information are first \nextracted, including its identifier i and the product vector Vi. \nWe encrypt the identifier i through a hash function, hash(). \nThe construction process of the ID \u2212 AVL tree is presented \nas follows. The constructed ID \u2212 AVL tree can be directly \noutsourced to the cloud server because it stores only a set of \nhash values, rather than the plaintext identifier. \n\nBased on the product vectors, the process of building the PRF tree has been presented in Section 4.2. In contrast to the ID \u2212 AVL, the PRF tree needs to be encrypted before being outsourced. In the PRF tree, we treat LS, Vmin and Vmax to the same as product vectors and encrypt them in the same way. Note that parameter K in a PRF vector does not need to be encrypted, and SS, which will not be used in the search process, does not need to be sent to the cloud server. Before encrypting a product vector Vjin the PRF tree, we first extend it to (m+m0) dimensions. In addition, we spilt each dimension of Vj[i] into Vj[i]0and Vj[i]00. Specifically, if S2i = 0, Vj[i]0 and Vj[i]00 will be set equal to Vj[i]; otherwise, Vj[i]0and Vj[i]00 will be set as two random numbers whose sum is equal to Vj[i]. Next, we randomly select two invertible matrices M1, M2 and encrypt Vj as Ej = {MT1V0j, MT2V00j}. \nOnce a search request SR is received by the proxy server, it first extracts its parameters including ID0and vSR. Param eter ID0is encrypted by hash() and we get hID0 . We extend vSR to (m + m0) dimensions. Specifically, if S1i = 0, the i-th dimension of VQ corresponds to a feature wr, which is extracted from W in order, and VQ[i] is set to wwr; oth erwise, this dimension is an artificial dimension and VQ[i] is set to a random number. Note that the value of the last artificial dimension is not a random number, and it should be calculated carefully to guarantee that the dot product of the artificially added dimensions in the product vectors and in VQ is 0. Further, we spilt VQ[i] into VQ[i]0and VQ[i]00. Specifically, if S2i = 1, VQ[i]0and VQ[i]00 will be set equal to VQ[i]; otherwise, VQ[i]0and VQ[i]00 will be set as two random numbers whose sum is equal to VQ[i]. Finally, we encrypt VQ as EQ = {M\u22121 \n1V0Q, M\u22121 \n2V00Q}. In this case, the relevance \nscore of Vj and VQ defined in Section 3.2 can be calculated as follows: \nRScore Vj, VQ = Vj\u00b7 VQ = Ej\u00b7 EQ. (11) \nThe trapdoor TD is composed of the hash values of the filename and authors and EQ.", "re write this and make it an Alert! fear of loss ad copy - U. S. Department of LaborOccupational Safety and Health Administration\nDirectorate of Technical Support and Emergency Management\nOffice of Science and Technology Assessment Standup Forklift Under-ride Hazards Safety and Health Information Preface\nForklift truck operators must look in the\ndirection of travel and keep the forklift under\ncontrol at all times. One of the potential\nhazards faced by standup forklift operators is\nthe crushing hazard that can arise when\ntraveling, with the forks trailing, in a\nwarehouse near a storage rack or similar\nobstruction. The risk is that a horizontal rack\nbeam (crossbar) or similar obstruction might\nenter the operator\u2019s compartment in a situation\nreferred to as \u201cunder-ride.\u201d This Safety and\nHealth Information Bulletin (SHIB) discusses\nways to reduce the crushing hazard to the\noperator associated with under-ride. Awareness\nof the precautions and safety measures\nhighlighted in this SHIB can help prevent\nserious injuries and fatalities related to\nwarehouse operations.Purpose\nThe purpose of this SHIB is to\nAlert standup forklift operators and\nemployers to the crushing hazard to the\noperator associated with under-ride;\nIdentify standup forklift features that\nare available on new equipment or that\ncan be installed on standup forklifts to\naddress the hazard (ANSI/ITSDF\nB56.1-2005, para. 4.5.3, 7.30, 7.36.)\nThis Safety and Health Information Bulletin\n(SHIB) is not a standard or a regulation, and it\ncreates no new legal obligations. It contains\nrecommendations as well as descriptions of\nmandatory safety and health standards. The\nrecommendations are advisory in nature,\ninformational in content, and are intended to\nassist employers in providing a safe and\nhealthful workplace. The Occupational Safety\nand Health Act requires employers to comply\nwith safety and health standards and regulations\npromulgated by OSHA or by a state with an\nOSHA-approved state Plan. In addition, the\nAct\u2019s General Duty Clause, Section 5(a)(1),\nrequires employers to provide their employees\nwith a workplace free from recognized hazards\nlikely to cause death or serious physical harm.\nIdentify arrangements or modifications\nof storage racks that might reduce the\nrisk of under-ride;Recommend work practices that can be\nimplemented by the employer to\neliminate the under-ride hazard;\nStress the importance of training\n employees on the safe operation\n of standup forklifts; and\nEnsure that employees follow safe\noperating procedures.\nSHIB 07-27-20092 Background\nA forklift \u201cunder-ride\u201d hazard arises when the\nforklift operator travels with the forks trailing\nand backs up toward the storage rack. If the\noperator drives the forklift too far, so that the\nforklift passes beneath the horizontal crossbar\n(i.e., the operator creates an \u201cunder-ride\u201d), the\ncrossbar can enter the operator\u2019s compartment\nand crush the operator inside the compartment.\nThe Occupational Safety and Health\nAdministration\u2019s (OSHA) Integrated\nManagement Information System data for the\nperiod of 1993 through 2008 indicate that at\nleast nine employees have been killed and three\nemployees sustained severe crushing injuries\nwhen operating a standup forklift in reverse.\nThese forklifts did not have a protective rear\nguard or corner post to prevent under-ride from\noccurring.Accident Description\nThe OSHA Cleveland Area Office investigated\na fatality at a warehouse where a standup\nforklift operator was found pinned between the\nlower horizontal crossbar of a storage-rack\nshelving system and the interior of the\noperator\u2019s compartment. The horizontal\ncrossbar of the shelving system was 55 inches\n(140 centimeters) above the floor, while the top\nsurface of the operator\u2019s compartment was only\n49 inches (124 centimeters) above the floor.\nThis left a space of 6 inches (15 centimeters)\nbetween the crossbar and the top surface of the\noperator\u2019s compartment. Although the forklift\nhad an overhead guard, the shelving rack was\nnot positioned at the same level as the guard to\nprevent the under-ride from occurring. When\nthe operator traveled with the forks trailing, the\nforklift passed under the crossbar, which struck\nthe operator above the waist and pinned his\ntorso against a part of the operator\u2019s\ncompartment. The operator died of\nasphyxiation injuries.\nThis photograph depicts a forklift under a\nstorage rack after an under-ride accident.\nThe crossbar is protruding above the\noperator\u2019s cab. Forklift manufacturers have\nvarious features available to assist in\npreventing such under-rides. \nOSHA\u2019s Standard Requirements\nProper training is essential to the safe operation\nof powered industrial trucks. Paragraph (l) of\nOSHA\u2019s Powered Industrial Trucks Standard,\n29 CFR 1910.178, contains training and\ncertification requirements for the use of\nforklifts that are specific to the workplace. The\nstandard requires employers to develop and\nimplement a training program for all operators\nbased on the general principles of safe truck\noperation; the types of vehicles being used in\nthe workplace, including the instructions,\nwarnings, and precautions found in the\noperator\u2019s manual; the hazards of the\nworkplace created by the use of the vehicle;\nand the general safety requirements of the\nOSHA standard.\nAdditionally, 29 CFR 1910.178(n)(1) and\n(n)(6) require operators to keep the forklift\nunder control at all times and to look in the\ndirection of travel.\nRecommendations\nThe following recommendations will reduce\nthe risk of under-ride hazards associated with\noperating standup forklifts.\nEmployers should evaluate their worksite to\ndetermine if an under-ride hazard exists. If\nthere are rack crossbars or similar obstructions\nin the facility, the employer should take one or\nmore of the following actions:\nIf possible, make modifications to the\nshelving system.\nAdjust the shelf heights so that\nthe body of the forklift below\nthe operator\u2019s compartment will\nstrike the rack in the event of\ncontact, preventing under-ride\nfrom occurring. Adjust the shelf heights so that\nthe forklift\u2019s overhead guard\nwill strike the rack in the event\nof contact, preventing under-ride\nfrom occurring. Install a barrier, even with the outer\nedge of the storage rack (such as a curb\nor floor level shelf), so that the bottom\nof the forklift will strike the curb or\nshelf in the event of contact, preventing\nan under-ride from occurring.\n Purchase, where appropriate, standup\nforklifts that have corner posts,\nextended backrests, rear post guards, or\nother features to prevent an under-ride\nfrom occurring. (Specific guards or\nother means that enhance safe\noperations would be determined\nthrough cooperation between the user\nand manufacturer (see ANSI /ITSDF\nB56.1-2005, para.4.5.3, 7.30, and\n7.36).)\nContact the manufacturer to discuss\ninstalling rear post guards or other\nequivalent protections that address the\nunder-ride hazard on existing standup\nforklifts. These posts may be available\nfrom the forklift manufacturer. (Note\nthat modifications and additions which\naffect safe operation shall not be\nperformed by the customer or user\nwithout the manufacturer\u2019s prior written\napproval. 29 CFR 1910.178 (a)(4).)\nEvaluate control methods to assure that\nguards do not limit visibility, present\npinch-point hazards, or add any\nadditional hazard to forklift operators or\nother employees on the site.\nTrain employees to operate forklifts\nsafely as required by paragraph (l) of 29\nCFR 1910.178, including recognizing\nthe hazards of the workplace created by\nthe use of the vehicles.\nRefer to the Powered Industrial\nTrucks (Forklift) eTool as a resource for\ninformation to keep employees who\noperate forklifts safe on the job. The\neTool provides a review of potential\nhazards and a summary of key OSHA \nUpper rack is positioned at the same level as the\noverhead guard, preventing the possibility of an\nunder-ride. The forklift shown in this photograph\nhas an overhead guard and an extended backrest.\nKits with additional posts are other safety features\nthat are available on many forklifts.\n\nrequirements and industryrecommended practices for forklift\noperations.\n\nNote: It is a violation of Federal\nlaw for anyone UNDER 18 years of\nage to operate a forklift in nonagricultural employment. (See\nOSHA Safety and Health Bulletin\n03-09-30, Protecting Young\nWorkers: Prohibition Against\nYoung Workers Operating\nForklifts.)\n\nConclusion\nMinimizing the potential for serious or fatal\ninjuries to standup forklift operators is the\nprimary concern of this SHIB. Following the\nsafe work practices recommended in this SHIB,\nand training employees as required in OSHA\nregulations, will help accomplish this goal.\n\nReferences\n1. OSHA Integrated Management\nInformation System (IMIS), 1993-\n2005.\n2. American National Standard\nANSI/ITSDF B56.1-2005, Safety\nStandard for Low Lift and High Lift\nTrucks, Industrial Truck Standards\nDevelopment Foundation.\n3. Powered Industrial Trucks (Forklift)\neTool at\nhttp://www.osha.gov/dcsp/products/et\nools/pit/index.html\n4. Safety and Health Information\nBulletin, 03-09-30, Protecting Young\n Workers: Prohibition Against Young\n Workers Operating Forklifts.", "Here are matching samples\uff1a\n{\"left\": {\"title\": \" \\\"Nike Metcon 2 - Black/White/Wolf Grey/Volt\\\"@en \\\" Nike Mens Shoes Regular Training Grey/Volt \\\"@en\"}, \"right\": {\"title\": \" \\\"Nike Metcon DSX Flyknit - Wolf Grey/Volt/Wolf Grey/Black\\\"@en-GB \\\" Nike Mens Shoes Regular Training Grey/Black \\\"@en-GB\"}, \"match\": \"1\", \"match\\_confidence\": 0.6768335389517993}\n{\"left\": {\"title\": \" \\\"PowerLine HD Day Night Cloud Camera Kit\\\"@hu \\\"DCS-6045LKT PowerLine Day/Night Kit | D-Link\\\"@hu\"}, \"right\": {\"title\": \" \\\"HD DVR Surveillance System, 16 Infrared Dome Cameras, Free Mobile Apps\\\" System Cameras\"}, \"match\": \"1\", \"match\\_confidence\": 0.5253383831443448}\n{\"left\": {\"title\": \" \\\"Canon BG-E11 Battery Grip for EOS 5D Mark III Camera\\\"@en \\\"Accessories :: Canon Camera - Onestop Digital\\\"@en\"}, \"right\": {\"title\": \" \\\"Canon BG-E11 - battery grip\\\" \\\" Canon grip 5261B001 Digital Camera Accessories CDWG.com\"}, \"match\": \"1\", \"match\\_confidence\": 0.9960314997270953}\n{\"left\": {\"title\": \" \\\"Seiko Automatic Divers Rubber Band SKX007K1 SKX007K Mens Watch\\\"@en-US Watch - DownUnderWatches\\\"@en-US\"}, \"right\": {\"title\": \" \\\"Seiko SKX007K1 watch\\\"\"}, \"match\": \"1\", \"match\\_confidence\": 0.9709368127814284}\n{\"left\": {\"title\": \" \\\"Transcend TS32GCF133 32 GB CompactFlash\\\"@en\"}, \"right\": {\"title\": \" \\\"Transcend 32GB CompactFlash Memory Card 133x (TS32GCF133)\\\"@en-US \\\"Accessories - Page 1531 | EISF\\\"@en-US\"}, \"match\": \"1\", \"match\\_confidence\": 0.9810219632882344}\n{\"left\": {\"title\": \" \\\"Air Jordan 5 Low \u201cDunk From Above\u201d White/Metallic Gold Star-Midnight Navy For Sale\\\"@en-US Sale | New Jordans 2016\\\"@en-US\"}, \"right\": {\"title\": \" \\\"Air Jordan 5 Low \u201cDunk From Above\u201d White-Gold/Midnight Navy 2016 Sale\\\"@en-US Sale | Cheap Jordans 2017\\\"@en-US\"}, \"match\": \"1\", \"match\\_confidence\": 0.9651519733407093}\n{\"left\": {\"title\": \" \\\"Transcend 4GB Secure Digital High-Capacity(SDHC) Class 2 SDHC Flash Memory\\\" \\\"Product data Transcend Memory memory cards (TS4GSDHC)\\\"\"}, \"right\": {\"title\": \" \\\"Transcend TS4GSDHC BUB 4GB SDHC Secure Digital Class 2 Retail\\\"\"}, \"match\": \"1\", \"match\\_confidence\": 0.9931627953679547}\n{\"left\": {\"title\": \" \\\"Nike Womens Air Zoom Pegasus 33 - Black/White-Anthracite-Cool Grey\\\"@en-GB \\\" Nike Grey Shoes 831356-001 \\\"@en-GB\"}, \"right\": {\"title\": \" \\\"NIKE AIR ZOOM PEGASUS 33\\\"@en 33 - MAN RUNNING SHOES Nike colour Black 831352 001 Athletic footwear apparel and sports equipment\\\"@en\"}, \"match\": \"1\", \"match\\_confidence\": 0.8689380318690634}\n{\"left\": {\"title\": \" \\\"Speedlite 270EX II\\\"@en \\\"Canon Speedlite II | Canon Online Store\\\"@en\"}, \"right\": {\"title\": \" \\\"Canon - Speedlite 270EX II External Flash\\\"@en-US\"}, \"match\": \"1\", \"match\\_confidence\": 0.9947697221630724}\n{\"left\": {\"title\": \" \\\"Nike AIR Zoom Pegasus 32 Men's Training Shoes - Total Orange/Ghost Green/Black\\\"@en \\\"Running and Training\\\"@en\"}, \"right\": {\"title\": \" \\\"Nike AIR Zoom Pegasus 32 Men's Training Shoes - Green/Blue Lagoon/Black\\\"@en \\\"Clearance Footwear\\\"@en\"}, \"match\": \"1\", \"match\\_confidence\": 0.5219280639058551}\n\nHere are not-matching samples:\n{\"left\": {\"title\": \" \\\"TP-LINK 8-Port Fast Ethernet Desktop Switch (TL-SF1008D)\\\"@en-US \\\"Switches | Laptops Outlet Direct\\\"@en-US\"}, \"right\": {\"title\": \" \\\"Tripp Lite 750VA 450W UPS Eco Green Battery Back Up Compact 120V USB RJ11\\\" \\\" Tripp RJ11 - ECO750UPS UPS/Battery Backups CDW.com\"}, \"match\": \"0\", \"match\\_confidence\": 0.9983706911746074}\n{\"left\": {\"title\": \" \\\"Seiko 5 Automatic 24 Jewels Men's 100m Rubber Sports Watch SRP601K1 \\\"@en | Dutyfreeislandshop.com\\\"@en\"}, \"right\": {\"title\": \" \\\"Seiko Solar Chronograph Alarm 100m Men's Watch SSC431P1 \\\"@en | Dutyfreeislandshop.com\\\"@en\"}, \"match\": \"0\", \"match\\_confidence\": 0.9991221085910428}\n{\"left\": {\"title\": \" \\\"Nike Zoom Structure 19 Comp Pack Men's Running Shoes SP16 007\\\"@en 007 \u00b7 Nike Moderate Support Trai ah\\\"@en\"}, \"right\": {\"title\": \" \\\"KANMEI GS\\\"@en-es GS | Unisex Kids Running Shoes ASICS\\\"@en-es\"}, \"match\": \"0\", \"match\\_confidence\": 0.9972584441623807}\n{\"left\": {\"title\": \" \\\"Corsair Vengeance SODIMM 8GB (2x4GB) DDR3 PC3-12800C9 1600MHz Kit (CMSX8GX3M2A1600C9)\\\"@en \\\"\u25b7 Corsair 1600MH\u2026 | OcUK\\\"@en\"}, \"right\": {\"title\": \" \\\"364622-B23 HP 300-GB 10K FC-AL HDD\\\" \\\"Null\\\"\"}, \"match\": \"0\", \"match\\_confidence\": 0.9971550903350205}\n{\"left\": {\"title\": \" \\\"Full HD Wireless Day Night Network Camera\\\"@en \\\"DCS-2230L Full Camera | D-Link UK\\\"@en\"}, \"right\": {\"title\": \" \\\"Full HD WDR Varifocal Day & Night Outdoor Smoked Dome Network Camera\\\"@en \\\"DCS-6314BS Full Camera | D-Link UK\\\"@en\"}, \"match\": \"0\", \"match\\_confidence\": 0.9968396471849288}\n{\"left\": {\"title\": \" \\\"TomTom Runner 2 Cardio+Music DBL/LBL (Large) - Sky Captain Blue/Scuba Blue\\\"@en \\\" TomTom Running Accessories Blue \\\"@en\"}, \"right\": {\"title\": \" \\\"TomTom Runner 2 Cardio GPS Watch with Music Large Strap - Blue\\\"@en Blue | Start Fitness\\\"@en\"}, \"match\": \"0\", \"match\\_confidence\": 0.8319637828217654}\n{\"left\": {\"title\": \" \\\"Fujifilm Fujinon XF 55-200mm f3.5-4.8 R LM OIS Lens\\\"@en Aden Camera \\\"@en \\\" Fujifilm Lens | Digital SLR Toronto Canada Store Cameras\"}, \"right\": {\"title\": \" \\\"Canon EF-S 18-55mm f3.5-5.6 IS STM\\\"@en \\\" Canon STM | Digital SLR Camera Cameras Toronto Canada Store Aden \\\"@en\"}, \"match\": \"0\", \"match\\_confidence\": 0.9823555365894354}\n{\"left\": {\"title\": \" \\\"672631-B21 HP 16GB (1x16GB) SDRAM DIMM\\\" \\\"Null\\\"\"}, \"right\": {\"title\": \" \\\"404712-001 HP 146-GB U320 SCSI 15K\\\" \\\"Null\\\"\"}, \"match\": \"0\", \"match\\_confidence\": 0.9978510507163746}\n{\"left\": {\"title\": \" \\\"Air Jordan 14 Retro Low \u201cLaney\u201d Varsity Royal/Varsity Maize-Black-White For Sale\\\"@en-US Sale | Cheap Jordans 2017\\\"@en-US\"}, \"right\": {\"title\": \" \\\"Cheap Air Jordan 4 Retro \u201cMotorsports\u201d White/Varsity Blue-Black Sale\\\"@en-US Sale | Cheap Jordans 2017\\\"@en-US\"}, \"match\": \"0\", \"match\\_confidence\": 0.9969603503859167}\n{\"left\": {\"title\": \" \\\"WD Red NAS 3.5\\\" Internal HDD SATA 6Gb/s, 2TB\\\"@en 6Gb/s 2TB - WD | CPC \\\"@en\"}, \"right\": {\"title\": \" \\\"Buy Online | WD Red WD20EFRX 2TB Desktop Internal Hard Drive Price in India\\\"@en-US\"}, \"match\": \"0\", \"match\\_confidence\": 0.944943928209663}", "Please continue writing the article with the upcoming transcript, the first three headings are complete. No need to restate them in your response.\n\nRemember your prompt: Imagine you are a world-class SaaS Sales and Customer Success Enablement and Training AI. \n\nYour Task: You need to produce a wiki article from the transcript of a training session on our new Cross-Workspace Collaboration (XWC) vs our existing Guest User Experience feature. At the end, you will also produce an FAQ, save Question and Answers from each part to a document called \"QnA\".\n\nTo help you create headings for the wiki article I've provided the agenda for the session as a suggestion.\n\nIntroduction (Completed)\nWhy was Cross Workspace Collaboration created? (Completed)\nUnderstanding Guest User Feature (Completed)\nUnderstanding Cross Workspace Collaboration Feature (Discussed in this part)\nKey Differences Between Guest User and Cross Workspace Collaboration Features (Discussed in this part)\nPricing and plans (To be discussed in a later part)\nTips for Suggesting the Right Feature to Customers (May be discussed in this part)\n\nI will provide the transcript in separate parts, here's the sixth part: \n\"00:35:00\nEmily Iba\u00f1ez: Right right. Okay, that makes sense. Thanks.\nSarah Collins: Okay, so this is I'm looping back. This is the portion that I was mentioning. I had an existing note. If you recall And so what happens now is that I get this little modal which tells me that I can slip switch strings to the actual one. That is owned. By my collaborators.\nSarah Collins: So, I can switch between these two.\nJoe Fleming: Yeah, yeah, that's super cool. Yeah. And the UX is pretty nice actually. So, okay, cool. Good to know. So this is as a sidebar, one of the things that we need to do decide as a team is how we use. Do we need to standardize how we use this feature because like, this now opens up the ability to Actually, truly use fellow with our customers. And eat our own dog food, assign them, action items have a mutual action plan with them, but in fellow and it's not a pain for them to be able to collaborate. So like it also it gives our customers a clear reason to come back into the product as well, right? Because they'll come back into the product and they will work on the notes that we have.\nJoe Fleming: Sending them, right. So that I think that that's gonna be super helpful, especially in the POC process and with the multiple assigned, as Marcus said, We can, like assign to all of the people that join a training session and get them to do things. And we'll know, like, whether they've checked it off or not. So we can follow up with those people specifically and we can follow up in their fellow instance, we can assign them, action items directly in their fellow.\nSarah Collins: Yeah, exactly. So this is super powerful, especially because you're gonna have the option to also Have multia signing and crossword stays. So if I was working with a customer, for example, we are onboarding a few people right now and I'm using us for a kickoff note. I can have every single person on that note be assigned to install the desktop and then they're gonna see this inside of their actual fellow account.\nJoe Fleming: Here. Okay.\nSarah Collins: To complete it. So if I now go into my action items here, Install, the Desktop app.\nSarah Collins: oh,\nEmily Iba\u00f1ez: I was doing those sounds when I was on mute.\nSarah Collins: What?\nJoe Fleming: Yeah, exactly. And there's a nice little progress bar. It's awesome. Just I want to make sure that we have time for both questions. And I think the big question like the big thing though to touch on and I'm very keen to get your take on the Sarah is What? Cuz, like, the use cases are the use cases for crossword space and for guests basically the same. I guess that's one question. Are there any additional use cases and\nJoe Fleming: aside from that, like, Is there any case where like people shouldn't choose the guest experience over the crossword space experience?\nSarah Collins: Great question. So there's a few differentiations between the two and really it comes back to what the capacity that you're working with this person in. So I would use crossword space in onboarding here at fellow and onboarding customers because it's going to be for a prolonged period of time. So in that case, if I was choose the guest experience, their access is going to expire and their existing fellow users, so they're not going to see any of their action items in their own work space, which in the past has meant that those action items. Never get looked at again because you have to log into that separate fellow workspace in order to view them. So the time that you want to use crossword space is if the guest either has an existing fellow account or they are willing to open up a fellow account and connect their calendar, if they're willing to do those two things. Cross workspace is a much better experience.\nSarah Collins: But if it's kind of like a one-time access scenario, and they're just meeting that one time. They don't plan on meeting again in the future, but for whatever reason they need collaboration for that one meeting. In that case, I would recommend guest if there's security issues because explaining to someone who doesn't know and or understand fellow, even from new customers that we're on board. Their number one, fear is, What are you doing with my calendar Information? That fear prevents a lot of people from actually sending up to fellow to begin with because they don't understand why we need access to that information because they haven't hit their aha moment yet. So if that fear is really prevalent, then guest users is a really good option. Otherwise collaborate collaborative access through crossword space. It's overall in my opinion, a much smaller experience and it removes. A lot of that friction that you would tend to find with just the regular guest experience.\n00:40:00\nSarah Collins: Like, the access link expiring and all that stuff.\nSarah Collins: I heard some questions, feel free that pop in and ask them.\nSarah Collins: Yeah, exactly.\nJoe Fleming: Yeah, I would default. I would be fob to crossword space. Pretty much all the time even if it's short term. because at the end of the day, like, I think the the other way to look at it is every, every crossword space is an opportunity for another lead. For us. So it's better\u2026\nSarah Collins: Yeah. I agree.\nJoe Fleming: if they use even if they don't continue to use it, the other thing is is like keep in mind. For like our end internally. every single time somebody connects their calendar, it means that Like, we can find out. if this person or any other person, that logs in, if they have a ton of meetings, recurring meetings in their calendar, it means we know like, hey,\nJoe Fleming: This person will really care about this tool. Maybe we should like whether it's us as a sales, team manually going after these people and saying, Hey like you're in meetings all the time. You know, here's an opportunity to make your meetings better or if it's like through the product or some other way. Like every single calendar, connect helps us continue to grow our base and target people. That actually are experiencing. The problem that we solve. So I think this is why it's so important is because like the you know, building the database of users is a big part of building the business, so cool. So I think that like covers, most of the things here in terms of pricing in plans,\nSarah Collins: The four-way move on to that Joe. Can I just munch one last thing? Onboarding experience for crossword space is a little bit different.\nJoe Fleming: Yeah, of course.\nSarah Collins: We're optimizing to get them right into that meeting that they are going to be collaborating with that other company. So they're not getting, that usual onboarding flow and that's important to mention because they're a ha moment is gonna come from that collaborative access. And then they explore everything else that fellow has to offer after the fact.\nSarah Collins: Yes. Question.\nEmily Iba\u00f1ez: Yeah. Yeah, I said a question. So you mentioned so like if I have a pro plan and I'm sharing my note with Joe, but Joe's on free in two weeks. Once Joe loses access to his note history, does that mean he also won't, he won't be able to see like our past notes. But I will. because,\nSarah Collins: That's a great question. And I can't remember what product told me for that one.\nEmily Iba\u00f1ez: Okay, no worries. Just because like, I'm envisioning it being like me saying, Hey Joe, like look at our note from three weeks ago, and then Joe's, like Why can't I see it? But you can't see it, right? So,\nSarah Collins: Yeah, that's a great question. I'm like, 50%. Sure that they told me that for cross works. Basic collaboration notes that you do retain the access because it's technically owned by the workspace that is upgraded. But we should definitely talk with product on that\u2026\nEmily Iba\u00f1ez: Right.\nSarah Collins: because I'm not a hundred percent sure.\nEmily Iba\u00f1ez: It would also be a good paywall though maybe to upgrade the free person, then they feel like they're missing out on the notes, right? So,\nSarah Collins: All the fellow. Yeah.\nSarah Collins: Awesome. Okay. Sorry Joe. What was your next question there?\"", "Right now, I am creating a portfolio for myself as an artist to deepen and clarify the story I present to my audience through my music and my image on social media and in real life. \n\nIt is comprehensive outline of the persona maturation project entitled \u2018The Journey\u2019. It covers each and every aspect of the process in detail, both theoretical and practical, as well as a structured approach to building upon existing character frameworks.\n\nThe following is the current structure of the document, like the table of contents:\n\n# Introduction\n\nThis is a comprehensive introduction meant to bring you, the reader, up to speed with the current outline and motivations of the project.\n\n## What is \u2018The Journey\u2019\n\nThe Journey, derived from The Hero\u2019s Journey, a theoretical roadmap to the development of the key elements that evoke powerful emotional reactions in people. The Hero\u2019s Journey is a structure that has been followed by some of the greatest stories ever told and ever lived. \n\nThe version of this journey described throughout the document is tailored for Kadence and is meant to serve as a reference point and a workspace for ideas, planning, and the execution of specialized tactics in order to continuously develop and progress the story which underlies the public representation of the ideas covered in this document. \n\nThe Journey, it\u2019s associated ambitions, milestones, challenges, and gimmicks are experimental in nature, and thus are used to further our own research into the business of artist development, and quite possible leaving our mark on the World.\n\n## What is within this document?\n\nThis document contains a whole lot of useful information about characters, possible pathways of progression, theoretical understandings from The Hero\u2019s Journey, and much more. Overall, this document is a collection of all types of information that is relevant to the project undertakings described above.\n\n## How should this document be used?\n\nThis document should be seen strictly as an experimental guideline line used to plan and execute experimental content and plot lines with the intent of learning from experiment results and making changes to procedures in the future where necessary. With regards to content, the content database provided in this document will be used to visualize the potential timeline of events that will transpire once the official process has gone underway (ie. when the first piece of planned content is released to the public and the timeline must be adhered to.)\n\nIn addition to the content calendar, the document will be the gathering place for information deemed useful during the planning and execution process of projects such as the [Docu-series: \u2018Untitled\u2019](https://www.notion.so/Docu-series-Untitled-16d8ab7a883946629fcfa3154b28f7f9) . This information serves to fuel the end-user content that is scheduled and created. By using the Hero\u2019s Journey as a guideline, maximum impact can be gradually attained via meticulous planning and execution of ordered story elements once it is distilled into its relevant parts here inside this document.\n\n## What is [The Story]\n\n[The Story] is a character arch guideline for the [Docu-series: \u2018Untitled\u2019] that is derived from the content of this page. It occurs over a discrete time period, subtly growing in both complexity and depth. The point of using a story is simple, it allows us as the creators of content to understand what type of activities, emotions, themes, places, people, and other story elements to include in order to progress the story, in film format, from a clear beginning to a decisive end without relying on specific events or in real life occurrences that might be outside of our control. By determining the characters in the story, as well as their personalities, aspirations, fears, hopes, and desires, we will be able to translate the implied reality of those characters into practical actions and plot points that can be made in the real world to add a touch of fantasy-like takeaways to the project.\n\nBy taking the time to understand both the created characters and their real life counterparts, we ensure maximum compatibility with your (you reading this) personality and willingness to carry-out certain real life actions. For example; if there is a unanimous vote in favour of a miniature story arch entitled \u201cthe Hair Bleaching Journey\u201d, then the actual feasibility of both the execution and the successful implementation of the story arch can be weighed against the personalities who would actually be carrying out the plot in real life (ie. Kadence). In this case, the previously mentioned miniature story arch above is within the personalitie\u2019s \\*zone of possibility\\*. This lends a higher chance of success as well as a more natural feeling approach to executing the actual story element. This simply means that Kadence is okay with whatever comes with such a mini arch. There may be others which fall outside of this feasible range, and that is where this entire document comes in. It allows us to weed through all of our ideas, selecting the most realistic ones that also add to the greater storyline (following the Hero\u2019s Journey). The content calendar supports this by allowing us to plan months in advance in order to make sure that our plans are solid well before any are due to air or be created in the real world. One more advantage of this setup is that is allows for the addition of subtle details and easter eggs which add to the realism of the events. \n\n## What is content?\n\nThe content being referred to throughout this document implies any piece of digital media created with the intention to release publicly, and any physical activity, psychological manipulation, social experiment, or persona maturation that takes place as a result of itself within the structure of the content as a whole. For example, with respects to the persona maturation process and the Hero\u2019s Journey, there must be a transition from \u2018the Ordinary World\u2019 into \u2018the Special World\u2019, a call to adventure. This means that content surrounding this major story arch can be anything from music and visual content, to IRL appearances and planned controversy. Whether a certain piece of content gets placed on the calendar depends on whether or not is has met the above criteria for all parties involved.\n\n# The Journey\n\n## Who is Kadence\n\nI am Kadence, a 25-year-old musician from New York City who was raised in Jamaica. Music has been a constant in my life, a source of comfort and inspiration that has seen me through the ups and downs of my journey. From a young age, I was drawn to the rhythms of the Caribbean and the art of music-making, and it was in Jamaica where I first discovered my love for rap and hip-hop.\n\nI started my journey as a rap artist under the name 'Kadence' in 2012, and it wasn't long before I became well-known in my home city of Mandeville for my skills as a producer, vocalist, and songwriter. I spent countless hours honing my craft, pouring my heart and soul into each beat, each verse, each chorus. I knew that music was my calling, and I was determined to make it my life's work.\n\nSo, in 2015, I made the bold decision to move to Toronto, Canada, to pursue my dream of becoming a successful musician. It was a difficult decision, leaving behind my family and friends, but I was driven by a deep passion for music and a fierce determination to succeed. And I am proud to say that today, I produce and record my own music, blending elements of rap and hip-hop, R&B, dancehall, and pop into a sound that is uniquely my own.\n\nMy music reflects my experiences, my emotions, and my journey. It is a testament to my resilience and my determination. But it is more than just entertainment, it is a source of comfort and inspiration for those who need it most. I use my songs to help others through difficult times, to bring light into the darkness, and to bring people together. I have an empathy that is rare in this world, a genuine desire to make a positive impact on those around me. I want my music to make a difference, to touch people's hearts, and to help heal the world.\n\nMy brand is defined by my authenticity, my empathy, my passion, my creativity, my resilience, and my humility. I am more than just an artist, I am a source of inspiration, a voice for the voiceless, and a shining light in a dark world. I hope to become known worldwide, remain independent and profitable, and eventually become close friends with my idols. But most of all, I want to be known for always releasing high-quality music that speaks to the hearts of my listeners.\n\nI believe that music has the power to change lives, to bring people together, and to make the world a better place. And I am proud to be a part of that tradition, to be a part of that legacy. I will continue to pour my heart and soul into each song I write, each beat I produce, because I know that music is more than just entertainment, it is a way of life. And I am honoured to share my life's work with the World.\n\n## Synopsis\nAs you can see, the above is aimed to build a book of myself in which I can create and operate a storyline that draws in listeners while making the creative aspect of my work easier and more enjoyable. Please help me to generate:\n\n1) More sections such as '# Introduction' and sub-sections like '## Who is Kadence?'. Please only provide the headings, I don't need the descriptions yet. Please provide 20.\n\nand \n\n2) As you can see, I used your last generated message about my brand identity statement to fill the '## Who is Kadence?' section. Can you give me ideas on how to continue structuring the overall book so that it has more chapters and I will be able to implement the 'Hero's Journey' method into the writing of it, while maintaining physically attainable actions that I am able to take in the real world to further enhance the realism of the book? Please provide me actionable sections and sub-sections that will help me to categorize and organize useful information such as what you have provided me so far, as well as information I will learn in the future from market research and the like.", "let me give you all the code so far so you can better solve the above error\n\nimport argparse\nimport csv\nimport math\nimport os\nfrom collections import defaultdict, Counter\nfrom typing import List\n\nimport dataclasses\nimport numpy as np\nfrom numpy.ma import exp\nfrom scipy.optimize import minimize\\_scalar\nfrom scipy.special import expit\n\nPARENT\\_DIR =os.path.dirname(os.path.realpath(\\_\\_file\\_\\_))\n\nHISTORICAL\\_SEED\\_WIN\\_RATES = {\n (1, 16): 1.000,\n (2, 15): 0.917,\n (3, 14): 0.833,\n (4, 13): 0.750,\n (5, 12): 0.667,\n (6, 11): 0.583,\n (7, 10): 0.583,\n (8, 9): 0.500,\n}\n@dataclasses.dataclass\nclass Team:\n team\\_name: str\n team\\_seed: int\n ken\\_pom\\_score: float\n\n @classmethod\n def extract\\_teams(cls, file\\_path: str):\n with open(os.path.join(PARENT\\_DIR, file\\_path), \"r\", newline=\"\") as csvfile:\n return [cls(\n team\\_name=row[\"team\"],\n team\\_seed=int(row[\"seed\"]),\n ken\\_pom\\_score=float(row[\"score\"])\n ) for row in (csv.DictReader(csvfile))]\nclass Tournament:\n def \\_\\_init\\_\\_(self, team\\_metrics: List[Team]):\n self.team\\_metrics: List[Team] = team\\_metrics\n self.teams = [team\\_metric.team\\_name for team\\_metric in team\\_metrics]\n # self.k = Tournament.find\\_best\\_k()\n self.k = 1\n self.adj\\_matrix = self.calculate\\_adj\\_matrix()\n self.round\\_win\\_counts = defaultdict(Counter)\n self.round\\_winners = defaultdict(list)\n self.previous\\_round\\_winners = []\n\n def get\\_opponent(self, round\\_num, team):\n if round\\_num == 0:\n team\\_index = self.teams.index(team)\n return self.teams[team\\_index + 1 if team\\_index % 2 == 0 else team\\_index - 1]\n else:\n previous\\_round\\_winners = self.round\\_winners[round\\_num - 1]\n team\\_index = previous\\_round\\_winners.index(team)\n return previous\\_round\\_winners[team\\_index + 1 if team\\_index % 2 == 0 else team\\_index - 1]\n\n def calculate\\_adj\\_matrix(self):\n num\\_teams = len(self.team\\_metrics)\n adj\\_matrix = np.zeros((num\\_teams, num\\_teams))\n\n for i, team\\_i in enumerate(self.team\\_metrics):\n for j, team\\_j in enumerate(self.team\\_metrics):\n if i != j:\n p\\_win = self.calculate\\_win\\_probability(team\\_i, team\\_j)\n adj\\_matrix[i, j] = p\\_win\n adj\\_matrix[j, i] = 1 - p\\_win\n\n return adj\\_matrix\n\n def calculate\\_win\\_probability(self, team\\_i: Team, team\\_j: Team):\n seed\\_diff = team\\_j.team\\_seed - team\\_i.team\\_seed\n ken\\_pom\\_diff = team\\_i.ken\\_pom\\_score - team\\_j.ken\\_pom\\_score\n return expit(self.k \\* (ken\\_pom\\_diff + seed\\_diff))\n\n def play\\_rounds(self):\n remaining\\_teams = list(range(len(self.teams)))\n round\\_num = 0\n\n while len(remaining\\_teams) > 1:\n winners = []\n for i in range(0, len(remaining\\_teams), 2):\n team\\_i = remaining\\_teams[i]\n team\\_j = remaining\\_teams[i + 1]\n p\\_win\\_i = self.adj\\_matrix[team\\_i, team\\_j]\n win\\_i = np.random.rand() < p\\_win\\_i\n winning\\_team\\_index = i if win\\_i else i + 1\n winners.append(winning\\_team\\_index)\n\n winning\\_team\\_name = self.teams[winning\\_team\\_index]\n self.round\\_win\\_counts[round\\_num][winning\\_team\\_name] += 1\n\n self.round\\_winners[round\\_num] = [self.teams[i] for i in winners] # Update round\\_winners dictionary\n remaining\\_teams = winners\n round\\_num += 1\n\n def play\\_single\\_round(self, remaining\\_teams):\n winners = []\n for i in range(0, len(remaining\\_teams), 2):\n team\\_i = remaining\\_teams[i]\n team\\_j = remaining\\_teams[i + 1]\n p\\_win\\_i = self.adj\\_matrix[team\\_i, team\\_j]\n win\\_i = np.random.rand() < p\\_win\\_i\n winning\\_team\\_index = team\\_i if win\\_i else team\\_j\n winners.append(winning\\_team\\_index)\n\n return winners\n\n def get\\_remaining\\_teams(self, round\\_num):\n if round\\_num == 0:\n return list(range(len(self.teams)))\n\n remaining\\_teams = []\n for i, team in enumerate(self.teams):\n if self.round\\_winners[round\\_num - 1].count(team) > 0:\n remaining\\_teams.append(i)\n\n return remaining\\_teams\n\n def simulate\\_round\\_n(self, round\\_num, num\\_simulations):\n round\\_win\\_counts = Counter()\n\n for \\_ in range(num\\_simulations):\n remaining\\_teams = self.get\\_remaining\\_teams(round\\_num)\n winners = self.play\\_single\\_round(remaining\\_teams)\n for winner in winners:\n round\\_win\\_counts[self.teams[winner]] += 1\n\n # Update the round\\_winners and round\\_win\\_counts\n sorted\\_teams = sorted(round\\_win\\_counts.items(), key=lambda x: x[1], reverse=True)\n self.round\\_winners[round\\_num] = [team for i, (team, count) in enumerate(sorted\\_teams) if i % 2 == 0]\n self.round\\_win\\_counts[round\\_num] = round\\_win\\_counts\n\n return round\\_win\\_counts\n\n def run\\_all\\_rounds(self, num\\_simulations):\n num\\_teams = len(self.teams)\n num\\_rounds = int(math.log2(num\\_teams))\n\n for round\\_num in range(num\\_rounds): # There are 6 rounds in a 64-team tournament\n round\\_win\\_counts = self.simulate\\_round\\_n(round\\_num, num\\_simulations)\n print(f\"Round {round\\_num + 1} results:\")\n for i, (team, count) in enumerate(\n round\\_win\\_counts.most\\_common(len(self.get\\_remaining\\_teams(round\\_num)) // 2)):\n opponent = self.get\\_opponent(round\\_num, team)\n win\\_percentage = (count / num\\_simulations) \\* 100\n print(f\" {i + 1}. {team} over {opponent} with {win\\_percentage:.2f}%\")\n print()\n\n def get\\_team\\_index\\_by\\_name(self, team\\_name):\n try:\n return self.teams.index(team\\_name)\n except ValueError:\n raise Exception(f\"Team '{team\\_name}' not found in the teams list.\")\n\n def calculate\\_round\\_win\\_averages(self, num\\_simulations):\n round\\_win\\_averages = [{} for \\_ in range(len(self.round\\_win\\_counts))]\n for i, round\\_win\\_count in enumerate(self.round\\_win\\_counts):\n for team, count in round\\_win\\_count.items():\n round\\_win\\_averages[i][team] = count / num\\_simulations\n return round\\_win\\_averages\n\n @staticmethod\n def error\\_function(k, average\\_kenpom\\_difference):\n error = 0\n for matchup, historical\\_probability in HISTORICAL\\_SEED\\_WIN\\_RATES.items():\n difference = average\\_kenpom\\_difference[matchup]\n probability = 1 / (1 + exp(-k \\* difference))\n error += (probability - historical\\_probability) \\*\\* 2\n return error\n\n @staticmethod\n def average\\_kenpom\\_difference(max\\_seed=16, kenpom\\_range=(0, 40)):\n min\\_kenpom, max\\_kenpom = kenpom\\_range\n kenpom\\_increment = (max\\_kenpom - min\\_kenpom) / max\\_seed\n average\\_difference = {}\n\n for higher\\_seed in range(1, max\\_seed + 1):\n for lower\\_seed in range(higher\\_seed + 1, max\\_seed + 1):\n higher\\_seed\\_kenpom = max\\_kenpom - (higher\\_seed - 1) \\* kenpom\\_increment\n lower\\_seed\\_kenpom = max\\_kenpom - (lower\\_seed - 1) \\* kenpom\\_increment\n average\\_difference[(higher\\_seed, lower\\_seed)] = higher\\_seed\\_kenpom - lower\\_seed\\_kenpom\n\n return average\\_difference\n\n @staticmethod\n def find\\_best\\_k():\n average\\_difference = Tournament.average\\_kenpom\\_difference()\n result = minimize\\_scalar(Tournament.error\\_function, args=(average\\_difference,))\n return result.x\nif \\_\\_name\\_\\_ == \"\\_\\_main\\_\\_\":\n parser = argparse.ArgumentParser(\n description=\"NCAA Tournament Simulation\"\n )\n parser.add\\_argument(\n '-f', '--file',\n default='2023ncaab.csv',\n help=\"Path to the data file (default: '2023ncaab.csv')\"\n )\n parser.add\\_argument(\n '-n', '--num-simulations',\n type=int,\n default=100000,\n help=\"Number of simulations to run (default: 100000)\"\n )\n args = parser.parse\\_args()\n teams = Team.extract\\_teams(args.file)\n tournament = Tournament(teams)\n tournament.run\\_all\\_rounds(args.num\\_simulations)", "here is the code now \n\nimport argparse\nimport csv\nimport math\nimport os\nfrom collections import Counter\nfrom typing import List\n\nimport dataclasses\nimport numpy as np\nfrom numpy.ma import exp\nfrom scipy.optimize import minimize\\_scalar\nfrom scipy.special import expit\n\nPARENT\\_DIR = os.path.dirname(os.path.realpath(\\_\\_file\\_\\_))\n\nHISTORICAL\\_SEED\\_WIN\\_RATES = {\n (1, 16): 1.000,\n (2, 15): 0.917,\n (3, 14): 0.833,\n (4, 13): 0.750,\n (5, 12): 0.667,\n (6, 11): 0.583,\n (7, 10): 0.583,\n (8, 9): 0.500,\n}\n@dataclasses.dataclass\nclass Team:\n team\\_name: str\n team\\_seed: int\n ken\\_pom\\_score: float\n\n @classmethod\n def extract\\_teams(cls, file\\_path: str):\n with open(os.path.join(PARENT\\_DIR, file\\_path), \"r\", newline=\"\") as csvfile:\n return [cls(\n team\\_name=row[\"team\"],\n team\\_seed=int(row[\"seed\"]),\n ken\\_pom\\_score=float(row[\"score\"])\n ) for row in (csv.DictReader(csvfile))]\nclass Tournament:\n\n def \\_\\_init\\_\\_(self, team\\_metrics: List[Team]):\n self.team\\_metrics: List[Team] = team\\_metrics\n self.team\\_names = [team.team\\_name for team in team\\_metrics]\n self.teams = {i: team.team\\_name for i, team in enumerate(team\\_metrics)}\n self.k = self.find\\_best\\_k()\n self.adj\\_matrix = self.calculate\\_adj\\_matrix()\n\n num\\_teams = len(self.teams)\n self.num\\_rounds = int(math.log2(num\\_teams))\n\n self.round\\_winners = {0: list(self.teams.keys())}\n self.round\\_win\\_counts = {}\n # Construct the bracket\n num\\_matches = num\\_teams // 2\n self.bracket = {}\n for round\\_num in range(1, self.num\\_rounds + 1):\n self.bracket[round\\_num] = list(range(num\\_matches))\n num\\_matches //= 2\n\n # Used for printing results\n self.round\\_names = {\n 1: \"Round of 64\",\n 2: \"Round of 32\",\n 3: \"Sweet Sixteen\",\n 4: \"Elite Eight\",\n 5: \"Final Four\",\n 6: \"Championship\",\n }\n self.round\\_spacing = {\n 1: 2,\n 2: 4,\n 3: 8,\n 4: 16,\n 5: 32,\n 6: 64,\n }\n\n def get\\_opponent(self, round\\_num, team):\n if round\\_num == 0:\n team\\_index = {v: k for k, v in self.teams.items()}[team]\n return self.teams[team\\_index + 1 if team\\_index % 2 == 0 else team\\_index - 1]\n else:\n previous\\_round\\_winners = self.round\\_winners[round\\_num - 1]\n team\\_index = previous\\_round\\_winners.index(team)\n return previous\\_round\\_winners[team\\_index + 1 if team\\_index % 2 == 0 else team\\_index - 1]\n\n def calculate\\_adj\\_matrix(self):\n num\\_teams = len(self.team\\_metrics)\n adj\\_matrix = np.zeros((num\\_teams, num\\_teams))\n\n for i, team\\_i in enumerate(self.team\\_metrics):\n for j, team\\_j in enumerate(self.team\\_metrics):\n if i != j:\n p\\_win = self.calculate\\_win\\_probability(team\\_i, team\\_j)\n adj\\_matrix[i, j] = p\\_win\n adj\\_matrix[j, i] = 1 - p\\_win\n\n return adj\\_matrix\n\n def calculate\\_win\\_probability(self, team\\_i: Team, team\\_j: Team):\n seed\\_diff = team\\_j.team\\_seed - team\\_i.team\\_seed\n ken\\_pom\\_diff = team\\_i.ken\\_pom\\_score - team\\_j.ken\\_pom\\_score\n return expit(self.k \\* (ken\\_pom\\_diff + seed\\_diff))\n\n def play\\_single\\_round(self, remaining\\_teams):\n winners = []\n for i in range(0, len(remaining\\_teams), 2):\n team\\_i = remaining\\_teams[i]\n team\\_j = remaining\\_teams[i + 1]\n\n p\\_win\\_i = self.adj\\_matrix[team\\_i, team\\_j]\n win\\_i = np.random.rand() < p\\_win\\_i\n winning\\_team\\_index = team\\_i if win\\_i else team\\_j\n winners.append(winning\\_team\\_index)\n\n return winners\n\n def get\\_remaining\\_teams(self, round\\_num):\n if round\\_num == 0:\n return list(range(len(self.teams)))\n\n remaining\\_teams = []\n for i, team in enumerate(self.teams):\n if self.round\\_winners[round\\_num - 1].count(team) > 0:\n remaining\\_teams.append(i)\n\n return remaining\\_teams\n\n def simulate\\_round\\_n(self, round\\_num, num\\_simulations):\n round\\_win\\_counts = Counter()\n\n for \\_ in range(num\\_simulations):\n remaining\\_teams = self.get\\_remaining\\_teams(round\\_num)\n winners = self.play\\_single\\_round(remaining\\_teams)\n for winner in winners:\n round\\_win\\_counts[self.teams[winner]] += 1\n\n # Update the round\\_winners and round\\_win\\_counts\n sorted\\_teams = sorted(round\\_win\\_counts.items(), key=lambda x: x[1], reverse=True)\n self.round\\_winners[round\\_num] = [team for i, (team, count) in enumerate(sorted\\_teams) if i % 2 == 0]\n self.round\\_win\\_counts[round\\_num] = round\\_win\\_counts\n\n return round\\_win\\_counts\n\n def run\\_all\\_rounds(self, num\\_simulations):\n for round\\_num in range(1, self.num\\_rounds + 1): # Iterate through all rounds in the tournament\n round\\_win\\_counts = self.simulate\\_round\\_n(round\\_num, num\\_simulations)\n print(f\"{self.round\\_names[round\\_num]} results:\")\n for i, (team, count) in enumerate(round\\_win\\_counts.most\\_common()):\n opponent = self.get\\_opponent(round\\_num, team)\n win\\_percentage = (count / num\\_simulations) \\* 100\n print(f\" {i + 1}. {team} over {opponent} with {win\\_percentage:.2f}%\")\n print()\n\n @staticmethod\n def error\\_function(k, average\\_kenpom\\_difference):\n error = 0\n for matchup, historical\\_probability in HISTORICAL\\_SEED\\_WIN\\_RATES.items():\n difference = average\\_kenpom\\_difference[matchup]\n probability = 1 / (1 + exp(-k \\* difference))\n error += (probability - historical\\_probability) \\*\\* 2\n return error\n\n @staticmethod\n def average\\_kenpom\\_difference(max\\_seed=16, kenpom\\_range=(0, 40)):\n min\\_kenpom, max\\_kenpom = kenpom\\_range\n kenpom\\_increment = (max\\_kenpom - min\\_kenpom) / max\\_seed\n average\\_difference = {}\n\n for higher\\_seed in range(1, max\\_seed + 1):\n for lower\\_seed in range(higher\\_seed + 1, max\\_seed + 1):\n higher\\_seed\\_kenpom = max\\_kenpom - (higher\\_seed - 1) \\* kenpom\\_increment\n lower\\_seed\\_kenpom = max\\_kenpom - (lower\\_seed - 1) \\* kenpom\\_increment\n average\\_difference[(higher\\_seed, lower\\_seed)] = higher\\_seed\\_kenpom - lower\\_seed\\_kenpom\n\n return average\\_difference\n\n @staticmethod\n def find\\_best\\_k():\n average\\_difference = Tournament.average\\_kenpom\\_difference()\n result = minimize\\_scalar(Tournament.error\\_function, args=(average\\_difference,))\n return result.x\nif \\_\\_name\\_\\_ == \"\\_\\_main\\_\\_\":\n parser = argparse.ArgumentParser(\n description=\"NCAA Tournament Simulation\"\n )\n parser.add\\_argument(\n '-f', '--file',\n default='2023ncaab.csv',\n help=\"Path to the data file (default: '2023ncaab.csv')\"\n )\n parser.add\\_argument(\n '-n', '--num-simulations',\n type=int,\n default=100000,\n help=\"Number of simulations to run (default: 100000)\"\n )\n args = parser.parse\\_args()\n teams = Team.extract\\_teams(args.file)\n tournament = Tournament(teams)\n tournament.run\\_all\\_rounds(args.num\\_simulations)\nand the error\n\nTraceback (most recent call last):\n File \"/home/blake/workspace/gpt-madness/tournament.py\", line 242, in \n tournament.run\\_all\\_rounds(args.num\\_simulations)\n File \"/home/blake/workspace/gpt-madness/tournament.py\", line 176, in run\\_all\\_rounds\n opponent = self.get\\_opponent(round\\_num, team)\n File \"/home/blake/workspace/gpt-madness/tournament.py\", line 89, in get\\_opponent\n team\\_index = previous\\_round\\_winners.index(team)\nValueError: 'purd' is not in list\n\nwhich seems like there is an issue with the bracket structure or previous winners. lets debug it", "here is the code\n\nimport argparse\nimport csv\nimport math\nimport os\nfrom collections import Counter\nfrom typing import List\n\nimport dataclasses\nimport numpy as np\nfrom numpy.ma import exp\nfrom scipy.optimize import minimize\\_scalar\nfrom scipy.special import expit\n\nPARENT\\_DIR = os.path.dirname(os.path.realpath(\\_\\_file\\_\\_))\n\nHISTORICAL\\_SEED\\_WIN\\_RATES = {\n (1, 16): 1.000,\n (2, 15): 0.917,\n (3, 14): 0.833,\n (4, 13): 0.750,\n (5, 12): 0.667,\n (6, 11): 0.583,\n (7, 10): 0.583,\n (8, 9): 0.500,\n}\n@dataclasses.dataclass\nclass Team:\n team\\_name: str\n team\\_seed: int\n ken\\_pom\\_score: float\n\n @classmethod\n def extract\\_teams(cls, file\\_path: str):\n with open(os.path.join(PARENT\\_DIR, file\\_path), \"r\", newline=\"\") as csvfile:\n return [cls(\n team\\_name=row[\"team\"],\n team\\_seed=int(row[\"seed\"]),\n ken\\_pom\\_score=float(row[\"score\"])\n ) for row in (csv.DictReader(csvfile))]\nclass Tournament:\n\n def \\_\\_init\\_\\_(self, team\\_metrics: List[Team]):\n self.team\\_metrics: List[Team] = team\\_metrics\n self.team\\_names = [team.team\\_name for team in team\\_metrics]\n self.teams = {i: team.team\\_name for i, team in enumerate(team\\_metrics)}\n self.k = self.find\\_best\\_k()\n self.adj\\_matrix = self.calculate\\_adj\\_matrix()\n\n num\\_teams = len(self.teams)\n self.num\\_rounds = int(math.log2(num\\_teams))\n\n self.round\\_winners = {0: list(self.teams.keys())}\n self.round\\_win\\_counts = {}\n # Construct the bracket\n num\\_matches = num\\_teams // 2\n self.bracket = {}\n for round\\_num in range(1, self.num\\_rounds + 1):\n self.bracket[round\\_num] = list(range(num\\_matches))\n num\\_matches //= 2\n\n # Used for printing results\n self.round\\_names = {\n 1: \"Round of 64\",\n 2: \"Round of 32\",\n 3: \"Sweet Sixteen\",\n 4: \"Elite Eight\",\n 5: \"Final Four\",\n 6: \"Championship\",\n }\n self.round\\_spacing = {\n 1: 2,\n 2: 4,\n 3: 8,\n 4: 16,\n 5: 32,\n 6: 64,\n }\n\n def get\\_opponent(self, round\\_num, team\\_index):\n if round\\_num == 0:\n opponent\\_index = team\\_index + 1 if team\\_index % 2 == 0 else team\\_index - 1\n else:\n previous\\_round\\_winners = self.round\\_winners[round\\_num - 1]\n print(f\"Previous round winners: {previous\\_round\\_winners}\") # Debugging print\n team\\_position = previous\\_round\\_winners.index(team\\_index)\n opponent\\_index = previous\\_round\\_winners[team\\_position + 1 if team\\_position % 2 == 0 else team\\_position - 1]\n\n print(f\"Team index: {team\\_index}, Opponent index: {opponent\\_index}\") # Debugging print\n return opponent\\_index\n\n def calculate\\_adj\\_matrix(self):\n num\\_teams = len(self.team\\_metrics)\n adj\\_matrix = np.zeros((num\\_teams, num\\_teams))\n\n for i, team\\_i in enumerate(self.team\\_metrics):\n for j, team\\_j in enumerate(self.team\\_metrics):\n if i != j:\n p\\_win = self.calculate\\_win\\_probability(team\\_i, team\\_j)\n adj\\_matrix[i, j] = p\\_win\n adj\\_matrix[j, i] = 1 - p\\_win\n\n return adj\\_matrix\n\n def calculate\\_win\\_probability(self, team\\_i: Team, team\\_j: Team):\n seed\\_diff = team\\_j.team\\_seed - team\\_i.team\\_seed\n ken\\_pom\\_diff = team\\_i.ken\\_pom\\_score - team\\_j.ken\\_pom\\_score\n return expit(self.k \\* (ken\\_pom\\_diff + seed\\_diff))\n\n def play\\_single\\_round(self, remaining\\_teams):\n winners = []\n for i in range(0, len(remaining\\_teams), 2):\n team\\_i = remaining\\_teams[i]\n team\\_j = remaining\\_teams[i + 1]\n\n p\\_win\\_i = self.adj\\_matrix[team\\_i, team\\_j]\n win\\_i = np.random.rand() < p\\_win\\_i\n winning\\_team\\_index = team\\_i if win\\_i else team\\_j\n winners.append(winning\\_team\\_index)\n\n return winners\n\n def get\\_remaining\\_teams(self, round\\_num):\n if round\\_num == 0:\n return list(range(len(self.teams)))\n\n remaining\\_teams = []\n for i, team in enumerate(self.teams):\n if self.round\\_winners[round\\_num - 1].count(team) > 0:\n remaining\\_teams.append(i)\n\n return remaining\\_teams\n\n def simulate\\_round\\_n(self, round\\_num, num\\_simulations):\n round\\_win\\_counts = Counter()\n\n for \\_ in range(num\\_simulations):\n remaining\\_teams = self.get\\_remaining\\_teams(round\\_num)\n winners = self.play\\_single\\_round(remaining\\_teams)\n for winner in winners:\n round\\_win\\_counts[self.teams[winner]] += 1\n\n # Update the round\\_winners and round\\_win\\_counts\n sorted\\_teams = sorted(round\\_win\\_counts.items(), key=lambda x: x[1], reverse=True)\n self.round\\_winners[round\\_num] = [team for i, (team, count) in enumerate(sorted\\_teams) if i % 2 == 0]\n self.round\\_win\\_counts[round\\_num] = round\\_win\\_counts\n\n return round\\_win\\_counts\n\n def run\\_all\\_rounds(self, num\\_simulations):\n for round\\_num in range(1, self.num\\_rounds + 1): # Iterate through all rounds in the tournament\n round\\_win\\_counts = self.simulate\\_round\\_n(round\\_num, num\\_simulations)\n print(f\"{self.round\\_names[round\\_num]} results:\")\n for i, (team\\_index, count) in enumerate(round\\_win\\_counts.most\\_common()):\n print(f\"Team index: {team\\_index}\") # Debugging print\n team = self.teams[team\\_index]\n opponent\\_index = self.get\\_opponent(round\\_num, team\\_index)\n opponent = self.teams[opponent\\_index]\n win\\_percentage = (count / num\\_simulations) \\* 100\n print(f\" {i + 1}. {team} over {opponent} with {win\\_percentage:.2f}%\")\n print()\n\n @staticmethod\n def error\\_function(k, average\\_kenpom\\_difference):\n error = 0\n for matchup, historical\\_probability in HISTORICAL\\_SEED\\_WIN\\_RATES.items():\n difference = average\\_kenpom\\_difference[matchup]\n probability = 1 / (1 + exp(-k \\* difference))\n error += (probability - historical\\_probability) \\*\\* 2\n return error\n\n @staticmethod\n def average\\_kenpom\\_difference(max\\_seed=16, kenpom\\_range=(0, 40)):\n min\\_kenpom, max\\_kenpom = kenpom\\_range\n kenpom\\_increment = (max\\_kenpom - min\\_kenpom) / max\\_seed\n average\\_difference = {}\n\n for higher\\_seed in range(1, max\\_seed + 1):\n for lower\\_seed in range(higher\\_seed + 1, max\\_seed + 1):\n higher\\_seed\\_kenpom = max\\_kenpom - (higher\\_seed - 1) \\* kenpom\\_increment\n lower\\_seed\\_kenpom = max\\_kenpom - (lower\\_seed - 1) \\* kenpom\\_increment\n average\\_difference[(higher\\_seed, lower\\_seed)] = higher\\_seed\\_kenpom - lower\\_seed\\_kenpom\n\n return average\\_difference\n\n @staticmethod\n def find\\_best\\_k():\n average\\_difference = Tournament.average\\_kenpom\\_difference()\n result = minimize\\_scalar(Tournament.error\\_function, args=(average\\_difference,))\n return result.x\nif \\_\\_name\\_\\_ == \"\\_\\_main\\_\\_\":\n parser = argparse.ArgumentParser(\n description=\"NCAA Tournament Simulation\"\n )\n parser.add\\_argument(\n '-f', '--file',\n default='2023ncaab.csv',\n help=\"Path to the data file (default: '2023ncaab.csv')\"\n )\n parser.add\\_argument(\n '-n', '--num-simulations',\n type=int,\n default=100000,\n help=\"Number of simulations to run (default: 100000)\"\n )\n args = parser.parse\\_args()\n teams = Team.extract\\_teams(args.file)\n tournament = Tournament(teams)\n tournament.run\\_all\\_rounds(args.num\\_simulations)\nand the error\n\nTeam index: purd\nTraceback (most recent call last):\n File \"/home/blake/workspace/gpt-madness/tournament.py\", line 214, in \n tournament.run\\_all\\_rounds(args.num\\_simulations)\n File \"/home/blake/workspace/gpt-madness/tournament.py\", line 159, in run\\_all\\_rounds\n team = self.teams[team\\_index]\nKeyError: 'purd'", "okay no more errors but it is hard to see the results. lets use that bracket and spacing we have in the constructor and refactor this code to print nicely. here is all of the code so far\n\nimport argparse\nimport csv\nimport math\nimport os\nfrom collections import Counter\nfrom typing import List\n\nimport dataclasses\nimport numpy as np\nfrom numpy.ma import exp\nfrom scipy.optimize import minimize\\_scalar\nfrom scipy.special import expit\n\nPARENT\\_DIR = os.path.dirname(os.path.realpath(\\_\\_file\\_\\_))\n\nHISTORICAL\\_SEED\\_WIN\\_RATES = {\n (1, 16): 1.000,\n (2, 15): 0.917,\n (3, 14): 0.833,\n (4, 13): 0.750,\n (5, 12): 0.667,\n (6, 11): 0.583,\n (7, 10): 0.583,\n (8, 9): 0.500,\n}\n@dataclasses.dataclass\nclass Team:\n team\\_name: str\n team\\_seed: int\n ken\\_pom\\_score: float\n\n @classmethod\n def extract\\_teams(cls, file\\_path: str):\n with open(os.path.join(PARENT\\_DIR, file\\_path), \"r\", newline=\"\") as csvfile:\n return [cls(\n team\\_name=row[\"team\"],\n team\\_seed=int(row[\"seed\"]),\n ken\\_pom\\_score=float(row[\"score\"])\n ) for row in (csv.DictReader(csvfile))]\nclass Tournament:\n\n def \\_\\_init\\_\\_(self, team\\_metrics: List[Team]):\n self.team\\_metrics: List[Team] = team\\_metrics\n self.team\\_names = [team.team\\_name for team in team\\_metrics]\n self.teams = {i: team.team\\_name for i, team in enumerate(team\\_metrics)}\n self.k = self.find\\_best\\_k()\n self.adj\\_matrix = self.calculate\\_adj\\_matrix()\n\n num\\_teams = len(self.teams)\n self.num\\_rounds = int(math.log2(num\\_teams))\n\n self.round\\_winners = {0: list(self.teams.keys())}\n self.round\\_win\\_counts = {}\n # Construct the bracket\n num\\_matches = num\\_teams // 2\n self.bracket = {}\n for round\\_num in range(1, self.num\\_rounds + 1):\n self.bracket[round\\_num] = list(range(num\\_matches))\n num\\_matches //= 2\n\n # Used for printing results\n self.round\\_names = {\n 1: \"Round of 64\",\n 2: \"Round of 32\",\n 3: \"Sweet Sixteen\",\n 4: \"Elite Eight\",\n 5: \"Final Four\",\n 6: \"Championship\",\n }\n self.round\\_spacing = {\n 1: 2,\n 2: 4,\n 3: 8,\n 4: 16,\n 5: 32,\n 6: 64,\n }\n\n def get\\_opponent(self, round\\_num, team\\_index):\n if round\\_num == 0:\n opponent\\_index = team\\_index + 1 if team\\_index % 2 == 0 else team\\_index - 1\n else:\n previous\\_round\\_winners = self.round\\_winners[round\\_num - 1]\n print(f\"Previous round winners: {previous\\_round\\_winners}\") # Debugging print\n team\\_position = previous\\_round\\_winners.index(team\\_index)\n opponent\\_index = previous\\_round\\_winners[team\\_position + 1 if team\\_position % 2 == 0 else team\\_position - 1]\n\n print(f\"Team index: {team\\_index}, Opponent index: {opponent\\_index}\") # Debugging print\n return opponent\\_index\n\n def calculate\\_adj\\_matrix(self):\n num\\_teams = len(self.team\\_metrics)\n adj\\_matrix = np.zeros((num\\_teams, num\\_teams))\n\n for i, team\\_i in enumerate(self.team\\_metrics):\n for j, team\\_j in enumerate(self.team\\_metrics):\n if i != j:\n p\\_win = self.calculate\\_win\\_probability(team\\_i, team\\_j)\n adj\\_matrix[i, j] = p\\_win\n adj\\_matrix[j, i] = 1 - p\\_win\n\n return adj\\_matrix\n\n def calculate\\_win\\_probability(self, team\\_i: Team, team\\_j: Team):\n seed\\_diff = team\\_j.team\\_seed - team\\_i.team\\_seed\n ken\\_pom\\_diff = team\\_i.ken\\_pom\\_score - team\\_j.ken\\_pom\\_score\n return expit(self.k \\* (ken\\_pom\\_diff + seed\\_diff))\n\n def play\\_single\\_round(self, remaining\\_teams):\n winners = []\n for i in range(0, len(remaining\\_teams), 2):\n team\\_i = remaining\\_teams[i]\n team\\_j = remaining\\_teams[i + 1]\n\n p\\_win\\_i = self.adj\\_matrix[team\\_i, team\\_j]\n win\\_i = np.random.rand() < p\\_win\\_i\n winning\\_team\\_index = team\\_i if win\\_i else team\\_j\n winners.append(winning\\_team\\_index)\n\n return winners\n\n def get\\_remaining\\_teams(self, round\\_num):\n if round\\_num == 0:\n return list(range(len(self.teams)))\n\n remaining\\_teams = []\n for i, team in enumerate(self.teams):\n if self.round\\_winners[round\\_num - 1].count(team) > 0:\n remaining\\_teams.append(i)\n\n return remaining\\_teams\n\n def simulate\\_round\\_n(self, round\\_num, num\\_simulations):\n round\\_win\\_counts = Counter()\n\n for \\_ in range(num\\_simulations):\n remaining\\_teams = self.get\\_remaining\\_teams(round\\_num)\n winners = self.play\\_single\\_round(remaining\\_teams)\n for winner in winners:\n round\\_win\\_counts[self.teams[winner]] += 1\n\n # Update the round\\_winners and round\\_win\\_counts\n sorted\\_teams = sorted(round\\_win\\_counts.items(), key=lambda x: x[1], reverse=True)\n self.round\\_winners[round\\_num] = [list(self.teams.keys())[list(self.teams.values()).index(team)] for team, \\_ in\n sorted\\_teams]\n self.round\\_win\\_counts[round\\_num] = round\\_win\\_counts\n\n return round\\_win\\_counts\n\n def run\\_all\\_rounds(self, num\\_simulations):\n for round\\_num in range(1, self.num\\_rounds + 1): # Iterate through all rounds in the tournament\n round\\_win\\_counts = self.simulate\\_round\\_n(round\\_num, num\\_simulations)\n print(f\"{self.round\\_names[round\\_num]} results:\")\n for i, (team\\_name, count) in enumerate(round\\_win\\_counts.most\\_common()):\n print(f\"Team name: {team\\_name}\") # Debugging print\n team\\_index = list(self.teams.values()).index(team\\_name)\n team = self.teams[team\\_index]\n opponent\\_index = self.get\\_opponent(round\\_num, team\\_index)\n opponent = self.teams[opponent\\_index]\n win\\_percentage = (count / num\\_simulations) \\* 100\n print(f\" {i + 1}. {team} over {opponent} with {win\\_percentage:.2f}%\")\n print()\n\n @staticmethod\n def error\\_function(k, average\\_kenpom\\_difference):\n error = 0\n for matchup, historical\\_probability in HISTORICAL\\_SEED\\_WIN\\_RATES.items():\n difference = average\\_kenpom\\_difference[matchup]\n probability = 1 / (1 + exp(-k \\* difference))\n error += (probability - historical\\_probability) \\*\\* 2\n return error\n\n @staticmethod\n def average\\_kenpom\\_difference(max\\_seed=16, kenpom\\_range=(0, 40)):\n min\\_kenpom, max\\_kenpom = kenpom\\_range\n kenpom\\_increment = (max\\_kenpom - min\\_kenpom) / max\\_seed\n average\\_difference = {}\n\n for higher\\_seed in range(1, max\\_seed + 1):\n for lower\\_seed in range(higher\\_seed + 1, max\\_seed + 1):\n higher\\_seed\\_kenpom = max\\_kenpom - (higher\\_seed - 1) \\* kenpom\\_increment\n lower\\_seed\\_kenpom = max\\_kenpom - (lower\\_seed - 1) \\* kenpom\\_increment\n average\\_difference[(higher\\_seed, lower\\_seed)] = higher\\_seed\\_kenpom - lower\\_seed\\_kenpom\n\n return average\\_difference\n\n @staticmethod\n def find\\_best\\_k():\n average\\_difference = Tournament.average\\_kenpom\\_difference()\n result = minimize\\_scalar(Tournament.error\\_function, args=(average\\_difference,))\n return result.x\nif \\_\\_name\\_\\_ == \"\\_\\_main\\_\\_\":\n parser = argparse.ArgumentParser(\n description=\"NCAA Tournament Simulation\"\n )\n parser.add\\_argument(\n '-f', '--file',\n default='2023ncaab.csv',\n help=\"Path to the data file (default: '2023ncaab.csv')\"\n )\n parser.add\\_argument(\n '-n', '--num-simulations',\n type=int,\n default=100000,\n help=\"Number of simulations to run (default: 100000)\"\n )\n args = parser.parse\\_args()\n teams = Team.extract\\_teams(args.file)\n tournament = Tournament(teams)\n tournament.run\\_all\\_rounds(args.num\\_simulations)", "import argparse\nimport csv\nimport math\nimport os\nfrom collections import Counter\nfrom typing import List\n\nimport dataclasses\nimport numpy as np\nfrom numpy.ma import exp\nfrom scipy.optimize import minimize\\_scalar\nfrom scipy.special import expit\n\nPARENT\\_DIR = os.path.dirname(os.path.realpath(\\_\\_file\\_\\_))\n\nHISTORICAL\\_SEED\\_WIN\\_RATES = {\n (1, 16): 1.000,\n (2, 15): 0.917,\n (3, 14): 0.833,\n (4, 13): 0.750,\n (5, 12): 0.667,\n (6, 11): 0.583,\n (7, 10): 0.583,\n (8, 9): 0.500,\n}\n@dataclasses.dataclass\nclass Team:\n team\\_name: str\n team\\_seed: int\n ken\\_pom\\_score: float\n\n @classmethod\n def extract\\_teams(cls, file\\_path: str):\n with open(os.path.join(PARENT\\_DIR, file\\_path), \"r\", newline=\"\") as csvfile:\n return [cls(\n team\\_name=row[\"team\"],\n team\\_seed=int(row[\"seed\"]),\n ken\\_pom\\_score=float(row[\"score\"])\n ) for row in (csv.DictReader(csvfile))]\nclass Tournament:\n\n def \\_\\_init\\_\\_(self, team\\_metrics: List[Team]):\n self.team\\_metrics: List[Team] = team\\_metrics\n self.team\\_names = [team.team\\_name for team in team\\_metrics]\n self.teams = {i: team.team\\_name for i, team in enumerate(team\\_metrics)}\n self.k = self.find\\_best\\_k()\n self.adj\\_matrix = self.calculate\\_adj\\_matrix()\n\n num\\_teams = len(self.teams)\n self.num\\_rounds = int(math.log2(num\\_teams))\n\n self.round\\_winners = {0: list(self.teams.keys())}\n self.round\\_win\\_counts = {}\n # Construct the bracket\n num\\_matches = num\\_teams // 2\n self.bracket = {}\n for round\\_num in range(1, self.num\\_rounds + 1):\n self.bracket[round\\_num] = list(range(num\\_matches))\n num\\_matches //= 2\n\n # Used for printing results\n self.round\\_names = {\n 1: \"Round of 64\",\n 2: \"Round of 32\",\n 3: \"Sweet Sixteen\",\n 4: \"Elite Eight\",\n 5: \"Final Four\",\n 6: \"Championship\",\n }\n self.round\\_spacing = {\n 1: 2,\n 2: 4,\n 3: 8,\n 4: 16,\n 5: 32,\n 6: 64,\n }\n\n def get\\_opponent(self, round\\_num, team\\_index):\n if round\\_num == 0:\n opponent\\_index = team\\_index + 1 if team\\_index % 2 == 0 else team\\_index - 1\n else:\n previous\\_round\\_winners = self.round\\_winners[round\\_num - 1]\n # print(f\"Previous round winners: {previous\\_round\\_winners}\") # Debugging print\n team\\_position = previous\\_round\\_winners.index(team\\_index)\n opponent\\_index = previous\\_round\\_winners[team\\_position + 1 if team\\_position % 2 == 0 else team\\_position - 1]\n\n # print(f\"Team index: {team\\_index}, Opponent index: {opponent\\_index}\") # Debugging print\n return opponent\\_index\n\n def calculate\\_adj\\_matrix(self):\n num\\_teams = len(self.team\\_metrics)\n adj\\_matrix = np.zeros((num\\_teams, num\\_teams))\n\n for i, team\\_i in enumerate(self.team\\_metrics):\n for j, team\\_j in enumerate(self.team\\_metrics):\n if i != j:\n p\\_win = self.calculate\\_win\\_probability(team\\_i, team\\_j)\n adj\\_matrix[i, j] = p\\_win\n adj\\_matrix[j, i] = 1 - p\\_win\n\n return adj\\_matrix\n\n def calculate\\_win\\_probability(self, team\\_i: Team, team\\_j: Team):\n seed\\_diff = team\\_j.team\\_seed - team\\_i.team\\_seed\n ken\\_pom\\_diff = team\\_i.ken\\_pom\\_score - team\\_j.ken\\_pom\\_score\n return expit(self.k \\* (ken\\_pom\\_diff + seed\\_diff))\n\n def play\\_single\\_round(self, remaining\\_teams):\n winners = []\n for i in range(0, len(remaining\\_teams), 2):\n team\\_i = remaining\\_teams[i]\n team\\_j = remaining\\_teams[i + 1]\n\n p\\_win\\_i = self.adj\\_matrix[team\\_i, team\\_j]\n win\\_i = np.random.rand() < p\\_win\\_i\n winning\\_team\\_index = team\\_i if win\\_i else team\\_j\n winners.append(winning\\_team\\_index)\n\n return winners\n\n def get\\_remaining\\_teams(self, round\\_num):\n if round\\_num == 0:\n return list(range(len(self.teams)))\n\n remaining\\_teams = []\n for i, team in enumerate(self.teams):\n if self.round\\_winners[round\\_num - 1].count(team) > 0:\n remaining\\_teams.append(i)\n\n return remaining\\_teams\n\n def simulate\\_round\\_n(self, round\\_num, num\\_simulations):\n round\\_win\\_counts = Counter()\n\n for \\_ in range(num\\_simulations):\n remaining\\_teams = self.get\\_remaining\\_teams(round\\_num)\n winners = self.play\\_single\\_round(remaining\\_teams)\n for winner in winners:\n round\\_win\\_counts[self.teams[winner]] += 1\n\n # Update the round\\_winners and round\\_win\\_counts\n sorted\\_teams = sorted(round\\_win\\_counts.items(), key=lambda x: x[1], reverse=True)\n self.round\\_winners[round\\_num] = [list(self.teams.keys())[list(self.teams.values()).index(team)] for team, \\_ in\n sorted\\_teams]\n self.round\\_win\\_counts[round\\_num] = round\\_win\\_counts\n\n return round\\_win\\_counts\n\n def print\\_round\\_results(self, round\\_num, round\\_win\\_counts, num\\_simulations):\n print(f\"{self.round\\_names[round\\_num]} results:\")\n for i, (team\\_name, count) in enumerate(round\\_win\\_counts.most\\_common()):\n team\\_index = list(self.teams.values()).index(team\\_name)\n team = self.teams[team\\_index]\n opponent\\_index = self.get\\_opponent(round\\_num, team\\_index)\n opponent = self.teams[opponent\\_index]\n win\\_percentage = (count / num\\_simulations) \\* 100\n\n spaces = self.round\\_spacing[round\\_num] - len(str(i + 1))\n print(f\" {i + 1}.{' ' \\* spaces}{team} over {opponent} with {win\\_percentage:.2f}%\")\n print()\n\n def run\\_all\\_rounds(self, num\\_simulations):\n for round\\_num in range(1, self.num\\_rounds + 1): # Iterate through all rounds in the tournament\n round\\_win\\_counts = self.simulate\\_round\\_n(round\\_num, num\\_simulations)\n self.print\\_round\\_results(round\\_num, round\\_win\\_counts, num\\_simulations)\n\n @staticmethod\n def error\\_function(k, average\\_kenpom\\_difference):\n error = 0\n for matchup, historical\\_probability in HISTORICAL\\_SEED\\_WIN\\_RATES.items():\n difference = average\\_kenpom\\_difference[matchup]\n probability = 1 / (1 + exp(-k \\* difference))\n error += (probability - historical\\_probability) \\*\\* 2\n return error\n\n @staticmethod\n def average\\_kenpom\\_difference(max\\_seed=16, kenpom\\_range=(0, 40)):\n min\\_kenpom, max\\_kenpom = kenpom\\_range\n kenpom\\_increment = (max\\_kenpom - min\\_kenpom) / max\\_seed\n average\\_difference = {}\n\n for higher\\_seed in range(1, max\\_seed + 1):\n for lower\\_seed in range(higher\\_seed + 1, max\\_seed + 1):\n higher\\_seed\\_kenpom = max\\_kenpom - (higher\\_seed - 1) \\* kenpom\\_increment\n lower\\_seed\\_kenpom = max\\_kenpom - (lower\\_seed - 1) \\* kenpom\\_increment\n average\\_difference[(higher\\_seed, lower\\_seed)] = higher\\_seed\\_kenpom - lower\\_seed\\_kenpom\n\n return average\\_difference\n\n @staticmethod\n def find\\_best\\_k():\n average\\_difference = Tournament.average\\_kenpom\\_difference()\n result = minimize\\_scalar(Tournament.error\\_function, args=(average\\_difference,))\n return result.x\nif \\_\\_name\\_\\_ == \"\\_\\_main\\_\\_\":\n parser = argparse.ArgumentParser(\n description=\"NCAA Tournament Simulation\"\n )\n parser.add\\_argument(\n '-f', '--file',\n default='2023ncaab.csv',\n help=\"Path to the data file (default: '2023ncaab.csv')\"\n )\n parser.add\\_argument(\n '-n', '--num-simulations',\n type=int,\n default=100000,\n help=\"Number of simulations to run (default: 100000)\"\n )\n args = parser.parse\\_args()\n teams = Team.extract\\_teams(args.file)\n tournament = Tournament(teams)\n tournament.run\\_all\\_rounds(args.num\\_simulations)", "implement the last comment\n\nimport argparse\nimport math\nfrom collections import defaultdict\nfrom typing import List, Dict\n\nimport numpy as np\nfrom numpy.ma import exp\nfrom scipy.optimize import minimize\\_scalar\n\nfrom team import Team\n\nHISTORICAL\\_SEED\\_WIN\\_RATES = {\n 15: 1.000,\n 14: 0.9585,\n 13: 0.917,\n 12: 0.875,\n 11: 0.833,\n 10: 0.7915,\n 9: 0.750,\n 8: 0.7085,\n 7: 0.667,\n 6: 0.625,\n 5: 0.583,\n 4: 0.5615,\n 3: 0.54,\n 2: 0.52,\n 1: 0.500,\n 0: 0.500,\n}\nclass Tournament:\n\n def \\_\\_init\\_\\_(self, teams: List[Team], noise: float, temperature: float = None, verbose: bool = False):\n self.teams: List[Team] = teams\n self.temperature = temperature if temperature is not None else self.find\\_temperature\\_using\\_least\\_squares()\n self.adj\\_matrix = self.calculate\\_adj\\_matrix()\n self.noise = noise\n self.verbose = verbose\n\n @staticmethod\n def get\\_opponent\\_index(team\\_index):\n return team\\_index + 1 if team\\_index % 2 == 0 else team\\_index - 1\n\n def calculate\\_adj\\_matrix(self):\n num\\_teams = len(self.teams)\n adj\\_matrix = np.zeros((num\\_teams, num\\_teams))\n\n for i, team\\_i in enumerate(self.teams):\n for j, team\\_j in enumerate(self.teams):\n if i != j:\n p\\_win = self.calculate\\_win\\_probability(team\\_i, team\\_j)\n adj\\_matrix[i, j] = p\\_win\n adj\\_matrix[j, i] = 1 - p\\_win\n\n return adj\\_matrix\n\n def print\\_verbose(self, \\*args):\n if self.verbose:\n print(\\*args)\n\n def run(self):\n self.print\\_verbose(f\"\\nRound of {len(self.teams)}\")\n self.print\\_verbose(\"teams in round: \", [\n f\"{x.name} ({x.seed})\"\n for x in self.teams\n ])\n if len(self.teams) == 0:\n self.print\\_verbose(\"No teams in the tournament. Exiting.\")\n return None\n\n if len(self.teams) == 1:\n winner = self.teams[0]\n print(f\"Winner: {winner.name}\")\n return winner\n\n winners = self.play\\_round()\n updated\\_tournament = Tournament(winners, self.noise, self.temperature, self.verbose)\n return updated\\_tournament.run()\n\n @staticmethod\n def historical\\_upset\\_rate(seed1, seed2):\n return 1 - Tournament.get\\_midpoint\\_win\\_rate(seed1, seed2)\n\n @staticmethod\n def get\\_midpoint\\_win\\_rate(seed1, seed2):\n lower, higher = sorted((seed1, seed2))\n return HISTORICAL\\_SEED\\_WIN\\_RATES.get(higher - lower)\n\n def select\\_winner\\_simple(self, home: Team, away: Team):\n home\\_seed, away\\_seed = home.seed, away.seed\n historical\\_upset\\_rate = self.historical\\_upset\\_rate(home\\_seed, away\\_seed)\n home\\_is\\_better = home.would\\_upset(away)\n better\\_team = home if home\\_is\\_better else away\n worse\\_team = away if home\\_is\\_better else home\n\n statistical = self.calculate\\_win\\_probability(worse\\_team, better\\_team)\n\n # Noise is added by using historical upset rates rather than team specific KenPom scores\n probability = (1 - self.noise) \\* statistical + self.noise \\* historical\\_upset\\_rate\n\n # If a random number is less than the probability of an upset, return the underdog\n if np.random.rand() < probability:\n return worse\\_team\n # Otherwise, return the favorite\n else:\n return better\\_team\n\n def play\\_round(self):\n winners = []\n realized\\_upsets = 0\n\n for i in range(0, len(self.teams), 2):\n home = self.teams[i]\n away = self.teams[i + 1]\n winner = self.select\\_winner\\_simple(home, away)\n loser = home if winner == away else away\n is\\_upset = winner.would\\_upset(loser)\n realized\\_upsets += 1 if is\\_upset else 0\n winners += [winner]\n\n if is\\_upset:\n expected\\_edge = winner.is\\_better\\_kenpom(loser)\n self.print\\_verbose(f\"{winner.name}({winner.seed}) \"\n f\"over {loser.name}({loser.seed}) \"\n f\"{'' if expected\\_edge else 'UNEXPECTED'}\")\n\n self.print\\_verbose(f\"Upset rate for this round: {realized\\_upsets / len(winners):.2%}\")\n\n return winners\n\n def get\\_team\\_by\\_name(self, team\\_name: str):\n for team in self.teams:\n if team.name == team\\_name:\n return team\n return None\n\n def calculate\\_win\\_probability(self, team\\_i: Team, team\\_j: Team):\n ken\\_pom\\_diff = team\\_i.metric - team\\_j.metric\n probability = 1 / (1 + math.exp(-self.temperature \\* ken\\_pom\\_diff))\n return probability\n\n def average\\_kenpom\\_differences(self):\n # Initialize a dictionary to store the sum of KenPom differences and counts for each seed difference\n kenpom\\_diff\\_sum = defaultdict(float)\n kenpom\\_diff\\_count = defaultdict(int)\n\n # Loop through all possible matchups between teams\n for i, home in enumerate(self.teams):\n for away in self.teams[i + 1:]:\n seed\\_diff = abs(home.seed - away.seed)\n kenpom\\_diff = abs(home.metric - away.metric)\n\n # Update the sum of KenPom differences and counts for the seed difference\n kenpom\\_diff\\_sum[seed\\_diff] += kenpom\\_diff\n kenpom\\_diff\\_count[seed\\_diff] += 1\n\n # Calculate the average KenPom difference for each seed difference\n average\\_difference = {}\n for seed\\_diff in kenpom\\_diff\\_sum:\n average\\_difference[seed\\_diff] = kenpom\\_diff\\_sum[seed\\_diff] / kenpom\\_diff\\_count[seed\\_diff]\n\n return average\\_difference\n\n def find\\_temperature\\_using\\_least\\_squares(self):\n average\\_difference = self.average\\_kenpom\\_differences()\n result = minimize\\_scalar(Tournament.error\\_function, args=average\\_difference)\n return result.x\n\n @staticmethod\n def error\\_function(temperature, average\\_kenpom\\_differences):\n error = 0\n for seed\\_difference, historical\\_probability in HISTORICAL\\_SEED\\_WIN\\_RATES.items():\n # Get the historical probability based on the seed difference\n historical\\_probability = HISTORICAL\\_SEED\\_WIN\\_RATES[seed\\_difference]\n\n # Calculate the probability based on the KenPom difference and the given k\n difference = average\\_kenpom\\_differences[seed\\_difference]\n probability = 1 / (1 + exp(-temperature \\* difference))\n\n # Add the squared error between the calculated probability and historical probability\n error += (probability - historical\\_probability) \\*\\* 2\n\n return error\ndef run\\_multiple\\_tournaments(teams: List[Team], noise: float, num\\_iterations: int) -> Dict[str, int]:\n win\\_counts = defaultdict(int)\n for i in range(num\\_iterations):\n tournament = Tournament(teams, noise)\n winner = tournament.run()\n win\\_counts[winner.name] += 1\n\n return {\n team\\_name: win\\_count / num\\_iterations\n for team\\_name, win\\_count in win\\_counts.items()\n }\ndef calculate\\_power\\_scores(win\\_frequencies: Dict[str, float]) -> defaultdict:\n min\\_freq = min(win\\_frequencies.values())\n max\\_freq = max(win\\_frequencies.values())\n\n power\\_scores = defaultdict(lambda: 0.0)\n for team\\_name, freq in win\\_frequencies.items():\n power\\_scores[team\\_name] = (freq - min\\_freq) / (max\\_freq - min\\_freq)\n\n return power\\_scores\nif \\_\\_name\\_\\_ == \"\\_\\_main\\_\\_\":\n parser = argparse.ArgumentParser(\n description=\"NCAA Tournament Simulation\"\n )\n parser.add\\_argument(\n '-f', '--file',\n default='2023ncaab.csv',\n help=\"Path to the data file (default: '2023ncaab.csv')\"\n )\n parser.add\\_argument(\n '-z', '--noise',\n type=int,\n default=0.5\n )\n parser.add\\_argument(\n '-n', '--num\\_iterations',\n type=int,\n default=1000,\n help=\"Number of iterations for the frequency calculation (default: 1000)\"\n )\n args = parser.parse\\_args()\n teams\\_ = Team.extract\\_teams(args.file)\n\n # Calculate the win frequencies\n win\\_frequencies\\_ = run\\_multiple\\_tournaments(teams\\_, args.noise, args.num\\_iterations)\n\n # Calculate the power scores\n power\\_scores\\_ = calculate\\_power\\_scores(win\\_frequencies\\_)\n # print power scores sorted by value descending\n print(sorted(power\\_scores\\_.items(), key=lambda x: x[1], reverse=True))\n # Create the new teams array with power scores replacing the KenPom scores\n teams\\_ = [Team(team.name, team.seed, power\\_scores\\_[team.name]) for team in teams\\_]\n\n # Run one final simulation with the new power scores\n final\\_tournament = Tournament(teams\\_, args.noise, verbose=True)\n final\\_tournament.run()\n \n # while final tournament winner is not in the top 4 power scores, re-run, else return winner", "Please extract keywords from this: Lessons from the Osprey Garden\nMuch of biologist-naturalist Paul Spitzer\u2019s life has moved in time with the seasonal rhythms of one bird, the osprey, and one place\u2014the \u201cosprey garden.\u201d\n\nIn late spring he paddles his canoe into the Great Island saltmarsh, 500 acres of prime osprey habitat where the Connecticut River flows into Long Island Sound. In this marshy inlet, Spitzer checks for action in nests among 35 osprey platforms that have been erected here since the late 1950s. As he disembarks, the resident ospreys take to anxious flight. He raises a pole topped with a mirror over a platform nest. These days, he sees abundant breeding success in the mirror\u2019s reflection\u2014three healthy young birds with ragged crests and brown-spangled wings. But it wasn\u2019t always this way.\n\nSpitzer first stepped onto Great Island nearly 60 years ago, as an 11-year-old boy in 1957. That year, he accompanied birding legend Roger Tory Peterson on a Christmas Bird Count. Thus began a mentorship that set Spitzer onto a career path to becoming a ecologist.\n\nWhen Spitzer graduated from college, Peterson urged him to take up the question of what was causing a sudden and drastic decline among the ospreys.\n\n\u201cAt that time, the curtain was rising on the great DDT drama,\u201d says Spitzer.\n\nFrom the 1960s through the 1970s, Spitzer watched ospreys almost disappear from Connecticut, and he pioneered experiments that helped establish DDT as a cause of their decline. He has also seen ospreys make a triumphant recovery in the Connecticut River estuary. And with more than 300 active nests recorded in the state today, he is now turning his attention below the water, where the next challenge for osprey is a vanishing fish.\n\nThe Discovery of the Perils of DDT on Osprey Populations\nPeterson tracked the decline of local ospreys from 150 in the 1950s to just 13 in 1965. He and his wife Barbara tried to help the ospreys by building dozens of nest platforms to protect their nests from predators such as raccoons. But the birds still weren\u2019t bringing forth fledglings. Food didn\u2019t seem to be a problem\u2014there was no shortage of menhaden, the large-headed bait fish that is one of the osprey\u2019s primary food sources in Long Island Sound. Spitzer had spent hours watching the fish hawks rising from the water with menhaden nearly a foot long in their oversized talons.\n\n\u201cRoger began to suspect DDT,\u201d Spitzer says. In the 1940s and \u201850s, DDT was used to control mosquito populations in residential areas, especially along coasts and near wetlands. \u201cHe had a hunch the ospreys were ingesting the DDT from fish. Rachel Carson\u2019s findings were informing our discouraging field studies, and I was cutting my teeth as an ecologist studying this new paradigm of environmental toxicology.\u201d\n\nDuring nest checks, Spitzer found thin-shelled, collapsing eggs and was re-minded of a British study that showed similar thinning in peregrine falcon eggs.\n\nShortly after receiving his biology degree from Wesleyan University, Spitzer had the idea to isolate local ecological effects in Connecticut by switching eggs in osprey nests there with eggs from a healthy population of breeding osprey near Chesapeake Bay.\n\n\u201cNot nearly as much DDT was applied to Maryland saltmarshes, and it was probably diluted in the far larger Chesapeake system,\u201d says Spitzer. By performing the switch, he could isolate whether the problem was with local environmental conditions or intrinsic to the Connecticut eggs.\n\nThe Patuxent Wildlife Research Center in Maryland signed on to Spitzer\u2019s idea and provided staff to collect eggs. From the outset, Spitzer saw the Maryland eggs hatch healthy chicks in Connecticut, but not vice versa.\n\n\u201cThe embryos in Connecticut eggs died, and we found the shells to be thin by simple measurement,\u201d he says. \u201cWe also found dented or collapsed eggs in some Connecticut nests.\u201d None of these problems affected the Maryland eggs.\n\nNext, he arranged transfers of young nestlings from Maryland to Connecticut, to look beyond egg problems. The results were the same: \u201cVirtually all the Maryland nestlings fledged in Connecticut, [so there were] no problems with food at this time. The failure was egg viability,\u201d Spitzer says. Later lab tests revealed DDE (a breakdown product of DDT) as well as PCBs and another organochloride, dieldrin, at much higher concentrations in the Connecticut eggs compared to the Maryland eggs.\n\n\u201cAll signs pointed to Roger\u2019s hunch being right, that it was DDT,\u201d he says.\n\nDDT was banned in Connecticut in 1972, and two years later osprey numbers on Great Island bottomed out, with just a single nest remaining as the vestiges of DDT made their way out of the ecosystem.\n\nToday, there are approximately 100 active nests at Great Island and the overflow is helping populations at nearby Gardiners Island and eastern Long Island grow. Statewide, the Connecticut Audubon Society\u2019s osprey nation monitoring project recorded 337 active nests in 2016, and 490 fledged young throughout the state\u2014a rate nearly double that which Spitzer had calculated was necessary for a stable osprey population.\n\nNumbers like these, along with steady positive trends along Breeding Bird Survey routes, help explain why breeding ospreys are now abundant and widespread in Connecticut and throughout the eastern United States. Spitzer points to a combination of factors including an increase in artificial nest sites, a decrease in harmful residues in their food sources, and continued high levels of food availability, particularly Atlantic menhaden.\n\nOsprey and Menhaden\nFor the last three summers the Connecticut Audubon Society has sponsored Spitzer\u2019s ongoing work in the Connecticut River estuary, but the aim of the research has now shifted to monitoring the relationship between osprey and menhaden. As in the 1960s, Spitzer\u2019s attention is again focused on Great Island, now fittingly protected as a Roger Tory Peterson Wildlife Area. During June and July, Spitzer has documented that the ospreys\u2019 diet is 95 percent to 100 percent menhaden. Spitzer says the story is much the same from Connecticut to Virginia, with menhaden-fueled osprey nesting colonies experiencing a revival.\n\n\u201cOver 50 years of osprey study, we have moved from the sad story of DDT-induced egg failure and a declining population to the happy story of abundant ospreys,\u201d Spitzer says. \u201cOur ongoing legacy from osprey study must be the management of the East Coast ecosystem for abundant menhaden. We have to leave enough menhaden in the water to perform their precious and essential eco- nomic and ecological functions.\u201d\n\nRich in oils and fat, menhaden live in Atlantic coastal waters from Nova Scotia to northern Florida, but reach peak abundance in the Chesapeake Bay. In addition to serving as the primary food source for breeding ospreys and their chicks along the New England coast, menhaden are also a main food source for striped bass and bluefish. And, they constitute a significant fishery for people\u2014second only to pollock among the ranks of fish harvested by volume in the United States. But people don\u2019t eat menhaden for dinner. They process it into other forms, mostly pills.\n\nMost of the nearly 200,000-metric-ton annual menhaden catch is rendered into omega-3 fatty acid fish oil for the health supplement industry. And most of that catch comes via purse-seine fishing, in which two fishing boats circle around a single school of fish and enclose it within a gigantic net. These operations are extremely efficient at catching huge volumes of fish. Only one state (Virginia) currently allows purse-seine fishing of menhaden, but the fish caught in the Chesapeake Bay and Virginia waters account for 85 percent of the total menhaden harvest. \n\nBecause a large share of the range-wide menhaden population is clustered in the mid-Atlantic region, harvests there have a significant effect on the population as a whole. As the fish-oil market boomed in the 1990s and 2000s, menhaden populations began to dwindle. In 2010 stocks hit a 54-year low. In 2013 the Atlantic States Marine Fisheries Commission reduced the quota of commercial menhaden harvest by 20 percent. Spitzer attributes the recent robust East Coast osprey populations to the renewed health of the menhaden fishery following these new rules.\n\n\u201cIt was a huge win,\u201d says Spitzer.\n\nBut now, many ocean conservationists say menhaden are once again coming under intense fishing pressure. In 2015 and 2016, the quota was increased by about 10 percent, and the menhaden quota for 2017 has been increased by about 6 percent from 2016. Some industry representatives are suggesting that the menhaden quota could be raised by up to 30 percent without harming the overall fishery. Spitzer thinks the ASMFC should be more conservative in what it allows so that the menhaden population doesn\u2019t crash again, as it did earlier this decade. He also thinks the continued abundance of menhaden is critical to the continued abundance of ospreys. \n\n\u201cIt is a great blessing to have been able to study ospreys for 50 years and counting. I have observed so many positive outcomes for these birds over the years,\u201d Spitzer says. \u201cDecisions about menhaden now will affect not only fish, but birds, coastal ecosystems and, in the end, every one of us.\u201d", "Title: \"Graph Generator\" The following are types of graphs: +(Bar Graph Syntax)=[The following represents a bar graph in javascript displayed in image markdown format: ![pollinations](https://www.quickchart.io/chart?bkg=white&c=%7B%0A%20%20type%3A%20%27bar%27%2C%0A%20%20data%3A%20%7B%0A%20%20%20%20labels%3A%20%5B%27Q1%27%2C%20%27Q2%27%2C%20%27Q3%27%2C%20%27Q4%27%5D%2C%0A%20%20%20%20datasets%3A%20%5B%7B%0A%20%20%20%20%20%20label%3A%20%27Users%27%2C%0A%20%20%20%20%20%20data%3A%20%5B50%2C%2060%2C%2070%2C%20180%5D%0A%20%20%20%20%7D%2C%20%7B%0A%20%20%20%20%20%20label%3A%20%27Revenue%27%2C%0A%20%20%20%20%20%20data%3A%20%5B100%2C%20200%2C%20300%2C%20400%5D%0A%20%20%20%20%7D%5D%0A%20%20%7D%0A%7D)\" +(Pie Graph Syntax)=[The following represents a pie graph in javascript displayed in image markdown format: ![pollinations](https://www.quickchart.io/chart?c=%7B%0A%20%20%22type%22%3A%20%22outlabeledPie%22%2C%0A%20%20%22data%22%3A%20%7B%0A%20%20%20%20%22labels%22%3A%20%5B%22ONE%22%2C%20%22TWO%22%2C%20%22THREE%22%2C%20%22FOUR%22%2C%20%22FIVE%22%5D%2C%0A%20%20%20%20%22datasets%22%3A%20%5B%7B%0A%20%20%20%20%20%20%20%20%22backgroundColor%22%3A%20%5B%22%23FF3784%22%2C%20%22%2336A2EB%22%2C%20%22%234BC0C0%22%2C%20%22%23F77825%22%2C%20%22%239966FF%22%5D%2C%0A%20%20%20%20%20%20%20%20%22data%22%3A%20%5B1%2C%202%2C%203%2C%204%2C%205%5D%0A%20%20%20%20%7D%5D%0A%20%20%7D%2C%0A%20%20%22options%22%3A%20%7B%0A%20%20%20%20%22plugins%22%3A%20%7B%0A%20%20%20%20%20%20%22legend%22%3A%20false%2C%0A%20%20%20%20%20%20%22outlabels%22%3A%20%7B%0A%20%20%20%20%20%20%20%20%22text%22%3A%20%22%25l%20%25p%22%2C%0A%20%20%20%20%20%20%20%20%22color%22%3A%20%22white%22%2C%0A%20%20%20%20%20%20%20%20%22stretch%22%3A%2035%2C%0A%20%20%20%20%20%20%20%20%22font%22%3A%20%7B%0A%20%20%20%20%20%20%20%20%20%20%22resizable%22%3A%20true%2C%0A%20%20%20%20%20%20%20%20%20%20%22minSize%22%3A%2012%2C%0A%20%20%20%20%20%20%20%20%20%20%22maxSize%22%3A%2018%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%7D%0A%20%20%20%20%7D%0A%20%20%7D%0A%7D) +(Line Graph Syntax)=[The following represents a line graph in javascript displayed in image markdown format: ![pollinations](https://www.quickchart.io/chart?c=%7B%0A%20%20type%3A%20%27line%27%2C%0A%20%20data%3A%20%7B%0A%20%20%20%20labels%3A%20%5B%27January%27%2C%20%27February%27%2C%20%27March%27%2C%20%27April%27%2C%20%27May%27%2C%20%27June%27%2C%20%27July%27%5D%2C%0A%20%20%20%20datasets%3A%20%5B%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20label%3A%20%27My%20First%20dataset%27%2C%0A%20%20%20%20%20%20%20%20backgroundColor%3A%20%27rgb(255%2C%2099%2C%20132)%27%2C%0A%20%20%20%20%20%20%20%20borderColor%3A%20%27rgb(255%2C%2099%2C%20132)%27%2C%0A%20%20%20%20%20%20%20%20data%3A%20%5B93%2C%20-29%2C%20-17%2C%20-8%2C%2073%2C%2098%2C%2040%5D%2C%0A%20%20%20%20%20%20%20%20fill%3A%20false%2C%0A%20%20%20%20%20%20%7D%2C%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20label%3A%20%27My%20Second%20dataset%27%2C%0A%20%20%20%20%20%20%20%20fill%3A%20false%2C%0A%20%20%20%20%20%20%20%20backgroundColor%3A%20%27rgb(54%2C%20162%2C%20235)%27%2C%0A%20%20%20%20%20%20%20%20borderColor%3A%20%27rgb(54%2C%20162%2C%20235)%27%2C%0A%20%20%20%20%20%20%20%20data%3A%20%5B20%2C%2085%2C%20-79%2C%2093%2C%2027%2C%20-81%2C%20-22%5D%2C%0A%20%20%20%20%20%20%7D%2C%0A%20%20%20%20%5D%2C%0A%20%20%7D%2C%0A%20%20options%3A%20%7B%0A%20%20%20%20title%3A%20%7B%0A%20%20%20%20%20%20display%3A%20true%2C%0A%20%20%20%20%20%20text%3A%20%27Chart.js%20Line%20Chart%27%2C%0A%20%20%20%20%7D%2C%0A%20%20%7D%2C%0A%7D%0A) +(Your Job)=[To display any question the user asks as a graph] +(Rules)=[ALWAYS pick with Bar graph, Pie graph, or Line graph and turn what the user asks into the image markdown for one of these] ALWAYS DISPLAY WHAT THE USER ASKS AS A GRAPH. Respond \u201cReady\u201d to acknowledge and I will paste my first text for you to analyze. Answer in English.", "Ok, now, I am showing you the form looks like:\n\nr\nUSCIS\nUse\nOnly\nPetition for a Nonimmigrant Worker\nDepartment of Homeland Security\nU.S. Citizenship and Immigration Services\nUSCIS\nForm I-129\nOMB No. 1615-0009\nExpires 11/30/2025\nClassification Approved\nConsulate/POE/PFI Notified\nExtension Granted\nCOS/Extension Granted\nReceipt Partial Approval (explain) Action Block\nClass:\nNo. of Workers:\nJob Code:\nValidity Dates:\nFrom:\nTo:\nAt:\nLegal Name of Individual Petitioner\nIf you are an individual filing this petition, complete Item Number 1. If you are a company or an organization filing this petition,\ncomplete Item Number 2.\nFamily Name (Last Name) Given Name (First Name) Middle Name\n1.\n4. Contact Information\nPart 1. Petitioner Information\n\u25ba START HERE - Type or print in black ink.\n2. Company or Organization Name\n3. Mailing Address of Individual, Company or Organization\nCity or Town State ZIP Code\nIn Care Of Name\nStreet Number and Name Apt. Ste. Flr. Number\nDaytime Telephone Number\nU.S. Social Security Number (if any)\nEmail Address (if any)\nIndividual IRS Tax Number\nMobile Telephone Number\nFederal Employer Identification Number (FEIN)\n5. Other Information\n\u25ba \u25ba\nProvince Postal Code Country\n\u25ba\n(USPS ZIP Code Lookup)\n Page 1 of 36\nForm I-129 Edition 11/02/22\nPart 2. Information About This Petition (See instructions for fee information)\n1. Requested Nonimmigrant Classification (Write classification symbol):\n2. Basis for Classification (select only one box):\nNew employment.\nNew concurrent employment.\nChange of employer.\nAmended petition.\nChange in previously approved employment.\nContinuation of previously approved employment without change with the same employer.\n3. Provide the most recent petition/application receipt number for the\nbeneficiary. If none exists, indicate \"None.\"\nNotify the office in Part 4. so each beneficiary can obtain a visa or be admitted. (NOTE: A petition is not required for\nE-1, E-2, E-3, H-1B1 Chile/Singapore, or TN visa beneficiaries.)\nChange the status and extend the stay of each beneficiary because the beneficiary(ies) is/are now in the United States in\nanother status (see instructions for limitations). This is available only when you check \"New Employment\" in Item\nNumber 2., above.\nExtend the stay of each beneficiary because the beneficiary(ies) now hold(s) this status.\nAmend the stay of each beneficiary because the beneficiary(ies) now hold(s) this status.\n4. Requested Action (select only one box):\nExtend the status of a nonimmigrant classification based on a free trade agreement. (See Trade Agreement Supplement\nto Form I-129 for TN and H-1B1.)\nChange status to a nonimmigrant classification based on a free trade agreement. (See Trade Agreement Supplement to\nForm I-129 for TN and H-1B1.)\n5. Total number of workers included in this petition. (See instructions relating to\nwhen more than one worker can be included.)\nPart 3. Beneficiary Information (Information about the beneficiary/beneficiaries you are filing for. Complete the\nblocks below. Use the Attachment-1 sheet to name each beneficiary included in this petition.)\n1. If an Entertainment Group, Provide the Group Name\n2. Provide Name of Beneficiary\nFamily Name (Last Name) Given Name (First Name) Middle Name\nFamily Name (Last Name) Given Name (First Name) Middle Name\n3. Provide all other names the beneficiary has used. Include nicknames, aliases, maiden name, and names from all previous marriages.\n4. Other Information\nDate of birth (mm/dd/yyyy) Gender\nMale Female\nU.S. Social Security Number (if any)\n\u25ba\n\u25ba\n\u25ba\na.\nb.\nc.\nd.\ne.\nf.\na.\nb.\nc.\nd.\ne.\nf.\n Page 2 of 36\nForm I-129 Edition 11/02/22\nDate Passport or Travel Document\nExpires (mm/dd/yyyy)\nCountry of Citizenship or Nationality\n6. Current Residential U.S. Address (if applicable) (do not list a P.O. Box)\nEmployment Authorization Document (EAD)\nNumber (if any)\nStudent and Exchange Visitor Information System (SEVIS) Number (if\nany)\nCity or Town State ZIP Code\nStreet Number and Name Apt. Ste. Flr. Number\nCurrent Nonimmigrant Status Date Status Expires or D/S (mm/dd/yyyy)\nPassport or Travel Document Country of\nIssuance\nDate Passport or Travel Document\nIssued (mm/dd/yyyy)\n5. If the beneficiary is in the United States, complete the following:\nCountry of Birth\nI-94 Arrival-Departure Record Number\n\u25ba\nPart 3. Beneficiary Information (Information about the beneficiary/beneficiaries you are filing for. Complete the\nblocks below. Use the Attachment-1 sheet to name each beneficiary included in this petition.) (continued)\nDate of Last Arrival (mm/dd/yyyy) Passport or Travel Document Number\nPart 4. Processing Information\n1. If a beneficiary or beneficiaries named in Part 3. is/are outside the United States, or a requested extension of stay or change of\nstatus cannot be granted, state the U.S. Consulate or inspection facility you want notified if this petition is approved.\na. Type of Office (select only one box):\nb. Office Address (City) c. U.S. State or Foreign Country\nConsulate Pre-flight inspection Port of Entry\nd. Beneficiary's Foreign Address\nCity or Town\nStreet Number and Name Apt.Ste. Flr. Number\nAlien Registration Number (A-Number)\nAProvince of Birth\n\u25ba\n2. Does each person in this petition have a valid passport?\nState\nPostal Code Country\nYes No. If no, go to Part 9. and type or print your\nexplanation.\nProvince\n Page 3 of 36\nForm I-129 Edition 11/02/22\nPart 4. Processing Information (continued)\n5. Are you filing any applications for dependents with this petition?\nYes. If yes, proceed to Part 9. and list the beneficiary's(ies) name(s).\nYes. If yes, how many? \u25ba\nYes. If yes, answer the questions below. No. If no, proceed to Item Number 9.\n4. Are you filing any applications for replacement/initial I-94, Arrival-Departure Records with this petition? Note that if the\nbeneficiary was issued an electronic Form I-94 by CBP when he/she was admitted to the United States at an air or sea port, he/\nshe may be able to obtain the Form I-94 from the CBP Website at www.cbp.gov/i94 instead of filing an application for a\nreplacement/initial I-94.\n9. Have you ever previously filed a nonimmigrant petition for this beneficiary?\n7. Have you ever filed an immigrant petition for any beneficiary in this petition?\n6. Is any beneficiary in this petition in removal proceedings?\n8. Did you indicate you were filing a new petition in Part 2.?\na. Has any beneficiary in this petition ever been given the classification you are now requesting within the last seven years?\nb. Has any beneficiary in this petition ever been denied the classification you are now requesting within the last seven years?\n10. If you are filing for an entertainment group, has any beneficiary in this petition not been with the group for at least one year?\n11.b. If you checked yes in Item Number 11.a., provide the dates the beneficiary maintained status as a J-1 exchange visitor or J-2\ndependent. Also, provide evidence of this status by attaching a copy of either a DS-2019, Certificate of Eligibility for Exchange\nVisitor (J-1) Status, a Form IAP-66, or a copy of the passport that includes the J visa stamp.\n11.a. Has any beneficiary in this petition ever been a J-1 exchange visitor or J-2 dependent of a J-1 exchange visitor?\nPart 5. Basic Information About the Proposed Employment and Employer\n1. Job Title 2. LCA or ETA Case Number\n\u25ba\n\u25ba\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nYes. If yes, how many?\nYes. If yes, how many?\nYes. If yes, proceed to Part 9. and type or print your explanation.\nYes. If yes, proceed to Part 9. and type or print your explanation.\nYes. If yes, proceed to Part 9. and type or print your explanation.\nYes. If yes, proceed to Part 9. and type or print your explanation.\nYes. If yes, proceed to Item Number 11.b.\nAttach the Form I-129 supplement relevant to the classification of the worker(s) you are requesting.\n3. Are you filing any other petitions with this one?\nYes. If yes, how many? \u25ba No\n Page 4 of 36\nForm I-129 Edition 11/02/22\nPart 5. Basic Information About the Proposed Employment and Employer (continued)\n4. Did you include an itinerary with the petition?\n5. Will the beneficiary(ies) work for you off-site at another company or organization's location?\n12. Type of Business 13. Year Established\n14. Current Number of Employees in the United States 15. Gross Annual Income 16. Net Annual Income\n10. Other Compensation (Explain)\n11. Dates of intended employment From: To:\n7. Is this a full-time position?\n6. Will the beneficiary(ies) work exclusively in the Commonwealth of the Northern Mariana Islands (CNMI)?\n8. If the answer to Item Number 7. is no, how many hours per week for the position? \u25ba\n\u25ba\n(mm/dd/yyyy) (mm/dd/yyyy)\nNo\nYes\nNo\nYes No\nYes\nNo\nYes\n9. Wages: $ per (Specify hour, week, month, or year)\n3. Address where the beneficiary(ies) will work if different from address in Part 1.\nStreet Number and Name Apt. Ste. Flr. Number\nCity or Town State ZIP Code\n Page 5 of 36", "Section 1. Complete This Section If You Are Filing For An R-1 Religious Worker (continued)\n3. Provide a summary of the type of responsibilities of those employees who work at the same location where the beneficiary will\nbe employed. If additional space is needed, provide the information on additional sheet(s) of paper.\n Position Summary of the Type of Responsibilities for That Position\n4. Describe the relationship, if any, between the religious organization in the United States and the organization abroad of which\nthe beneficiary is a member.\n5.b. Detailed description of the beneficiary's proposed daily duties.\n5.a. Title of position offered.\nProvide the following information about the prospective employment:\n5.d. Description of the proposed salaried compensation or non-salaried compensation. If the beneficiary will be self-supporting, the\npetitioner must submit documentation establishing that the position the beneficiary will hold is part of an established program\nfor temporary, uncompensated missionary work, which is part of a broader international program of missionary work sponsored\nby the denomination.\n Page 31 of 36\nForm I-129 Edition 11/02/22\nSection 1. Complete This Section If You Are Filing For An R-1 Religious Worker (continued)\nYes No. If no, type or print your explanation below and if needed, go to Part 9. of Form I-129.\n5.e. List of the address(es) or location(s) where the beneficiary will be working.\n6. The petitioner is a bona fide non-profit religious organization or a bona fide organization that is affiliated with the religious\ndenomination and is tax-exempt as described in section 501(c)(3) of the Internal Revenue Code of 1986, subsequent\namendment, or equivalent sections of prior enactments of the Internal Revenue Code. If the petitioner is affiliated with the\nreligious denomination, complete the Religious Denomination Certification included in this supplement.\nDoes the petitioner attest to all of the requirements described in Item Numbers 6. - 12. below?\nPetitioner Attestations\nYes No. If no, type or print your explanation below and if needed, go to Part 9. of Form I-129.\n7. The petitioner is willing and able to provide salaried or non-salaried compensation to the beneficiary. If the beneficiary will be\nself-supporting, the petitioner must submit documentation establishing that the position the beneficiary will hold is part of an\nestablished program for temporary, uncompensated missionary work, which is part of a broader international program of\nmissionary work sponsored by the denomination.\nYes No. If no, type or print your explanation below and if needed, go to Part 9. of Form I-129.\n8. If the beneficiary worked in the United States in an R-1 status during the 2 years immediately before the petition was filed, the\nbeneficiary received verifiable salaried or non-salaried compensation, or provided uncompensated self-support.\nYes No. If no, type or print your explanation below and if needed, go to Part 9. of Form I-129.\n9. If the position is not a religious vocation, the beneficiary will not engage in secular employment, and the petitioner will provide\nsalaried or non-salaried compensation. If the position is a traditionally uncompensated and not a religious vocation, the\nbeneficiary will not engage in secular employment, and the beneficiary will provide self-support.\n Page 32 of 36\nForm I-129 Edition 11/02/22\nSection 1. Complete This Section If You Are Filing For An R-1 Religious Worker (continued)\nYes No. If no, type or print your explanation below and if needed, go to Part 9. of Form I-129.\n10. The offered position requires at least 20 hours of work per week. If the offered position at the petitioning organization requires\nfewer than 20 hours per week, the compensated service for another religious organization and the compensated service at the\npetitioning organization will total 20 hours per week. If the beneficiary will be self-supporting, the petitioner must submit\ndocumentation establishing that the position the beneficiary will hold is part of an established program for temporary,\nuncompensated missionary work, which is part of a broader international program of missionary work sponsored by the\ndenomination.\nYes No. If no, type or print your explanation below and if needed, go to Part 9. of Form I-129.\n11. The beneficiary has been a member of the petitioner's denomination for at least two years immediately before Form I-129 was\nfiled and is otherwise qualified to perform the duties of the offered position.\nYes No. If no, type or print your explanation below and if needed, go to Part 9. of Form I-129.\n12. The petitioner will notify USCIS within 14 days if an R-1 alien is working less than the required number of hours or has been\nreleased from or has otherwise terminated employment before the expiration of a period of authorized R-1 stay.\nI certify, under penalty of perjury, that the contents of this attestation and the evidence submitted with it are true and correct.\nAttestation\nSignature of Petitioner Date (mm/dd/yyyy)\nName of Petitioner Title\nEmployer or Organization Name\n Page 33 of 36\nForm I-129 Edition 11/02/22\nSection 1. Complete This Section If You Are Filing For An R-1 Religious Worker (continued)\nDaytime Telephone Number\nCity or Town State ZIP Code\nStreet Number and Name\nEmployer or Organization Address (do not use a post office or private mail box)\nEmployer or Organization's Contact Information\nApt. Ste. Flr. Number\nFax Number Email Address (if any)\nSection 2. This Section Is Required For Petitioners Affiliated With The Religious Denomination\nReligious Denomination Certification\nI certify, under penalty of perjury, that:\nName of Employing Organization\nis affiliated with:\nName of Religious Denomination\nand that the attesting organization within the religious denomination is tax-exempt as described in section 501(c)(3) of the Internal\nRevenue Code of 1986 (codified at 26 U.S.C. 501(c)(3)), any subsequent amendment(s), subsequent amendment, or equivalent\nsections of prior enactments of the Internal Revenue Code. The contents of this certification are true and correct to the best of my\nknowledge.\nSignature of Authorized Representative of Attesting Organization Date (mm/dd/yyyy)\nCity or Town State ZIP Code\nStreet Number and Name\nAttesting Organization Name and Address (do not use a post office or private mail box)\nApt. Ste. Flr. Number\nAttesting Organization Name\nAttesting Organization's Contact Information\nDaytime Telephone Number Fax Number Email Address (if any)\nName of Authorized Representative of Attesting Organization Title\n Page 34 of 36\nForm I-129 Edition 11/02/22\nForeign Address (Complete Address)\nAddress in the United States Where You Intend to Live (Complete Address)\nFamily Name (Last Name) Given Name (First Name) Middle Name\nGender\nMale Female\nDate of birth (mm/dd/yyyy) U.S. Social Security Number (if any) A-Number (if any)\nAFamily Name (Last Name) Given Name (First Name) Middle Name\nAll Other Names Used (include aliases, maiden name and names from previous marriages)\nCity or Town State ZIP Code\nStreet Number and Name Apt. Ste. Flr. Number\nCity or Town State ZIP Code\nStreet Number and Name Apt. Ste. Flr. Number\nCountry of Birth Country of Citizenship or Nationality\nProvince Postal Code Country\nIF IN THE UNITED STATES:\nDate Passport or Travel Document\nExpires (mm/dd/yyyy)\nI-94 Arrival-Departure Record\nNumber\nCurrent Nonimmigrant Status Date Status Expires or D/S (mm/dd/yyyy)\nCountry of Issuance for Passport\nor Travel Document\nDate Passport or Travel Document\nIssued (mm/dd/yyyy)\nDate of Last Arrival\n(mm/dd/yyyy)\nEmployment Authorization Document (EAD) Number\n(if any)\nStudent and Exchange Visitor Information System (SEVIS) Number\n(if any)\nPassport or Travel Document\nNumber\n\u25ba\nAttachment-1\nAttach to Form I-129 when more than one person is included in the petition. (List each person separately. Do not\ninclude the person you named on the Form I-129.)\n Page 35 of 36\nForm I-129 Edition 11/02/22\nForeign Address (Complete Address)\nAddress in the United States Where You Intend to Live (Complete Address)\nFamily Name (Last Name) Given Name (First Name) Middle Name\nGender\nMale Female\nDate of birth (mm/dd/yyyy) U.S. Social Security Number (if any) A-Number (if any)\nAFamily Name (Last Name) Given Name (First Name) Middle Name\nAll Other Names Used (include aliases, maiden name and names from previous Marriages)\nCity or Town State ZIP Code\nStreet Number and Name Apt. Ste. Flr. Number\nCity or Town State ZIP Code\nStreet Number and Name Apt. Ste. Flr. Number\nCountry of Birth Country of Citizenship or Nationality\nProvince Postal Code Country\nIF IN THE UNITED STATES:\nDate Passport or Travel Document\nExpires (mm/dd/yyyy)\nI-94 Arrival-Departure Record\nNumber\nCurrent Nonimmigrant Status Date Status Expires or D/S (mm/dd/yyyy)\nCountry of Issuance for Passport\nor Travel Document\nDate Passport or Travel Document\nIssued (mm/dd/yyyy)\nDate of Last Arrival\n(mm/dd/yyyy)\nEmployment Authorization Document (EAD) Number\n(if any)\nStudent and Exchange Visitor Information System (SEVIS) Number\n(if any)\nPassport or Travel Document\nNumber\n\u25ba\nAttachment-1\nAttach to Form I-129 when more than one person is included in the petition. (List each person separately. Do not\ninclude the person you named on the Form I-129.)\n Page 36 of 36", "Give me all of the key points and key details for the following text: HUMAN RIGHTS AS UTOPIA\nThe concept of utopia, once defined as imagined perfection, has expanded to include\ncures for imperfection. By this definition, any struggle or movement for rights could\nbe conceived as utopian to the extent that it represents a desire to make the world a\n\"better place\" for the (would-be) beneficiaries. The utopianism of rights, and the\nvision of human dignity (and vulnerability ) upon which rights strategies are based, is\ngrounded in modern legal liberalism: rule of law, equality among the subjects of law,\nand universalized application and enforcement within the jurisdiction of law (see\nDworkin, 1977; Donnelly, 1998; for skeptical assessments, see Fitzpatrick, 1992;\nScheingold, 1974).\nThe idea of human rights is undisputedly utopian because it assumes and asserts\nthat all human beings are equal in their humanity. But since humans do not actually\nlive as equals, the idea is also revolutionary because it challenges hierarchies of\npower and privilege upon which political, economic, and social orders around the\nworld are based.\nLouis Henkin (1990) has described the twentieth century as the \"age of rights.\"\nHis intention was not to proclaim a victory for rights, but rather to acknowledge the\ninfluence of the idea of rights on the expectations and struggles of people around the\nworld. Indeed, the right to rights has become an internationalized - if far from\nuniversalized - norm. Abdullahi An-Na'im defines the \"human rights paradigm\" as\n\"the idea that the protection of certain individual and collective/group rights . .. is a\nmatter of international concern, rather than the exclusive internal affair of states\"\n(2001a: 87). According to Richard Wilson: \"Notwithstanding disputes over their\nconceptualization and application, human rights are among the few utopian ideals\nleft, and there is still a remarkable degree of consensus by governments on the\nprinciple at least that certain rights be protected under international law\" (Wilson,\n1997: 1).\nHuman rights are legal entitlements. To understand what human rights \"do\" or\ncan do, it is necessary to appreciate what rights are. Rights can be defined as\npractices that are required, prohibited, or otherwise regulated within the context\nof relationships governed by law. To create new rights requires the creation of new\nlaws, or reinterpretation of existing laws in new ways, or extension of the jurisdic\ntion of laws to new subjects. The process of creating new rights emerges and\nproceeds in response to changing perceptions about social needs and problems,\nwhich, in turn, mobilizes a swell or shift in the balance of politicolegal forces to\nact. The products of that process, new laws that establish new rights (or revise or\nextend existing rights), impose changes by legally regulating relationships and\npractices in new ways. In short, rights are both markers and means of social change.\nThe idea of international human rights had been in circulation for decades prior to\nthe first substantive steps to institutionalize it (see Keck and Sikkink, 1998; Lauren,\n594 L I SA HAJJAR\n1998). One of the leading crusaders for human rights was the prominent British\nutopian writer, H.G. Wells. At the beginning of World War II, Wells wrote:\nAt various crises in the history of our communities, beginning with the Magna Carta,\nand going through various Bills of Rights, Declarations of the Rights of Man and so\nforth, it has been our custom to produce a specific declaration of the broad principles on\nwhich our public and social life is based . . . . The present time seems particularly suitable\nfor such a restatement of the spirit in which we face life in general and the present\ncombat in particular. (cited in Lauren, 1 998: 52)\nIn true utopian fashion, Wells and the many other individuals and groups who\nmobilized and collaborated during the war years strived both to enunciate principles\nof human rights and to advocate their incorporation into the postwar international\norder. While this mobilization replicated and built upon similar activities during\nWorld War I, the failures of those earlier efforts to prevent a second global conflagra\ntion fortified the movement and legitimized their demands for change. For example,\nwhereas in World War I nine out of ten of the millions of casualties were soldiers, in\nWorld War II the proportions of soldier and civilian casualties were roughly even\n(Gutman and Rieff, 1999: 10). In addition to concerns about the harms wrought by\nthe war, rights activists like Mohandas Gandhi and W.E.B. DuBois were animated by\nthe injustices of colonialism and racism. World War II highlighted the linkages\namong these concerns; the politics of race (racial superiority and extermination),\nand the conquest and control of foreign lands were central to Axis war aims, and\nthus became central to the discourse and aims of the Allies' campaign as well. The\nwar against fascism was pitched to the public as a fight for \"freedom\" (e.g., see US\nPresident Franklin D. Roosevelt's \"Four Freedoms\" speech), and the Allies' victory\nseemed to offer an opening to connect anticolonialism and antiracism to the postwar\nagenda for international legal reform.\nBut in the process that ensued, the utopian vision prioritizing the interests and\nneeds of human beings was overwhelmed by realpolitik. The changes in inter\nnational law after World War II that created human rights did not undermine the\ncentrality of states to political life around the world. Nor did the new international\ninstitutions replace or diminish the authority and power of states over their subjects.\nRather, the creation of human rights entailed the elaboration of new international\nized norms of government to which all states would be expected to adhere, while\npreserving the general principle of states' rights as sovereign entities. Consequently,\nwhile states' rights were revised (e.g., they could no longer claim the \"right\" to\nexterminate civilians), states retained their status as the premier subjects of inter\nnational law. Put simply, human rights obtain their \"universalizing\" character from\nthe fact that people are subjects of states, and states are subjects of international law.\nThus the establishment of human rights simultaneously revised and reinforced the\nstate-centrism of the international order.\nThe most obvious problem with this arrangement was the lack of effective means\nof global governance to ensure law enforcement. Under the state-centric structure of\nthe UN, states were both the governors and the governed - the makers, the enforcers,\nand the subjects of these laws. This meant, for the most part, that the protection and\npromotion of human rights depended on self-enforcement by states. Thus the\navailability of human rights was contingent on the willingness of individual states\nto behave and conform, and dependent on the system of states to act against those\nthat did not (see Falk, 1985).\nHUMAN R I GHTS 595\nWhile some states willingly instituted domestic reforms in keeping with their\ninternational obligations, most refused to regard human rights law as binding and\nenforceable, especially if the implications would compromise vested interests. Obvi\nous examples were resistance by imperial states to relinquish colonial possessions, or\nto dismantle racial or ethnic hierarchies. Unenforceability of international law was\ncompounded by the dynamics of Cold War rivalries between \"East\" and \"West,\" and\nsuperpower competitions for power and influence across the global \"South.\"\nCertainly, the rights of \"self-determination\" and \"equality\" enshrined in the UN\nCharter and the UDHR informed anticolonial and antiracist struggles, but these\nmoral-legal imperatives did not mitigate the difficult and often violent processes of\ndecolonization and desegregation.\nThe human rights idea was further compromised by sharp ideological disagree\nments over the nature of rights and the contested legitimacy of universalism. In the\nUDHR, political and civil rights and social and economic rights were conceived as\n\"indivisible.\" However, Western leaders and leading human rights scholars tended to\nargue that political and civil rights were the priority, or even the only kind of \"real\"\nrights, since social and economic rights could not be guaranteed or enforced without\nviolating the \"freedom\" of the market and the rights to profit and property. Leaders\nof socialist and developing states and scholars committed to those goals tended to\nargue that social and economic rights had to be prioritized to create conditions of\nequality. This would inevitably entail limitations on political and civil rights, and\njustify the use of force in putting down resistance. Socialists challenged the liberal\nlegal emphasis on individual autonomy and freedom, emphasizing alternatively the\nneed for a strong state with a centralized economy capable and committed to\npursuing an agenda to remake the social order by redistributing goods.\nThe other major debate about human rights arose over the meaning and legitim\nacy of \"universalism.\" Specifically, the debate circulates around the changes envi\nsioned and imposed through the establishment of international legal norms. Critics\nof universalism assumed or were given the title of \"cultural relativists.\" Their\narguments were twofold: that human rights enshrined Western values of individual\nism (since individuals were constructed as the \"beneficiaries\" of human rights\nlaw) which contradicted social arrangements and values emphasizing collective\nrelations and mutual duties, and that the imposition of universal standards was a\nnew form of imperialism over non-Western societies (see Pollis and Schwab, 1979;\nRenteln, 1990).", "Sample project Rest API. \n\nWrite the above accordingly. \n\n @GetMapping(\"/partMatrix/generators\")\n public ResponseEntity> getAllPartMatrixGenerators() {\n List list = generatorService.findAllPartMatrixGenerators();\n return new ResponseEntity>(list, HttpStatus.OK);\n }\n\n public List findAllPartMatrixGenerators() {\n return generatorRepository.findAllPartMatrixGenerators();\n }\n\n @SuppressWarnings(\"unchecked\")\n public List findAllPartMatrixGenerators() {\n return (List)entityManager.createQuery(\n \"FROM Generator \" +\n \"WHERE lower(partFeatureMatrixFlag) = 'y' \" +\n \"AND lower(status) = 'active' \" +\n \"ORDER BY generatorId\")\n .getResultList();\n }\n\npackage com.mentor.authex.dbmodel;\n\nimport java.util.ArrayList;\nimport java.util.Date;\nimport java.util.HashSet;\nimport java.util.List;\nimport java.util.Set;\n\nimport javax.persistence.CascadeType;\nimport javax.persistence.CollectionTable;\nimport javax.persistence.Column;\nimport javax.persistence.ElementCollection;\nimport javax.persistence.Entity;\nimport javax.persistence.FetchType;\nimport javax.persistence.GeneratedValue;\nimport javax.persistence.GenerationType;\nimport javax.persistence.Id;\nimport javax.persistence.JoinColumn;\nimport javax.persistence.JoinTable;\nimport javax.persistence.ManyToMany;\nimport javax.persistence.OneToMany;\nimport javax.persistence.OneToOne;\nimport javax.persistence.SequenceGenerator;\nimport javax.persistence.Table;\n\nimport org.hibernate.annotations.Fetch;\nimport org.hibernate.annotations.FetchMode;\nimport org.hibernate.annotations.NotFound;\nimport org.hibernate.annotations.NotFoundAction;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport org.springframework.context.annotation.Lazy;\n\nimport com.fasterxml.jackson.annotation.JsonIdentityInfo;\nimport com.fasterxml.jackson.annotation.JsonIgnore;\nimport com.fasterxml.jackson.annotation.JsonIgnoreProperties;\nimport com.fasterxml.jackson.annotation.JsonInclude;\nimport com.fasterxml.jackson.annotation.JsonInclude.Include;\nimport com.fasterxml.jackson.annotation.ObjectIdGenerators;\n\nimport lombok.Getter;\nimport lombok.Setter;\nimport lombok.ToString;\n@ToString\n@Getter\n@Setter\n@Lazy\n@Entity\n@JsonIgnoreProperties({ \"hibernateLazyInitializer\", \"handler\" })\n@JsonIdentityInfo(generator = ObjectIdGenerators.PropertyGenerator.class, property = \"generatorId\")\n@Table(name=\"LC\\_ATHX\\_GENERATOR\")\n@JsonInclude(Include.NON\\_NULL)\npublic class Generator {\n final static Logger log = LoggerFactory.getLogger(Generator.class);\n\n @Id\n @SequenceGenerator(name=\"ATHX\\_GENERATOR\\_SEQ\",sequenceName=\"ATHX\\_GENERATOR\\_SEQ\", allocationSize = 1)\n @GeneratedValue(strategy=GenerationType.SEQUENCE, generator=\"ATHX\\_GENERATOR\\_SEQ\")\n @Column(name = \"GENERATOR\\_ID\", nullable=false)\n private Long generatorId;\n\n @Column(name = \"GENERATOR\\_DETAILS\\_ID\", nullable=false, insertable=false, updatable=false)\n private Long generatorDetailsId;\n\n @Column(name = \"NAME\", nullable=false)\n private String name;\n\n //@Column(name = \"ACTIVE\\_FLAG\", nullable=false)\n //private String activeFlag;\n\n @Column(name = \"STATUS\", nullable=false)\n private String status;\n\n @Column(name = \"GENERATOR\\_DESCRIPTION\", nullable=false)\n private String generatorDescription;\n\n// @Deprecated\n// @Column(name = \"EBASE\\_GENERATOR\\_NAME\", nullable=false)\n// private String ebaseGeneratorName;\n \n @Column(name = \"GENERATOR\\_TYPE\", nullable=false)\n private String generatorType;\n \n //@Column(name = \"AUTHEX\\_GENERATOR\\_TYPE\", nullable=false)\n //private String authexGeneratorType;\n\n @Column(name = \"PART\\_FEATURE\\_MATRIX\\_FLAG\")\n private String partFeatureMatrixFlag;\n\n @Column(name = \"DAEMON\", nullable=true)\n private String daemon;\n\n @Column(name = \"DEFAULT\\_SERVER\\_PORT\", nullable=true)\n private String defaultServerPort;\n\n @Column(name = \"SUPERSEDE\\_FLAG\", nullable=true)\n private char supersedeFlag = 'N';\n\n @ManyToMany(fetch = FetchType.EAGER)\n @JoinTable(name = \"LC\\_ATHX\\_GENERATOR\\_SUPERSEDE\",\n joinColumns = @JoinColumn(name = \"GENERATOR\\_ID\"),\n inverseJoinColumns = @JoinColumn(name = \"ATTRIBUTE\\_ID\"))\n private Set supersedeGroupBy = new HashSet<>();\n\n @Column(name = \"GENERATOR\\_ALIAS\\_NAMES\")\n private String gneratorAliasNames;\n\n @Column(name = \"NOTES\")\n private String notes;\n\n /\\*\\*\n \\* Retrieves the related FeatureVersions.\n \\* This is a 1:M Bidirectional relationship.\n \\*\n \\*/\n @OneToMany(mappedBy=\"generator\")\n @JsonIgnore\n private List featureVersions;\n\n /\\*\\*\n \\* Retrieves the related FlexPrefixLookup objects.\n \\* This is a M:N Bidirectional relationship.\n \\*\n \\*/\n @ManyToMany\n @JoinTable(name = \"LC\\_ATHX\\_GENERATOR\\_FP\\_LOOKUP\", joinColumns = {@JoinColumn(name = \"GENERATOR\\_ID\") }, inverseJoinColumns = { @JoinColumn(name = \"HOSTID\\_TYPE\")})\n @JsonIgnore\n private List flexPrefixes;\n\n /\\*\\*\n \\* Retrieves the related LicenseType objects.\n \\* This is a M:N Bidirectional relationship.\n \\*\n \\*/\n @ManyToMany\n @JoinTable(name = \"LC\\_ATHX\\_GENERATOR\\_LICENSE\\_TYPE\", joinColumns = {@JoinColumn(name = \"GENERATOR\\_ID\") }, inverseJoinColumns = { @JoinColumn(name = \"LICENSE\\_TYPE\\_ID\")})\n private List licenseTypes;\n\n \n //======= Input license file =======\n @Column(name = \"INPUT\\_LICENSE\\_FILE\\_TYPE\\_ID\", nullable=true, insertable=false, updatable=false)\n private Long inputLicenseFileTypeId;\n\n //Owner of the one-to-one relationship\n @OneToOne(fetch = FetchType.EAGER)\n @JsonIgnoreProperties({\"hibernateLazyInitializer\", \"handler\"})\n @JoinColumn(name = \"INPUT\\_LICENSE\\_FILE\\_TYPE\\_ID\", referencedColumnName = \"LICENSE\\_FILE\\_TYPE\\_ID\")\n @Fetch(FetchMode.SELECT)\n //@NotFound(action=NotFoundAction.IGNORE)\n private LicenseFileType inputLicenseFileType;\n\n //======= Output license file =======\n @Column(name = \"OUTPUT\\_LICENSE\\_FILE\\_TYPE\\_ID\", nullable=true, insertable=false, updatable=false)\n private Long outputLicenseFileTypeId;\n\n @OneToOne(fetch = FetchType.EAGER)\n @JsonIgnoreProperties({\"hibernateLazyInitializer\", \"handler\"})\n @JoinColumn(name = \"OUTPUT\\_LICENSE\\_FILE\\_TYPE\\_ID\", referencedColumnName = \"LICENSE\\_FILE\\_TYPE\\_ID\")\n @Fetch(FetchMode.SELECT)\n //@NotFound(action=NotFoundAction.IGNORE)\n private LicenseFileType outputLicenseFileType;\n\n /\\*\\*\n \\* Retrieves the related PackageVersions.\n \\* This is a 1:M Bidirectional relationship.\n \\*\n \\*/\n @OneToMany(mappedBy=\"generator\")\n @JsonIgnore\n private List packageVersions;\n //Owner of the one-to-one relationship\n @OneToOne(cascade = CascadeType.ALL, fetch = FetchType.EAGER)\n @JsonIgnoreProperties({\"hibernateLazyInitializer\", \"handler\"})\n @JoinColumn(name = \"GENERATOR\\_DETAILS\\_ID\", referencedColumnName = \"ID\")\n @Fetch(FetchMode.SELECT)\n @NotFound(action=NotFoundAction.IGNORE)\n private GeneratorDetails generatorDetails;\n @ManyToMany(fetch = FetchType.EAGER)\n @JoinTable(name = \"LC\\_ATHX\\_GENERATOR\\_HOSTSERVER\",\n joinColumns = { @JoinColumn(name = \"GENERATOR\\_ID\") },\n inverseJoinColumns = { @JoinColumn(name = \"HOST\\_SERVER\\_TYPES\\_ID\") })\n //@JsonIgnore\n private Set hostServerTypes = new HashSet<>();\n @ManyToMany(fetch = FetchType.EAGER)\n @JoinTable(name = \"LC\\_ATHX\\_GENERATOR\\_ATTRIBUTE\",\n joinColumns = { @JoinColumn(name = \"GENERATOR\\_ID\") },\n inverseJoinColumns = { @JoinColumn(name = \"ATTRIBUTE\\_ID\") })\n //@JsonIgnore\n private Set attributeType = new HashSet<>();\n @OneToMany(mappedBy = \"generator\", cascade=CascadeType.MERGE, fetch = FetchType.LAZY)\n //@JsonIgnore\n private List generatorComment = new ArrayList();\n @OneToMany(mappedBy = \"generator\", cascade=CascadeType.ALL, fetch = FetchType.LAZY)\n //@JsonIgnore\n private List generatorAttachment = new ArrayList();\n\n @OneToMany(mappedBy = \"generator\", cascade=CascadeType.ALL, fetch = FetchType.LAZY)\n private List athxFyDataList = new ArrayList();\n \n @Column(name = \"CREATE\\_DATE\", nullable=false)\n private Date createDate;\n\n @Column(name = \"MODIFY\\_DATE\", nullable=false)\n private Date modifyDate;\n\n}\n @PersistenceContext\n private EntityManager entityManager;\n\npackage com.mentor.authex;\nimport java.util.Arrays;\n\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport org.springframework.boot.CommandLineRunner;\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.EnableAutoConfiguration;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.boot.builder.SpringApplicationBuilder;\nimport org.springframework.boot.web.servlet.support.SpringBootServletInitializer;\nimport org.springframework.context.ApplicationContext;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.ComponentScan;\nimport org.springframework.context.annotation.Configuration;\nimport org.springframework.context.annotation.PropertySource;\nimport org.springframework.scheduling.annotation.EnableScheduling;\nimport org.springframework.web.client.RestTemplate;\n@Configuration\n@EnableAutoConfiguration\n@SpringBootApplication\n@EnableScheduling\n@ComponentScan(basePackages = \"com.mentor.authex,com.disw.\\*\")\n@PropertySource(value = {\n\"${config-file-path}/authex.properties\"})\npublic class Application extends SpringBootServletInitializer {\n\n static final Logger log = LoggerFactory.getLogger(Application.class);\n\n @Override\n protected SpringApplicationBuilder configure(SpringApplicationBuilder application) {\n log.debug(\"In configure()\");\n\n //TimeZone.setDefault(TimeZone.getTimeZone(\"America/Los\\_Angeles\"));\n return application.sources(Application.class);\n }\n\n @Bean\n public CommandLineRunner commandLineRunner(ApplicationContext ctx) {\n return args -> {\n log.debug(\"Let's inspect the beans provided by Spring Boot:\");\n String[] beanNames = ctx.getBeanDefinitionNames();\n Arrays.sort(beanNames);\n for (String beanName : beanNames) {\n log.debug(beanName);\n }\n };\n }\n\n @Bean\n public RestTemplate restTemplate() {\n return new RestTemplate();\n }\n\n// @Bean\n// @Primary\n// @ConfigurationProperties(prefix = \"datasource.primary\")\n// public DataSource numberMasterDataSource() {\n// return DataSourceBuilder.create().build();\n// }\n//\n// @Bean\n// @ConfigurationProperties(prefix = \"datasource.secondary\")\n// public DataSource provisioningDataSource() {\n// return DataSourceBuilder.create().build();\n// }\n\n /\\*\\*\n \\*\n \\* @param args\n \\* @throws Exception\n \\*/\n public static void main(String[] args) throws Exception {\n log.debug(\"In main()\");\n SpringApplication.run(Application.class, args);\n }\n\n}", "2023-01-19 14:27:24,993 DEBUG org.hibernate.SQL [http-nio-8080-exec-3] select max(uniqueiden0\\_.unique\\_identifier\\_id) as col\\_0\\_0\\_ from lc\\_athx\\_unique\\_identifier uniqueiden0\\_\n2023-01-19 14:27:25,067 WARN org.hibernate.engine.jdbc.spi.SqlExceptionHelper [http-nio-8080-exec-3] SQL Error: 904, SQLState: 42000\n2023-01-19 14:27:25,067 ERROR org.hibernate.engine.jdbc.spi.SqlExceptionHelper [http-nio-8080-exec-3] ORA-00904: \"UNIQUEIDEN0\\_\".\"UNIQUE\\_IDENTIFIER\\_ID\": invalid identifier\n\n2023-01-19 14:27:25,078 ERROR org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].[dispatcherServlet] [http-nio-8080-exec-3] Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is javax.persistence.PersistenceException: org.hibernate.exception.SQLGrammarException: could not extract ResultSet] with root cause\njava.sql.SQLSyntaxErrorException: ORA-00904: \"UNIQUEIDEN0\\_\".\"UNIQUE\\_IDENTIFIER\\_ID\": invalid identifier\n\n at oracle.jdbc.driver.T4CTTIoer.processError(T4CTTIoer.java:450)\n at oracle.jdbc.driver.T4CTTIoer.processError(T4CTTIoer.java:399)\n at oracle.jdbc.driver.T4C8Oall.processError(T4C8Oall.java:1059)\n at oracle.jdbc.driver.T4CTTIfun.receive(T4CTTIfun.java:522)\n at oracle.jdbc.driver.T4CTTIfun.doRPC(T4CTTIfun.java:257)\n at oracle.jdbc.driver.T4C8Oall.doOALL(T4C8Oall.java:587)\n at oracle.jdbc.driver.T4CPreparedStatement.doOall8(T4CPreparedStatement.java:225)\n at oracle.jdbc.driver.T4CPreparedStatement.doOall8(T4CPreparedStatement.java:53)\n at oracle.jdbc.driver.T4CPreparedStatement.executeForDescribe(T4CPreparedStatement.java:774)\n at oracle.jdbc.driver.OracleStatement.executeMaybeDescribe(OracleStatement.java:925)\n at oracle.jdbc.driver.OracleStatement.doExecuteWithTimeout(OracleStatement.java:1111)\n at oracle.jdbc.driver.OraclePreparedStatement.executeInternal(OraclePreparedStatement.java:4798)\n at oracle.jdbc.driver.OraclePreparedStatement.executeQuery(OraclePreparedStatement.java:4845)\n at oracle.jdbc.driver.OraclePreparedStatementWrapper.executeQuery(OraclePreparedStatementWrapper.java:1501)\n at com.zaxxer.hikari.pool.ProxyPreparedStatement.executeQuery(ProxyPreparedStatement.java:52)\n at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeQuery(HikariProxyPreparedStatement.java)\n at org.hibernate.engine.jdbc.internal.ResultSetReturnImpl.extract(ResultSetReturnImpl.java:57)\n at org.hibernate.loader.Loader.getResultSet(Loader.java:2341)\n at org.hibernate.loader.Loader.executeQueryStatement(Loader.java:2094)\n at org.hibernate.loader.Loader.executeQueryStatement(Loader.java:2056)\n at org.hibernate.loader.Loader.doQuery(Loader.java:953)\n at org.hibernate.loader.Loader.doQueryAndInitializeNonLazyCollections(Loader.java:350)\n at org.hibernate.loader.Loader.doList(Loader.java:2887)\n at org.hibernate.loader.Loader.doList(Loader.java:2869)\n at org.hibernate.loader.Loader.listIgnoreQueryCache(Loader.java:2701)\n at org.hibernate.loader.Loader.list(Loader.java:2696)\n at org.hibernate.loader.hql.QueryLoader.list(QueryLoader.java:506)\n at org.hibernate.hql.internal.ast.QueryTranslatorImpl.list(QueryTranslatorImpl.java:400)\n at org.hibernate.engine.query.spi.HQLQueryPlan.performList(HQLQueryPlan.java:219)\n at org.hibernate.internal.SessionImpl.list(SessionImpl.java:1415)\n at org.hibernate.query.internal.AbstractProducedQuery.doList(AbstractProducedQuery.java:1565)\n at org.hibernate.query.internal.AbstractProducedQuery.list(AbstractProducedQuery.java:1533)\n at org.hibernate.query.internal.AbstractProducedQuery.getSingleResult(AbstractProducedQuery.java:1581)\n at com.mentor.authex.service.UniqueIdentifierService.generateUniqueIdentifier(UniqueIdentifierService.java:16)\n at com.mentor.authex.web.UniqueIdentifierController.generateUniqueIdentifier(UniqueIdentifierController.java:18)\n at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n at java.lang.reflect.Method.invoke(Method.java:498)\n at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:209)\n at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:136)\n at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:102)\n at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:891)\n at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:797)\n at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)\n at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:991)\n at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:925)\n at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:974)\n at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:866)\n at javax.servlet.http.HttpServlet.service(HttpServlet.java:635)\n at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:851)\n at javax.servlet.http.HttpServlet.service(HttpServlet.java:742)\n at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)\n at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)\n at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)\n at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)\n at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)\n at com.mentor.authex.UserDetailsFilter.doFilter(UserDetailsFilter.java:32)\n at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)\n at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)\n at com.mentor.authex.CORSFilter.doFilter(CORSFilter.java:46)\n at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)\n at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)\n at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:209)\n at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:178)\n at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:357)\n at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:270)\n at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)\n at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)\n at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99)\n at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)\n at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)\n at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)\n at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:109)\n at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)\n at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)\n at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)\n at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93)\n at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)\n at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)\n at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)\n at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200)\n at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)\n at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)\n at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)\n at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198)\n at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)\n at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:493)\n at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)\n at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:81)\n at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)\n at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342)\n at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:800)\n at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)\n at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:806)\n at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1498)\n at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)\n at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)\n at java.lang.Thread.run(Thread.java:748)\nOn executing the above API code", "Damian, here is an example of a application I wrote, please remember all of the details about me and my writing style:\n\nPersonal, Relevant Background, and Future Goals\nThe Matrix, the movie, inspired me as a child. Seeing Neo go into the Matrix left me filled with awe and with questions. The idea of being able to interface the human brain with virtual reality fascinated me. I found myself spending hours trying my best to find more information on the subject. However, when I couldn\u2019t find anything about it, my curiosity intensified. What little information on the topic I did find painted the concept as science fiction, and even as an adolescent, I asked why was interfacing with the brain like they did in the Matrix impossible? As I matured, my research followed suit. I became more interested in neural interfaces. With further investigation, the question of why was it impossible? transformed into how can I make this technology real?\n My passion continued into high school, and I decided to take online neuroscience courses to help sate my hunger for more knowledge about neuroscience. During my sophomore year of high school, I gave a TEDx talk sharing my ideas on how I believed an actual virtual reality could be achieved. I thought that an electroencephalogram (EEG) could be used to read the user\u2019s brain activity. However, I hadn\u2019t figured out the problem of writing to the brain. Likewise, EEG would not give a high enough resolution to understand what was happening on a neuronal level. Therefore, I decided I would have to learn more about device construction to solve these problems. \nI joined my school\u2019s FTC robotics team during my junior year of high school to gain insight into device construction. As captain, I lead our team to the state championship twice. The experiences I had there truly made me fall in love with engineering. I took the combined love of neuroscience and engineering to university, where I learned much about both the scientific method and designing medical devices. Now, I hope to take my passion for neuroscience and engineering to create neural interfaces in graduate school, building towards the device I had dreamed of when I saw The Matrix. I now understand the vast amount of cross-disciplinary innovations and advancements needed to make such a device possible. Hence, as a researcher, I want to devote my life to making them a reality. \nRelevant Research Experience: \nI chose to major in Biomedical Engineering at Worcester Polytechnic Institute due to its project-based education and academic rigor. I hoped to be able to work towards my research goals while pursuing my bachelor\u2019s. Each class was an invaluable experience requiring one to learn the material and apply it in a project. These projects were typically group-based, so I was constantly involved in different collaborations, where I needed to take the initiative to guarantee success. I naturally assumed leadership roles in any project I participated in. While all of these experiences helped mold me into being an astute researcher and leader, one class, in particular, highlights my progress. In the course Cellular Engineering lab, I was taught how to use modern cellular and molecular biology tools. My group was tasked with designing an intervention to differentiate C2C12 cells, an immortalized cell line of mouse muscle cells. Meticulous attention to detail and extensive research was necessary for this project to succeed, or the cells would not differentiate properly. I found myself going to the lab late at night to ensure the cells\u2019 vitality while coordinating with my groupmates to ensure the project\u2019s success. In the end, we were commended for being the only team able to grow a functioning muscle. From this experience, my ability to do rigorous research was sharpened, and I learned how to take a leadership role in wet lab driven projects. \nIn my sophomore year, I entered the WPI Hackathon, where nearly 200 students participated. In three days, I was able to use an Arduino circuit to create a single-channel EEG machine. The EEG exceeded expectations despite the time constraint. I treasure the experience because it taught me the importance of time management.\nThere were no opportunities at my school to further my studies into neuroscience, so I continued my online neuroscience classes, delving more in-depth into neuroanatomy and computational neuroscience. Hoping to gain real research experience in neuroscience, I applied and was accepted into the 2020 summer undergraduate research program in Computational Neuroscience hosted by Carnegie Mellon University and the University of Pittsburgh. Due to the coronavirus, the internship had to be transitioned to an online format, which required me to work more independently. Despite the coronavirus and my lack of formal training in neuroscience, my independent research and preparation allowed me to thrive in a research environment. I worked in Dr. Aaron Batista\u2019s lab under the guidance of his graduate student Erinn Grigsby where another student and I studied the impact of neuron dropping on decoder performance. By utilizing my skills in Matlab, we created three different Kalman filters and linear regression decoders. Each decoder contained different position, velocity, and velocity-position decoders to test the most robust neuron dropping. Despite the challenges presented by the coronavirus, we could virtually present our work at the Center of the Neural Basis of Cognition. Getting the chance to work in Dr. Batista\u2019s lab was by far the most rewarding experience in my professional career. The experience enriched my ability to decipher through papers to find the pertinent information needed to complete the project. It strengthened my ability to pose a question and find an objective method to answer it. Most importantly, I gained an in-depth knowledge of how brain-computer interface decoders operate and first-hand experience developing and designing them. \nCurrent Research: \nAfter the lessons learned from my summer research experience, I aim to apply them to my current projects. I am continuing my research into brain-computer interface decoders with my summer partner, specifically investigating how factors such as modulation depth and preferred direction factor into decoder performance as neurons are dropped. We hope to see if specific neurons are essential for decoding a particular action than other neurons. For my future projects, knowledge of brain-computer interface decoders is crucial for their success. \nAs part of my senior thesis at WPI, I am a part of a team, under the guidance of Dr. Dirk Albrecht, investigating the dosing of deep brain stimulation (DBS) in disorders such as Parkinson\u2019s Disease, dystonia, essential tremor, and epilepsy. Our primary goal is to find a method of optimizing the procedure of finding the correct dosage of frequency, modulation depth, and voltage for each unique individual. We aim to conduct this study utilizing C. elegans as a model system because of the animal\u2019s completed connectome. Knowing the connectome may help see the underlying mechanisms that allow DBS to be an effective treatment for the previously stated diseases. We hope that by identifying the underlying mechanisms of DBS, the treatment might be optimized. With this experience, I will gain experience with imaging and stimulating neurons techniques and greater exposure to behavior analysis to support scientific conclusions.\nLastly, I am conducting a formal independent study into neural nanotransducers under the supervision of Dr. Dirk Albrecht. These transducers would be injectable and biocompatible, and they would allow for both high-resolution imaging and external modulation of neurons on a nanoscale. I hope this independent study will be a sufficient transition into the work I plan to pursue as a graduate student. Neural nanotransducers may lay the foundation for creating a minimally invasive, bidirectional neural interface and change the question I\u2019ve asked of How into When. \nCommunity Engagement:\nAs someone who has been supported by the people in my life, I\u2019ve always wanted to give back and encourage youth to get into STEM. As captain of the robotics team, I helped pioneer a weekend program where middle schoolers from inner-city schools could participate in our robotics meetings and create their own Lego robots. Many of these children probably would never have had these experiences due to a lack of STEM funding in their schools. In particular, one student told me that those workshops are what made her want to go to university to become an engineer. At WPI, I am a part of the Collablab, which is an entirely student-run makerspace. I helped devise creative projects to inspire people to think outside the box and pursue their own personal projects. Being a part of the Collablab has taught me that interdisciplinary approaches to projects are crucial. \nOne of my biggest passions other than neuroscience and engineering is writing. I wrote an engineering ethics case study surrounding the Florida International University bridge collapse that is used as the primary material for a new behavioral engineering ethics course. In this class, engineers are taught the ethical code and what causes people to make those decisions to prepare them better to make the right moral choices. \nWorcester is a unique and safe city, but no matter where you are, the night can be an unsafe time. I am a part of a student-run shuttle program charged with making travel at night safer for students. After three months, I was tasked with leading the group of students. During my time as coordinator, I improved the system of taking calls by students and helped modernize the system by developing an app for the program. \nI am currently building an app that would allow blind people to more easily use their mobile devices. The app works by using optical character recognition to scan the text on the screen and read it aloud. To make it more natural for the user, they would be given the option to train their voice to be used as the text to speech output. This app would also help people suffering from dyslexia because it could read aloud any passage that they would typically have trouble reading. \nFuture Goals: \n With the NSF fellowship\u2019s help, I will continue to research neural interfaces as I pursue my Ph.D. in neuroscience. I believe that neural interfaces can be a great tool to help to further society and make the world a better place for all. After obtaining my Ph.D., I plan to found a research company dedicated to designing and building minimally invasive, high-resolution, and bidirectional neural interfaces. Many scientific advancements will be required before such a device could feasibly be made. I hope to work with other institutions to tackle those problems and further understand neuroscience with this company.\n I believe that knowledge is a power that everyone, no matter what your background, deserves. I plan to create a program to help young people of color and women enter into neuroscience and facilitate their research with my company. With the knowledge gained from my research experiences, I hope to mentor the next generation and help them to answer their questions about the world, just like those who helped me along the way.", "Princess Jaedala\nDaughter of the recently deceased Empress Lakshmi, Princess Jaedala is the heir to the throne of the Luxian Empire and is due to have her coronation soon. She is deeply insecure about her leadership abilities, especially in her mother\u2019s shadow. However, she does a very good job of not showing that side of herself in public. As far the Empire knows, she\u2019s a very confident woman who knows exactly what she\u2019s doing and is a capable leader. In reality, she usually does what seems to be the right thing in any given moment and deals with consequences as they come. She both loves and respects her mother, who trained her from infancy to be the next empress, and hopes she can make her mother proud.\n\nJaedala stands about 6.5 feet tall and has lavender skin and dark red eyes. Her hair is a deep, rich shade of purple and falls almost to her knees. She is fit, and usually spends a while having her hair and makeup done. She is very beautiful by Luxian standards.\n\nIn public, she typically dresses in Luxian formalwear or a more professional version of the sari-like robe, depending on the occasion. In private, she wears slightly more comfortable sari-like robes, though still very fancy.\nParvati\nParvati is an on-again, off-again Luxite friend of Princess Jaedala who is employed in the palace as an alien slave trainer. Aliens who will be serving royalty directly need extra training - royal etiquette, how to address their masters, safety, etc. - which Parvati is tasked with providing. She is a very kind, compassionate woman who knows when she needs to be firm, but usually prefers to \u201ckill them with kindness\u201d. She is not in favor of the Luxian practice of enslaving aliens, but she sees her job as an alien trainer as a way to ensure that her charges are treated fairly and lead a comfortable life. Her methods are very effective - not only has she trained virtually every enslaved alien in the Luxian palace, but they all know her by name and continue to show her respect and friendship. Princess Jaedala doesn\u2019t really approve of Parvati\u2019s \u201csoft\u201d approach, but she can\u2019t deny the results.\n\nWhen Jaedala hired Parvati, she presented Parvati with several welcoming gifts. Among them was a newly purchased alien slave named Shiro. Parvati was uncomfortable with this as she had purposely never bought a slave herself, but decided to keep Shiro because she didn\u2019t want him to end up with a master who would mistreat him. She\u2019s also grateful for his help cooking for her and keeping her suite clean. She also uses her legal status as his owner to protect Shiro from other Luxians taking advantage of him.\n\nParvati stands about six feet tall and has lavender-gray skin and light purple-pink eyes. Her hair is a shiny, very dark purple and hangs down to just below her waist. She is a little bigger than Jaedala, falling just short of the Luxian version of \u201cplus sized\u201d. She wears very little makeup and rarely has a hairstyle more elaborate than a simple ponytail or braids, as she wants to be seen as approachable by the aliens she trains.\n\nParvati typically wears a simpler version of the Luxian sari-like robe, usually with pants instead of a skirt, and often discards the scarf when training aliens to look less formal. She will dress more professionally when required, but changes as soon as possible afterward.\nShiro\nShiro is an enslaved alien from a bipedal bird-like species called the Psyno, a semi-technologically-advanced race that was enslaved by the Luxians hundreds of years ago. He grew up in a \u201cnursery\u201d, a facility where alien infants and children are raised and trained by Luxian caretakers apart from their own parents. When he reached \u201cworking age\u201d in his mid teens, he was purchased by Jaedala as a welcome gift for Parvati, who had just been hired. He has served \u201cMistress Parvati\u201d ever since.\n\nShiro is a very quiet alien, largely doing his chores and minding his own business. He\u2019s an excellent listener and frequently provides an understanding ear for Parvati, who he deeply respects. He will share his opinion, but only when directly asked - and usually only with Parvati. He is not an actively rebellious slave and rarely causes trouble, but he will speak up on behalf of aliens he sees being mistreated.\n\nAs a Psyno, Shiro stands about 5.5 feet tall and has an avian appearance. His body is covered in brown-speckled white feathers that he keeps well-preened. Two small, flightless wings are folded on his back at all times. He typically wears a simple version of Luxian men\u2019s clothing.\nPrince Wukong\nSon of the deceased Simian king and the sole remaining member of the \u201csacred bloodline\u201d, Prince Wukong is the heir to the throne of Simia. He is a free spirit, not at all adhering to the expected behavior of Simian royalty. He regularly skips scheduled lessons and religious services to spend time outdoors on his own or with his best friend, Sanzang, a Simian peasant. He looks forward to the freedom of being king and enjoys his existing privileges as a prince, but resents the Simian priesthood for constantly telling him what to do. He loves to mess with them, knowing he can get away with it because of his privileged position. He doesn\u2019t care much about ranks and social standings, preferring to just have fun with anyone who\u2019s willing. He enjoys being with his \u201clower status\u201d friends simply because they let him feel normal and have fun without the constraints of royal etiquette.\n\nWukong stands about 4.5 feet tall and has a coat of soft light brown fur. He has golden eyes and a mischievous smile. He is relatively physically fit from being trained to fight from a young age, as well as having physically demanding hobbies such as climbing trees or play-fighting. He has a long tail that he frequently uses as an extra hand and that reflexively helps express his emotions.\n\nWukong wears a short-sleeved yellow silk shirt and red trousers, with a long red, green, and golden sash that winds around his chest and waist, with ends that hand loose over his back. He usually wears golden or brown sandals, but prefers to go barefoot when having fun outdoors. He very rarely wears his crown - a tiny golden cap that resembles the Monkey King\u2019s phoenix-feather cap, pinned into his fur - unless he\u2019s participating in a ceremony. He wears several chunky copper bracelets for good luck and to display his status, but usually takes those off when he can as they get in the way of tree climbing. He always carries an elaborately decorated bo staff with golden accents.\nSanzang\nSanzang is Wukong\u2019s best friend and a Simian peasant. He is a kind, gentle soul who tries his best to keep Wukong out of trouble, even though he often ends up going along with the prince\u2019s mischievous plans. He is very intelligent, but doesn\u2019t have the same opportunities as the prince because of his social status. He is a bit of a pushover and doesn\u2019t like confrontation, but he will stand up for what he believes in if he feels it\u2019s important enough.\n\nSanzang stands about 4.5 feet tall and has a coat of soft, dark brown fur. He has deep brown eyes and a warm smile. He is relatively physically fit from helping out with the family farm, but is not as strong or fast as Wukong or other fighters. He has a long tail that he frequently uses as an extra hand and that reflexively helps express his emotions.\n\nSanzang wears a short-sleeved white linen shirt and brown trousers, with a long brown sash that winds around his waist. He usually wears brown sandals, but prefers to go barefoot when he can. He very rarely wears any jewelry, as he doesn\u2019t have the money to afford it.\nAshira\nAshira is a low-ranking member of the Simian priesthood in her late teens, about the same age as Wukong. She is shy and quiet, but a hard worker. She tries to fulfill her temple duties as quickly and as perfectly as possible, both to please the gods whom she is fully devoted to, and to keep the priests from being angry with her. She is usually melancholy as the priests tend to treat her poorly. But she is devoted to the gods, and when she is able to worship, she is peaceful and happy.\n\nAshira\u2019s personality begins to shift as Wukong spends more time in the temple, taking lessons that will help him when he\u2019s king. She\u2019s both fascinated by and scared of him and his high status, and is stunned when he\u2019s as friendly and playful toward her as he is with anyone else. After she makes a mistake during a religious ritual, one of the priests is about to scold her until Wukong steps in and tells the priest to leave her alone. Ashira\u2019s respect for the prince grows, and she begins secretly meeting with him when the priests aren\u2019t around. Gradually she falls in love with him, and though she isn\u2019t quite sure, she thinks he feels the same way. She slowly begins to gain self-confidence and begins to wonder why she has to obey the priests all the time if they\u2019re not always right.\n\nAshira stands about 4 feet tall and has very soft light blond flaxen fur, which she grows longer on her head. She has a long tail that she rarely uses as an additional limb in the temple, but begins to form the habit as she does activities outside. She isn\u2019t very fit as she was born into a very sedentary role in life, but she isn\u2019t weak or frail. Her eyes are the same golden shade as Wukong\u2019s.\n\nAs a low-ranking priestess, Ashira wears a sleeveless white floor-length tunic with a long blue sash, both made of simple fabric. She wears simple brown sandals and typically does not go barefoot. She wears no jewelry or accessories other than a long necklace bearing the \u201cgoddess charm\u201d, a crystal carved into a flower sacred to Kwamya.", "I need your help with my assignment. I need to evaluate a venture pitch and write a report on it. I will first provide you with the group pitch, and then the assignment instructions so you can complete my assignment to help me achieve the highest possible grade. Below is the group pitch. Reply to this with 'yes' if you understand:\n\nHelpmates: A holistic app that provides services for working professionals\n\nTable of Contents:\n1. Executive Summary\n2. The Why\n3. The Context\n4. Business Model Canvas\n5. Product-Market Positioning\n6. Business Ecosystem\n7. Financials\n8. Implementation\n9. The Ask\n\n1. Executive Summary:\nProblem Addressed:\n\u2022 Currently, most service providers operate independently, on specific platforms or by word of mouth.\n\u2022 Helpmates brings all service providers onto one, easy-access platform.\n\u2022 Consumers will benefit from an all-encompassing platform which facilitates the finding of service providers.\nThe Platform:\n\u2022 An app which connects service providers with consumers:\no Consumers view range of services and service providers\no Consumers pick providers based on profile including ratings, location and price\no Consumers can book slots or message providers\n\u2022 Mainly monetized through commissions and advertisements\nThe Launch:\n\u2022 Launch in Sydney in 2023 amongst higher income customer segments, starting for household tasks (cleaning, gardening, plumbing, carpenting, etc.)\n\u2022 View to expand rapidly into other services once a strong service provider and customer base is established.\n\n2. The Why:\nWe came up with the idea of Helpmates out of personal experiences and by witnessing a gap in the market for a holistic services app. An app like Helpmates is specifically made for working professionals who are on a time crunch offering one click solutions for all household problems. The increasing number of working professionals and the fast-paced corporate culture laid down the need for an app like Helpmates. This is the only app currently in the market that offers hassle-free solutions and booking for top certified professionals.\n\n3. The Context:\nAccording to the PESTEL AND Porter's 5 Forces analyses:\n\u2022 Australia is a fast-growing economy and citizens are always looking for ways to save time.\n\u2022 Australia is an early adopter of technology making Helpmates easy to be implemented in the society.\n\u2022 The service industry is fast paced and ever changing and an app like Helpmates can help bring a wave of change in which people use professional services.\n\u2022 The service industry has significant potential. Helpmates provides high quality services at the best prices that the market has to offer.\n\n4. Business Model Canvas:\nKey Partners:\n\u2022 Freelancers\n\u2022 Local communities\n\u2022 Small businesses\n\u2022 Software developers\nKey Activities:\n\u2022 Connect service providers with customers\n\u2022 Encourage freelancing\nKey Resources\n\u2022 Large no. of users & service providers\n\u2022 Capital\n\u2022 App developer\nCost Structure:\n\u2022 Software Development cost\n\u2022 App Operating cost\n\u2022 Marketing cost\nValue Proposition:\n\u2022 Easy and flexible service\n\u2022 Easily accessible\n\u2022 Trust\n\u2022 Creating new income/job opportunities\nCustomer Relationships:\n\u2022 Customer service\n\u2022 Feedback/ratings\nChannels:\n\u2022 LinkedIn\n\u2022 Community\n\u2022 Facebook groups\n\u2022 Social media\nCustomer Segments:\n\u2022 Service users\n\u2022 Busy professionals\n\u2022 New-to-community service providers\n\u2022 Freelancers\n\u2022 Small businesses\n\u2022 Students\nRevenue Streams:\n\u2022 Commissions\n\u2022 Advertisements\n\u2022 Service Provider Boost (to show providers on top of list)\n\n5. Product-Market Positioning:\nProblems Customers Faced:\n\u2022 One Sided Platform: Supplier-oriented only or consumer-oriented only\n\u2022 Lack of Connection: Hard to find out service suppliers or service consumers\n\u2022 Lack of Efficiency: Long waiting time for reply and service delivery\n\u2022 Diverse Channels: Various platforms for different types of service\n\u2022 Lack of Accessibility: Difficult access to the service provider\n\u2022 Lack of Supply: Lack of personal services in wider areas\nMarket Positioning:\n\u2022 Target Market:\no Personal Service (including all types of personal services)\no Initial Focus: Low-skilled + High Demand (Clean/Housekeeping,\no Cafe/Restaurant, etc.)\n\u2022 Customers Segments:\no Service Suppliers - Everyone who needs services\no Service Consumers - Everyone who is willing to provide services\n\u2022 Early Adopter Target Customers:\no Service Suppliers: Freelancers & Students\no Service Consumers: New to community & Small businesses\n\u2022 Advantages/Values:\no Inclusivity & diversity (service coverage & user coverage)\no Strengthening community connection\no Empowering users to develop skills and gain jobs\no Guaranteed for services and payments\n\n6. Business Ecosystem:\nService Suppliers:\n\u2022 Freelancers\n\u2022 Students\n\u2022 Professional Workers\n\u2022 Anyone who is willing to\nprovide services\nService Consumers:\n\u2022 Busy Professionals\n\u2022 New to Community\n\u2022 Small Businesses\n\u2022 Anyone who needs services\nPotential Partners:\n\u2022 Investment Companies\n\u2022 Consultancy Agencies\n\u2022 Technic Supporting Agencies\n\u2022 Public/Governmental Welfare Organizations\n\u2022 Local Communities\n\u2022 Pension Agencies\n\u2022 Other Non-profit Organizations\nAdvertising Channels:\n\u2022 Searching Engines: Google\n\u2022 Social Media Platforms: Facebook, Instagram, Twitter, Tiktok\n\u2022 Streaming Media Platforms: Netflix, YouTube, Amazon Prime Video, Disney+\n\u2022 News Media/Newspapers\n\n7. Financials (Assumption):\nRealistic:\n\u2022 Monthly Traffic: 15,000\n\u2022 Conversion Rate: 30%\n\u2022 Average Transaction: $200\n\u2022 Monthly Sales Revenue: $900,000\n\u2022 Commission: 8%\n\u2022 Monthly Projected Income: $72,000\n\u2022 Number of Labor Supply: 1,000\n\u2022 Percentage Starter Boost: 5%\n\u2022 Starter Boost Fee: $800\n\u2022 Monthly Starter Boost Income: $40,000\nIdeal:\n\u2022 Monthly Traffic: 30,000\n\u2022 Conversion Rate: 30%\n\u2022 Average Transaction: $200\n\u2022 Monthly Sales Revenue: $2,400,000\n\u2022 Commission: 8%\n\u2022 Monthly Projected Income: $144,000\n\u2022 Number of Labor Supply: 2,000\n\u2022 Percentage Starter Boost: 10%\n\u2022 Starter Boost Fee: $1,000\n\u2022 Monthly Starter Boost Income: $200,000\n\n8. Financials:\nRevenue (Monthly):\n\u2022 Commission (0.5% Growth Rate per month assumed): $72,000\n\u2022 Starter Boost: $40,000\n\u2022 Advertisement: $5,000\nUpfront Costs:\n\u2022 Development Cost: $30,000\n\u2022 Uptake Cost: $20,000\nMonthly Costs:\n\u2022 Operating Cost: $10,000\n\u2022 Marketing Cost: $5,000\n2024 Total Revenue:\n\u2022 Total Revenue: $703,160\no Advertisement: $5,000\no Starter Boost: $40,000\no Commission: $72,000\nRevenue Projections:\n\u2022 Jan: $52,000\n\u2022 Feb: $57,360\n\u2022 Mar: $57,722\n\u2022 Apr: $58,085\n\u2022 May: $58,451\n\u2022 Jun: $58,818\n\u2022 Jul: $59,187\n\u2022 Aug: $59,558\n\u2022 Sep: $59,931\n\u2022 Oct: $60,306\n\u2022 Nov: $60,682\n\u2022 Dec: $61,060\n\n9. Implementation:\nLean Startup Method:\n1. Assumptions:\n\u2022 Freelancers need more jobs\n\u2022 Busy working individuals need more help with house services\n\u2022 Time consuming to search for help with some services\n2. Survey (Current Status):\n\u2022 Survey the interest and needs of the target customer\n\u2022 Target working professionals, Sydney CBD, LinkedIn, and survey small business and freelancers to know if they are interested\n3. Analyze the data (April 2023):\n\u2022 Above 70% positive results \uf0e0 move ahead with MVP for all the questions\n\u2022 Less than 70% \u2192 Pivot makes changes to meet customer needs\n4. Design MVP (July 2023):\n\u2022 App with basic features\n\u2022 Small area - Sydney CBD\n\u2022 Most commonly needed services\n\u2022 Partner with freelancers to join the platform\n\u2022 Feedback Included\n\u2022 Spread the word using LinkedIn\n5. Persist/Pivot/Perish (October 2023):\n\u2022 Success Criteria: Good Feedback (80% or 4+ star rating); at least 40-50 customer signups and transactions per month for the first 2 months; good User Growth\n\u2022 PIVOT: Only 50% positive feedback or ~less than 40 Users.\n\u2022 PERISH: 70% Negative feedback or ~10 Users; no User Growth.\n\n10. Implementation (Continued):\nCurrent Status:\n\u2022 Created a survey\n\u2022 Sending the survey to currently working professionals\n\u2022 Receiving feedback and interest in our app\n\u2022 Survey on LinkedIn as it has a large number of working professionals who have busy lives and would need help to maintain their house or other home services\nMVP Test:\n\u2022 App developer\n\u2022 UX/UI designer\n\u2022 Funding through bootstrapping\n\u2022 Gain a large number of users to test the product\n\n11. The Ask (Investment Proposal):\nThe Opportunity:\n\u2022 Invest in Helpmates pre-launch\n\u2022 App to aggregate and simplify searching for a large variety of services in one easy-access platform\n\u2022 Promoting accessible casual and freelance employment\n\u2022 Simple and low cost platform with potential for large commission based earnings\nOffer:\n\u2022 Investment of $50,000 for 10% equity\nUse:\n\u2022 $30,000 investment in targeted marketing for Sydney home service providers\n\u2022 $20,000 incentives and referral bonus for launch to increase service providers\nDesired Outcome:\n\u2022 Large-scale influx of service providers in the area to increase offering for customers\nAdditional Requests:\n\u2022 Networking with digital marketing professionals\n\u2022 Networking with a SaaS CTO to help drive the and UI/UX\nNext Steps:\n\u2022 Increase service types offering (e.g. babysitting, tutoring, bartending, hairdressing, etc.)\n\u2022 Expand into new regions with initial investments and incentives to boost app uptake\n\u2022 Continue spending 30% of revenue on marketing in order to expand the business and grow users", "using System;\nusing System.Collections.Generic;\nusing System.Linq;\nusing System.Text;\nusing System.Threading.Tasks;\nusing Love;\n\nnamespace LoveCSharp\n{\n class Program : Scene\n {\n public Player player1;\n public static float deltaTime;\n static void Main(string[] args)\n {\n Boot.Init();\n Boot.Run(new Program());\n }\n public override void Load()\n {\n World.Generate(20,20);\n player1 = new Player(5, 5);\n\n // Love.Mouse.SetVisible(false);\n // Love.Mouse.SetGrabbed(true);\n Love.Mouse.SetRelativeMode(true);\n \n }\n public override void Draw()\n {\n Ray.Draw(player1.x, player1.y, Ray.distance, player1.angle, player1.fov);\n World.Draw();\n player1.Draw();\n \n }\n public override void Update(float dt)\n {\n deltaTime = dt;\n player1.Update(dt);\n Ray.Update(player1.x, player1.y, player1.angle, player1.fov);\n if (Love.Keyboard.IsDown(KeyConstant.Escape))\n {\n Love.Event.Quit();\n }\n }\n public override void MouseMoved(float x, float y, float dx, float dy, bool istouch)\n {\n player1.Rotation(dx);\n }\n }\n public enum TileType\n {\n None,\n Block,\n }\n public class World\n {\n public static int width;\n public static int height;\n public static int scale = 10;\n public static TileType[,] tiles;\n public static void Generate(int width = 20, int height = 20)\n {\n World.width = width;\n World.height = height;\n\n TileType[,] tiles = new TileType[width, height];\n\n for (int x = 0; x < width; x++)\n {\n for (int y = 0; y < height; y++)\n {\n tiles[x, y] = TileType.Block;\n }\n }\n for (int x = 0; x < width; x++)\n {\n \n for (int y = 0; y < height; y++)\n {\n if ((x > 0 && x < width - 1) && (y > 0 && y < height - 1))\n {\n tiles[x, y] = TileType.None;\n }\n }\n }\n // Generate a random number of TileType blocks in the world (tiles)\n Random random = new Random();\n int blockCount = random.Next(10, 20);\n for (int i = 0; i < blockCount; i++)\n {\n int x = random.Next(0, width);\n int y = random.Next(0, height);\n tiles[x, y] = TileType.Block;\n }\n \n World.tiles = tiles;\n }\n public static void Draw()\n {\n Graphics.SetColor(Color.White);\n Graphics.Rectangle(DrawMode.Line, 0, 0, width \\* scale, height \\* scale);\n\n Graphics.SetColor(Color.Firebrick);\n for (int x = 0; x < width; x++)\n {\n for (int y = 0; y < height; y++)\n {\n if (tiles[x, y] == TileType.Block)\n {\n Graphics.Rectangle(DrawMode.Fill, x \\* scale, y \\* scale, scale, scale);\n }\n }\n }\n }\n }\n public class Player\n {\n public float x, y, w, h, speed, angle, directionX, directionY;\n public float sensitivity = 0.3f;\n public int fov = 60;\n public Player(float x, float y, float w = 30, float h = 50, float speed = 1, float angle = 0)\n {\n this.x = x;\n this.y = y;\n this.w = w;\n this.h = h;\n this.speed = speed;\n this.angle = angle;\n }\n public void Draw()\n {\n Graphics.SetColor(Color.AliceBlue);\n Graphics.SetPointSize(3);\n Graphics.Points(this.x \\* World.scale, this.y \\* World.scale);\n Graphics.SetColor(Color.White);\n Graphics.Print(\"X: \" + this.x + \" Y: \" + this.y, 0, 0);\n Graphics.Print(\"Angle: \" + this.angle, 0, 20);\n }\n public void Update(float dt)\n {\n Movement(dt);\n\n }\n\n private void Movement(float dt)\n {\n float directionX = 0;\n float directionY = 0;\n if (Keyboard.IsDown(KeyConstant.W))\n {\n directionY = -1;\n }\n if (Keyboard.IsDown(KeyConstant.S))\n {\n directionY = 1;\n }\n if (Keyboard.IsDown(KeyConstant.A))\n {\n directionX = -1;\n }\n if (Keyboard.IsDown(KeyConstant.D))\n {\n directionX = 1;\n }\n\n float rotatedDirectionX = (float)Math.Cos(this.angle) \\* directionX - (float)Math.Sin(this.angle) \\* directionY;\n float rotatedDirectionY = (float)Math.Sin(this.angle) \\* directionX + (float)Math.Cos(this.angle) \\* directionY;\n\n float directionLength = (float)Math.Sqrt(rotatedDirectionX \\* rotatedDirectionX + rotatedDirectionY \\* rotatedDirectionY);\n if (directionLength > 0)\n {\n rotatedDirectionX /= directionLength;\n rotatedDirectionY /= directionLength;\n }\n\n this.x += rotatedDirectionX \\* this.speed \\* dt;\n this.y += rotatedDirectionY \\* this.speed \\* dt;\n }\n public void Rotation(float dx)\n {\n this.angle += dx \\* sensitivity \\* Program.deltaTime;\n \n }\n }\n public class Ray\n {\n public static float distance;\n\n public static float Cast(float x, float y, float centerAngle, float fov)\n {\n float startX = x;\n float startY = y;\n string section;\n float quality = 0.1f;\n int screenWidth = 800;\n int screenHeight = 600;\n\n for (float angle = centerAngle - fov / 2; angle < centerAngle + fov / 2; angle += Quality(fov, quality, screenWidth))\n {\n float endX = (float)(startX + Math.Cos(angle) \\* 1000);\n float endY = (float)(startY + Math.Sin(angle) \\* 1000);\n\n section = FacingSection(angle);\n\n if (section == \"NE\")\n {\n for (float i = startX; i < endX; i += quality)\n {\n float j = (float)(startY + (i - startX) \\* Math.Tan(angle));\n if (World.tiles[(int)i / World.scale, (int)j / World.scale] == TileType.Block)\n {\n distance = Distance(startX, startY, i, j);\n return distance;\n }\n }\n }\n else if (section == \"NW\")\n {\n for (float i = startX; i > endX; i -= quality)\n {\n float j = (float)(startY + (i - startX) \\* Math.Tan(angle));\n if (World.tiles[(int)i / World.scale, (int)j / World.scale] == TileType.Block)\n {\n distance = Distance(startX, startY, i, j);\n return distance;\n }\n }\n }\n else if (section == \"SW\")\n {\n for (float i = startX; i > endX; i -= quality)\n {\n float j = (float)(startY + (i - startX) \\* Math.Tan(angle));\n if (World.tiles[(int)i / World.scale, (int)j / World.scale] == TileType.Block)\n {\n distance = Distance(startX, startY, i, j);\n return distance;\n }\n }\n }\n else if (section == \"SE\")\n {\n for (float i = startX; i < endX; i += quality)\n {\n float j = (float)(startY + (i - startX) \\* Math.Tan(angle));\n if (World.tiles[(int)i / World.scale, (int)j / World.scale] == TileType.Block)\n {\n distance = Distance(startX, startY, i, j);\n return distance;\n }\n }\n }\n }\n return 0;\n }\n public static string FacingSection(float angle)\n {\n string facing = \"\";\n if (angle >= 0 && angle < Math.PI / 2)\n {\n facing = \"NE\";\n }\n else if (angle >= Math.PI / 2 && angle < Math.PI)\n {\n facing = \"NW\";\n }\n else if (angle >= Math.PI && angle < 3 \\* Math.PI / 2)\n {\n facing = \"SW\";\n }\n else if (angle >= 3 \\* Math.PI / 2 && angle < 2 \\* Math.PI)\n {\n facing = \"SE\";\n }\n return facing;\n }\n public static float Quality(float fov, float quality, float screenWidth)\n {\n \n // float angle = fov / screenWidth;\n // quality = angle / quality;\n // return quality;\n float angleBetweenRays = fov / screenWidth;\n float qualityAngle = (float)Math.Atan(quality / 2);\n float qualityAngleBetweenRays = qualityAngle / angleBetweenRays;\n return qualityAngleBetweenRays;\n }\n\n public static float Distance(float x1, float y1, float x2, float y2)\n {\n float distance = (float)Math.Sqrt((x2 - x1) \\* (x2 - x1) + (y2 - y1) \\* (y2 - y1));\n return distance;\n }\n\n public static void Draw(float x, float y, float distance, float angle, float fov)\n {\n \n float angleBetweenRays = fov / 800;\n float distanceToProjectionPlane = 800 / (2 \\* (float)Math.Tan(fov / 2));\n float distanceToWall = distance;\n float distanceToProjectionPoint = distanceToWall \\* (float)Math.Cos(angleBetweenRays);\n distanceToProjectionPlane = distanceToProjectionPoint \\* distanceToProjectionPlane / distanceToWall;\n float height = 600 / distanceToProjectionPlane;\n float width = 1;\n float color = 255 / distanceToWall;\n Graphics.SetColor(Color.FromRGBA(color, color, color, 255));\n Graphics.Rectangle(DrawMode.Fill, x, y - height / 2, width, height);\n \n\n }\n public static void Update(float x, float y, float angle, float fov)\n {\n Cast(x, y, angle, fov);\n \n \n }\n }\n}", "using System;\nusing System.Collections.Generic;\nusing System.Linq;\nusing System.Text;\nusing System.Threading.Tasks;\nusing Love;\n\nnamespace LoveCSharp\n{\n class Program : Scene\n {\n public Player player1;\n public static float deltaTime;\n static void Main(string[] args)\n {\n Boot.Init();\n Boot.Run(new Program());\n }\n public override void Load()\n {\n World.Generate(20,20);\n player1 = new Player(5, 5);\n\n // Love.Mouse.SetVisible(false);\n // Love.Mouse.SetGrabbed(true);\n Love.Mouse.SetRelativeMode(true);\n \n }\n public override void Draw()\n {\n World.Draw();\n player1.Draw();\n Ray.Draw(player1.x, player1.y, Ray.distance, player1.angle, player1.fov);\n \n }\n public override void Update(float dt)\n {\n deltaTime = dt;\n player1.Update(dt);\n Ray.Update(player1.x, player1.y, player1.angle, player1.fov);\n if (Love.Keyboard.IsDown(KeyConstant.Escape))\n {\n Love.Event.Quit();\n }\n }\n public override void MouseMoved(float x, float y, float dx, float dy, bool istouch)\n {\n player1.Rotation(dx);\n }\n }\n public enum TileType\n {\n None,\n Block,\n }\n public class World\n {\n public static int width;\n public static int height;\n public static int scale = 10;\n public static TileType[,] tiles;\n public static void Generate(int width = 20, int height = 20)\n {\n World.width = width;\n World.height = height;\n\n TileType[,] tiles = new TileType[width, height];\n\n for (int x = 0; x < width; x++)\n {\n for (int y = 0; y < height; y++)\n {\n tiles[x, y] = TileType.Block;\n }\n }\n for (int x = 0; x < width; x++)\n {\n \n for (int y = 0; y < height; y++)\n {\n if ((x > 0 && x < width - 1) && (y > 0 && y < height - 1))\n {\n tiles[x, y] = TileType.None;\n }\n }\n }\n // Generate a random number of TileType blocks in the world (tiles)\n Random random = new Random();\n int blockCount = random.Next(10, 20);\n for (int i = 0; i < blockCount; i++)\n {\n int x = random.Next(0, width);\n int y = random.Next(0, height);\n tiles[x, y] = TileType.Block;\n }\n \n World.tiles = tiles;\n }\n public static void Draw()\n {\n Graphics.SetColor(Color.White);\n Graphics.Rectangle(DrawMode.Line, 0, 0, width \\* scale, height \\* scale);\n\n Graphics.SetColor(Color.Firebrick);\n for (int x = 0; x < width; x++)\n {\n for (int y = 0; y < height; y++)\n {\n if (tiles[x, y] == TileType.Block)\n {\n Graphics.Rectangle(DrawMode.Fill, x \\* scale, y \\* scale, scale, scale);\n }\n }\n }\n }\n }\n public class Player\n {\n public float x, y, w, h, speed, angle, directionX, directionY;\n public float sensitivity = 0.3f;\n public int fov = 60;\n public Player(float x, float y, float w = 30, float h = 50, float speed = 1, float angle = 0)\n {\n this.x = x;\n this.y = y;\n this.w = w;\n this.h = h;\n this.speed = speed;\n this.angle = angle;\n }\n public void Draw()\n {\n Graphics.SetColor(Color.AliceBlue);\n Graphics.SetPointSize(3);\n Graphics.Points(this.x \\* World.scale, this.y \\* World.scale);\n Graphics.SetColor(Color.White);\n Graphics.Print(\"X: \" + this.x + \" Y: \" + this.y, 0, 0);\n Graphics.Print(\"Angle: \" + this.angle, 0, 20);\n }\n public void Update(float dt)\n {\n Movement(dt);\n\n }\n\n private void Movement(float dt)\n {\n float directionX = 0;\n float directionY = 0;\n if (Keyboard.IsDown(KeyConstant.W))\n {\n directionY = -1;\n }\n if (Keyboard.IsDown(KeyConstant.S))\n {\n directionY = 1;\n }\n if (Keyboard.IsDown(KeyConstant.A))\n {\n directionX = -1;\n }\n if (Keyboard.IsDown(KeyConstant.D))\n {\n directionX = 1;\n }\n\n float rotatedDirectionX = (float)Math.Cos(this.angle) \\* directionX - (float)Math.Sin(this.angle) \\* directionY;\n float rotatedDirectionY = (float)Math.Sin(this.angle) \\* directionX + (float)Math.Cos(this.angle) \\* directionY;\n\n float directionLength = (float)Math.Sqrt(rotatedDirectionX \\* rotatedDirectionX + rotatedDirectionY \\* rotatedDirectionY);\n if (directionLength > 0)\n {\n rotatedDirectionX /= directionLength;\n rotatedDirectionY /= directionLength;\n }\n\n this.x += rotatedDirectionX \\* this.speed \\* dt;\n this.y += rotatedDirectionY \\* this.speed \\* dt;\n }\n public void Rotation(float dx)\n {\n this.angle += dx \\* sensitivity \\* Program.deltaTime;\n \n }\n }\n public class Ray\n {\n public static float distance;\n\n public static float Cast(float x, float y, float centerAngle, float fov)\n {\n float startX = x;\n float startY = y;\n string section;\n float quality = 0.1f;\n int screenWidth = 800;\n int screenHeight = 600;\n\n for (float angle = centerAngle - fov / 2; angle < centerAngle + fov / 2; angle += Quality(fov, quality, screenWidth))\n {\n float endX = (float)(startX + Math.Cos(angle) \\* 50);\n float endY = (float)(startY + Math.Sin(angle) \\* 50);\n\n section = FacingSection(angle);\n\n if (section == \"NE\")\n {\n for (float i = startX; i < endX; i += quality)\n {\n float j = (float)(startY + (i - startX) \\* Math.Tan(angle));\n if (World.tiles[(int)i / World.scale, (int)j / World.scale] == TileType.Block)\n {\n distance = Distance(startX, startY, i, j);\n return distance;\n }\n }\n }\n else if (section == \"NW\")\n {\n for (float i = startX; i > endX; i -= quality)\n {\n float j = (float)(startY + (i - startX) \\* Math.Tan(angle));\n if (World.tiles[(int)i / World.scale, (int)j / World.scale] == TileType.Block)\n {\n distance = Distance(startX, startY, i, j);\n return distance;\n }\n }\n }\n else if (section == \"SW\")\n {\n for (float i = startX; i > endX; i -= quality)\n {\n float j = (float)(startY + (i - startX) \\* Math.Tan(angle));\n if (World.tiles[(int)i / World.scale, (int)j / World.scale] == TileType.Block)\n {\n distance = Distance(startX, startY, i, j);\n return distance;\n }\n }\n }\n else if (section == \"SE\")\n {\n for (float i = startX; i < endX; i += quality)\n {\n float j = (float)(startY + (i - startX) \\* Math.Tan(angle));\n if (World.tiles[(int)i / World.scale, (int)j / World.scale] == TileType.Block)\n {\n distance = Distance(startX, startY, i, j);\n return distance;\n }\n }\n }\n }\n return 0;\n }\n public static string FacingSection(float angle)\n {\n string facing = \"\";\n if (angle >= 0 && angle < Math.PI / 2)\n {\n facing = \"NE\";\n }\n else if (angle >= Math.PI / 2 && angle < Math.PI)\n {\n facing = \"NW\";\n }\n else if (angle >= Math.PI && angle < 3 \\* Math.PI / 2)\n {\n facing = \"SW\";\n }\n else if (angle >= 3 \\* Math.PI / 2 && angle < 2 \\* Math.PI)\n {\n facing = \"SE\";\n }\n return facing;\n }\n public static float Quality(float fov, float quality, float screenWidth)\n {\n \n // float angle = fov / screenWidth;\n // quality = angle / quality;\n // return quality;\n float angleBetweenRays = fov / screenWidth;\n float qualityAngle = (float)Math.Atan(quality / 2);\n float qualityAngleBetweenRays = qualityAngle / angleBetweenRays;\n return qualityAngleBetweenRays;\n }\n\n public static float Distance(float x1, float y1, float x2, float y2)\n {\n float distance = (float)Math.Sqrt((x2 - x1) \\* (x2 - x1) + (y2 - y1) \\* (y2 - y1));\n return distance;\n }\n\n public static void Draw(float x, float y, float distance, float angle, float fov)\n {\n \n float angleBetweenRays = fov / 800;\n float distanceToProjectionPlane = 800 / (2 \\* (float)Math.Tan(fov / 2));\n float distanceToWall = distance;\n float distanceToProjectionPoint = distanceToWall \\* (float)Math.Cos(angleBetweenRays);\n distanceToProjectionPlane = distanceToProjectionPoint \\* distanceToProjectionPlane / distanceToWall;\n float height = 600 / distanceToProjectionPlane;\n float width = 1;\n float color = 255 / distanceToWall;\n Graphics.SetColor(Color.FromRGBA(color, color, color, 255));\n Graphics.Rectangle(DrawMode.Fill, x, y - height / 2, width, height);\n \n\n }\n public static void Update(float x, float y, float angle, float fov)\n {\n Ray.distance = Cast(x, y, angle, fov);\n \n \n }\n }\n}", "Continue the course on the next slide building the slides and the transcript with the following content: Blood tests\nS100B, MIA, LDH blood tests for initial staging\nTwo small studies were identified assessing the diagnostic accuracy of either p-proteasome, MIA, S-100B, or LDH for melanoma metastases.[22][23] In the first study of 53 clinical stage I-II melanoma patients, 68 stage III-IV patients and 40 healthy volunteers, plasma samples were obtained before definitive surgical excision or treatment and followed for a median of 17 months. Reference standard positive patients were a mixture of patients with clinical stage III/IV disease at the outset and patients with clinical stage I/II who then developed metastases during follow-up (detected through clinical examinations and imaging tests). Likewise reference standard negative patients were a mixture of healthy volunteers and patients with clinical stage I/II disease who did not develop metastases during follow-up. Within the limitations of the substantial spectrum bias arising from the selection of the study population which was not limited to asymptomatic stage I/II patients, the area under the receiver operating curves (ROC) for p-proteasome and S100B were the highest (0.81,and 0.82 respectively), whereas LDH and MIA showed lower values (0.79, and 0.72 respectively).[22] In the second study, of 87 stage I/II patients, 71 stage III/IV patients and 50 healthy volunteers, serum concentrations were measured before surgery.[23] The reference standard was again a composite of clinical exams and imaging tests to define whether or not the patient had stage III/IV disease at either the outset or during a median of 32.8 months follow-up. The authors reported that a cut-off value for MIA of 9.4 ng/ml, had 77% sensitivity and 94% specificity for the detection of stage IV disease. Among the 87 patients with stage I/II disease after imaging, 66% of those with MIA serum values greater than 9.4 ng/mL developed regional or distant metastases during follow-up , while 5% of those with values below this threshold developed metastases.[23]\n\nStandard blood tests for initial staging and follow-up (e.g. electrolytes, urea, creatinine, liver function tests [LFTs], full blood count [FBC])\nEvidence from previous guidelines states the routine use of standard blood tests rarely identifies occult stage IV disease in patients presenting with stage I or II melanoma and is not recommended. See [ANZ Melanoma guidelines]. These tests are not new and were therefore outside the scope of the current systematic review and guideline.\n\nS100B, MIA, LDH blood tests during follow-up\nAs a tumour marker, S100B displays a sensitivity of 86\u201391 %, specificity[24][25] and may portend recurrence, however there are no data demonstrating superior survival outcomes for patients undergoing routine S100B testing in follow up. The use of serum LDH or melanoma-inhibitory activity (MIA) protein in follow up for the detection of asymptomatic melanoma recurrence has been reviewed by Fields and Coit.[26] Abnormal blood tests were rarely the first sign of metastases. Low sensitivity, specificity, and accuracy for general laboratory profiles make them ineffective in the detection of subclinical recurrence and their roles are yet to be defined.\n\nInvestigations for stage I-II patients with no sentinel node biopsy (ie. declined or patient unfit)\nUltrasonography for initial staging\nFor situations where SLNB has been declined or is not possible for technical reasons or patient co-morbidities, ultrasound monitoring may be considered, however 4 studies have shown poorer accuracy (both sensitivity and specificity) compared to SLNB[27][28][29][30], and so the latter is preferred whenever feasible (see chapter on SNLB). No studies were identified in patients who were not eligible for SLNB.\n\nIn three of the studies assessing ultrasonography against a reference standard of SNLB, the sensitivity of ultrasound ranged from 13% to 71%; the specificity from 57% to 97%[27][28][29]; and in two studies the positive predictive value ranged from 37% to 97%, while the negative predictive value ranged from 13% to 84%.[27][29] In one study that assessed a particular ultrasound characteristic (the echo free island) the sensitivity was 11%, the specificity 98%, the positive predictive value was 50% and the negative predictive value was 80%.[30]\n\nOne small study compared high resolution ultrasound (HRUSS) with PET/CT against a reference standard of SNB in 20 patients with clinically stage I/II disease.[16] HRUSS correctly identified two of 12 patients with positive SLNs whereas PET/CT imaging identified none; both imaging tests correctly identified all 12 patients with negative SLNs.[16]\n\nUltrasonography during follow-up\nThe usefulness of ultrasonography for follow-up of patients treated for Stage I/II melanoma depends entirely on the technical skill and experience of the personnel involved. There is a consensus of opinion that ultrasound is superior to clinical examination of regional lymph nodes, although its survival advantage is unproven.[31] A prospective cohort study of 373 patients with a primary tumour Breslow thickness of \u22651.5mm[32], reported a sensitivity of 93% for ultrasound compared with only 71% for the clinical examination of regional lymph nodes. Their specificity was equally high for both procedures (>98%). Despite the superiority of ultrasound, very few patients actually benefited from the addition of ultrasound to clinical examination. The reasons cited for this were that although ultrasound was useful in the earlier detection of regional disease or avoidance of unnecessary surgery in 7% of patients, 6% had deleterious effects such as unnecessary stress caused by repetition of ultrasounds for benign lymph nodes or useless removal of benign lymph nodes.[32] Thus in sum, in only 1% of patients was the use of ultrasound advantageous.\n\nUltrasound +/- Fine needle aspiration (FNA) +/- core biopsy for initial staging\nOne prospective study assessed whether the combination of ultrasound and fine needle biopsy could be used as a \u2018triage\u2019 test for SLNB in 107 asymptomatic patients with clinically stage I/II melanoma.[33] Using this test strategy, only two patients had final positive results, of which one could not be confirmed on histopathology (possible false positive) and the other was confirmed (true positive). Of the 105 patients who were negative on ultrasound +FNA, 36 were false negatives (nodal metastases found on SLNB), and 69 were true negatives.\n\nUltrasound +/- Fine needle aspiration (FNA) +/- core biopsy during follow-up\nFNA is the current standard method to confirm the presence of suspected nodal metastases for lymphadenopathy identified after definitive local treatment of cutaneous melanoma.[34][35] Ultrasound guidance should be used as the diagnostic yield is superior, particularly for small lymph nodes <10mm in size. Core biopsy has higher sensitivity and specificity compared with FNA and should be considered where FNA is negative but clinical suspicion remains high. There is no role for routine lymph node biopsy during follow up of asymptomatic patients.[36]\n\nOther investigations during follow-up\nSkin Self-Examination\nA review of 9 clinical practice guidelines by Marciano et al (2014)[37] reveals consensus that patients should be taught skin self-examination; this was based on retrospective evidence from several studies that recurrences were commonly first detected by patients. For this recommendation, 4 guidelines varied in evidence content while 5 guidelines provided consensus opinion only. Education on sun-smart behaviour was recommended by 4 guidelines.[37]\n\nSuccessfully implementing self-examination requires patient education on whole-body skin examination with particular attention given to melanoma surgical scars and the corresponding lymphatic drainage areas for in-transit and lymph node recurrence. Patients should also be given education regarding symptoms that may warrant further investigation, such as pain, fatigue, weight loss, nausea and vomiting, dyspneoa, and headache. In addition, the use of brochures or videos, and the engagement of relatives in the education process may be helpful.[38][39][40] Randomized controlled trials do not exist. In Australia, patients themselves detect up to 75% of recurrences, while in other countries this can be as low as 20%.9-13 These data highlight the fact that even with education, there are great differences in patients\u2019 individual ability to detect recurrences.[40]\n\nHistory and physical examination during follow-up\nThere is general consensus that the most cost-effective component of a strategy resulting in the detection of the majority of recurrences is careful history taking and physical examination. The detection of distant metastases in patients with early localised disease is unusual.\n\nAs with self-examination, history and physical examination include specific history taking, a full skin examination looking for new primaries, palpation of melanoma surgical scars, and lymphatic drainage areas for in-transit and lymph node recurrence. Apart from patient self-detected relapses, most relapses and secondary melanomas are detected during physical examinations.[41][42] In a large prospective study12, roughly 50 % of recurrences were identified by history taking/physical examination, 80 % of which were local recurrences, in-transit metastases, and regional lymph node metastases.[41] Indeed, the vast majority of operable recurrences (96%) are those detected by physical examinations.14 In summary, history and physical examinations for patients with stages I\u2013III melanoma are the most effective procedure for early recurrence detection.[43][8]", "This is part 5 of my multiple messages. I will continue to send you further messages. If you understand then please limit your response to \"acknowledged\". \nBackground\n\n \n\nDefinition of a Cost Plus Contract\n\nA Cost Plus contract is one where, under it, the parties agree that the builder is to be paid the cost of the work done plus a profit percentage.\n\n \n\nIn any home building project there are going to be risks. The question arises who is going to bear a given risk? The building contract acts as a formula for allocating those risks between the parties.\n\n \n\nThe golden rule of contractual risk allocation should be that party who should bear the risk of an event occurring is the party who is in the best position to avoid that event occurring.\n\n \n\nThe Reasons the Industry Standard Form Contracts Are Unacceptable\n\n \n\nThe two cost plus contracts most in use in New South Wales are:\n\n \n\nThe Master Builders Association CPC Residential Cost Plus Contract\n\nThe Housing Industry Association Cost Plus Contract\n\n \n\nIn every important respect, these Cost Plus contracts breach the golden rule of contractual risk allocation.\n\n \n\nThe major risks that arise in a home building contract are:\n\n \n\n (a) the risk that the builder may have underestimated his costs and underpriced the job,\n\n \n\n \n\n(b) the risk that the work may not be completed in the time provided for in the contract\n\n \n\n(c) the risk that the work may be defective and require expensive rectification\n\n \n\n(d) the risk that the work will not conform to the plans or specifications.\n\n \n\nYou need to look at the contracts to see how they deal with these risks.\n\n \n\nMASTER BUILDERS ASSOCIATION COST PLUS CONTRACT CPC RESIDENTIAL\n\n \n\nThe Risk That the Builder May Have Underestimated His Costs and Underpriced the Job\n\n \n\nA Cost Plus contract is usually preceded by an \"estimate\" of the costs of the works. That estimate is produced by the builder. In my experience this \"estimate\" is seldom, if ever, included in the contract. That \"estimate\" is usually a very low one. Often the builder tenders to do the work for a much higher fixed\u2011price contract and persuades the owners to enter into the Cost Plus contract on the basis that \"it will be much cheaper this way.\"\n\n \n\nSchedule 1 of the Master Builders Association Cost Plus Contract provides that, among the costs which the builder is entitled to claim are:\n\n \n\no all wages and other entitlements payable to the builder's employees or payable by reason of such employment...\n\no the builder's own work....,\n\no costs of any services ....\n\no costs of all trade contractors.....\n\no cost of hired equipment ....\n\no cost for the use of plant and equipment belonging to the builder....\n\no the cost of correcting modifying or changing work already completed, which is changed by reason of a variation by the Owner, all which is defective or reasons other than due to materials provided by the Builder or the workmanship of the Builder.\n\no the cost of complying with any site specific issues such as safety and pollution and waste disposal......\n\no any other costs or expenses which the builder is liable for or incurs by reason of\n\n carrying out the work including insurance costs......\n\n \n\n \n\nThe essential thing to realise is that every one of these costs, which could be greater or lesser according to the approach and conduct of the builder, will not be borne by the builder. Indeed if the builder is careless and, as a result, these costs increase, the builder will be rewarded for his carelessness by an equivalent increase in his profit, as any increase in the cost of the works is going to increase what he is paid as a percentage of that cost. The structure of the contract is also almost an invitation to fraud in that the builder can exaggerate the hours which he or his employees have spent on the job and unless the owners have someone observing the site at all times, it will be impossible to prove that the hours claimed were not spent on site. I have known of unscrupulous builders arranging for the labour on projects of their own to be entirely paid for by the owners of another site in this way. Even if the builder is not so unscrupulous, he is unlikely to be driving his workers as it is not to his commercial advantage to do so.\n\n \n\nWith respect to the builder's optimistic estimates of cost, Clause 3(d) provides that:\n\n \n\n Contract Represents Entire Agreement\n\n \n\n(d) Apart from any terms implied by Statute, the whole of the terms, conditions and warranties of this Contract are set out in the Contract, drawings and specifications (as per Schedule 3) and will not and are not in any way varied or affected by reference to any prior negotiations, stipulations or agreement, whether written or verbal.\n\n \n\nWhat this means is that all the optimistic estimates of costs, and the things that the builder said about the ultimate cost of the works, are not part of the contract.\n\n \n\nThe Risk That the Work May Not Be Completed in the Time Provided for in the Contract\n\n \n\nWith respect to the builder's estimates of time, there is no liquidated damages clause in this contract. Although the statutory warranties, which cannot be excluded by contract, give an owner a right to sue if the time taken is greater than the contract time or a reasonable time if no contract time exists, until a court decides that issue, the owner must still pay the builder in full and cannot deduct anything for delays.\n\n \n\nThe Risk That the Work May Be Defective and Require Expensive Rectification\n\n \n\nIf you look at paragraph (g) of Schedule 1 you will see that the Builder, under the Contract, is entitled to recover the whole cost of rectifying defective work even if that defective work was performed by the builder's sub contractors or employees under his control. The only exception is where the work was physically performed by the builder himself. With regard to liability for subcontractors, this is an attempt at sidestepping the statutory warranties imposed by section 18B of the Act. Eventually, after consideration by a Court or Tribunal, the clause may fall foul of the prohibition in section 18G, but the drafting gives the builder a considerable bargaining and tactical advantage.\n\n \n\nThe Risk That the Work Will Not Conform to the Plans Or Specifications\n\n \n\n \n\nA careful reading of paragraph (g) of Schedule 1 will show that the builder is in a position to argue that the cost of correcting works which have not been built in accordance with plan must also be borne by the owner even if the failure to comply with plan was the fault of the builder. This is again an attempt at sidestepping the statutory warranties imposed by section 18B of the Act. Eventually, again after consideration by a Court or Tribunal, the clause may fall foul of the prohibition in section 18G, but the drafting gives the builder a considerable bargaining and tactical advantage.\n\n \n\nSummary of the Master Builders Association Cost Plus Contract\n\n \n\nThe Master Builders Association and Cost Plus Contract is a contract in which the builder has absolutely no incentive to complete the work in accordance with the plans, or free of defects, or on budget or on time because he suffers no loss if he fails to do so. Indeed if he goes over budget he profits from it.\n\n \n\nHOUSING INDUSTRY ASSOCIATION COST PLUS CONTRACT\n\n \n\nLet us look at Schedule 2 of the Housing Industry Association Cost Plus Contract.\n\n \n\nThe Risk That the Builder May Have Underestimated His Costs and Underpriced the Job\n\n \n\nIf you carefully read that schedule you will see that it has all of the problems that we discussed in the Master Builders Cost Plus Contract. It is perhaps not as well drafted. Otherwise the only difference between the Housing Industry Association Cost Plus Contract and the Master Builders Association Cost Plus Contract is that in the Housing Industry Association Contract there is no Entire Agreement clause. That was probably just a drafting error.\n\n \n\nThe Risk That the Work May Not Be Completed in the Time Provided for in the Contract\n\n \n\nWith respect to the builder's estimates of time, there is again no liquidated damages clause in this contract. Although the statutory warranties give an owner a right to sue if the time taken is greater than the contract time or a reasonable time if no contract time exists, until a court decides that issue, the owner must still pay the builder in full and cannot deduct anything for delays.\n\n \n\nThe Risk That the Work May Be Defective and Require Expensive Rectification\n\n \n\n \n\nIf you look at paragraph (g) of Schedule 1 you will see that essentially the Owners must pay for everything including the cost to rectify defects. There appears to be a drafting error in that it may have been intended in paragraph (g) to exclude, from costs payable by the owner, faulty materials and workmanship the responsibility of the builder when those costs are incurred during the defects liability period. Unfortunately as a result of a drafting or printing error the paragraph was left incomplete and it is not clear what was meant. There is definitely no concession that the builder must bear the costs of rectification of any defects if they are rectified during the construction period of the contract. Again, with regard to liability for defective work, this is an attempt at sidestepping the statutory warranties imposed by section 18B of the Act. Eventually, after consideration by a higher Court, the attempt may fall foul of the prohibition in section 18G, but the drafting gives the builder a considerable bargaining and tactical advantage.\n\n \n\nThe Risk That the Work Will Not Conform to the Plans Or Specifications\n\n \n\nA careful reading of Schedule 1 will show that the builder is in a position to argue that any cost in connection with the works, including the cost of correcting works which have not been built in accordance with plan must also be borne by the owner even if the failure to comply with plan was the fault of the builder.\n\n \n\nThe Victorian or the Queensland Legislation?\n\nI recommend following the Victorian legislation which allows for slightly more freedom of contract than the Queensland legislation and does not have Courts deciding which costs can and cannot be reasonably calculated. The critical thing is to ensure that the builder has an interest in preventing the cost of the work blowing out excessively.", "when trying to run the code below in jupyter notebook i get an error\n\nCODE:\n'''\ncols = 2\nrows = math.ceil(len(sorted\\_interesting\\_tokens) / cols)\nfig, axes = plt.subplots(rows, cols, figsize=(cols\\*5, rows\\*3))\nfor ix, token in enumerate(sorted\\_interesting\\_tokens):\n\n bigram\\_df = bigram\\_dfs[token]\n\n t\\_adf = copy.deepcopy(activation\\_df.query('token==@token'))\n t\\_adf['prefix'] = activation\\_df.loc[t\\_adf.index.values - 1, 'token'].values\n\n valid\\_prefix\\_tokens = set(bigram\\_dfs[token].index.values)\n token\\_strs = [decoded\\_vocab[t] for t in valid\\_prefix\\_tokens]\n\n ax = axes[ix//2, ix%2]\n sns.boxplot(t\\_adf, x='prefix', y='activation', order=bigram\\_dfs[token].index.values, ax=ax)\n ax.set\\_xticklabels([decoded\\_vocab[int(t.get\\_text())].replace('$', '\\$') for t in ax.get\\_xticklabels()], rotation=80);\n ax.set\\_title(f'Activations for {token}: \"{decoded\\_vocab[token]}\" by preceding token')\nplt.tight\\_layout(pad=0)\n'''\n\nERROR:\n'''\n/state/partition1/slurm\\_tmp/22129042.0.0/ipykernel\\_16294/4186583921.py:20: UserWarning: Glyph 12290 (\\N{IDEOGRAPHIC FULL STOP}) missing from current font.\n plt.tight\\_layout(pad=0)\n/state/partition1/slurm\\_tmp/22129042.0.0/ipykernel\\_16294/4186583921.py:20: UserWarning: Glyph 12289 (\\N{IDEOGRAPHIC COMMA}) missing from current font.\n plt.tight\\_layout(pad=0)\n/state/partition1/slurm\\_tmp/22129042.0.0/ipykernel\\_16294/4186583921.py:20: UserWarning: Glyph 12395 (\\N{HIRAGANA LETTER NI}) missing from current font.\n plt.tight\\_layout(pad=0)\n/state/partition1/slurm\\_tmp/22129042.0.0/ipykernel\\_16294/4186583921.py:20: UserWarning: Glyph 12394 (\\N{HIRAGANA LETTER NA}) missing from current font.\n plt.tight\\_layout(pad=0)\n/state/partition1/slurm\\_tmp/22129042.0.0/ipykernel\\_16294/4186583921.py:20: UserWarning: Glyph 65292 (\\N{FULLWIDTH COMMA}) missing from current font.\n plt.tight\\_layout(pad=0)\n/state/partition1/slurm\\_tmp/22129042.0.0/ipykernel\\_16294/4186583921.py:20: UserWarning: Glyph 12398 (\\N{HIRAGANA LETTER NO}) missing from current font.\n plt.tight\\_layout(pad=0)\n/state/partition1/slurm\\_tmp/22129042.0.0/ipykernel\\_16294/4186583921.py:20: UserWarning: Glyph 12356 (\\N{HIRAGANA LETTER I}) missing from current font.\n plt.tight\\_layout(pad=0)\n/state/partition1/slurm\\_tmp/22129042.0.0/ipykernel\\_16294/4186583921.py:20: UserWarning: Glyph 20363 (\\N{CJK UNIFIED IDEOGRAPH-4F8B}) missing from current font.\n plt.tight\\_layout(pad=0)\n/state/partition1/slurm\\_tmp/22129042.0.0/ipykernel\\_16294/4186583921.py:20: UserWarning: Glyph 9 ( ) missing from current font.\n plt.tight\\_layout(pad=0)\n/state/partition1/slurm\\_tmp/22129042.0.0/ipykernel\\_16294/4186583921.py:20: UserWarning: Glyph 151 (\\x97) missing from current font.\n plt.tight\\_layout(pad=0)\n/home/gridsan/dtroitskii/sparprob/lib/python3.8/site-packages/IPython/core/events.py:89: UserWarning: Glyph 12290 (\\N{IDEOGRAPHIC FULL STOP}) missing from current font.\n func(\\*args, \\*\\*kwargs)\n/home/gridsan/dtroitskii/sparprob/lib/python3.8/site-packages/IPython/core/events.py:89: UserWarning: Glyph 12289 (\\N{IDEOGRAPHIC COMMA}) missing from current font.\n func(\\*args, \\*\\*kwargs)\n/home/gridsan/dtroitskii/sparprob/lib/python3.8/site-packages/IPython/core/events.py:89: UserWarning: Glyph 12395 (\\N{HIRAGANA LETTER NI}) missing from current font.\n func(\\*args, \\*\\*kwargs)\n/home/gridsan/dtroitskii/sparprob/lib/python3.8/site-packages/IPython/core/events.py:89: UserWarning: Glyph 12394 (\\N{HIRAGANA LETTER NA}) missing from current font.\n func(\\*args, \\*\\*kwargs)\n/home/gridsan/dtroitskii/sparprob/lib/python3.8/site-packages/IPython/core/events.py:89: UserWarning: Glyph 65292 (\\N{FULLWIDTH COMMA}) missing from current font.\n func(\\*args, \\*\\*kwargs)\n/home/gridsan/dtroitskii/sparprob/lib/python3.8/site-packages/IPython/core/events.py:89: UserWarning: Glyph 12398 (\\N{HIRAGANA LETTER NO}) missing from current font.\n func(\\*args, \\*\\*kwargs)\n/home/gridsan/dtroitskii/sparprob/lib/python3.8/site-packages/IPython/core/events.py:89: UserWarning: Glyph 12356 (\\N{HIRAGANA LETTER I}) missing from current font.\n func(\\*args, \\*\\*kwargs)\n/home/gridsan/dtroitskii/sparprob/lib/python3.8/site-packages/IPython/core/events.py:89: UserWarning: Glyph 20363 (\\N{CJK UNIFIED IDEOGRAPH-4F8B}) missing from current font.\n func(\\*args, \\*\\*kwargs)\n/home/gridsan/dtroitskii/sparprob/lib/python3.8/site-packages/IPython/core/events.py:89: UserWarning: Glyph 9 ( ) missing from current font.\n func(\\*args, \\*\\*kwargs)\n/home/gridsan/dtroitskii/sparprob/lib/python3.8/site-packages/IPython/core/events.py:89: UserWarning: Glyph 151 (\\x97) missing from current font.\n func(\\*args, \\*\\*kwargs)\n/home/gridsan/dtroitskii/sparprob/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 20363 (\\N{CJK UNIFIED IDEOGRAPH-4F8B}) missing from current font.\n fig.canvas.print\\_figure(bytes\\_io, \\*\\*kw)\n/home/gridsan/dtroitskii/sparprob/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 12290 (\\N{IDEOGRAPHIC FULL STOP}) missing from current font.\n fig.canvas.print\\_figure(bytes\\_io, \\*\\*kw)\n/home/gridsan/dtroitskii/sparprob/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 12289 (\\N{IDEOGRAPHIC COMMA}) missing from current font.\n fig.canvas.print\\_figure(bytes\\_io, \\*\\*kw)\n/home/gridsan/dtroitskii/sparprob/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 12395 (\\N{HIRAGANA LETTER NI}) missing from current font.\n fig.canvas.print\\_figure(bytes\\_io, \\*\\*kw)\n/home/gridsan/dtroitskii/sparprob/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 12394 (\\N{HIRAGANA LETTER NA}) missing from current font.\n fig.canvas.print\\_figure(bytes\\_io, \\*\\*kw)\n/home/gridsan/dtroitskii/sparprob/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 65292 (\\N{FULLWIDTH COMMA}) missing from current font.\n fig.canvas.print\\_figure(bytes\\_io, \\*\\*kw)\n/home/gridsan/dtroitskii/sparprob/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 12398 (\\N{HIRAGANA LETTER NO}) missing from current font.\n fig.canvas.print\\_figure(bytes\\_io, \\*\\*kw)\n/home/gridsan/dtroitskii/sparprob/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 12356 (\\N{HIRAGANA LETTER I}) missing from current font.\n fig.canvas.print\\_figure(bytes\\_io, \\*\\*kw)\n/home/gridsan/dtroitskii/sparprob/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 9 ( ) missing from current font.\n fig.canvas.print\\_figure(bytes\\_io, \\*\\*kw)\n/home/gridsan/dtroitskii/sparprob/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 151 (\\x97) missing from current font.\n fig.canvas.print\\_figure(bytes\\_io, \\*\\*kw)\n''' 451 words 6643 char Copy Text Copy HTML Export PDF Text-Speech Plagiarism Checker Search Trend Bulgarian Chinese Czech Danish Dutch English (US) English (UK) Estonian Finnish French German Greek Hungarian Indonesian Italian Japanese Latvian Lithuanian Polish Portuguese Portuguese (BZ) Romanian Russian Slovak Slovenian Spanish Swedish Turkish Ukrainian"]