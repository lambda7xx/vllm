agentA bs:8 and max_token:256 and model:/home/xiaoxiang/data/Llama-3.1-8B
0 vllm/config.py scheduler_config.py __init__ max_num_batched_tokens: None
3 vllm/config.py scheduler_config.py __init__ max_num_batched_tokens: 1024
INFO 11-07 03:48:11 config.py:1061] Chunked prefill is enabled with max_num_batched_tokens=1024.
INFO 11-07 03:48:11 llm_engine.py:238] Initializing an LLM engine (v0.6.3.post2.dev36+g855e0e6f) with config: model='/home/xiaoxiang/data/Llama-3.1-8B', speculative_config=None, tokenizer='/home/xiaoxiang/data/Llama-3.1-8B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/home/xiaoxiang/data/Llama-3.1-8B, num_scheduler_steps=1, chunked_prefill_enabled=True multi_step_stream_outputs=True, enable_prefix_caching=True, use_async_output_proc=True, use_cached_outputs=False, mm_processor_kwargs=None)
INFO 11-07 03:48:13 model_runner.py:1055] Starting to load model /home/xiaoxiang/data/Llama-3.1-8B...
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.53s/it]
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:03<00:03,  1.67s/it]
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:05<00:01,  1.73s/it]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:05<00:00,  1.27s/it]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:05<00:00,  1.42s/it]

INFO 11-07 03:48:19 model_runner.py:1066] Loading model weights took 14.9888 GB
INFO 11-07 03:48:20 worker.py:260] Memory profiling results: total_gpu_memory=79.15GiB initial_memory_usage=15.50GiB peak_torch_memory=16.17GiB memory_usage_post_profile=15.53Gib non_torch_memory=0.54GiB kv_cache_size=54.53GiB gpu_memory_utilization=0.90
INFO 11-07 03:48:20 gpu_executor.py:122] # GPU blocks: 27919, # CPU blocks: 2048
INFO 11-07 03:48:20 gpu_executor.py:126] Maximum concurrency for 131072 tokens per request: 3.41x
INFO 11-07 03:48:23 model_runner.py:1394] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 11-07 03:48:23 model_runner.py:1398] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 11-07 03:48:37 model_runner.py:1522] Graph capturing finished in 14 secs.
start warm up
start warm up
finish warm up
recv data from B:{'agentB': 'ok'}
warm up finished
4 agentA rid:7 is added to engine for prefill+decode and reactA[rid]:0
4 agentA rid:6 is added to engine for prefill+decode and reactA[rid]:0
4 agentA rid:5 is added to engine for prefill+decode and reactA[rid]:0
4 agentA rid:4 is added to engine for prefill+decode and reactA[rid]:0
4 agentA rid:3 is added to engine for prefill+decode and reactA[rid]:0
4 agentA rid:2 is added to engine for prefill+decode and reactA[rid]:0
4 agentA rid:1 is added to engine for prefill+decode and reactA[rid]:0
4 agentA rid:0 is added to engine for prefill+decode and reactA[rid]:0
6 agentA rid:5 is finished and req_type:REQ_TYPE.Prefill_DECODE and reactA[rid]:1 
8 agentA rid:5 is prefill+decode but the application is not done and type(rid):<class 'str'>, set its send_time and reactA[rid]:1 and send_time:1730951319.1602004
6 agentA rid:6 is finished and req_type:REQ_TYPE.Prefill_DECODE and reactA[rid]:1 
8 agentA rid:6 is prefill+decode but the application is not done and type(rid):<class 'str'>, set its send_time and reactA[rid]:1 and send_time:1730951319.1604562
12 agentA send data to B and len(send_data):2
6 agentA rid:3 is finished and req_type:REQ_TYPE.Prefill_DECODE and reactA[rid]:1 
8 agentA rid:3 is prefill+decode but the application is not done and type(rid):<class 'str'>, set its send_time and reactA[rid]:1 and send_time:1730951319.235182
6 agentA rid:4 is finished and req_type:REQ_TYPE.Prefill_DECODE and reactA[rid]:1 
8 agentA rid:4 is prefill+decode but the application is not done and type(rid):<class 'str'>, set its send_time and reactA[rid]:1 and send_time:1730951319.2354028
12 agentA send data to B and len(send_data):2
6 agentA rid:1 is finished and req_type:REQ_TYPE.Prefill_DECODE and reactA[rid]:1 
8 agentA rid:1 is prefill+decode but the application is not done and type(rid):<class 'str'>, set its send_time and reactA[rid]:1 and send_time:1730951319.2857797
12 agentA send data to B and len(send_data):1
0 agentA recv data from B rid:1 and finished:True
1 agentA recv from agent B rid:1 is prefill+decode reactA[rid]:1 and type(rid):<class 'str'> and rid in info:True
1.2 agentA recv from agent B rid:1 is prefill+decode and info[rid].send_time:1730951319.2857797
4 agentA rid:1 is added to engine for prefill+decode and reactA[rid]:1
0 agentA recv data from B rid:5 and finished:True
1 agentA recv from agent B rid:5 is prefill+decode reactA[rid]:1 and type(rid):<class 'str'> and rid in info:True
1.2 agentA recv from agent B rid:5 is prefill+decode and info[rid].send_time:1730951319.1602004
0 agentA recv data from B rid:6 and finished:True
1 agentA recv from agent B rid:6 is prefill+decode reactA[rid]:1 and type(rid):<class 'str'> and rid in info:True
1.2 agentA recv from agent B rid:6 is prefill+decode and info[rid].send_time:1730951319.1604562
4 agentA rid:6 is added to engine for prefill+decode and reactA[rid]:1
4 agentA rid:5 is added to engine for prefill+decode and reactA[rid]:1
6 agentA rid:1 is finished and req_type:REQ_TYPE.Prefill_DECODE and reactA[rid]:2 
7 agentA application rid:1 is finished and num_reqs:1 and reactA[rid]:2
0 agentA recv data from B rid:3 and finished:True
1 agentA recv from agent B rid:3 is prefill+decode reactA[rid]:1 and type(rid):<class 'str'> and rid in info:True
1.2 agentA recv from agent B rid:3 is prefill+decode and info[rid].send_time:1730951319.235182
0 agentA recv data from B rid:4 and finished:True
1 agentA recv from agent B rid:4 is prefill+decode reactA[rid]:1 and type(rid):<class 'str'> and rid in info:True
1.2 agentA recv from agent B rid:4 is prefill+decode and info[rid].send_time:1730951319.2354028
4 agentA rid:4 is added to engine for prefill+decode and reactA[rid]:1
4 agentA rid:3 is added to engine for prefill+decode and reactA[rid]:1
6 agentA rid:6 is finished and req_type:REQ_TYPE.Prefill_DECODE and reactA[rid]:2 
7 agentA application rid:6 is finished and num_reqs:2 and reactA[rid]:2
0 agentA recv data from B rid:1 and finished:True
1 agentA recv from agent B rid:1 is prefill+decode reactA[rid]:2 and type(rid):<class 'str'> and rid in info:True
1.2 agentA recv from agent B rid:1 is prefill+decode and info[rid].send_time:None
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/xiaoxiang/vllm/agent/agent_parallelism/agent1.py", line 363, in <module>
[rank0]:     agentA(args.num_act,reactA, comm_args, args)
[rank0]:   File "/home/xiaoxiang/vllm/agent/agent_parallelism/agent1.py", line 224, in agentA
[rank0]:     info[rid].total_duration += now - info[rid].send_time
[rank0]: TypeError: unsupported operand type(s) for -: 'float' and 'NoneType'
